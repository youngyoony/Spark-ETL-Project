[2024-07-26T00:00:13.830+0000] {processor.py:157} INFO - Started process (PID=79060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:00:13.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:00:13.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:00:13.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:00:13.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:00:13.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:00:13.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:00:13.871+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:00:13.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:00:13.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T00:00:44.443+0000] {processor.py:157} INFO - Started process (PID=79085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:00:44.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:00:44.447+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:00:44.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:00:44.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:00:44.485+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:00:44.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:00:44.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:00:44.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:00:44.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T00:01:14.806+0000] {processor.py:157} INFO - Started process (PID=79110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:01:14.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:01:14.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:01:14.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:01:14.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:01:14.838+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:01:14.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:01:14.847+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:01:14.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:01:14.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:01:45.268+0000] {processor.py:157} INFO - Started process (PID=79135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:01:45.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:01:45.271+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:01:45.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:01:45.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:01:45.296+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:01:45.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:01:45.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:01:45.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:01:45.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:02:15.761+0000] {processor.py:157} INFO - Started process (PID=79160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:02:15.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:02:15.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:02:15.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:02:15.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:02:15.794+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:02:15.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:02:15.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:02:15.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:02:15.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:02:46.272+0000] {processor.py:157} INFO - Started process (PID=79185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:02:46.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:02:46.278+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:02:46.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:02:46.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:02:46.316+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:02:46.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:02:46.327+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:02:46.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:02:46.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T00:03:16.732+0000] {processor.py:157} INFO - Started process (PID=79210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:03:16.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:03:16.736+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:03:16.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:03:16.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:03:16.765+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:03:16.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:03:16.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:03:16.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:03:16.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:03:47.209+0000] {processor.py:157} INFO - Started process (PID=79235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:03:47.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:03:47.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:03:47.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:03:47.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:03:47.242+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:03:47.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:03:47.251+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:03:47.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:03:47.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:04:17.649+0000] {processor.py:157} INFO - Started process (PID=79260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:04:17.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:04:17.654+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:04:17.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:04:17.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:04:17.680+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:04:17.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:04:17.690+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:04:17.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:04:17.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:04:48.029+0000] {processor.py:157} INFO - Started process (PID=79285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:04:48.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:04:48.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:04:48.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:04:48.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:04:48.057+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:04:48.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:04:48.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:04:48.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:04:48.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T00:05:18.526+0000] {processor.py:157} INFO - Started process (PID=79310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:05:18.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:05:18.530+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:05:18.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:05:18.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:05:18.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:05:18.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:05:18.569+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:05:18.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:05:18.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:05:48.897+0000] {processor.py:157} INFO - Started process (PID=79335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:05:48.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:05:48.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:05:48.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:05:48.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:05:48.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:05:48.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:05:48.941+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:05:48.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:05:48.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T00:06:19.397+0000] {processor.py:157} INFO - Started process (PID=79360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:06:19.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:06:19.404+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:06:19.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:06:19.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:06:19.441+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:06:19.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:06:19.451+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:06:19.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:06:19.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T00:06:49.904+0000] {processor.py:157} INFO - Started process (PID=79385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:06:49.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:06:49.908+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:06:49.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:06:49.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:06:49.933+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:06:49.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:06:49.946+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:06:49.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:06:49.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:07:20.436+0000] {processor.py:157} INFO - Started process (PID=79410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:07:20.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:07:20.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:07:20.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:07:20.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:07:20.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:07:20.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:07:20.480+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:07:20.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:07:20.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:07:50.865+0000] {processor.py:157} INFO - Started process (PID=79435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:07:50.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:07:50.867+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:07:50.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:07:50.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:07:50.894+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:07:50.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:07:50.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:07:50.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:07:50.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T00:08:21.319+0000] {processor.py:157} INFO - Started process (PID=79460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:08:21.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:08:21.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:08:21.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:08:21.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:08:21.353+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:08:21.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:08:21.362+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:08:21.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:08:21.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T00:08:51.837+0000] {processor.py:157} INFO - Started process (PID=79485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:08:51.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:08:51.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:08:51.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:08:51.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:08:51.867+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:08:51.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:08:51.877+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:08:51.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:08:51.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:09:22.273+0000] {processor.py:157} INFO - Started process (PID=79510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:09:22.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:09:22.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:09:22.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:09:22.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:09:22.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:09:22.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:09:22.315+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:09:22.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:09:22.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:09:52.753+0000] {processor.py:157} INFO - Started process (PID=79535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:09:52.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:09:52.758+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:09:52.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:09:52.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:09:52.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:09:52.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:09:52.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:09:52.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:09:52.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:10:23.167+0000] {processor.py:157} INFO - Started process (PID=79560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:10:23.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:10:23.170+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:10:23.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:10:23.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:10:23.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:10:23.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:10:23.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:10:23.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:10:23.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T00:10:53.586+0000] {processor.py:157} INFO - Started process (PID=79585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:10:53.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:10:53.590+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:10:53.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:10:53.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:10:53.615+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:10:53.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:10:53.627+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:10:53.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:10:53.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:11:24.045+0000] {processor.py:157} INFO - Started process (PID=79610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:11:24.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:11:24.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:11:24.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:11:24.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:11:24.074+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:11:24.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:11:24.084+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:11:24.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:11:24.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T00:11:54.464+0000] {processor.py:157} INFO - Started process (PID=79635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:11:54.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:11:54.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:11:54.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:11:54.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:11:54.495+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:11:54.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:11:54.504+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:11:54.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:11:54.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:12:24.983+0000] {processor.py:157} INFO - Started process (PID=79660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:12:24.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:12:24.986+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:12:24.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:12:24.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:12:25.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:12:25.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:12:25.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:12:25.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:12:25.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:12:55.360+0000] {processor.py:157} INFO - Started process (PID=79685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:12:55.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:12:55.362+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:12:55.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:12:55.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:12:55.393+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:12:55.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:12:55.404+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:12:55.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:12:55.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:13:25.764+0000] {processor.py:157} INFO - Started process (PID=79710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:13:25.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:13:25.767+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:13:25.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:13:25.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:13:25.794+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:13:25.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:13:25.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:13:25.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:13:25.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:13:56.220+0000] {processor.py:157} INFO - Started process (PID=79735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:13:56.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:13:56.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:13:56.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:13:56.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:13:56.244+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:13:56.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:13:56.252+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:13:56.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:13:56.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-26T00:14:26.649+0000] {processor.py:157} INFO - Started process (PID=79760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:14:26.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:14:26.651+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:14:26.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:14:26.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:14:26.679+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:14:26.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:14:26.692+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:14:26.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:14:26.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:14:57.114+0000] {processor.py:157} INFO - Started process (PID=79785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:14:57.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:14:57.120+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:14:57.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:14:57.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:14:57.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:14:57.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:14:57.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:14:57.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:14:57.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T00:15:27.575+0000] {processor.py:157} INFO - Started process (PID=79810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:15:27.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:15:27.580+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:15:27.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:15:27.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:15:27.610+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:15:27.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:15:27.620+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:15:27.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:15:27.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T00:15:58.033+0000] {processor.py:157} INFO - Started process (PID=79835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:15:58.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:15:58.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:15:58.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:15:58.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:15:58.065+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:15:58.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:15:58.075+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:15:58.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:15:58.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:16:28.427+0000] {processor.py:157} INFO - Started process (PID=79860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:16:28.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:16:28.431+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:16:28.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:16:28.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:16:28.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:16:28.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:16:28.471+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:16:28.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:16:28.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T00:16:58.874+0000] {processor.py:157} INFO - Started process (PID=79885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:16:58.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:16:58.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:16:58.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:16:58.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:16:58.908+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:16:58.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:16:58.917+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:16:58.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:16:58.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:17:29.328+0000] {processor.py:157} INFO - Started process (PID=79910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:17:29.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:17:29.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:17:29.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:17:29.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:17:29.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:17:29.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:17:29.372+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:17:29.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:17:29.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:17:59.804+0000] {processor.py:157} INFO - Started process (PID=79935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:17:59.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:17:59.807+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:17:59.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:17:59.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:17:59.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:17:59.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:17:59.843+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:17:59.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:17:59.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:18:30.186+0000] {processor.py:157} INFO - Started process (PID=79960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:18:30.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:18:30.189+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:18:30.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:18:30.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:18:30.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:18:30.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:18:30.227+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:18:30.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:18:30.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:19:00.584+0000] {processor.py:157} INFO - Started process (PID=79985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:19:00.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:19:00.587+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:19:00.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:19:00.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:19:00.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:19:00.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:19:00.627+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:19:00.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:19:00.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T00:19:31.152+0000] {processor.py:157} INFO - Started process (PID=80010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:19:31.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:19:31.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:19:31.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:19:31.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:19:31.185+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:19:31.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:19:31.194+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:19:31.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:19:31.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T00:20:01.655+0000] {processor.py:157} INFO - Started process (PID=80035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:20:01.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:20:01.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:20:01.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:20:01.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:20:01.691+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:20:01.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:20:01.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:20:01.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:20:01.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T00:20:32.138+0000] {processor.py:157} INFO - Started process (PID=80060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:20:32.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:20:32.143+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:20:32.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:20:32.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:20:32.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:20:32.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:20:32.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:20:32.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:20:32.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T00:21:02.651+0000] {processor.py:157} INFO - Started process (PID=80085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:21:02.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:21:02.653+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:21:02.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:21:02.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:21:02.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:21:02.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:21:02.693+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:21:02.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:21:02.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T00:21:33.106+0000] {processor.py:157} INFO - Started process (PID=80110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:21:33.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:21:33.110+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:21:33.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:21:33.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:21:33.138+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:21:33.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:21:33.150+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:21:33.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:21:33.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:22:03.652+0000] {processor.py:157} INFO - Started process (PID=80135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:22:03.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:22:03.656+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:22:03.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:22:03.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:22:03.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:22:03.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:22:03.695+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:22:03.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:22:03.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:22:34.084+0000] {processor.py:157} INFO - Started process (PID=80160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:22:34.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:22:34.088+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:22:34.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:22:34.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:22:34.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:22:34.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:22:34.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:22:34.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:22:34.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T00:23:04.515+0000] {processor.py:157} INFO - Started process (PID=80185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:23:04.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:23:04.519+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:23:04.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:23:04.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:23:04.544+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:23:04.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:23:04.553+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:23:04.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:23:04.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:23:34.981+0000] {processor.py:157} INFO - Started process (PID=80210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:23:34.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:23:34.983+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:23:34.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:23:34.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:23:35.009+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:23:35.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:23:35.019+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:23:35.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:23:35.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T00:24:05.506+0000] {processor.py:157} INFO - Started process (PID=80235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:24:05.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:24:05.509+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:24:05.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:24:05.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:24:05.536+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:24:05.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:24:05.545+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:24:05.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:24:05.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:24:35.889+0000] {processor.py:157} INFO - Started process (PID=80260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:24:35.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:24:35.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:24:35.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:24:35.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:24:35.912+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:24:35.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:24:35.921+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:24:35.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:24:35.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-26T00:25:06.353+0000] {processor.py:157} INFO - Started process (PID=80285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:25:06.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:25:06.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:25:06.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:25:06.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:25:06.382+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:25:06.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:25:06.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:25:06.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:25:06.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T00:25:36.852+0000] {processor.py:157} INFO - Started process (PID=80310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:25:36.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:25:36.855+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:25:36.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:25:36.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:25:36.885+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:25:36.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:25:36.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:25:36.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:25:36.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:26:07.307+0000] {processor.py:157} INFO - Started process (PID=80335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:26:07.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:26:07.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:26:07.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:26:07.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:26:07.338+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:26:07.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:26:07.348+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:26:07.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:26:07.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:26:37.830+0000] {processor.py:157} INFO - Started process (PID=80360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:26:37.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:26:37.836+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:26:37.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:26:37.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:26:37.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:26:37.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:26:37.884+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:26:37.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:26:37.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T00:27:08.307+0000] {processor.py:157} INFO - Started process (PID=80385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:27:08.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:27:08.311+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:27:08.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:27:08.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:27:08.344+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:27:08.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:27:08.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:27:08.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:27:08.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T00:27:38.809+0000] {processor.py:157} INFO - Started process (PID=80410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:27:38.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:27:38.811+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:27:38.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:27:38.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:27:38.839+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:27:38.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:27:38.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:27:38.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:27:38.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:28:09.227+0000] {processor.py:157} INFO - Started process (PID=80435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:28:09.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:28:09.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:28:09.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:28:09.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:28:09.255+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:28:09.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:28:09.266+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:28:09.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:28:09.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T00:28:39.750+0000] {processor.py:157} INFO - Started process (PID=80460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:28:39.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:28:39.753+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:28:39.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:28:39.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:28:39.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:28:39.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:28:39.794+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:28:39.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:28:39.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:29:10.192+0000] {processor.py:157} INFO - Started process (PID=80485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:29:10.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:29:10.196+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:29:10.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:29:10.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:29:10.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:29:10.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:29:10.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:29:10.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:29:10.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T00:29:40.675+0000] {processor.py:157} INFO - Started process (PID=80510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:29:40.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:29:40.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:29:40.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:29:40.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:29:40.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:29:40.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:29:40.712+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:29:40.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:29:40.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T00:30:11.091+0000] {processor.py:157} INFO - Started process (PID=80908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:30:11.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:30:11.101+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:30:11.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:30:11.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:30:11.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:30:11.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:30:11.174+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:30:11.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:30:11.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T00:30:41.707+0000] {processor.py:157} INFO - Started process (PID=80956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:30:41.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:30:41.711+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:30:41.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:30:41.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:30:41.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:30:41.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:30:41.768+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:30:41.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:30:41.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T00:31:12.152+0000] {processor.py:157} INFO - Started process (PID=80981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:31:12.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:31:12.153+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:31:12.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:31:12.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:31:12.177+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:31:12.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:31:12.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:31:12.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:31:12.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-26T00:31:42.712+0000] {processor.py:157} INFO - Started process (PID=81006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:31:42.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:31:42.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:31:42.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:31:42.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:31:42.765+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:31:42.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:31:42.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:31:42.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:31:42.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T00:32:13.187+0000] {processor.py:157} INFO - Started process (PID=81031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:32:13.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:32:13.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:32:13.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:32:13.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:32:13.242+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:32:13.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:32:13.258+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:32:13.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:32:13.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T00:32:43.681+0000] {processor.py:157} INFO - Started process (PID=81059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:32:43.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:32:43.686+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:32:43.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:32:43.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:32:43.719+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:32:43.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:32:43.731+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:32:43.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:32:43.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T00:33:14.238+0000] {processor.py:157} INFO - Started process (PID=81084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:33:14.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:33:14.242+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:33:14.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:33:14.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:33:14.271+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:33:14.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:33:14.281+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:33:14.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:33:14.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:33:44.761+0000] {processor.py:157} INFO - Started process (PID=81109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:33:44.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:33:44.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:33:44.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:33:44.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:33:44.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:33:44.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:33:44.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:33:44.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:33:44.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T00:34:15.310+0000] {processor.py:157} INFO - Started process (PID=81134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:34:15.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:34:15.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:34:15.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:34:15.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:34:15.341+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:34:15.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:34:15.352+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:34:15.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:34:15.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T00:34:45.704+0000] {processor.py:157} INFO - Started process (PID=81159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:34:45.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:34:45.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:34:45.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:34:45.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:34:45.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:34:45.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:34:45.757+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:34:45.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:34:45.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T00:35:16.261+0000] {processor.py:157} INFO - Started process (PID=81184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:35:16.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:35:16.265+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:35:16.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:35:16.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:35:16.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:35:16.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:35:16.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:35:16.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:35:16.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T00:35:46.699+0000] {processor.py:157} INFO - Started process (PID=81209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:35:46.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:35:46.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:35:46.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:35:46.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:35:46.732+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:35:46.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:35:46.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:35:46.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:35:46.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:36:17.157+0000] {processor.py:157} INFO - Started process (PID=81234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:36:17.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:36:17.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:36:17.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:36:17.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:36:17.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:36:17.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:36:17.210+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:36:17.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:36:17.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T00:51:24.315+0000] {processor.py:157} INFO - Started process (PID=81259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:51:24.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:51:24.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:51:24.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:51:24.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:51:24.394+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:51:24.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:51:24.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:51:24.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:51:24.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T00:51:54.965+0000] {processor.py:157} INFO - Started process (PID=81286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:51:54.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:51:54.973+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:51:54.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:51:54.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:51:55.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:51:55.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:51:55.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:51:55.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:51:55.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T00:52:25.405+0000] {processor.py:157} INFO - Started process (PID=81311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:52:25.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:52:25.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:52:25.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:52:25.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:52:25.436+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:52:25.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:52:25.446+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:52:25.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:52:25.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T00:52:55.911+0000] {processor.py:157} INFO - Started process (PID=81336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:52:55.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:52:55.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:52:55.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:52:55.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:52:55.945+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:52:55.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:52:55.955+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:52:55.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:52:55.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:53:26.338+0000] {processor.py:157} INFO - Started process (PID=81361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:53:26.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:53:26.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:53:26.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:53:26.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:53:26.381+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:53:26.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:53:26.393+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:53:26.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:53:26.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T00:53:56.774+0000] {processor.py:157} INFO - Started process (PID=81386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:53:56.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:53:56.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:53:56.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:53:56.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:53:56.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:53:56.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:53:56.824+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:53:56.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:53:56.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T00:54:27.278+0000] {processor.py:157} INFO - Started process (PID=81411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:54:27.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:54:27.281+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:54:27.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:54:27.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:54:27.315+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:54:27.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:54:27.326+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:54:27.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:54:27.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T00:54:57.654+0000] {processor.py:157} INFO - Started process (PID=81436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:54:57.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:54:57.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:54:57.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:54:57.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:54:57.687+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:54:57.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:54:57.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:54:57.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:54:57.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T00:55:28.179+0000] {processor.py:157} INFO - Started process (PID=81461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:55:28.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:55:28.185+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:55:28.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:55:28.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:55:28.242+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:55:28.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:55:28.255+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:55:28.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:55:28.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T00:55:58.632+0000] {processor.py:157} INFO - Started process (PID=81486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:55:58.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:55:58.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:55:58.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:55:58.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:55:58.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:55:58.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:55:58.674+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:55:58.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:55:58.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T00:56:29.154+0000] {processor.py:157} INFO - Started process (PID=81511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:56:29.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:56:29.157+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:56:29.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:56:29.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:56:29.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:56:29.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:56:29.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:56:29.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:56:29.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T00:56:59.597+0000] {processor.py:157} INFO - Started process (PID=81536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:56:59.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:56:59.601+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:56:59.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:56:59.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:56:59.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:56:59.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:56:59.650+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:56:59.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:56:59.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T00:57:30.106+0000] {processor.py:157} INFO - Started process (PID=81561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:57:30.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:57:30.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:57:30.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:57:30.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:57:30.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:57:30.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:57:30.148+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:57:30.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:57:30.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T00:58:00.555+0000] {processor.py:157} INFO - Started process (PID=81586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:58:00.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:58:00.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:58:00.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:58:00.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:58:00.588+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:58:00.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:58:00.598+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:58:00.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:58:00.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:58:31.014+0000] {processor.py:157} INFO - Started process (PID=81611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:58:31.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:58:31.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:58:31.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:58:31.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:58:31.042+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:58:31.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:58:31.052+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:58:31.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:58:31.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T00:59:01.461+0000] {processor.py:157} INFO - Started process (PID=81636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:59:01.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:59:01.464+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:59:01.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:59:01.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:59:01.491+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:59:01.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:59:01.503+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:59:01.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:59:01.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T00:59:31.837+0000] {processor.py:157} INFO - Started process (PID=81661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:59:31.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T00:59:31.841+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:59:31.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:59:31.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T00:59:31.870+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:59:31.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T00:59:31.881+0000] {logging_mixin.py:151} INFO - [2024-07-26T00:59:31.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-25T01:00:00+00:00, run_after=2024-07-26T01:00:00+00:00
[2024-07-26T00:59:31.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:00:02.311+0000] {processor.py:157} INFO - Started process (PID=81741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:00:02.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:00:02.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:00:02.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:00:02.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:00:02.355+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:00:02.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:00:02.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:00:02.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:00:02.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T01:00:32.790+0000] {processor.py:157} INFO - Started process (PID=82103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:00:32.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:00:32.805+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:00:32.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:00:32.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:00:32.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:00:32.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:00:32.862+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:00:32.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:00:32.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T01:01:03.277+0000] {processor.py:157} INFO - Started process (PID=82128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:01:03.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:01:03.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:01:03.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:01:03.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:01:03.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:01:03.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:01:03.320+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:01:03.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:01:03.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T01:01:33.771+0000] {processor.py:157} INFO - Started process (PID=82153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:01:33.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:01:33.775+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:01:33.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:01:33.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:01:33.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:01:33.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:01:33.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:01:33.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:01:33.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T01:02:04.282+0000] {processor.py:157} INFO - Started process (PID=82178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:02:04.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:02:04.286+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:02:04.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:02:04.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:02:04.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:02:04.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:02:04.331+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:02:04.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:02:04.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T01:02:34.743+0000] {processor.py:157} INFO - Started process (PID=82203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:02:34.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:02:34.750+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:02:34.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:02:34.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:02:34.788+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:02:34.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:02:34.801+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:02:34.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:02:34.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T01:03:05.174+0000] {processor.py:157} INFO - Started process (PID=82228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:03:05.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:03:05.178+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:03:05.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:03:05.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:03:05.209+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:03:05.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:03:05.219+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:03:05.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:03:05.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:03:35.668+0000] {processor.py:157} INFO - Started process (PID=82253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:03:35.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:03:35.671+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:03:35.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:03:35.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:03:35.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:03:35.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:03:35.709+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:03:35.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:03:35.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:04:06.059+0000] {processor.py:157} INFO - Started process (PID=82278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:04:06.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:04:06.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:04:06.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:04:06.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:04:06.092+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:04:06.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:04:06.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:04:06.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:04:06.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T01:04:36.519+0000] {processor.py:157} INFO - Started process (PID=82303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:04:36.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:04:36.522+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:04:36.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:04:36.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:04:36.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:04:36.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:04:36.564+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:04:36.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:04:36.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:05:07.032+0000] {processor.py:157} INFO - Started process (PID=82328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:05:07.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:05:07.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:05:07.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:05:07.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:05:07.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:05:07.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:05:07.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:05:07.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:05:07.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T01:05:37.511+0000] {processor.py:157} INFO - Started process (PID=82353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:05:37.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:05:37.513+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:05:37.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:05:37.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:05:37.544+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:05:37.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:05:37.555+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:05:37.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:05:37.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T01:06:07.956+0000] {processor.py:157} INFO - Started process (PID=82378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:06:07.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:06:07.959+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:06:07.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:06:07.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:06:07.987+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:06:07.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:06:07.996+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:06:07.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:06:08.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T01:06:38.421+0000] {processor.py:157} INFO - Started process (PID=82403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:06:38.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:06:38.425+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:06:38.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:06:38.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:06:38.461+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:06:38.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:06:38.473+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:06:38.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:06:38.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T01:07:08.934+0000] {processor.py:157} INFO - Started process (PID=82428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:07:08.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:07:08.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:07:08.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:07:08.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:07:08.976+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:07:08.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:07:08.987+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:07:08.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:07:08.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T01:07:39.369+0000] {processor.py:157} INFO - Started process (PID=82453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:07:39.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:07:39.372+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:07:39.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:07:39.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:07:39.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:07:39.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:07:39.414+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:07:39.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:07:39.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T01:08:09.802+0000] {processor.py:157} INFO - Started process (PID=82478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:08:09.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:08:09.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:08:09.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:08:09.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:08:09.831+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:08:09.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:08:09.841+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:08:09.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:08:09.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T01:08:40.273+0000] {processor.py:157} INFO - Started process (PID=82503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:08:40.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:08:40.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:08:40.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:08:40.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:08:40.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:08:40.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:08:40.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:08:40.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:08:40.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:09:10.767+0000] {processor.py:157} INFO - Started process (PID=82528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:09:10.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:09:10.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:09:10.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:09:10.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:09:10.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:09:10.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:09:10.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:09:10.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:09:10.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:09:41.228+0000] {processor.py:157} INFO - Started process (PID=82553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:09:41.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:09:41.230+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:09:41.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:09:41.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:09:41.249+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:09:41.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:09:41.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:09:41.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:09:41.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-26T01:10:11.730+0000] {processor.py:157} INFO - Started process (PID=82578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:10:11.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:10:11.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:10:11.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:10:11.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:10:11.762+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:10:11.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:10:11.775+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:10:11.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:10:11.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:10:42.222+0000] {processor.py:157} INFO - Started process (PID=82603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:10:42.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:10:42.233+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:10:42.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:10:42.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:10:42.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:10:42.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:10:42.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:10:42.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:10:42.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T01:11:12.847+0000] {processor.py:157} INFO - Started process (PID=82628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:11:12.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:11:12.851+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:11:12.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:11:12.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:11:12.883+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:11:12.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:11:12.893+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:11:12.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:11:12.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:11:43.374+0000] {processor.py:157} INFO - Started process (PID=82653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:11:43.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:11:43.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:11:43.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:11:43.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:11:43.407+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:11:43.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:11:43.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:11:43.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:11:43.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T01:12:13.800+0000] {processor.py:157} INFO - Started process (PID=82678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:12:13.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:12:13.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:12:13.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:12:13.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:12:13.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:12:13.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:12:13.843+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:12:13.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:12:13.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:12:44.275+0000] {processor.py:157} INFO - Started process (PID=82703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:12:44.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:12:44.282+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:12:44.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:12:44.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:12:44.319+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:12:44.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:12:44.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:12:44.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:12:44.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T01:13:14.728+0000] {processor.py:157} INFO - Started process (PID=82728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:13:14.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:13:14.732+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:13:14.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:13:14.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:13:14.759+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:13:14.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:13:14.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:13:14.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:13:14.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:13:45.232+0000] {processor.py:157} INFO - Started process (PID=82753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:13:45.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:13:45.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:13:45.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:13:45.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:13:45.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:13:45.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:13:45.274+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:13:45.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:13:45.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T01:14:15.680+0000] {processor.py:157} INFO - Started process (PID=82778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:14:15.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:14:15.683+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:14:15.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:14:15.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:14:15.709+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:14:15.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:14:15.719+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:14:15.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:14:15.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T01:14:46.119+0000] {processor.py:157} INFO - Started process (PID=82803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:14:46.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:14:46.121+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:14:46.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:14:46.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:14:46.151+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:14:46.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:14:46.162+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:14:46.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:14:46.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:15:16.546+0000] {processor.py:157} INFO - Started process (PID=82828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:15:16.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:15:16.553+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:15:16.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:15:16.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:15:16.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:15:16.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:15:16.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:15:16.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:15:16.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T01:15:46.980+0000] {processor.py:157} INFO - Started process (PID=82853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:15:46.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:15:46.982+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:15:46.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:15:46.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:15:47.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:15:47.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:15:47.022+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:15:47.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:15:47.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:16:17.426+0000] {processor.py:157} INFO - Started process (PID=82878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:16:17.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:16:17.429+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:16:17.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:16:17.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:16:17.455+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:16:17.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:16:17.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:16:17.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:16:17.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T01:16:47.925+0000] {processor.py:157} INFO - Started process (PID=82903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:16:47.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:16:47.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:16:47.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:16:47.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:16:47.961+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:16:47.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:16:47.971+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:16:47.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:16:47.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T01:17:18.478+0000] {processor.py:157} INFO - Started process (PID=82928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:17:18.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:17:18.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:17:18.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:17:18.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:17:18.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:17:18.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:17:18.551+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:17:18.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:17:18.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T01:17:48.955+0000] {processor.py:157} INFO - Started process (PID=82953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:17:48.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:17:48.958+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:17:48.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:17:48.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:17:48.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:17:48.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:17:48.998+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:17:48.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:17:49.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T01:18:19.423+0000] {processor.py:157} INFO - Started process (PID=82978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:18:19.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:18:19.426+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:18:19.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:18:19.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:18:19.455+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:18:19.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:18:19.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:18:19.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:18:19.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:18:49.890+0000] {processor.py:157} INFO - Started process (PID=83003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:18:49.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:18:49.892+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:18:49.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:18:49.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:18:49.923+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:18:49.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:18:49.933+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:18:49.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:18:49.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:19:20.384+0000] {processor.py:157} INFO - Started process (PID=83028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:19:20.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:19:20.388+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:19:20.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:19:20.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:19:20.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:19:20.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:19:20.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:19:20.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:19:20.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T01:19:50.812+0000] {processor.py:157} INFO - Started process (PID=83053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:19:50.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:19:50.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:19:50.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:19:50.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:19:50.836+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:19:50.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:19:50.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:19:50.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:19:50.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-26T01:20:21.193+0000] {processor.py:157} INFO - Started process (PID=83078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:20:21.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:20:21.197+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:20:21.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:20:21.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:20:21.224+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:20:21.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:20:21.234+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:20:21.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:20:21.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:20:51.618+0000] {processor.py:157} INFO - Started process (PID=83103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:20:51.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:20:51.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:20:51.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:20:51.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:20:51.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:20:51.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:20:51.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:20:51.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:20:51.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:21:22.010+0000] {processor.py:157} INFO - Started process (PID=83128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:21:22.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:21:22.012+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:21:22.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:21:22.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:21:22.039+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:21:22.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:21:22.049+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:21:22.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:21:22.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T01:21:52.537+0000] {processor.py:157} INFO - Started process (PID=83153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:21:52.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:21:52.541+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:21:52.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:21:52.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:21:52.579+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:21:52.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:21:52.594+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:21:52.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:21:52.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T01:22:23.020+0000] {processor.py:157} INFO - Started process (PID=83178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:22:23.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:22:23.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:22:23.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:22:23.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:22:23.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:22:23.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:22:23.061+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:22:23.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:22:23.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:22:53.490+0000] {processor.py:157} INFO - Started process (PID=83203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:22:53.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:22:53.493+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:22:53.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:22:53.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:22:53.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:22:53.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:22:53.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:22:53.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:22:53.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T01:23:23.953+0000] {processor.py:157} INFO - Started process (PID=83228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:23:23.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:23:23.957+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:23:23.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:23:23.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:23:23.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:23:23.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:23:23.997+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:23:23.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:23:24.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:23:54.377+0000] {processor.py:157} INFO - Started process (PID=83253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:23:54.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:23:54.383+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:23:54.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:23:54.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:23:54.411+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:23:54.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:23:54.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:23:54.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:23:54.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T01:24:24.868+0000] {processor.py:157} INFO - Started process (PID=83278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:24:24.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:24:24.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:24:24.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:24:24.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:24:24.902+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:24:24.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:24:24.912+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:24:24.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:24:24.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T01:24:55.269+0000] {processor.py:157} INFO - Started process (PID=83303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:24:55.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:24:55.274+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:24:55.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:24:55.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:24:55.311+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:24:55.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:24:55.326+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:24:55.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:24:55.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T01:25:25.739+0000] {processor.py:157} INFO - Started process (PID=83328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:25:25.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:25:25.743+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:25:25.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:25:25.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:25:25.772+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:25:25.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:25:25.784+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:25:25.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:25:25.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:25:56.222+0000] {processor.py:157} INFO - Started process (PID=83353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:25:56.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:25:56.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:25:56.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:25:56.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:25:56.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:25:56.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:25:56.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:25:56.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:25:56.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:26:26.670+0000] {processor.py:157} INFO - Started process (PID=83378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:26:26.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:26:26.673+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:26:26.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:26:26.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:26:26.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:26:26.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:26:26.713+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:26:26.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:26:26.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:26:57.151+0000] {processor.py:157} INFO - Started process (PID=83403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:26:57.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:26:57.155+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:26:57.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:26:57.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:26:57.180+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:26:57.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:26:57.190+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:26:57.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:26:57.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T01:27:27.568+0000] {processor.py:157} INFO - Started process (PID=83428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:27:27.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:27:27.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:27:27.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:27:27.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:27:27.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:27:27.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:27:27.613+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:27:27.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:27:27.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:27:58.027+0000] {processor.py:157} INFO - Started process (PID=83453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:27:58.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:27:58.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:27:58.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:27:58.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:27:58.069+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:27:58.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:27:58.081+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:27:58.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:27:58.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T01:28:28.484+0000] {processor.py:157} INFO - Started process (PID=83478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:28:28.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:28:28.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:28:28.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:28:28.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:28:28.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:28:28.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:28:28.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:28:28.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:28:28.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T01:28:58.990+0000] {processor.py:157} INFO - Started process (PID=83503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:28:58.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:28:58.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:28:58.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:28:59.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:28:59.019+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:28:59.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:28:59.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:28:59.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:28:59.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T01:29:29.420+0000] {processor.py:157} INFO - Started process (PID=83528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:29:29.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:29:29.423+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:29:29.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:29:29.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:29:29.453+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:29:29.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:29:29.465+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:29:29.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:29:29.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:29:59.919+0000] {processor.py:157} INFO - Started process (PID=83553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:29:59.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:29:59.922+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:29:59.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:29:59.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:29:59.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:29:59.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:29:59.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:29:59.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:29:59.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T01:30:30.331+0000] {processor.py:157} INFO - Started process (PID=83578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:30:30.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:30:30.334+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:30:30.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:30:30.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:30:30.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:30:30.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:30:30.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:30:30.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:30:30.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T01:31:00.729+0000] {processor.py:157} INFO - Started process (PID=83603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:31:00.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:31:00.734+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:31:00.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:31:00.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:31:00.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:31:00.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:31:00.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:31:00.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:31:00.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T01:31:31.203+0000] {processor.py:157} INFO - Started process (PID=83628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:31:31.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:31:31.205+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:31:31.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:31:31.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:31:31.231+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:31:31.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:31:31.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:31:31.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:31:31.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T01:32:01.665+0000] {processor.py:157} INFO - Started process (PID=83653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:32:01.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:32:01.669+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:32:01.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:32:01.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:32:01.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:32:01.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:32:01.720+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:32:01.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:32:01.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T01:32:32.160+0000] {processor.py:157} INFO - Started process (PID=83678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:32:32.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:32:32.163+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:32:32.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:32:32.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:32:32.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:32:32.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:32:32.200+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:32:32.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:32:32.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T01:33:02.620+0000] {processor.py:157} INFO - Started process (PID=83703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:33:02.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:33:02.624+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:33:02.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:33:02.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:33:02.659+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:33:02.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:33:02.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:33:02.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:33:02.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T01:33:33.061+0000] {processor.py:157} INFO - Started process (PID=83728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:33:33.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:33:33.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:33:33.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:33:33.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:33:33.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:33:33.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:33:33.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:33:33.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:33:33.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T01:34:03.605+0000] {processor.py:157} INFO - Started process (PID=83753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:34:03.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:34:03.613+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:34:03.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:34:03.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:34:03.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:34:03.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:34:03.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:34:03.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:34:03.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-26T01:34:34.155+0000] {processor.py:157} INFO - Started process (PID=83778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:34:34.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:34:34.160+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:34:34.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:34:34.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:34:34.188+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:34:34.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:34:34.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:34:34.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:34:34.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:35:04.589+0000] {processor.py:157} INFO - Started process (PID=83803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:35:04.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:35:04.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:35:04.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:35:04.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:35:04.619+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:35:04.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:35:04.639+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:35:04.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:35:04.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T01:35:35.100+0000] {processor.py:157} INFO - Started process (PID=83828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:35:35.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:35:35.104+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:35:35.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:35:35.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:35:35.143+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:35:35.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:35:35.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:35:35.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:35:35.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T01:36:05.605+0000] {processor.py:157} INFO - Started process (PID=83853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:36:05.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:36:05.608+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:36:05.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:36:05.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:36:05.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:36:05.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:36:05.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:36:05.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:36:05.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:36:36.032+0000] {processor.py:157} INFO - Started process (PID=83878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:36:36.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:36:36.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:36:36.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:36:36.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:36:36.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:36:36.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:36:36.079+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:36:36.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:36:36.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T01:37:06.522+0000] {processor.py:157} INFO - Started process (PID=83903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:37:06.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:37:06.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:37:06.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:37:06.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:37:06.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:37:06.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:37:06.580+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:37:06.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:37:06.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T01:37:36.922+0000] {processor.py:157} INFO - Started process (PID=83928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:37:36.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:37:36.925+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:37:36.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:37:36.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:37:36.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:37:36.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:37:36.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:37:36.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:37:36.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T01:38:07.285+0000] {processor.py:157} INFO - Started process (PID=83953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:38:07.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:38:07.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:38:07.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:38:07.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:38:07.314+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:38:07.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:38:07.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:38:07.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:38:07.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T01:38:37.737+0000] {processor.py:157} INFO - Started process (PID=83978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:38:37.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:38:37.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:38:37.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:38:37.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:38:37.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:38:37.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:38:37.780+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:38:37.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:38:37.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:39:08.205+0000] {processor.py:157} INFO - Started process (PID=84003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:39:08.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:39:08.208+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:39:08.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:39:08.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:39:08.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:39:08.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:39:08.248+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:39:08.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:39:08.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:39:38.647+0000] {processor.py:157} INFO - Started process (PID=84028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:39:38.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:39:38.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:39:38.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:39:38.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:39:38.691+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:39:38.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:39:38.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:39:38.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:39:38.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T01:40:09.100+0000] {processor.py:157} INFO - Started process (PID=84053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:40:09.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:40:09.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:40:09.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:40:09.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:40:09.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:40:09.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:40:09.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:40:09.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:40:09.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T01:40:39.549+0000] {processor.py:157} INFO - Started process (PID=84078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:40:39.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:40:39.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:40:39.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:40:39.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:40:39.582+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:40:39.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:40:39.594+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:40:39.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:40:39.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:41:09.975+0000] {processor.py:157} INFO - Started process (PID=84103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:41:09.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:41:09.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:41:09.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:41:09.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:41:10.002+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:41:10.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:41:10.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:41:10.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:41:10.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T01:41:40.469+0000] {processor.py:157} INFO - Started process (PID=84128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:41:40.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:41:40.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:41:40.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:41:40.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:41:40.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:41:40.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:41:40.524+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:41:40.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:41:40.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T01:42:10.939+0000] {processor.py:157} INFO - Started process (PID=84153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:42:10.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:42:10.943+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:42:10.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:42:10.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:42:10.972+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:42:10.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:42:10.986+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:42:10.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:42:10.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T01:42:41.382+0000] {processor.py:157} INFO - Started process (PID=84178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:42:41.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:42:41.386+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:42:41.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:42:41.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:42:41.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:42:41.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:42:41.429+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:42:41.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:42:41.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T01:43:11.806+0000] {processor.py:157} INFO - Started process (PID=84203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:43:11.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:43:11.808+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:43:11.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:43:11.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:43:11.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:43:11.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:43:11.843+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:43:11.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:43:11.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T01:43:42.246+0000] {processor.py:157} INFO - Started process (PID=84228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:43:42.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:43:42.248+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:43:42.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:43:42.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:43:42.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:43:42.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:43:42.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:43:42.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:43:42.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T01:44:12.750+0000] {processor.py:157} INFO - Started process (PID=84253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:44:12.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:44:12.753+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:44:12.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:44:12.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:44:12.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:44:12.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:44:12.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:44:12.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:44:12.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T01:44:43.149+0000] {processor.py:157} INFO - Started process (PID=84278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:44:43.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:44:43.150+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:44:43.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:44:43.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:44:43.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:44:43.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:44:43.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:44:43.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:44:43.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-26T01:45:13.650+0000] {processor.py:157} INFO - Started process (PID=84302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:45:13.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:45:13.657+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:45:13.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:45:13.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:45:13.706+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:45:13.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:45:13.720+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:45:13.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:45:13.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T01:45:44.136+0000] {processor.py:157} INFO - Started process (PID=84328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:45:44.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:45:44.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:45:44.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:45:44.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:45:44.169+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:45:44.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:45:44.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:45:44.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:45:44.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:46:14.562+0000] {processor.py:157} INFO - Started process (PID=84353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:46:14.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:46:14.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:46:14.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:46:14.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:46:14.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:46:14.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:46:14.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:46:14.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:46:14.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T01:46:45.059+0000] {processor.py:157} INFO - Started process (PID=84378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:46:45.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:46:45.065+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:46:45.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:46:45.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:46:45.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:46:45.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:46:45.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:46:45.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:46:45.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T01:47:15.507+0000] {processor.py:157} INFO - Started process (PID=84403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:47:15.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:47:15.510+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:47:15.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:47:15.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:47:15.539+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:47:15.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:47:15.551+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:47:15.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:47:15.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:47:45.966+0000] {processor.py:157} INFO - Started process (PID=84428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:47:45.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:47:45.970+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:47:45.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:47:45.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:47:46.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:47:46.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:47:46.024+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:47:46.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:47:46.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T01:48:16.331+0000] {processor.py:157} INFO - Started process (PID=84453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:48:16.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:48:16.334+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:48:16.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:48:16.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:48:16.360+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:48:16.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:48:16.371+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:48:16.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:48:16.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T01:48:46.786+0000] {processor.py:157} INFO - Started process (PID=84478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:48:46.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:48:46.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:48:46.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:48:46.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:48:46.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:48:46.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:48:46.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:48:46.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:48:46.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T01:49:17.245+0000] {processor.py:157} INFO - Started process (PID=84503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:49:17.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:49:17.250+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:49:17.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:49:17.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:49:17.281+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:49:17.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:49:17.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:49:17.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:49:17.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T01:49:47.724+0000] {processor.py:157} INFO - Started process (PID=84528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:49:47.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:49:47.728+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:49:47.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:49:47.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:49:47.756+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:49:47.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:49:47.765+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:49:47.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:49:47.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T01:50:18.163+0000] {processor.py:157} INFO - Started process (PID=84553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:50:18.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:50:18.168+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:50:18.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:50:18.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:50:18.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:50:18.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:50:18.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:50:18.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:50:18.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T01:50:48.634+0000] {processor.py:157} INFO - Started process (PID=84578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:50:48.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:50:48.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:50:48.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:50:48.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:50:48.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:50:48.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:50:48.689+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:50:48.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:50:48.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T01:51:19.127+0000] {processor.py:157} INFO - Started process (PID=84603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:51:19.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:51:19.130+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:51:19.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:51:19.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:51:19.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:51:19.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:51:19.170+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:51:19.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:51:19.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T01:51:49.540+0000] {processor.py:157} INFO - Started process (PID=84628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:51:49.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:51:49.543+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:51:49.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:51:49.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:51:49.568+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:51:49.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:51:49.578+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:51:49.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:51:49.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T01:52:20.003+0000] {processor.py:157} INFO - Started process (PID=84653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:52:20.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T01:52:20.009+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:52:20.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:52:20.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T01:52:20.059+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:52:20.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T01:52:20.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T01:52:20.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T01:52:20.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T02:08:09.446+0000] {processor.py:157} INFO - Started process (PID=84678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:08:09.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:08:09.450+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:08:09.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:08:09.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:08:09.493+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:08:09.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:08:09.527+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:08:09.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:08:09.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T02:08:39.981+0000] {processor.py:157} INFO - Started process (PID=84703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:08:39.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:08:39.986+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:08:39.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:08:40.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:08:40.039+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:08:40.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:08:40.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:08:40.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:08:40.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T02:25:55.789+0000] {processor.py:157} INFO - Started process (PID=84732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:25:55.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:25:55.798+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:25:55.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:25:55.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:25:55.867+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:25:55.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:25:55.889+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:25:55.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:25:55.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T02:26:26.443+0000] {processor.py:157} INFO - Started process (PID=84757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:26:26.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:26:26.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:26:26.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:26:26.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:26:26.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:26:26.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:26:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:26:26.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:26:26.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T02:26:56.961+0000] {processor.py:157} INFO - Started process (PID=84782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:26:56.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:26:56.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:26:56.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:26:56.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:26:56.993+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:26:56.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:26:57.004+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:26:57.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:26:57.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T02:27:27.435+0000] {processor.py:157} INFO - Started process (PID=84807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:27:27.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:27:27.437+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:27:27.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:27:27.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:27:27.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:27:27.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:27:27.480+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:27:27.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:27:27.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T02:27:57.868+0000] {processor.py:157} INFO - Started process (PID=84832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:27:57.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:27:57.875+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:27:57.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:27:57.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:27:57.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:27:57.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:27:57.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:27:57.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:27:57.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T02:28:28.269+0000] {processor.py:157} INFO - Started process (PID=84857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:28:28.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:28:28.273+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:28:28.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:28:28.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:28:28.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:28:28.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:28:28.319+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:28:28.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:28:28.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T02:28:58.747+0000] {processor.py:157} INFO - Started process (PID=84882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:28:58.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:28:58.753+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:28:58.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:28:58.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:28:58.789+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:28:58.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:28:58.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:28:58.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:28:58.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T02:29:29.184+0000] {processor.py:157} INFO - Started process (PID=84907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:29:29.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:29:29.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:29:29.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:29:29.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:29:29.214+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:29:29.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:29:29.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:29:29.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:29:29.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T02:29:59.552+0000] {processor.py:157} INFO - Started process (PID=84932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:29:59.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:29:59.555+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:29:59.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:29:59.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:29:59.583+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:29:59.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:29:59.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:29:59.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:29:59.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T02:30:29.986+0000] {processor.py:157} INFO - Started process (PID=84957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:30:29.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:30:29.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:30:29.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:30:30.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:30:30.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:30:30.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:30:30.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:30:30.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:30:30.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T02:31:00.438+0000] {processor.py:157} INFO - Started process (PID=84982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:31:00.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:31:00.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:31:00.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:31:00.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:31:00.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:31:00.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:31:00.479+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:31:00.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:31:00.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T02:31:30.936+0000] {processor.py:157} INFO - Started process (PID=85007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:31:30.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:31:30.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:31:30.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:31:30.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:31:30.963+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:31:30.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:31:30.973+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:31:30.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:31:30.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T02:32:01.405+0000] {processor.py:157} INFO - Started process (PID=85032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:32:01.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:32:01.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:32:01.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:32:01.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:32:01.442+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:32:01.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:32:01.452+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:32:01.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:32:01.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T02:32:31.850+0000] {processor.py:157} INFO - Started process (PID=85057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:32:31.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:32:31.856+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:32:31.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:32:31.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:32:31.892+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:32:31.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:32:31.903+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:32:31.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:32:31.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T02:33:02.310+0000] {processor.py:157} INFO - Started process (PID=85082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:33:02.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:33:02.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:33:02.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:33:02.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:33:02.341+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:33:02.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:33:02.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:33:02.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:33:02.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T02:33:32.805+0000] {processor.py:157} INFO - Started process (PID=85107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:33:32.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:33:32.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:33:32.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:33:32.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:33:32.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:33:32.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:33:32.844+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:33:32.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:33:32.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T02:34:03.282+0000] {processor.py:157} INFO - Started process (PID=85132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:34:03.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:34:03.286+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:34:03.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:34:03.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:34:03.314+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:34:03.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:34:03.325+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:34:03.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:34:03.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:34:33.742+0000] {processor.py:157} INFO - Started process (PID=85157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:34:33.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:34:33.750+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:34:33.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:34:33.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:34:33.815+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:34:33.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:34:33.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:34:33.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:34:33.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-26T02:35:04.218+0000] {processor.py:157} INFO - Started process (PID=85182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:35:04.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:35:04.221+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:35:04.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:35:04.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:35:04.250+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:35:04.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:35:04.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:35:04.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:35:04.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:35:34.634+0000] {processor.py:157} INFO - Started process (PID=85207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:35:34.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:35:34.639+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:35:34.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:35:34.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:35:34.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:35:34.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:35:34.691+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:35:34.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:35:34.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T02:36:05.154+0000] {processor.py:157} INFO - Started process (PID=85232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:36:05.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:36:05.160+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:36:05.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:36:05.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:36:05.188+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:36:05.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:36:05.200+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:36:05.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:36:05.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T02:36:35.563+0000] {processor.py:157} INFO - Started process (PID=85257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:36:35.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:36:35.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:36:35.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:36:35.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:36:35.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:36:35.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:36:35.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:36:35.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:36:35.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T02:37:05.984+0000] {processor.py:157} INFO - Started process (PID=85282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:37:05.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:37:05.987+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:37:05.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:37:05.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:37:06.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:37:06.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:37:06.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:37:06.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:37:06.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:37:36.383+0000] {processor.py:157} INFO - Started process (PID=85307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:37:36.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:37:36.385+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:37:36.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:37:36.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:37:36.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:37:36.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:37:36.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:37:36.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:37:36.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T02:38:06.743+0000] {processor.py:157} INFO - Started process (PID=85332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:38:06.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:38:06.746+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:38:06.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:38:06.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:38:06.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:38:06.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:38:06.787+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:38:06.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:38:06.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T02:38:37.260+0000] {processor.py:157} INFO - Started process (PID=85357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:38:37.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:38:37.266+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:38:37.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:38:37.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:38:37.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:38:37.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:38:37.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:38:37.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:38:37.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T02:39:07.732+0000] {processor.py:157} INFO - Started process (PID=85382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:39:07.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:39:07.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:39:07.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:39:07.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:39:07.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:39:07.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:39:07.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:39:07.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:39:07.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T02:39:38.241+0000] {processor.py:157} INFO - Started process (PID=85407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:39:38.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:39:38.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:39:38.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:39:38.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:39:38.270+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:39:38.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:39:38.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:39:38.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:39:38.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T02:40:08.675+0000] {processor.py:157} INFO - Started process (PID=85432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:40:08.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:40:08.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:40:08.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:40:08.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:40:08.700+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:40:08.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:40:08.711+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:40:08.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:40:08.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T02:40:39.123+0000] {processor.py:157} INFO - Started process (PID=85457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:40:39.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:40:39.127+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:40:39.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:40:39.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:40:39.155+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:40:39.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:40:39.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:40:39.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:40:39.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T02:41:09.597+0000] {processor.py:157} INFO - Started process (PID=85482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:41:09.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:41:09.599+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:41:09.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:41:09.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:41:09.634+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:41:09.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:41:09.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:41:09.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:41:09.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T02:41:40.004+0000] {processor.py:157} INFO - Started process (PID=85507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:41:40.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:41:40.007+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:41:40.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:41:40.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:41:40.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:41:40.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:41:40.046+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:41:40.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:41:40.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:42:10.443+0000] {processor.py:157} INFO - Started process (PID=85532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:42:10.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:42:10.448+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:42:10.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:42:10.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:42:10.476+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:42:10.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:42:10.485+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:42:10.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:42:10.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T02:42:40.884+0000] {processor.py:157} INFO - Started process (PID=85557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:42:40.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:42:40.888+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:42:40.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:42:40.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:42:40.926+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:42:40.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:42:40.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:42:40.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:42:40.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T02:43:11.370+0000] {processor.py:157} INFO - Started process (PID=85582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:43:11.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:43:11.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:43:11.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:43:11.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:43:11.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:43:11.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:43:11.413+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:43:11.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:43:11.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:43:41.825+0000] {processor.py:157} INFO - Started process (PID=85607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:43:41.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:43:41.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:43:41.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:43:41.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:43:41.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:43:41.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:43:41.864+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:43:41.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:43:41.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T02:44:12.315+0000] {processor.py:157} INFO - Started process (PID=85632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:44:12.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:44:12.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:44:12.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:44:12.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:44:12.346+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:44:12.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:44:12.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:44:12.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:44:12.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T02:44:42.802+0000] {processor.py:157} INFO - Started process (PID=85657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:44:42.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:44:42.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:44:42.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:44:42.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:44:42.844+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:44:42.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:44:42.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:44:42.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:44:42.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T02:45:13.488+0000] {processor.py:157} INFO - Started process (PID=85682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:45:13.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:45:13.495+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:45:13.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:45:13.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:45:13.553+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:45:13.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:45:13.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:45:13.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:45:13.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T02:45:43.968+0000] {processor.py:157} INFO - Started process (PID=85707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:45:43.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:45:43.971+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:45:43.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:45:43.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:45:43.999+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:45:43.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:45:44.010+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:45:44.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:45:44.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T02:46:14.438+0000] {processor.py:157} INFO - Started process (PID=85732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:46:14.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:46:14.441+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:46:14.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:46:14.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:46:14.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:46:14.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:46:14.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:46:14.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:46:14.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T02:46:44.905+0000] {processor.py:157} INFO - Started process (PID=85757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:46:44.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:46:44.908+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:46:44.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:46:44.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:46:44.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:46:44.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:46:44.950+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:46:44.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:46:44.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:47:15.271+0000] {processor.py:157} INFO - Started process (PID=85782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:47:15.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:47:15.274+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:47:15.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:47:15.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:47:15.301+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:47:15.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:47:15.314+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:47:15.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:47:15.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T02:47:45.694+0000] {processor.py:157} INFO - Started process (PID=85807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:47:45.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:47:45.713+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:47:45.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:47:45.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:47:45.789+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:47:45.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:47:45.807+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:47:45.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:47:45.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-26T02:48:16.273+0000] {processor.py:157} INFO - Started process (PID=85832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:48:16.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:48:16.288+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:48:16.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:48:16.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:48:16.338+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:48:16.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:48:16.358+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:48:16.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:48:16.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T02:48:46.820+0000] {processor.py:157} INFO - Started process (PID=85857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:48:46.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:48:46.823+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:48:46.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:48:46.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:48:46.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:48:46.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:48:46.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:48:46.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:48:46.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T02:49:17.245+0000] {processor.py:157} INFO - Started process (PID=85882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:49:17.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:49:17.248+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:49:17.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:49:17.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:49:17.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:49:17.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:49:17.288+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:49:17.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:49:17.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:49:47.675+0000] {processor.py:157} INFO - Started process (PID=85907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:49:47.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:49:47.683+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:49:47.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:49:47.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:49:47.744+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:49:47.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:49:47.758+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:49:47.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:49:47.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T02:50:18.192+0000] {processor.py:157} INFO - Started process (PID=85932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:50:18.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:50:18.196+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:50:18.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:50:18.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:50:18.295+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:50:18.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:50:18.313+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:50:18.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:50:18.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-26T02:50:48.797+0000] {processor.py:157} INFO - Started process (PID=85957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:50:48.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:50:48.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:50:48.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:50:48.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:50:48.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:50:48.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:50:48.870+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:50:48.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:50:48.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T02:51:19.352+0000] {processor.py:157} INFO - Started process (PID=85982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:51:19.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:51:19.359+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:51:19.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:51:19.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:51:19.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:51:19.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:51:19.423+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:51:19.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:51:19.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T02:51:49.858+0000] {processor.py:157} INFO - Started process (PID=86007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:51:49.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:51:49.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:51:49.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:51:49.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:51:49.913+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:51:49.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:51:49.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:51:49.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:51:49.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T02:52:20.368+0000] {processor.py:157} INFO - Started process (PID=86031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:52:20.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:52:20.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:52:20.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:52:20.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:52:20.426+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:52:20.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:52:20.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:52:20.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:52:20.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T02:52:50.844+0000] {processor.py:157} INFO - Started process (PID=86057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:52:50.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:52:50.848+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:52:50.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:52:50.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:52:50.889+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:52:50.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:52:50.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:52:50.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:52:50.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T02:53:21.316+0000] {processor.py:157} INFO - Started process (PID=86082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:53:21.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:53:21.319+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:53:21.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:53:21.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:53:21.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:53:21.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:53:21.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:53:21.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:53:21.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T02:53:51.748+0000] {processor.py:157} INFO - Started process (PID=86107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:53:51.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:53:51.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:53:51.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:53:51.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:53:51.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:53:51.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:53:51.791+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:53:51.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:53:51.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:54:22.157+0000] {processor.py:157} INFO - Started process (PID=86132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:54:22.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:54:22.162+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:54:22.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:54:22.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:54:22.200+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:54:22.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:54:22.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:54:22.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:54:22.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T02:54:52.586+0000] {processor.py:157} INFO - Started process (PID=86157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:54:52.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:54:52.590+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:54:52.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:54:52.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:54:52.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:54:52.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:54:52.627+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:54:52.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:54:52.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T02:55:23.030+0000] {processor.py:157} INFO - Started process (PID=86182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:55:23.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:55:23.033+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:55:23.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:55:23.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:55:23.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:55:23.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:55:23.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:55:23.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:55:23.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T02:55:53.479+0000] {processor.py:157} INFO - Started process (PID=86207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:55:53.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:55:53.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:55:53.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:55:53.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:55:53.522+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:55:53.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:55:53.534+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:55:53.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:55:53.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T02:56:24.042+0000] {processor.py:157} INFO - Started process (PID=86232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:56:24.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:56:24.050+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:56:24.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:56:24.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:56:24.117+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:56:24.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:56:24.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:56:24.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:56:24.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-26T02:56:54.512+0000] {processor.py:157} INFO - Started process (PID=86257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:56:54.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:56:54.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:56:54.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:56:54.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:56:54.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:56:54.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:56:54.618+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:56:54.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:56:54.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-26T02:57:25.029+0000] {processor.py:157} INFO - Started process (PID=86282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:57:25.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:57:25.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:57:25.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:57:25.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:57:25.064+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:57:25.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:57:25.079+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:57:25.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:57:25.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T02:57:55.453+0000] {processor.py:157} INFO - Started process (PID=86307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:57:55.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:57:55.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:57:55.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:57:55.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:57:55.509+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:57:55.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:57:55.523+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:57:55.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:57:55.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-26T02:58:25.913+0000] {processor.py:157} INFO - Started process (PID=86332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:58:25.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:58:25.918+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:58:25.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:58:25.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:58:25.950+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:58:25.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:58:25.961+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:58:25.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:58:25.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T02:58:56.364+0000] {processor.py:157} INFO - Started process (PID=86357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:58:56.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:58:56.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:58:56.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:58:56.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:58:56.406+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:58:56.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:58:56.419+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:58:56.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:58:56.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T02:59:26.824+0000] {processor.py:157} INFO - Started process (PID=86382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:59:26.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:59:26.829+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:59:26.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:59:26.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:59:26.871+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:59:26.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:59:26.885+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:59:26.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:59:26.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T02:59:57.281+0000] {processor.py:157} INFO - Started process (PID=86407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:59:57.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T02:59:57.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:59:57.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:59:57.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T02:59:57.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:59:57.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T02:59:57.320+0000] {logging_mixin.py:151} INFO - [2024-07-26T02:59:57.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T02:59:57.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T03:00:27.739+0000] {processor.py:157} INFO - Started process (PID=86432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:00:27.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:00:27.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:00:27.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:00:27.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:00:27.778+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:00:27.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:00:27.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:00:27.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:00:27.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T03:00:58.154+0000] {processor.py:157} INFO - Started process (PID=86457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:00:58.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:00:58.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:00:58.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:00:58.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:00:58.182+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:00:58.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:00:58.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:00:58.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:00:58.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T03:01:28.533+0000] {processor.py:157} INFO - Started process (PID=86482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:01:28.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:01:28.536+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:01:28.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:01:28.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:01:28.562+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:01:28.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:01:28.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:01:28.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:01:28.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T03:01:58.917+0000] {processor.py:157} INFO - Started process (PID=86507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:01:58.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:01:58.920+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:01:58.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:01:58.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:01:58.950+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:01:58.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:01:58.962+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:01:58.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:01:58.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:02:29.325+0000] {processor.py:157} INFO - Started process (PID=86532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:02:29.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:02:29.327+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:02:29.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:02:29.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:02:29.355+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:02:29.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:02:29.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:02:29.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:02:29.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T03:02:59.767+0000] {processor.py:157} INFO - Started process (PID=86557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:02:59.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:02:59.774+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:02:59.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:02:59.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:02:59.812+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:02:59.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:02:59.823+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:02:59.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:02:59.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T03:03:30.227+0000] {processor.py:157} INFO - Started process (PID=86582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:03:30.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:03:30.230+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:03:30.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:03:30.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:03:30.261+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:03:30.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:03:30.270+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:03:30.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:03:30.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:04:00.611+0000] {processor.py:157} INFO - Started process (PID=86607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:04:00.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:04:00.613+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:04:00.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:04:00.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:04:00.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:04:00.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:04:00.644+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:04:00.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:04:00.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-26T03:04:31.045+0000] {processor.py:157} INFO - Started process (PID=86632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:04:31.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:04:31.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:04:31.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:04:31.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:04:31.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:04:31.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:04:31.089+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:04:31.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:04:31.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:05:01.488+0000] {processor.py:157} INFO - Started process (PID=86657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:05:01.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:05:01.493+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:05:01.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:05:01.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:05:01.523+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:05:01.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:05:01.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:05:01.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:05:01.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:05:31.934+0000] {processor.py:157} INFO - Started process (PID=86682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:05:31.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:05:31.942+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:05:31.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:05:31.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:05:31.980+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:05:31.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:05:31.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:05:31.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:05:32.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T03:06:02.474+0000] {processor.py:157} INFO - Started process (PID=86707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:06:02.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:06:02.476+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:06:02.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:06:02.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:06:02.505+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:06:02.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:06:02.515+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:06:02.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:06:02.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T03:06:32.855+0000] {processor.py:157} INFO - Started process (PID=86732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:06:32.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:06:32.858+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:06:32.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:06:32.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:06:32.887+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:06:32.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:06:32.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:06:32.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:06:32.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T03:07:03.312+0000] {processor.py:157} INFO - Started process (PID=86757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:07:03.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:07:03.316+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:07:03.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:07:03.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:07:03.341+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:07:03.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:07:03.352+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:07:03.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:07:03.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T03:07:33.748+0000] {processor.py:157} INFO - Started process (PID=86782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:07:33.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:07:33.750+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:07:33.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:07:33.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:07:33.771+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:07:33.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:07:33.779+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:07:33.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:07:33.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-26T03:08:04.297+0000] {processor.py:157} INFO - Started process (PID=86807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:08:04.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:08:04.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:08:04.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:08:04.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:08:04.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:08:04.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:08:04.363+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:08:04.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:08:04.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T03:08:34.805+0000] {processor.py:157} INFO - Started process (PID=86832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:08:34.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:08:34.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:08:34.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:08:34.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:08:34.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:08:34.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:08:34.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:08:34.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:08:34.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:09:05.224+0000] {processor.py:157} INFO - Started process (PID=86857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:09:05.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:09:05.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:09:05.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:09:05.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:09:05.263+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:09:05.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:09:05.273+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:09:05.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:09:05.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T03:09:35.655+0000] {processor.py:157} INFO - Started process (PID=86882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:09:35.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:09:35.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:09:35.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:09:35.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:09:35.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:09:35.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:09:35.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:09:35.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:09:35.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T03:10:06.043+0000] {processor.py:157} INFO - Started process (PID=86907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:10:06.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:10:06.047+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:10:06.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:10:06.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:10:06.075+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:10:06.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:10:06.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:10:06.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:10:06.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T03:10:36.515+0000] {processor.py:157} INFO - Started process (PID=86932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:10:36.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:10:36.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:10:36.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:10:36.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:10:36.547+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:10:36.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:10:36.581+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:10:36.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:10:36.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T03:11:06.979+0000] {processor.py:157} INFO - Started process (PID=86957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:11:06.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:11:06.981+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:11:06.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:11:06.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:11:07.004+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:11:07.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:11:07.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:11:07.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:11:07.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T03:11:37.433+0000] {processor.py:157} INFO - Started process (PID=86982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:11:37.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:11:37.438+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:11:37.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:11:37.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:11:37.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:11:37.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:11:37.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:11:37.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:11:37.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:12:07.908+0000] {processor.py:157} INFO - Started process (PID=87007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:12:07.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:12:07.912+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:12:07.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:12:07.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:12:07.940+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:12:07.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:12:07.952+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:12:07.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:12:07.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T03:12:38.331+0000] {processor.py:157} INFO - Started process (PID=87032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:12:38.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:12:38.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:12:38.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:12:38.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:12:38.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:12:38.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:12:38.385+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:12:38.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:12:38.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T03:13:08.764+0000] {processor.py:157} INFO - Started process (PID=87057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:13:08.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:13:08.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:13:08.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:13:08.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:13:08.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:13:08.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:13:08.812+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:13:08.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:13:08.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T03:13:39.222+0000] {processor.py:157} INFO - Started process (PID=87082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:13:39.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:13:39.227+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:13:39.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:13:39.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:13:39.261+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:13:39.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:13:39.269+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:13:39.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:13:39.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T03:14:09.673+0000] {processor.py:157} INFO - Started process (PID=87107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:14:09.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:14:09.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:14:09.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:14:09.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:14:09.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:14:09.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:14:09.728+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:14:09.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:14:09.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T03:14:40.118+0000] {processor.py:157} INFO - Started process (PID=87132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:14:40.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:14:40.120+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:14:40.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:14:40.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:14:40.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:14:40.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:14:40.150+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:14:40.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:14:40.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-26T03:15:10.594+0000] {processor.py:157} INFO - Started process (PID=87157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:15:10.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:15:10.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:15:10.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:15:10.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:15:10.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:15:10.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:15:10.639+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:15:10.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:15:10.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T03:15:41.044+0000] {processor.py:157} INFO - Started process (PID=87182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:15:41.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:15:41.052+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:15:41.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:15:41.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:15:41.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:15:41.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:15:41.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:15:41.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:15:41.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T03:16:11.561+0000] {processor.py:157} INFO - Started process (PID=87207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:16:11.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:16:11.564+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:16:11.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:16:11.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:16:11.591+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:16:11.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:16:11.601+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:16:11.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:16:11.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T03:16:42.020+0000] {processor.py:157} INFO - Started process (PID=87232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:16:42.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:16:42.024+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:16:42.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:16:42.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:16:42.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:16:42.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:16:42.066+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:16:42.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:16:42.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T03:17:12.403+0000] {processor.py:157} INFO - Started process (PID=87257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:17:12.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:17:12.407+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:17:12.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:17:12.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:17:12.436+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:17:12.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:17:12.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:17:12.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:17:12.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T03:17:42.886+0000] {processor.py:157} INFO - Started process (PID=87282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:17:42.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:17:42.889+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:17:42.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:17:42.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:17:42.919+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:17:42.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:17:42.930+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:17:42.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:17:42.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T03:18:13.328+0000] {processor.py:157} INFO - Started process (PID=87307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:18:13.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:18:13.333+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:18:13.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:18:13.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:18:13.370+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:18:13.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:18:13.384+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:18:13.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:18:13.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T03:18:43.830+0000] {processor.py:157} INFO - Started process (PID=87332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:18:43.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:18:43.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:18:43.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:18:43.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:18:43.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:18:43.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:18:43.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:18:43.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:18:43.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T03:19:14.311+0000] {processor.py:157} INFO - Started process (PID=87357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:19:14.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:19:14.315+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:19:14.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:19:14.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:19:14.342+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:19:14.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:19:14.352+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:19:14.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:19:14.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T03:19:44.691+0000] {processor.py:157} INFO - Started process (PID=87382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:19:44.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:19:44.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:19:44.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:19:44.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:19:44.722+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:19:44.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:19:44.732+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:19:44.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:19:44.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T03:20:15.199+0000] {processor.py:157} INFO - Started process (PID=87407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:20:15.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:20:15.215+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:20:15.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:20:15.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:20:15.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:20:15.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:20:15.292+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:20:15.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:20:15.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T03:20:45.719+0000] {processor.py:157} INFO - Started process (PID=87432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:20:45.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:20:45.722+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:20:45.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:20:45.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:20:45.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:20:45.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:20:45.763+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:20:45.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:20:45.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:21:16.167+0000] {processor.py:157} INFO - Started process (PID=87457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:21:16.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:21:16.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:21:16.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:21:16.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:21:16.196+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:21:16.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:21:16.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:21:16.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:21:16.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T03:21:46.621+0000] {processor.py:157} INFO - Started process (PID=87482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:21:46.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:21:46.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:21:46.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:21:46.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:21:46.647+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:21:46.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:21:46.657+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:21:46.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:21:46.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T03:22:17.042+0000] {processor.py:157} INFO - Started process (PID=87507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:22:17.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:22:17.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:22:17.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:22:17.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:22:17.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:22:17.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:22:17.083+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:22:17.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:22:17.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T03:22:47.469+0000] {processor.py:157} INFO - Started process (PID=87532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:22:47.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:22:47.474+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:22:47.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:22:47.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:22:47.516+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:22:47.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:22:47.527+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:22:47.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:22:47.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T03:23:17.975+0000] {processor.py:157} INFO - Started process (PID=87557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:23:17.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:23:17.981+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:23:17.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:23:18.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:23:18.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:23:18.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:23:18.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:23:18.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:23:18.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T03:23:48.505+0000] {processor.py:157} INFO - Started process (PID=87582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:23:48.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:23:48.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:23:48.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:23:48.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:23:48.561+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:23:48.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:23:48.574+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:23:48.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:23:48.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T03:24:18.967+0000] {processor.py:157} INFO - Started process (PID=87607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:24:18.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:24:18.973+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:24:18.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:24:18.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:24:19.025+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:24:19.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:24:19.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:24:19.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:24:19.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T03:24:49.465+0000] {processor.py:157} INFO - Started process (PID=87632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:24:49.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:24:49.470+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:24:49.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:24:49.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:24:49.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:24:49.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:24:49.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:24:49.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:24:49.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-26T03:25:19.899+0000] {processor.py:157} INFO - Started process (PID=87657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:25:19.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:25:19.902+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:25:19.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:25:19.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:25:19.934+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:25:19.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:25:19.946+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:25:19.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:25:19.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T03:25:50.373+0000] {processor.py:157} INFO - Started process (PID=87682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:25:50.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:25:50.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:25:50.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:25:50.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:25:50.423+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:25:50.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:25:50.444+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:25:50.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:25:50.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T03:26:20.856+0000] {processor.py:157} INFO - Started process (PID=87707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:26:20.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:26:20.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:26:20.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:26:20.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:26:20.896+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:26:20.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:26:20.908+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:26:20.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:26:20.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T03:26:51.273+0000] {processor.py:157} INFO - Started process (PID=87732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:26:51.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:26:51.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:26:51.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:26:51.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:26:51.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:26:51.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:26:51.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:26:51.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:26:51.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T03:27:21.694+0000] {processor.py:157} INFO - Started process (PID=87757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:27:21.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:27:21.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:27:21.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:27:21.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:27:21.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:27:21.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:27:21.737+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:27:21.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:27:21.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T03:27:52.177+0000] {processor.py:157} INFO - Started process (PID=87782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:27:52.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:27:52.184+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:27:52.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:27:52.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:27:52.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:27:52.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:27:52.250+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:27:52.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:27:52.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T03:28:22.673+0000] {processor.py:157} INFO - Started process (PID=87807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:28:22.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:28:22.675+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:28:22.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:28:22.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:28:22.699+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:28:22.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:28:22.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:28:22.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:28:22.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-26T03:28:53.138+0000] {processor.py:157} INFO - Started process (PID=87832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:28:53.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:28:53.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:28:53.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:28:53.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:28:53.171+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:28:53.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:28:53.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:28:53.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:28:53.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T03:29:23.512+0000] {processor.py:157} INFO - Started process (PID=87857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:29:23.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:29:23.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:29:23.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:29:23.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:29:23.555+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:29:23.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:29:23.567+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:29:23.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:29:23.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T03:29:53.870+0000] {processor.py:157} INFO - Started process (PID=87882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:29:53.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:29:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:29:53.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:29:53.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:29:53.902+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:29:53.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:29:53.912+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:29:53.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:29:53.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T03:30:24.337+0000] {processor.py:157} INFO - Started process (PID=87907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:30:24.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:30:24.342+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:30:24.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:30:24.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:30:24.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:30:24.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:30:24.379+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:30:24.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:30:24.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T03:30:54.809+0000] {processor.py:157} INFO - Started process (PID=87931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:30:54.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:30:54.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:30:54.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:30:54.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:30:54.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:30:54.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:30:54.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:30:54.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:30:54.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-26T03:31:25.303+0000] {processor.py:157} INFO - Started process (PID=87957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:31:25.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:31:25.305+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:31:25.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:31:25.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:31:25.331+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:31:25.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:31:25.341+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:31:25.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:31:25.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T03:31:55.801+0000] {processor.py:157} INFO - Started process (PID=87982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:31:55.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:31:55.824+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:31:55.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:31:55.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:31:55.893+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:31:55.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:31:55.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:31:55.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:31:55.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-26T03:32:26.326+0000] {processor.py:157} INFO - Started process (PID=88007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:32:26.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:32:26.330+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:32:26.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:32:26.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:32:26.359+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:32:26.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:32:26.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:32:26.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:32:26.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T03:32:56.802+0000] {processor.py:157} INFO - Started process (PID=88032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:32:56.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:32:56.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:32:56.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:32:56.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:32:56.836+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:32:56.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:32:56.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:32:56.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:32:56.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T03:33:27.223+0000] {processor.py:157} INFO - Started process (PID=88057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:33:27.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:33:27.232+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:33:27.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:33:27.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:33:27.292+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:33:27.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:33:27.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:33:27.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:33:27.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T03:33:57.687+0000] {processor.py:157} INFO - Started process (PID=88082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:33:57.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:33:57.691+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:33:57.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:33:57.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:33:57.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:33:57.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:33:57.732+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:33:57.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:33:57.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T03:34:28.087+0000] {processor.py:157} INFO - Started process (PID=88107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:34:28.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:34:28.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:34:28.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:34:28.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:34:28.125+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:34:28.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:34:28.136+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:34:28.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:34:28.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T03:34:58.547+0000] {processor.py:157} INFO - Started process (PID=88132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:34:58.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:34:58.554+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:34:58.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:34:58.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:34:58.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:34:58.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:34:58.639+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:34:58.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:34:58.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-26T03:35:29.036+0000] {processor.py:157} INFO - Started process (PID=88157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:35:29.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:35:29.042+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:35:29.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:35:29.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:35:29.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:35:29.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:35:29.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:35:29.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:35:29.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T03:35:59.634+0000] {processor.py:157} INFO - Started process (PID=88182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:35:59.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:35:59.642+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:35:59.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:35:59.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:35:59.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:35:59.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:35:59.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:35:59.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:35:59.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-26T03:36:30.158+0000] {processor.py:157} INFO - Started process (PID=88207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:36:30.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:36:30.165+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:36:30.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:36:30.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:36:30.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:36:30.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:36:30.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:36:30.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:36:30.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-26T03:37:00.742+0000] {processor.py:157} INFO - Started process (PID=88232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:37:00.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:37:00.755+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:37:00.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:37:00.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:37:00.830+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:37:00.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:37:00.851+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:37:00.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:37:00.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T03:37:31.311+0000] {processor.py:157} INFO - Started process (PID=88256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:37:31.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:37:31.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:37:31.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:37:31.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:37:31.384+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:37:31.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:37:31.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:37:31.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:37:31.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T03:38:01.956+0000] {processor.py:157} INFO - Started process (PID=88280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:38:01.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:38:01.963+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:38:01.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:38:01.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:38:02.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:38:02.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:38:02.044+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:38:02.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:38:02.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T03:38:32.496+0000] {processor.py:157} INFO - Started process (PID=88307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:38:32.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:38:32.502+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:38:32.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:38:32.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:38:32.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:38:32.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:38:32.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:38:32.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:38:32.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T03:39:03.031+0000] {processor.py:157} INFO - Started process (PID=88332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:39:03.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:39:03.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:39:03.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:39:03.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:39:03.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:39:03.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:39:03.106+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:39:03.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:39:03.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T03:39:33.591+0000] {processor.py:157} INFO - Started process (PID=88357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:39:33.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:39:33.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:39:33.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:39:33.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:39:33.649+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:39:33.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:39:33.670+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:39:33.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:39:33.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T03:40:04.146+0000] {processor.py:157} INFO - Started process (PID=88382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:40:04.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:40:04.157+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:40:04.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:40:04.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:40:04.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:40:04.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:40:04.224+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:40:04.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:40:04.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T03:40:34.636+0000] {processor.py:157} INFO - Started process (PID=88407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:40:34.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:40:34.641+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:40:34.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:40:34.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:40:34.671+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:40:34.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:40:34.683+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:40:34.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:40:34.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T03:41:05.134+0000] {processor.py:157} INFO - Started process (PID=88432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:41:05.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:41:05.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:41:05.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:41:05.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:41:05.188+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:41:05.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:41:05.201+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:41:05.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:41:05.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T03:41:35.618+0000] {processor.py:157} INFO - Started process (PID=88456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:41:35.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:41:35.624+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:41:35.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:41:35.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:41:35.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:41:35.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:41:35.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:41:35.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:41:35.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T03:42:06.148+0000] {processor.py:157} INFO - Started process (PID=88482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:42:06.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:42:06.188+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:42:06.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:42:06.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:42:06.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:42:06.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:42:06.270+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:42:06.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:42:06.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-26T03:42:36.648+0000] {processor.py:157} INFO - Started process (PID=88507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:42:36.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:42:36.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:42:36.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:42:36.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:42:36.690+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:42:36.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:42:36.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:42:36.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:42:36.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T03:43:07.158+0000] {processor.py:157} INFO - Started process (PID=88531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:43:07.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:43:07.166+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:43:07.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:43:07.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:43:07.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:43:07.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:43:07.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:43:07.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:43:07.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T03:43:37.672+0000] {processor.py:157} INFO - Started process (PID=88557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:43:37.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:43:37.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:43:37.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:43:37.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:43:37.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:43:37.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:43:37.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:43:37.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:43:37.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-26T03:44:08.233+0000] {processor.py:157} INFO - Started process (PID=88582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:44:08.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:44:08.237+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:44:08.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:44:08.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:44:08.261+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:44:08.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:44:08.272+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:44:08.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:44:08.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T03:44:38.713+0000] {processor.py:157} INFO - Started process (PID=88606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:44:38.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:44:38.719+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:44:38.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:44:38.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:44:38.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:44:38.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:44:38.789+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:44:38.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:44:38.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T03:45:09.219+0000] {processor.py:157} INFO - Started process (PID=88632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:45:09.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:45:09.221+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:45:09.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:45:09.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:45:09.249+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:45:09.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:45:09.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:45:09.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:45:09.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T03:45:39.594+0000] {processor.py:157} INFO - Started process (PID=88657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:45:39.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:45:39.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:45:39.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:45:39.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:45:39.625+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:45:39.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:45:39.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:45:39.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:45:39.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T03:46:10.071+0000] {processor.py:157} INFO - Started process (PID=88682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:46:10.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:46:10.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:46:10.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:46:10.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:46:10.115+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:46:10.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:46:10.129+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:46:10.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:46:10.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T03:46:40.526+0000] {processor.py:157} INFO - Started process (PID=88707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:46:40.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:46:40.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:46:40.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:46:40.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:46:40.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:46:40.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:46:40.570+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:46:40.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:46:40.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T03:47:10.988+0000] {processor.py:157} INFO - Started process (PID=88732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:47:10.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:47:10.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:47:10.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:47:11.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:47:11.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:47:11.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:47:11.026+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:47:11.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:47:11.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T03:47:41.433+0000] {processor.py:157} INFO - Started process (PID=88757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:47:41.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:47:41.441+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:47:41.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:47:41.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:47:41.459+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:47:41.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:47:41.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:47:41.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:47:41.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-26T03:48:11.912+0000] {processor.py:157} INFO - Started process (PID=88781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:48:11.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:48:11.918+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:48:11.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:48:11.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:48:11.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:48:11.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:48:11.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:48:11.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:48:12.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T03:48:42.372+0000] {processor.py:157} INFO - Started process (PID=88807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:48:42.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:48:42.375+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:48:42.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:48:42.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:48:42.403+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:48:42.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:48:42.415+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:48:42.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:48:42.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T03:49:12.815+0000] {processor.py:157} INFO - Started process (PID=88832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:49:12.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:49:12.828+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:49:12.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:49:12.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:49:12.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:49:12.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:49:12.933+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:49:12.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:49:12.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-26T03:49:43.311+0000] {processor.py:157} INFO - Started process (PID=88857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:49:43.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:49:43.314+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:49:43.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:49:43.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:49:43.345+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:49:43.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:49:43.355+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:49:43.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:49:43.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T03:50:13.763+0000] {processor.py:157} INFO - Started process (PID=88882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:50:13.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:50:13.771+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:50:13.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:50:13.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:50:13.815+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:50:13.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:50:13.829+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:50:13.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:50:13.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T03:50:44.237+0000] {processor.py:157} INFO - Started process (PID=88907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:50:44.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:50:44.241+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:50:44.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:50:44.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:50:44.282+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:50:44.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:50:44.296+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:50:44.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:50:44.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T03:51:14.673+0000] {processor.py:157} INFO - Started process (PID=88932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:51:14.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:51:14.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:51:14.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:51:14.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:51:14.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:51:14.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:51:14.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:51:14.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:51:14.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T03:51:45.127+0000] {processor.py:157} INFO - Started process (PID=88957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:51:45.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:51:45.130+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:51:45.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:51:45.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:51:45.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:51:45.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:51:45.169+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:51:45.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:51:45.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T03:52:15.584+0000] {processor.py:157} INFO - Started process (PID=88982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:52:15.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:52:15.590+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:52:15.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:52:15.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:52:15.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:52:15.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:52:15.673+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:52:15.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:52:15.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T03:52:46.069+0000] {processor.py:157} INFO - Started process (PID=89007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:52:46.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:52:46.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:52:46.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:52:46.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:52:46.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:52:46.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:52:46.145+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:52:46.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:52:46.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T03:53:16.460+0000] {processor.py:157} INFO - Started process (PID=89032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:53:16.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:53:16.465+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:53:16.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:53:16.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:53:16.495+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:53:16.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:53:16.506+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:53:16.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:53:16.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T03:53:46.898+0000] {processor.py:157} INFO - Started process (PID=89057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:53:46.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:53:46.904+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:53:46.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:53:46.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:53:46.968+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:53:46.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:53:46.985+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:53:46.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:53:46.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T03:54:17.355+0000] {processor.py:157} INFO - Started process (PID=89082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:54:17.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:54:17.358+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:54:17.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:54:17.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:54:17.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:54:17.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:54:17.404+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:54:17.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:54:17.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T03:54:47.775+0000] {processor.py:157} INFO - Started process (PID=89107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:54:47.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:54:47.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:54:47.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:54:47.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:54:47.828+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:54:47.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:54:47.842+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:54:47.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:54:47.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T03:55:18.314+0000] {processor.py:157} INFO - Started process (PID=89132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:55:18.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:55:18.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:55:18.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:55:18.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:55:18.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:55:18.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:55:18.381+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:55:18.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:55:18.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T03:55:48.746+0000] {processor.py:157} INFO - Started process (PID=89157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:55:48.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:55:48.753+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:55:48.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:55:48.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:55:48.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:55:48.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:55:48.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:55:48.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:55:48.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T03:56:19.287+0000] {processor.py:157} INFO - Started process (PID=89182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:56:19.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:56:19.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:56:19.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:56:19.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:56:19.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:56:19.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:56:19.353+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:56:19.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:56:19.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T03:56:49.740+0000] {processor.py:157} INFO - Started process (PID=89207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:56:49.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:56:49.747+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:56:49.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:56:49.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:56:49.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:56:49.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:56:49.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:56:49.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:56:49.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T03:57:20.326+0000] {processor.py:157} INFO - Started process (PID=89232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:57:20.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:57:20.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:57:20.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:57:20.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:57:20.407+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:57:20.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:57:20.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:57:20.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:57:20.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-26T03:57:50.824+0000] {processor.py:157} INFO - Started process (PID=89257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:57:50.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:57:50.831+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:57:50.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:57:50.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:57:50.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:57:50.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:57:50.927+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:57:50.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:57:50.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T03:58:21.411+0000] {processor.py:157} INFO - Started process (PID=89282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:58:21.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:58:21.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:58:21.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:58:21.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:58:21.478+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:58:21.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:58:21.494+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:58:21.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:58:21.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T03:58:51.868+0000] {processor.py:157} INFO - Started process (PID=89307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:58:51.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:58:51.875+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:58:51.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:58:51.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:58:51.921+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:58:51.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:58:51.939+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:58:51.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:58:51.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T03:59:22.441+0000] {processor.py:157} INFO - Started process (PID=89332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:59:22.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:59:22.460+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:59:22.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:59:22.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:59:22.521+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:59:22.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:59:22.550+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:59:22.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:59:22.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-26T03:59:52.980+0000] {processor.py:157} INFO - Started process (PID=89357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:59:52.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T03:59:52.986+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:59:52.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:59:53.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T03:59:53.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:59:53.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T03:59:53.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T03:59:53.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T03:59:53.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T04:00:23.512+0000] {processor.py:157} INFO - Started process (PID=89382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:00:23.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:00:23.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:00:23.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:00:23.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:00:23.562+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:00:23.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:00:23.574+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:00:23.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:00:23.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T04:00:53.968+0000] {processor.py:157} INFO - Started process (PID=89405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:00:53.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:00:53.974+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:00:53.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:00:53.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:00:54.034+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:00:54.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:00:54.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:00:54.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:00:54.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T04:01:24.415+0000] {processor.py:157} INFO - Started process (PID=89432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:01:24.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:01:24.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:01:24.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:01:24.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:01:24.437+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:01:24.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:01:24.445+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:01:24.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:01:24.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-26T04:01:54.872+0000] {processor.py:157} INFO - Started process (PID=89457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:01:54.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:01:54.877+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:01:54.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:01:54.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:01:54.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:01:54.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:01:54.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:01:54.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:01:54.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:02:25.275+0000] {processor.py:157} INFO - Started process (PID=89482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:02:25.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:02:25.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:02:25.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:02:25.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:02:25.313+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:02:25.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:02:25.325+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:02:25.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:02:25.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T04:02:55.693+0000] {processor.py:157} INFO - Started process (PID=89507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:02:55.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:02:55.700+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:02:55.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:02:55.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:02:55.760+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:02:55.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:02:55.774+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:02:55.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:02:55.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T04:03:26.187+0000] {processor.py:157} INFO - Started process (PID=89531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:03:26.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:03:26.196+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:03:26.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:03:26.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:03:26.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:03:26.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:03:26.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:03:26.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:03:26.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-26T04:03:56.674+0000] {processor.py:157} INFO - Started process (PID=89557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:03:56.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:03:56.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:03:56.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:03:56.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:03:56.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:03:56.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:03:56.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:03:56.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:03:56.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T04:04:27.094+0000] {processor.py:157} INFO - Started process (PID=89582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:04:27.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:04:27.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:04:27.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:04:27.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:04:27.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:04:27.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:04:27.138+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:04:27.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:04:27.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:04:57.492+0000] {processor.py:157} INFO - Started process (PID=89607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:04:57.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:04:57.496+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:04:57.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:04:57.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:04:57.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:04:57.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:04:57.540+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:04:57.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:04:57.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T04:05:27.938+0000] {processor.py:157} INFO - Started process (PID=89631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:05:27.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:05:27.942+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:05:27.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:05:27.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:05:27.976+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:05:27.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:05:27.999+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:05:27.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:05:28.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T04:05:58.428+0000] {processor.py:157} INFO - Started process (PID=89656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:05:58.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:05:58.462+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:05:58.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:05:58.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:05:58.534+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:05:58.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:05:58.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:05:58.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:05:58.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-26T04:06:29.049+0000] {processor.py:157} INFO - Started process (PID=89681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:06:29.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:06:29.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:06:29.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:06:29.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:06:29.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:06:29.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:06:29.120+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:06:29.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:06:29.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T04:06:59.584+0000] {processor.py:157} INFO - Started process (PID=89706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:06:59.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:06:59.593+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:06:59.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:06:59.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:06:59.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:06:59.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:06:59.649+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:06:59.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:06:59.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T04:07:30.095+0000] {processor.py:157} INFO - Started process (PID=89732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:07:30.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:07:30.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:07:30.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:07:30.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:07:30.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:07:30.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:07:30.150+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:07:30.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:07:30.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T04:08:00.570+0000] {processor.py:157} INFO - Started process (PID=89757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:08:00.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:08:00.574+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:08:00.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:08:00.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:08:00.601+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:08:00.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:08:00.611+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:08:00.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:08:00.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:08:31.013+0000] {processor.py:157} INFO - Started process (PID=89782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:08:31.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:08:31.019+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:08:31.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:08:31.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:08:31.063+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:08:31.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:08:31.078+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:08:31.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:08:31.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T04:09:01.494+0000] {processor.py:157} INFO - Started process (PID=89807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:09:01.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:09:01.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:09:01.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:09:01.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:09:01.525+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:09:01.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:09:01.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:09:01.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:09:01.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:09:31.916+0000] {processor.py:157} INFO - Started process (PID=89832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:09:31.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:09:31.918+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:09:31.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:09:31.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:09:31.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:09:31.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:09:31.957+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:09:31.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:09:31.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:10:02.343+0000] {processor.py:157} INFO - Started process (PID=89857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:10:02.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:10:02.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:10:02.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:10:02.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:10:02.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:10:02.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:10:02.383+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:10:02.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:10:02.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:10:32.790+0000] {processor.py:157} INFO - Started process (PID=89882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:10:32.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:10:32.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:10:32.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:10:32.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:10:32.823+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:10:32.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:10:32.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:10:32.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:10:32.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:11:03.204+0000] {processor.py:157} INFO - Started process (PID=89907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:11:03.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:11:03.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:11:03.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:11:03.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:11:03.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:11:03.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:11:03.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:11:03.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:11:03.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-26T04:11:33.693+0000] {processor.py:157} INFO - Started process (PID=89932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:11:33.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:11:33.695+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:11:33.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:11:33.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:11:33.724+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:11:33.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:11:33.736+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:11:33.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:11:33.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:12:04.166+0000] {processor.py:157} INFO - Started process (PID=89957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:12:04.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:12:04.170+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:12:04.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:12:04.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:12:04.197+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:12:04.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:12:04.206+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:12:04.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:12:04.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:12:34.601+0000] {processor.py:157} INFO - Started process (PID=89982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:12:34.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:12:34.604+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:12:34.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:12:34.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:12:34.629+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:12:34.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:12:34.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:12:34.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:12:34.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T04:13:05.036+0000] {processor.py:157} INFO - Started process (PID=90007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:13:05.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:13:05.039+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:13:05.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:13:05.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:13:05.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:13:05.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:13:05.092+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:13:05.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:13:05.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T04:13:35.493+0000] {processor.py:157} INFO - Started process (PID=90032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:13:35.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:13:35.498+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:13:35.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:13:35.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:13:35.524+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:13:35.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:13:35.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:13:35.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:13:35.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:14:05.950+0000] {processor.py:157} INFO - Started process (PID=90057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:14:05.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:14:05.955+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:14:05.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:14:05.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:14:05.983+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:14:05.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:14:05.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:14:05.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:14:06.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:14:36.367+0000] {processor.py:157} INFO - Started process (PID=90082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:14:36.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:14:36.370+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:14:36.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:14:36.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:14:36.394+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:14:36.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:14:36.403+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:14:36.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:14:36.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T04:15:06.829+0000] {processor.py:157} INFO - Started process (PID=90107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:15:06.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:15:06.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:15:06.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:15:06.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:15:06.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:15:06.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:15:06.868+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:15:06.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:15:06.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T04:15:37.308+0000] {processor.py:157} INFO - Started process (PID=90132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:15:37.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:15:37.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:15:37.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:15:37.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:15:37.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:15:37.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:15:37.352+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:15:37.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:15:37.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:16:07.781+0000] {processor.py:157} INFO - Started process (PID=90157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:16:07.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:16:07.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:16:07.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:16:07.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:16:07.813+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:16:07.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:16:07.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:16:07.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:16:07.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:16:38.252+0000] {processor.py:157} INFO - Started process (PID=90182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:16:38.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:16:38.256+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:16:38.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:16:38.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:16:38.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:16:38.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:16:38.305+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:16:38.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:16:38.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T04:17:08.699+0000] {processor.py:157} INFO - Started process (PID=90207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:17:08.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:17:08.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:17:08.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:17:08.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:17:08.730+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:17:08.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:17:08.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:17:08.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:17:08.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:17:39.187+0000] {processor.py:157} INFO - Started process (PID=90232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:17:39.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:17:39.190+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:17:39.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:17:39.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:17:39.217+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:17:39.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:17:39.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:17:39.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:17:39.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:18:09.590+0000] {processor.py:157} INFO - Started process (PID=90257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:18:09.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:18:09.594+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:18:09.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:18:09.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:18:09.618+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:18:09.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:18:09.627+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:18:09.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:18:09.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T04:18:40.029+0000] {processor.py:157} INFO - Started process (PID=90282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:18:40.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:18:40.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:18:40.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:18:40.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:18:40.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:18:40.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:18:40.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:18:40.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:18:40.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:19:10.517+0000] {processor.py:157} INFO - Started process (PID=90307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:19:10.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:19:10.519+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:19:10.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:19:10.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:19:10.549+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:19:10.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:19:10.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:19:10.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:19:10.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:19:40.975+0000] {processor.py:157} INFO - Started process (PID=90332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:19:40.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:19:40.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:19:40.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:19:40.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:19:41.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:19:41.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:19:41.014+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:19:41.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:19:41.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T04:20:11.445+0000] {processor.py:157} INFO - Started process (PID=90357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:20:11.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:20:11.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:20:11.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:20:11.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:20:11.489+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:20:11.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:20:11.504+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:20:11.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:20:11.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T04:20:41.870+0000] {processor.py:157} INFO - Started process (PID=90382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:20:41.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:20:41.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:20:41.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:20:41.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:20:41.902+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:20:41.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:20:41.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:20:41.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:20:41.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:21:12.393+0000] {processor.py:157} INFO - Started process (PID=90407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:21:12.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:21:12.398+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:21:12.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:21:12.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:21:12.423+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:21:12.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:21:12.433+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:21:12.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:21:12.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T04:21:42.820+0000] {processor.py:157} INFO - Started process (PID=90432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:21:42.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:21:42.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:21:42.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:21:42.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:21:42.843+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:21:42.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:21:42.855+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:21:42.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:21:42.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T04:22:13.230+0000] {processor.py:157} INFO - Started process (PID=90457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:22:13.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:22:13.233+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:22:13.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:22:13.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:22:13.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:22:13.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:22:13.269+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:22:13.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:22:13.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T04:22:43.712+0000] {processor.py:157} INFO - Started process (PID=90482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:22:43.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:22:43.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:22:43.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:22:43.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:22:43.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:22:43.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:22:43.755+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:22:43.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:22:43.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:23:14.130+0000] {processor.py:157} INFO - Started process (PID=90506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:23:14.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:23:14.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:23:14.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:23:14.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:23:14.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:23:14.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:23:14.192+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:23:14.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:23:14.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T04:23:44.592+0000] {processor.py:157} INFO - Started process (PID=90532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:23:44.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:23:44.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:23:44.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:23:44.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:23:44.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:23:44.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:23:44.633+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:23:44.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:23:44.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T04:24:15.024+0000] {processor.py:157} INFO - Started process (PID=90557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:24:15.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:24:15.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:24:15.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:24:15.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:24:15.056+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:24:15.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:24:15.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:24:15.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:24:15.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:24:45.523+0000] {processor.py:157} INFO - Started process (PID=90582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:24:45.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:24:45.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:24:45.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:24:45.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:24:45.557+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:24:45.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:24:45.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:24:45.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:24:45.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:25:15.981+0000] {processor.py:157} INFO - Started process (PID=90607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:25:15.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:25:15.984+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:25:15.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:25:15.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:25:16.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:25:16.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:25:16.021+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:25:16.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:25:16.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T04:25:46.415+0000] {processor.py:157} INFO - Started process (PID=90632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:25:46.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:25:46.418+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:25:46.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:25:46.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:25:46.444+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:25:46.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:25:46.454+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:25:46.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:25:46.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T04:26:16.856+0000] {processor.py:157} INFO - Started process (PID=90657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:26:16.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:26:16.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:26:16.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:26:16.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:26:16.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:26:16.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:26:16.899+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:26:16.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:26:16.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:26:47.190+0000] {processor.py:157} INFO - Started process (PID=90682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:26:47.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:26:47.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:26:47.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:26:47.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:26:47.223+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:26:47.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:26:47.232+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:26:47.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:26:47.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:27:17.653+0000] {processor.py:157} INFO - Started process (PID=90707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:27:17.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:27:17.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:27:17.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:27:17.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:27:17.693+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:27:17.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:27:17.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:27:17.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:27:17.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T04:27:48.113+0000] {processor.py:157} INFO - Started process (PID=90732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:27:48.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:27:48.117+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:27:48.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:27:48.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:27:48.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:27:48.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:27:48.162+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:27:48.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:27:48.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T04:28:18.548+0000] {processor.py:157} INFO - Started process (PID=90757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:28:18.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:28:18.551+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:28:18.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:28:18.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:28:18.581+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:28:18.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:28:18.590+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:28:18.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:28:18.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:28:49.034+0000] {processor.py:157} INFO - Started process (PID=90782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:28:49.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:28:49.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:28:49.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:28:49.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:28:49.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:28:49.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:28:49.081+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:28:49.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:28:49.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T04:29:19.442+0000] {processor.py:157} INFO - Started process (PID=90807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:29:19.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:29:19.446+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:29:19.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:29:19.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:29:19.479+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:29:19.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:29:19.491+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:29:19.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:29:19.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T04:29:49.857+0000] {processor.py:157} INFO - Started process (PID=90832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:29:49.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:29:49.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:29:49.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:29:49.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:29:49.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:29:49.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:29:49.895+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:29:49.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:29:49.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T04:30:20.298+0000] {processor.py:157} INFO - Started process (PID=90857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:30:20.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:30:20.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:30:20.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:30:20.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:30:20.328+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:30:20.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:30:20.339+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:30:20.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:30:20.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:30:50.754+0000] {processor.py:157} INFO - Started process (PID=90882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:30:50.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:30:50.757+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:30:50.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:30:50.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:30:50.789+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:30:50.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:30:50.798+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:30:50.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:30:50.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T04:31:21.257+0000] {processor.py:157} INFO - Started process (PID=90907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:31:21.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:31:21.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:31:21.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:31:21.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:31:21.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:31:21.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:31:21.298+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:31:21.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:31:21.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:31:51.759+0000] {processor.py:157} INFO - Started process (PID=90932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:31:51.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:31:51.766+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:31:51.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:31:51.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:31:51.805+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:31:51.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:31:51.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:31:51.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:31:51.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T04:32:22.173+0000] {processor.py:157} INFO - Started process (PID=90957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:32:22.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:32:22.176+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:32:22.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:32:22.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:32:22.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:32:22.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:32:22.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:32:22.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:32:22.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:32:52.602+0000] {processor.py:157} INFO - Started process (PID=90982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:32:52.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:32:52.605+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:32:52.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:32:52.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:32:52.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:32:52.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:32:52.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:32:52.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:32:52.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:33:23.097+0000] {processor.py:157} INFO - Started process (PID=91007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:33:23.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:33:23.101+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:33:23.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:33:23.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:33:23.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:33:23.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:33:23.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:33:23.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:33:23.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T04:33:53.514+0000] {processor.py:157} INFO - Started process (PID=91032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:33:53.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:33:53.522+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:33:53.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:33:53.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:33:53.545+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:33:53.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:33:53.554+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:33:53.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:33:53.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:34:23.967+0000] {processor.py:157} INFO - Started process (PID=91057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:34:23.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:34:23.972+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:34:23.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:34:23.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:34:23.998+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:34:23.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:34:24.010+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:34:24.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:34:24.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:34:54.403+0000] {processor.py:157} INFO - Started process (PID=91082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:34:54.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:34:54.406+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:34:54.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:34:54.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:34:54.432+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:34:54.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:34:54.442+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:34:54.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:34:54.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T04:35:24.851+0000] {processor.py:157} INFO - Started process (PID=91107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:35:24.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:35:24.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:35:24.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:35:24.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:35:24.882+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:35:24.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:35:24.892+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:35:24.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:35:24.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:35:55.326+0000] {processor.py:157} INFO - Started process (PID=91132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:35:55.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:35:55.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:35:55.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:35:55.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:35:55.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:35:55.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:35:55.387+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:35:55.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:35:55.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T04:36:25.786+0000] {processor.py:157} INFO - Started process (PID=91157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:36:25.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:36:25.788+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:36:25.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:36:25.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:36:25.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:36:25.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:36:25.824+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:36:25.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:36:25.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T04:36:56.270+0000] {processor.py:157} INFO - Started process (PID=91182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:36:56.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:36:56.273+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:36:56.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:36:56.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:36:56.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:36:56.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:36:56.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:36:56.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:36:56.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T04:37:26.686+0000] {processor.py:157} INFO - Started process (PID=91207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:37:26.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:37:26.688+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:37:26.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:37:26.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:37:26.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:37:26.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:37:26.724+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:37:26.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:37:26.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T04:37:57.158+0000] {processor.py:157} INFO - Started process (PID=91232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:37:57.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:37:57.160+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:37:57.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:37:57.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:37:57.189+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:37:57.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:37:57.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:37:57.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:37:57.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:38:27.673+0000] {processor.py:157} INFO - Started process (PID=91257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:38:27.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:38:27.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:38:27.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:38:27.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:38:27.713+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:38:27.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:38:27.724+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:38:27.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:38:27.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T04:38:58.148+0000] {processor.py:157} INFO - Started process (PID=91282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:38:58.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:38:58.152+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:38:58.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:38:58.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:38:58.182+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:38:58.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:38:58.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:38:58.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:38:58.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T04:39:28.542+0000] {processor.py:157} INFO - Started process (PID=91307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:39:28.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:39:28.544+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:39:28.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:39:28.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:39:28.570+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:39:28.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:39:28.580+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:39:28.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:39:28.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T04:39:58.965+0000] {processor.py:157} INFO - Started process (PID=91332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:39:58.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:39:58.969+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:39:58.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:39:58.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:39:58.996+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:39:58.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:39:59.006+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:39:59.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:39:59.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:40:29.473+0000] {processor.py:157} INFO - Started process (PID=91357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:40:29.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:40:29.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:40:29.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:40:29.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:40:29.502+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:40:29.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:40:29.512+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:40:29.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:40:29.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:40:59.955+0000] {processor.py:157} INFO - Started process (PID=91382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:40:59.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:40:59.960+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:40:59.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:40:59.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:40:59.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:40:59.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:41:00.000+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:41:00.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:41:00.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T04:41:30.434+0000] {processor.py:157} INFO - Started process (PID=91407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:41:30.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:41:30.438+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:41:30.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:41:30.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:41:30.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:41:30.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:41:30.490+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:41:30.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:41:30.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T04:42:00.878+0000] {processor.py:157} INFO - Started process (PID=91432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:42:00.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:42:00.882+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:42:00.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:42:00.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:42:00.906+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:42:00.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:42:00.916+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:42:00.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:42:00.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T04:42:31.314+0000] {processor.py:157} INFO - Started process (PID=91457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:42:31.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:42:31.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:42:31.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:42:31.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:42:31.346+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:42:31.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:42:31.356+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:42:31.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:42:31.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:43:01.802+0000] {processor.py:157} INFO - Started process (PID=91482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:43:01.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:43:01.805+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:43:01.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:43:01.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:43:01.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:43:01.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:43:01.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:43:01.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:43:01.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T04:43:32.278+0000] {processor.py:157} INFO - Started process (PID=91507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:43:32.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:43:32.282+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:43:32.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:43:32.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:43:32.330+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:43:32.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:43:32.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:43:32.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:43:32.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T04:44:02.760+0000] {processor.py:157} INFO - Started process (PID=91532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:44:02.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:44:02.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:44:02.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:44:02.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:44:02.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:44:02.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:44:02.812+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:44:02.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:44:02.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T04:44:33.235+0000] {processor.py:157} INFO - Started process (PID=91557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:44:33.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:44:33.237+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:44:33.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:44:33.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:44:33.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:44:33.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:44:33.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:44:33.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:44:33.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:45:03.647+0000] {processor.py:157} INFO - Started process (PID=91582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:45:03.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:45:03.650+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:45:03.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:45:03.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:45:03.683+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:45:03.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:45:03.695+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:45:03.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:45:03.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T04:45:34.077+0000] {processor.py:157} INFO - Started process (PID=91607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:45:34.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:45:34.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:45:34.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:45:34.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:45:34.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:45:34.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:45:34.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:45:34.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:45:34.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:46:04.569+0000] {processor.py:157} INFO - Started process (PID=91632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:46:04.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:46:04.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:46:04.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:46:04.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:46:04.599+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:46:04.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:46:04.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:46:04.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:46:04.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T04:46:35.029+0000] {processor.py:157} INFO - Started process (PID=91657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:46:35.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:46:35.033+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:46:35.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:46:35.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:46:35.064+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:46:35.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:46:35.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:46:35.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:46:35.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:47:05.508+0000] {processor.py:157} INFO - Started process (PID=91682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:47:05.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:47:05.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:47:05.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:47:05.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:47:05.536+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:47:05.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:47:05.549+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:47:05.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:47:05.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:47:35.935+0000] {processor.py:157} INFO - Started process (PID=91707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:47:35.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:47:35.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:47:35.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:47:35.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:47:35.968+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:47:35.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:47:35.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:47:35.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:47:35.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T04:48:06.405+0000] {processor.py:157} INFO - Started process (PID=91732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:48:06.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:48:06.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:48:06.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:48:06.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:48:06.446+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:48:06.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:48:06.458+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:48:06.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:48:06.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T04:48:36.904+0000] {processor.py:157} INFO - Started process (PID=91757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:48:36.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:48:36.909+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:48:36.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:48:36.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:48:36.951+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:48:36.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:48:36.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:48:36.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:48:36.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T04:49:07.336+0000] {processor.py:157} INFO - Started process (PID=91782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:49:07.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:49:07.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:49:07.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:49:07.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:49:07.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:49:07.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:49:07.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:49:07.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:49:07.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T04:49:37.813+0000] {processor.py:157} INFO - Started process (PID=91807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:49:37.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:49:37.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:49:37.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:49:37.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:49:37.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:49:37.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:49:37.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:49:37.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:49:37.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T04:50:08.207+0000] {processor.py:157} INFO - Started process (PID=91832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:50:08.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:50:08.212+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:50:08.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:50:08.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:50:08.234+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:50:08.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:50:08.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:50:08.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:50:08.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T04:50:38.657+0000] {processor.py:157} INFO - Started process (PID=91857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:50:38.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:50:38.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:50:38.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:50:38.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:50:38.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:50:38.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:50:38.707+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:50:38.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:50:38.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T04:51:09.143+0000] {processor.py:157} INFO - Started process (PID=91882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:51:09.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:51:09.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:51:09.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:51:09.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:51:09.175+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:51:09.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:51:09.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:51:09.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:51:09.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:51:39.631+0000] {processor.py:157} INFO - Started process (PID=91907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:51:39.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:51:39.634+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:51:39.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:51:39.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:51:39.664+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:51:39.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:51:39.674+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:51:39.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:51:39.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T04:52:10.081+0000] {processor.py:157} INFO - Started process (PID=91932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:52:10.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:52:10.084+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:52:10.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:52:10.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:52:10.116+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:52:10.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:52:10.127+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:52:10.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:52:10.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T04:52:40.497+0000] {processor.py:157} INFO - Started process (PID=91957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:52:40.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:52:40.500+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:52:40.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:52:40.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:52:40.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:52:40.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:52:40.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:52:40.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:52:40.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T04:53:11.006+0000] {processor.py:157} INFO - Started process (PID=91982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:53:11.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:53:11.009+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:53:11.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:53:11.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:53:11.044+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:53:11.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:53:11.056+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:53:11.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:53:11.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T04:53:41.428+0000] {processor.py:157} INFO - Started process (PID=92007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:53:41.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:53:41.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:53:41.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:53:41.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:53:41.489+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:53:41.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:53:41.500+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:53:41.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:53:41.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-26T04:54:11.939+0000] {processor.py:157} INFO - Started process (PID=92032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:54:11.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:54:11.944+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:54:11.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:54:11.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:54:11.972+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:54:11.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:54:11.985+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:54:11.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:54:11.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T04:54:42.393+0000] {processor.py:157} INFO - Started process (PID=92057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:54:42.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:54:42.397+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:54:42.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:54:42.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:54:42.430+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:54:42.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:54:42.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:54:42.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:54:42.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:55:12.786+0000] {processor.py:157} INFO - Started process (PID=92082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:55:12.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:55:12.791+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:55:12.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:55:12.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:55:12.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:55:12.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:55:12.844+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:55:12.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:55:12.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T04:55:43.233+0000] {processor.py:157} INFO - Started process (PID=92107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:55:43.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:55:43.241+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:55:43.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:55:43.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:55:43.296+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:55:43.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:55:43.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:55:43.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:55:43.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T04:56:13.656+0000] {processor.py:157} INFO - Started process (PID=92132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:56:13.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:56:13.659+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:56:13.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:56:13.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:56:13.688+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:56:13.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:56:13.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:56:13.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:56:13.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:56:44.086+0000] {processor.py:157} INFO - Started process (PID=92156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:56:44.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:56:44.095+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:56:44.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:56:44.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:56:44.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:56:44.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:56:44.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:56:44.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:56:44.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-26T04:57:14.549+0000] {processor.py:157} INFO - Started process (PID=92182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:57:14.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:57:14.554+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:57:14.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:57:14.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:57:14.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:57:14.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:57:14.604+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:57:14.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:57:14.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T04:57:44.986+0000] {processor.py:157} INFO - Started process (PID=92207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:57:44.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:57:44.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:57:44.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:57:45.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:57:45.020+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:57:45.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:57:45.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:57:45.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:57:45.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:58:15.472+0000] {processor.py:157} INFO - Started process (PID=92231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:58:15.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:58:15.480+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:58:15.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:58:15.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:58:15.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:58:15.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:58:15.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:58:15.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:58:15.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T04:58:45.956+0000] {processor.py:157} INFO - Started process (PID=92257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:58:45.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:58:45.960+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:58:45.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:58:45.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:58:45.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:58:45.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:58:45.997+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:58:45.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:58:46.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T04:59:16.431+0000] {processor.py:157} INFO - Started process (PID=92282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:59:16.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:59:16.435+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:59:16.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:59:16.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:59:16.472+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:59:16.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:59:16.486+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:59:16.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:59:16.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T04:59:46.837+0000] {processor.py:157} INFO - Started process (PID=92307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:59:46.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T04:59:46.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:59:46.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:59:46.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T04:59:46.867+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:59:46.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T04:59:46.880+0000] {logging_mixin.py:151} INFO - [2024-07-26T04:59:46.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T04:59:46.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T05:00:17.293+0000] {processor.py:157} INFO - Started process (PID=92332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:00:17.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:00:17.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:00:17.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:00:17.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:00:17.327+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:00:17.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:00:17.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:00:17.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:00:17.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:00:47.669+0000] {processor.py:157} INFO - Started process (PID=92357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:00:47.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:00:47.672+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:00:47.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:00:47.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:00:47.699+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:00:47.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:00:47.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:00:47.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:00:47.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T05:01:18.112+0000] {processor.py:157} INFO - Started process (PID=92382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:01:18.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:01:18.123+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:01:18.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:01:18.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:01:18.145+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:01:18.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:01:18.154+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:01:18.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:01:18.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T05:01:48.516+0000] {processor.py:157} INFO - Started process (PID=92407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:01:48.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:01:48.519+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:01:48.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:01:48.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:01:48.551+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:01:48.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:01:48.562+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:01:48.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:01:48.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T05:02:18.963+0000] {processor.py:157} INFO - Started process (PID=92432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:02:18.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:02:18.966+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:02:18.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:02:18.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:02:18.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:02:18.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:02:19.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:02:19.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:02:19.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T05:02:49.394+0000] {processor.py:157} INFO - Started process (PID=92457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:02:49.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:02:49.396+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:02:49.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:02:49.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:02:49.422+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:02:49.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:02:49.435+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:02:49.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:02:49.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T05:03:19.813+0000] {processor.py:157} INFO - Started process (PID=92482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:03:19.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:03:19.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:03:19.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:03:19.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:03:19.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:03:19.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:03:19.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:03:19.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:03:19.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T05:03:50.228+0000] {processor.py:157} INFO - Started process (PID=92507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:03:50.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:03:50.234+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:03:50.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:03:50.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:03:50.261+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:03:50.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:03:50.272+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:03:50.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:03:50.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T05:04:20.644+0000] {processor.py:157} INFO - Started process (PID=92531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:04:20.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:04:20.650+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:04:20.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:04:20.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:04:20.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:04:20.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:04:20.674+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:04:20.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:04:20.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.037 seconds
[2024-07-26T05:04:51.116+0000] {processor.py:157} INFO - Started process (PID=92557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:04:51.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:04:51.120+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:04:51.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:04:51.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:04:51.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:04:51.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:04:51.158+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:04:51.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:04:51.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T05:05:21.521+0000] {processor.py:157} INFO - Started process (PID=92582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:05:21.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:05:21.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:05:21.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:05:21.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:05:21.555+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:05:21.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:05:21.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:05:21.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:05:21.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:05:51.864+0000] {processor.py:157} INFO - Started process (PID=92607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:05:51.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:05:51.869+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:05:51.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:05:51.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:05:51.903+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:05:51.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:05:51.913+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:05:51.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:05:51.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T05:06:22.325+0000] {processor.py:157} INFO - Started process (PID=92632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:06:22.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:06:22.329+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:06:22.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:06:22.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:06:22.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:06:22.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:06:22.371+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:06:22.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:06:22.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T05:06:52.787+0000] {processor.py:157} INFO - Started process (PID=92657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:06:52.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:06:52.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:06:52.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:06:52.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:06:52.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:06:52.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:06:52.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:06:52.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:06:52.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T05:07:23.244+0000] {processor.py:157} INFO - Started process (PID=92682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:07:23.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:07:23.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:07:23.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:07:23.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:07:23.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:07:23.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:07:23.285+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:07:23.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:07:23.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T05:07:53.701+0000] {processor.py:157} INFO - Started process (PID=92707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:07:53.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:07:53.707+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:07:53.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:07:53.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:07:53.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:07:53.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:07:53.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:07:53.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:07:53.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T05:08:24.107+0000] {processor.py:157} INFO - Started process (PID=92732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:08:24.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:08:24.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:08:24.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:08:24.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:08:24.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:08:24.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:08:24.154+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:08:24.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:08:24.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T05:08:54.530+0000] {processor.py:157} INFO - Started process (PID=92757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:08:54.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:08:54.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:08:54.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:08:54.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:08:54.571+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:08:54.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:08:54.581+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:08:54.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:08:54.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T05:09:24.983+0000] {processor.py:157} INFO - Started process (PID=92782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:09:24.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:09:24.985+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:09:24.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:09:25.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:09:25.021+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:09:25.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:09:25.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:09:25.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:09:25.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T05:09:55.455+0000] {processor.py:157} INFO - Started process (PID=92807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:09:55.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:09:55.458+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:09:55.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:09:55.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:09:55.484+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:09:55.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:09:55.495+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:09:55.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:09:55.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T05:10:25.907+0000] {processor.py:157} INFO - Started process (PID=92832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:10:25.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:10:25.909+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:10:25.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:10:25.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:10:25.940+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:10:25.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:10:25.949+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:10:25.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:10:25.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:10:56.309+0000] {processor.py:157} INFO - Started process (PID=92857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:10:56.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:10:56.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:10:56.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:10:56.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:10:56.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:10:56.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:10:56.353+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:10:56.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:10:56.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T05:11:26.761+0000] {processor.py:157} INFO - Started process (PID=92882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:11:26.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:11:26.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:11:26.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:11:26.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:11:26.792+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:11:26.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:11:26.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:11:26.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:11:26.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T05:11:57.236+0000] {processor.py:157} INFO - Started process (PID=92907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:11:57.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:11:57.241+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:11:57.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:11:57.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:11:57.271+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:11:57.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:11:57.280+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:11:57.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:11:57.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T05:12:27.733+0000] {processor.py:157} INFO - Started process (PID=92932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:12:27.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:12:27.738+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:12:27.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:12:27.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:12:27.775+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:12:27.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:12:27.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:12:27.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:12:27.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T05:12:58.117+0000] {processor.py:157} INFO - Started process (PID=92957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:12:58.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:12:58.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:12:58.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:12:58.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:12:58.152+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:12:58.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:12:58.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:12:58.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:12:58.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T05:13:28.606+0000] {processor.py:157} INFO - Started process (PID=92982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:13:28.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:13:28.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:13:28.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:13:28.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:13:28.639+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:13:28.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:13:28.651+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:13:28.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:13:28.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T05:13:59.084+0000] {processor.py:157} INFO - Started process (PID=93007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:13:59.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:13:59.089+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:13:59.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:13:59.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:13:59.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:13:59.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:13:59.129+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:13:59.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:13:59.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T05:14:29.543+0000] {processor.py:157} INFO - Started process (PID=93032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:14:29.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:14:29.546+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:14:29.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:14:29.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:14:29.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:14:29.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:14:29.598+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:14:29.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:14:29.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T05:14:59.997+0000] {processor.py:157} INFO - Started process (PID=93057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:14:59.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:15:00.001+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:15:00.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:15:00.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:15:00.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:15:00.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:15:00.041+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:15:00.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:15:00.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T05:15:30.395+0000] {processor.py:157} INFO - Started process (PID=93082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:15:30.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:15:30.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:15:30.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:15:30.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:15:30.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:15:30.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:15:30.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:15:30.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:15:30.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T05:16:00.848+0000] {processor.py:157} INFO - Started process (PID=93107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:16:00.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:16:00.851+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:16:00.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:16:00.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:16:00.879+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:16:00.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:16:00.891+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:16:00.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:16:00.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T05:16:31.302+0000] {processor.py:157} INFO - Started process (PID=93132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:16:31.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:16:31.305+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:16:31.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:16:31.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:16:31.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:16:31.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:16:31.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:16:31.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:16:31.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T05:17:01.766+0000] {processor.py:157} INFO - Started process (PID=93157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:17:01.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:17:01.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:17:01.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:17:01.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:17:01.798+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:17:01.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:17:01.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:17:01.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:17:01.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:17:32.254+0000] {processor.py:157} INFO - Started process (PID=93182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:17:32.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:17:32.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:17:32.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:17:32.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:17:32.290+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:17:32.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:17:32.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:17:32.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:17:32.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T05:18:02.735+0000] {processor.py:157} INFO - Started process (PID=93206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:18:02.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:18:02.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:18:02.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:18:02.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:18:02.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:18:02.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:18:02.794+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:18:02.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:18:02.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T05:18:33.208+0000] {processor.py:157} INFO - Started process (PID=93232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:18:33.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:18:33.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:18:33.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:18:33.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:18:33.236+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:18:33.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:18:33.246+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:18:33.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:18:33.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T05:19:03.648+0000] {processor.py:157} INFO - Started process (PID=93257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:19:03.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:19:03.653+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:19:03.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:19:03.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:19:03.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:19:03.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:19:03.688+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:19:03.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:19:03.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T05:19:34.016+0000] {processor.py:157} INFO - Started process (PID=93282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:19:34.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:19:34.020+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:19:34.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:19:34.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:19:34.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:19:34.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:19:34.056+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:19:34.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:19:34.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T05:20:04.490+0000] {processor.py:157} INFO - Started process (PID=93307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:20:04.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:20:04.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:20:04.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:20:04.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:20:04.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:20:04.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:20:04.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:20:04.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:20:04.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T05:20:34.936+0000] {processor.py:157} INFO - Started process (PID=93332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:20:34.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:20:34.939+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:20:34.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:20:34.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:20:34.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:20:34.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:20:34.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:20:34.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:20:35.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T05:21:05.434+0000] {processor.py:157} INFO - Started process (PID=93357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:21:05.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:21:05.437+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:21:05.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:21:05.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:21:05.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:21:05.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:21:05.476+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:21:05.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:21:05.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T05:21:35.874+0000] {processor.py:157} INFO - Started process (PID=93382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:21:35.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:21:35.878+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:21:35.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:21:35.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:21:35.906+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:21:35.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:21:35.919+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:21:35.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:21:35.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T05:22:06.301+0000] {processor.py:157} INFO - Started process (PID=93407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:22:06.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:22:06.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:22:06.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:22:06.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:22:06.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:22:06.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:22:06.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:22:06.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:22:06.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:22:36.672+0000] {processor.py:157} INFO - Started process (PID=93432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:22:36.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:22:36.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:22:36.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:22:36.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:22:36.706+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:22:36.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:22:36.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:22:36.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:22:36.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T05:23:07.133+0000] {processor.py:157} INFO - Started process (PID=93457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:23:07.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:23:07.136+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:23:07.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:23:07.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:23:07.165+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:23:07.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:23:07.175+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:23:07.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:23:07.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T05:23:37.570+0000] {processor.py:157} INFO - Started process (PID=93482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:23:37.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:23:37.573+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:23:37.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:23:37.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:23:37.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:23:37.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:23:37.614+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:23:37.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:23:37.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:24:08.054+0000] {processor.py:157} INFO - Started process (PID=93507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:24:08.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:24:08.057+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:24:08.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:24:08.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:24:08.083+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:24:08.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:24:08.093+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:24:08.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:24:08.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T05:24:38.529+0000] {processor.py:157} INFO - Started process (PID=93532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:24:38.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:24:38.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:24:38.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:24:38.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:24:38.561+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:24:38.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:24:38.571+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:24:38.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:24:38.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.355 seconds
[2024-07-26T05:25:09.427+0000] {processor.py:157} INFO - Started process (PID=93557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:25:09.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:25:09.431+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:25:09.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:25:09.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:25:09.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:25:09.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:25:09.482+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:25:09.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:25:09.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T05:25:39.855+0000] {processor.py:157} INFO - Started process (PID=93582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:25:39.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:25:39.858+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:25:39.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:25:39.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:25:39.883+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:25:39.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:25:39.894+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:25:39.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:25:39.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T05:26:10.301+0000] {processor.py:157} INFO - Started process (PID=93607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:26:10.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:26:10.305+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:26:10.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:26:10.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:26:10.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:26:10.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:26:10.342+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:26:10.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:26:10.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T05:26:40.747+0000] {processor.py:157} INFO - Started process (PID=93632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:26:40.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:26:40.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:26:40.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:26:40.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:26:40.787+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:26:40.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:26:40.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:26:40.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:26:40.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T05:27:11.211+0000] {processor.py:157} INFO - Started process (PID=93657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:27:11.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:27:11.215+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:27:11.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:27:11.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:27:11.248+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:27:11.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:27:11.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:27:11.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:27:11.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T05:27:41.677+0000] {processor.py:157} INFO - Started process (PID=93682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:27:41.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:27:41.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:27:41.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:27:41.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:27:41.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:27:41.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:27:41.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:27:41.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:27:41.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T05:28:12.046+0000] {processor.py:157} INFO - Started process (PID=93707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:28:12.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:28:12.049+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:28:12.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:28:12.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:28:12.078+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:28:12.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:28:12.088+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:28:12.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:28:12.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:28:42.518+0000] {processor.py:157} INFO - Started process (PID=93732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:28:42.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:28:42.523+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:28:42.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:28:42.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:28:42.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:28:42.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:28:42.569+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:28:42.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:28:42.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T05:29:12.940+0000] {processor.py:157} INFO - Started process (PID=93756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:29:12.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:29:12.943+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:29:12.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:29:12.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:29:12.967+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:29:12.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:29:12.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:29:12.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:29:12.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T05:29:43.353+0000] {processor.py:157} INFO - Started process (PID=93782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:29:43.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:29:43.358+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:29:43.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:29:43.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:29:43.390+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:29:43.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:29:43.403+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:29:43.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:29:43.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T05:30:13.814+0000] {processor.py:157} INFO - Started process (PID=93807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:30:13.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:30:13.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:30:13.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:30:13.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:30:13.843+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:30:13.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:30:13.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:30:13.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:30:13.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T05:30:44.189+0000] {processor.py:157} INFO - Started process (PID=93832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:30:44.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:30:44.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:30:44.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:30:44.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:30:44.219+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:30:44.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:30:44.230+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:30:44.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:30:44.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T05:31:14.600+0000] {processor.py:157} INFO - Started process (PID=93857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:31:14.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:31:14.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:31:14.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:31:14.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:31:14.631+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:31:14.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:31:14.640+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:31:14.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:31:14.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T05:31:44.989+0000] {processor.py:157} INFO - Started process (PID=93882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:31:44.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:31:44.998+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:31:44.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:31:45.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:31:45.021+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:31:45.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:31:45.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:31:45.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:31:45.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T05:32:15.401+0000] {processor.py:157} INFO - Started process (PID=93907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:32:15.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:32:15.406+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:32:15.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:32:15.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:32:15.438+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:32:15.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:32:15.447+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:32:15.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:32:15.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T05:32:45.794+0000] {processor.py:157} INFO - Started process (PID=93932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:32:45.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:32:45.798+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:32:45.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:32:45.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:32:45.829+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:32:45.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:32:45.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:32:45.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:32:45.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T05:33:16.182+0000] {processor.py:157} INFO - Started process (PID=93957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:33:16.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:33:16.185+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:33:16.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:33:16.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:33:16.210+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:33:16.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:33:16.220+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:33:16.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:33:16.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-07-26T05:33:46.942+0000] {processor.py:157} INFO - Started process (PID=93982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:33:46.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:33:46.947+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:33:46.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:33:46.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:33:46.987+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:33:46.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:33:46.999+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:33:46.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:33:47.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T05:34:17.439+0000] {processor.py:157} INFO - Started process (PID=94007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:34:17.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:34:17.448+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:34:17.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:34:17.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:34:17.501+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:34:17.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:34:17.514+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:34:17.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:34:17.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-26T05:34:47.995+0000] {processor.py:157} INFO - Started process (PID=94032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:34:47.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:34:48.002+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:34:48.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:34:48.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:34:48.064+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:34:48.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:34:48.079+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:34:48.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:34:48.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T05:35:18.488+0000] {processor.py:157} INFO - Started process (PID=94057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:35:18.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:35:18.491+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:35:18.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:35:18.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:35:18.527+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:35:18.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:35:18.540+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:35:18.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:35:18.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T05:35:49.072+0000] {processor.py:157} INFO - Started process (PID=94082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:35:49.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:35:49.082+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:35:49.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:35:49.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:35:49.162+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:35:49.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:35:49.178+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:35:49.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:35:49.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-26T05:36:19.794+0000] {processor.py:157} INFO - Started process (PID=94107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:36:19.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:36:19.805+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:36:19.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:36:19.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:36:19.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:36:19.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:36:19.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:36:19.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:36:19.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-26T05:36:50.427+0000] {processor.py:157} INFO - Started process (PID=94132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:36:50.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:36:50.435+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:36:50.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:36:50.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:36:50.486+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:36:50.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:36:50.498+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:36:50.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:36:50.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T05:37:21.025+0000] {processor.py:157} INFO - Started process (PID=94156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:37:21.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:37:21.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:37:21.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:37:21.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:37:21.173+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:37:21.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:37:21.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:37:21.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:37:21.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-07-26T05:37:51.675+0000] {processor.py:157} INFO - Started process (PID=94182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:37:51.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:37:51.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:37:51.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:37:51.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:37:51.737+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:37:51.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:37:51.751+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:37:51.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:37:51.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T05:38:22.210+0000] {processor.py:157} INFO - Started process (PID=94206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:38:22.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:38:22.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:38:22.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:38:22.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:38:22.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:38:22.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:38:22.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:38:22.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:38:22.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T05:38:52.807+0000] {processor.py:157} INFO - Started process (PID=94232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:38:52.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:38:52.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:38:52.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:38:52.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:38:52.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:38:52.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:38:52.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:38:52.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:38:53.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-07-26T05:39:23.461+0000] {processor.py:157} INFO - Started process (PID=94256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:39:23.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:39:23.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:39:23.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:39:23.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:39:23.515+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:39:23.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:39:23.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:39:23.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:39:23.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T05:39:53.968+0000] {processor.py:157} INFO - Started process (PID=94282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:39:53.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:39:53.973+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:39:53.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:39:53.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:39:54.001+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:39:54.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:39:54.012+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:39:54.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:39:54.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T05:40:24.457+0000] {processor.py:157} INFO - Started process (PID=94307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:40:24.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:40:24.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:40:24.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:40:24.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:40:24.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:40:24.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:40:24.541+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:40:24.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:40:24.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-26T05:40:54.912+0000] {processor.py:157} INFO - Started process (PID=94332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:40:54.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:40:54.917+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:40:54.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:40:54.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:40:54.949+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:40:54.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:40:54.959+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:40:54.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:40:54.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T05:41:25.393+0000] {processor.py:157} INFO - Started process (PID=94356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:41:25.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:41:25.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:41:25.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:41:25.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:41:25.470+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:41:25.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:41:25.484+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:41:25.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:41:25.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T05:41:55.988+0000] {processor.py:157} INFO - Started process (PID=94382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:41:55.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:41:55.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:41:55.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:41:56.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:41:56.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:41:56.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:41:56.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:41:56.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:41:56.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-07-26T05:42:26.900+0000] {processor.py:157} INFO - Started process (PID=94407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:42:26.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:42:26.909+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:42:26.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:42:26.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:42:26.974+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:42:26.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:42:26.997+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:42:26.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:42:27.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T05:42:57.404+0000] {processor.py:157} INFO - Started process (PID=94432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:42:57.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:42:57.407+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:42:57.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:42:57.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:42:57.434+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:42:57.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:42:57.444+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:42:57.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:42:57.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T05:43:27.863+0000] {processor.py:157} INFO - Started process (PID=94457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:43:27.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:43:27.874+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:43:27.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:43:27.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:43:27.928+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:43:27.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:43:27.945+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:43:27.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:43:27.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T05:43:58.371+0000] {processor.py:157} INFO - Started process (PID=94482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:43:58.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:43:58.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:43:58.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:43:58.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:43:58.418+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:43:58.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:43:58.432+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:43:58.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:43:58.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T05:44:28.785+0000] {processor.py:157} INFO - Started process (PID=94507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:44:28.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:44:28.791+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:44:28.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:44:28.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:44:28.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:44:28.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:44:28.851+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:44:28.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:44:28.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T05:44:59.296+0000] {processor.py:157} INFO - Started process (PID=94532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:44:59.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:44:59.303+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:44:59.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:44:59.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:44:59.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:44:59.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:44:59.589+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:44:59.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:44:59.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.308 seconds
[2024-07-26T05:45:30.145+0000] {processor.py:157} INFO - Started process (PID=94557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:45:30.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:45:30.148+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:45:30.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:45:30.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:45:30.176+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:45:30.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:45:30.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:45:30.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:45:30.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T05:46:00.749+0000] {processor.py:157} INFO - Started process (PID=94581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:46:00.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:46:00.760+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:46:00.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:46:00.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:46:00.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:46:00.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:46:00.878+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:46:00.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:46:00.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-26T05:46:31.416+0000] {processor.py:157} INFO - Started process (PID=94607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:46:31.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:46:31.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:46:31.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:46:31.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:46:31.494+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:46:31.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:46:31.507+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:46:31.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:46:31.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-26T05:47:01.936+0000] {processor.py:157} INFO - Started process (PID=94632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:47:01.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:47:01.958+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:47:01.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:47:01.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:47:02.019+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:47:02.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:47:02.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:47:02.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:47:02.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T05:47:32.426+0000] {processor.py:157} INFO - Started process (PID=94657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:47:32.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:47:32.430+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:47:32.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:47:32.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:47:32.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:47:32.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:47:32.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:47:32.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:47:32.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.263 seconds
[2024-07-26T05:48:03.241+0000] {processor.py:157} INFO - Started process (PID=94682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:48:03.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:48:03.288+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:48:03.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:48:03.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:48:03.346+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:48:03.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:48:03.381+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:48:03.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:48:03.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-07-26T05:48:33.770+0000] {processor.py:157} INFO - Started process (PID=94707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:48:33.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:48:33.778+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:48:33.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:48:33.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:48:33.831+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:48:33.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:48:33.847+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:48:33.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:48:33.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T05:49:04.283+0000] {processor.py:157} INFO - Started process (PID=94732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:49:04.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:49:04.290+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:49:04.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:49:04.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:49:04.345+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:49:04.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:49:04.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:49:04.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:49:04.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T05:49:34.730+0000] {processor.py:157} INFO - Started process (PID=94757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:49:34.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:49:34.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:49:34.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:49:34.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:49:34.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:49:34.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:49:34.783+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:49:34.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:49:34.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T05:50:05.291+0000] {processor.py:157} INFO - Started process (PID=94781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:50:05.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:50:05.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:50:05.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:50:05.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:50:05.356+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:50:05.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:50:05.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:50:05.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:50:05.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T05:50:35.700+0000] {processor.py:157} INFO - Started process (PID=94807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:50:35.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:50:35.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:50:35.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:50:35.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:50:35.734+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:50:35.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:50:35.744+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:50:35.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:50:35.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-07-26T05:51:06.430+0000] {processor.py:157} INFO - Started process (PID=94831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:51:06.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:51:06.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:51:06.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:51:06.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:51:06.485+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:51:06.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:51:06.499+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:51:06.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:51:06.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T05:51:36.940+0000] {processor.py:157} INFO - Started process (PID=94857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:51:36.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:51:36.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:51:36.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:51:36.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:51:36.985+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:51:36.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:51:36.999+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:51:36.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:51:37.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T05:52:07.426+0000] {processor.py:157} INFO - Started process (PID=94882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:52:07.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:52:07.431+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:52:07.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:52:07.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:52:07.463+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:52:07.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:52:07.474+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:52:07.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:52:07.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T05:52:37.835+0000] {processor.py:157} INFO - Started process (PID=94907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:52:37.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:52:37.838+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:52:37.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:52:37.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:52:37.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:52:37.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:52:37.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:52:37.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:52:37.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T05:53:08.319+0000] {processor.py:157} INFO - Started process (PID=94932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:53:08.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:53:08.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:53:08.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:53:08.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:53:08.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:53:08.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:53:08.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:53:08.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:53:08.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-07-26T05:53:38.983+0000] {processor.py:157} INFO - Started process (PID=94957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:53:38.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:53:38.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:53:38.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:53:39.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:53:39.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:53:39.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:53:39.175+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:53:39.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:53:39.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-07-26T05:54:09.609+0000] {processor.py:157} INFO - Started process (PID=94982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:54:09.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:54:09.611+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:54:09.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:54:09.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:54:09.645+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:54:09.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:54:09.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:54:09.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:54:09.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T05:54:40.064+0000] {processor.py:157} INFO - Started process (PID=95007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:54:40.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:54:40.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:54:40.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:54:40.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:54:40.115+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:54:40.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:54:40.125+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:54:40.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:54:40.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T05:55:10.539+0000] {processor.py:157} INFO - Started process (PID=95032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:55:10.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:55:10.544+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:55:10.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:55:10.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:55:10.581+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:55:10.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:55:10.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:55:10.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:55:10.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T05:55:41.048+0000] {processor.py:157} INFO - Started process (PID=95057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:55:41.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:55:41.054+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:55:41.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:55:41.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:55:41.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:55:41.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:55:41.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:55:41.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:55:41.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T05:56:11.477+0000] {processor.py:157} INFO - Started process (PID=95082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:56:11.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:56:11.484+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:56:11.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:56:11.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:56:11.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:56:11.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:56:11.532+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:56:11.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:56:11.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.238 seconds
[2024-07-26T05:56:42.222+0000] {processor.py:157} INFO - Started process (PID=95107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:56:42.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:56:42.233+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:56:42.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:56:42.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:56:42.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:56:42.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:56:42.292+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:56:42.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:56:42.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T05:57:12.717+0000] {processor.py:157} INFO - Started process (PID=95132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:57:12.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:57:12.723+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:57:12.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:57:12.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:57:12.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:57:12.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:57:12.789+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:57:12.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:57:12.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T05:57:43.254+0000] {processor.py:157} INFO - Started process (PID=95157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:57:43.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:57:43.263+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:57:43.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:57:43.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:57:43.344+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:57:43.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:57:43.363+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:57:43.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:57:43.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T05:58:13.799+0000] {processor.py:157} INFO - Started process (PID=95182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:58:13.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:58:13.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:58:13.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:58:13.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:58:13.846+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:58:13.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:58:13.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:58:13.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:58:13.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T05:58:44.235+0000] {processor.py:157} INFO - Started process (PID=95207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:58:44.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:58:44.245+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:58:44.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:58:44.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:58:44.330+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:58:44.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:58:44.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:58:44.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:58:44.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-26T05:59:14.777+0000] {processor.py:157} INFO - Started process (PID=95232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:59:14.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:59:14.780+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:59:14.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:59:14.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:59:14.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:59:14.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:59:14.955+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:59:14.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:59:14.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-07-26T05:59:45.375+0000] {processor.py:157} INFO - Started process (PID=95257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:59:45.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T05:59:45.383+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:59:45.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:59:45.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T05:59:45.419+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:59:45.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T05:59:45.431+0000] {logging_mixin.py:151} INFO - [2024-07-26T05:59:45.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T05:59:45.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T06:00:15.829+0000] {processor.py:157} INFO - Started process (PID=95282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:00:15.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:00:15.836+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:00:15.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:00:15.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:00:15.864+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:00:15.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:00:15.874+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:00:15.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:00:15.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T06:00:46.240+0000] {processor.py:157} INFO - Started process (PID=95307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:00:46.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:00:46.244+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:00:46.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:00:46.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:00:46.273+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:00:46.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:00:46.286+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:00:46.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:00:46.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T06:01:16.704+0000] {processor.py:157} INFO - Started process (PID=95332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:01:16.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:01:16.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:01:16.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:01:16.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:01:16.737+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:01:16.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:01:16.747+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:01:16.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:01:16.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T06:01:47.096+0000] {processor.py:157} INFO - Started process (PID=95357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:01:47.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:01:47.098+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:01:47.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:01:47.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:01:47.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:01:47.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:01:47.128+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:01:47.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:01:47.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-26T06:02:17.742+0000] {processor.py:157} INFO - Started process (PID=95382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:02:17.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:02:17.747+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:02:17.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:02:17.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:02:17.783+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:02:17.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:02:17.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:02:17.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:02:17.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T06:02:48.261+0000] {processor.py:157} INFO - Started process (PID=95407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:02:48.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:02:48.263+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:02:48.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:02:48.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:02:48.292+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:02:48.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:02:48.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:02:48.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:02:48.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T06:03:18.670+0000] {processor.py:157} INFO - Started process (PID=95432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:03:18.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:03:18.674+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:03:18.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:03:18.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:03:18.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:03:18.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:03:18.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:03:18.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:03:18.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T06:03:49.074+0000] {processor.py:157} INFO - Started process (PID=95457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:03:49.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:03:49.078+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:03:49.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:03:49.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:03:49.112+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:03:49.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:03:49.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:03:49.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:03:49.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T06:04:19.520+0000] {processor.py:157} INFO - Started process (PID=95482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:04:19.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:04:19.523+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:04:19.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:04:19.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:04:19.553+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:04:19.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:04:19.563+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:04:19.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:04:19.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T06:04:49.972+0000] {processor.py:157} INFO - Started process (PID=95507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:04:49.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:04:49.975+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:04:49.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:04:49.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:04:50.004+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:04:50.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:04:50.014+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:04:50.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:04:50.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-07-26T06:05:20.664+0000] {processor.py:157} INFO - Started process (PID=95532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:05:20.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:05:20.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:05:20.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:05:20.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:05:20.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:05:20.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:05:20.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:05:20.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:05:20.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-26T06:05:51.199+0000] {processor.py:157} INFO - Started process (PID=95557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:05:51.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:05:51.201+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:05:51.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:05:51.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:05:51.227+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:05:51.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:05:51.236+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:05:51.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:05:51.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T06:06:21.707+0000] {processor.py:157} INFO - Started process (PID=95582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:06:21.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:06:21.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:06:21.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:06:21.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:06:21.753+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:06:21.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:06:21.765+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:06:21.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:06:21.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T06:06:52.153+0000] {processor.py:157} INFO - Started process (PID=95607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:06:52.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:06:52.157+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:06:52.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:06:52.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:06:52.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:06:52.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:06:52.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:06:52.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:06:52.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T06:07:22.593+0000] {processor.py:157} INFO - Started process (PID=95632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:07:22.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:07:22.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:07:22.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:07:22.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:07:22.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:07:22.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:07:22.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:07:22.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:07:22.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T06:07:53.083+0000] {processor.py:157} INFO - Started process (PID=95657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:07:53.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:07:53.085+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:07:53.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:07:53.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:07:53.117+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:07:53.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:07:53.217+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:07:53.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:07:53.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-26T06:08:23.672+0000] {processor.py:157} INFO - Started process (PID=95682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:08:23.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:08:23.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:08:23.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:08:23.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:08:23.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:08:23.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:08:23.725+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:08:23.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:08:23.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T06:08:54.169+0000] {processor.py:157} INFO - Started process (PID=95707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:08:54.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:08:54.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:08:54.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:08:54.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:08:54.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:08:54.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:08:54.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:08:54.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:08:54.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T06:09:24.590+0000] {processor.py:157} INFO - Started process (PID=95732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:09:24.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:09:24.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:09:24.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:09:24.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:09:24.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:09:24.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:09:24.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:09:24.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:09:24.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T06:09:55.044+0000] {processor.py:157} INFO - Started process (PID=95757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:09:55.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:09:55.049+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:09:55.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:09:55.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:09:55.078+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:09:55.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:09:55.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:09:55.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:09:55.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T06:10:25.457+0000] {processor.py:157} INFO - Started process (PID=95782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:10:25.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:10:25.462+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:10:25.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:10:25.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:10:25.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:10:25.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:10:25.505+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:10:25.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:10:25.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-07-26T06:10:56.195+0000] {processor.py:157} INFO - Started process (PID=95807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:10:56.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:10:56.200+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:10:56.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:10:56.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:10:56.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:10:56.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:10:56.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:10:56.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:10:56.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-26T06:11:26.754+0000] {processor.py:157} INFO - Started process (PID=95832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:11:26.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:11:26.757+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:11:26.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:11:26.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:11:26.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:11:26.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:11:26.798+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:11:26.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:11:26.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T06:11:57.243+0000] {processor.py:157} INFO - Started process (PID=95855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:11:57.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:11:57.249+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:11:57.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:11:57.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:11:57.287+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:11:57.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:11:57.299+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:11:57.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:11:57.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T06:12:27.679+0000] {processor.py:157} INFO - Started process (PID=95882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:12:27.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:12:27.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:12:27.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:12:27.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:12:27.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:12:27.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:12:27.722+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:12:27.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:12:27.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T06:12:58.135+0000] {processor.py:157} INFO - Started process (PID=95907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:12:58.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:12:58.139+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:12:58.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:12:58.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:12:58.169+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:12:58.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:12:58.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:12:58.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:12:58.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T06:13:28.629+0000] {processor.py:157} INFO - Started process (PID=95932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:13:28.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:13:28.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:13:28.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:13:28.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:13:28.662+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:13:28.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:13:28.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:13:28.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:13:28.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-07-26T06:13:59.344+0000] {processor.py:157} INFO - Started process (PID=95957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:13:59.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:13:59.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:13:59.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:13:59.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:13:59.387+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:13:59.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:13:59.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:13:59.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:13:59.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-26T06:14:29.909+0000] {processor.py:157} INFO - Started process (PID=95982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:14:29.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:14:29.912+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:14:29.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:14:29.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:14:29.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:14:29.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:14:29.945+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:14:29.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:14:29.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T06:15:00.390+0000] {processor.py:157} INFO - Started process (PID=96007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:15:00.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:15:00.394+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:15:00.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:15:00.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:15:00.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:15:00.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:15:00.433+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:15:00.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:15:00.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T06:15:30.800+0000] {processor.py:157} INFO - Started process (PID=96032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:15:30.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:15:30.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:15:30.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:15:30.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:15:30.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:15:30.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:15:30.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:15:30.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:15:30.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T06:16:01.249+0000] {processor.py:157} INFO - Started process (PID=96057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:16:01.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:16:01.252+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:16:01.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:16:01.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:16:01.280+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:16:01.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:16:01.292+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:16:01.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:16:01.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-26T06:16:31.876+0000] {processor.py:157} INFO - Started process (PID=96082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:16:31.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:16:31.885+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:16:31.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:16:31.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:16:31.923+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:16:31.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:16:32.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:16:32.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:16:32.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-26T06:17:02.445+0000] {processor.py:157} INFO - Started process (PID=96107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:17:02.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:17:02.448+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:17:02.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:17:02.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:17:02.479+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:17:02.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:17:02.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:17:02.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:17:02.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T06:17:33.033+0000] {processor.py:157} INFO - Started process (PID=96132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:17:33.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:17:33.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:17:33.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:17:33.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:17:33.064+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:17:33.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:17:33.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:17:33.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:17:33.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T06:18:03.451+0000] {processor.py:157} INFO - Started process (PID=96157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:18:03.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:18:03.454+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:18:03.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:18:03.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:18:03.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:18:03.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:18:03.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:18:03.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:18:03.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T06:18:33.906+0000] {processor.py:157} INFO - Started process (PID=96182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:18:33.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:18:33.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:18:33.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:18:33.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:18:33.940+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:18:33.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:18:33.951+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:18:33.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:18:33.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T06:19:04.396+0000] {processor.py:157} INFO - Started process (PID=96207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:19:04.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:19:04.401+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:19:04.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:19:04.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:19:04.436+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:19:04.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:19:04.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:19:04.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:19:04.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-07-26T06:19:35.104+0000] {processor.py:157} INFO - Started process (PID=96232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:19:35.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:19:35.107+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:19:35.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:19:35.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:19:35.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:19:35.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:19:35.210+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:19:35.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:19:35.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T06:20:05.678+0000] {processor.py:157} INFO - Started process (PID=96257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:20:05.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:20:05.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:20:05.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:20:05.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:20:05.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:20:05.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:20:05.718+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:20:05.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:20:05.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T06:20:36.100+0000] {processor.py:157} INFO - Started process (PID=96282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:20:36.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:20:36.103+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:20:36.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:20:36.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:20:36.129+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:20:36.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:20:36.139+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:20:36.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:20:36.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T06:21:06.508+0000] {processor.py:157} INFO - Started process (PID=96307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:21:06.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:21:06.512+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:21:06.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:21:06.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:21:06.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:21:06.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:21:06.544+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:21:06.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:21:06.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T06:21:36.971+0000] {processor.py:157} INFO - Started process (PID=96332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:21:36.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:21:36.975+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:21:36.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:21:36.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:21:37.008+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:21:37.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:21:37.018+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:21:37.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:21:37.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T06:22:07.428+0000] {processor.py:157} INFO - Started process (PID=96357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:22:07.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:22:07.433+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:22:07.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:22:07.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:22:07.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:22:07.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:22:07.619+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:22:07.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:22:07.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-07-26T06:22:38.061+0000] {processor.py:157} INFO - Started process (PID=96382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:22:38.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:22:38.065+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:22:38.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:22:38.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:22:38.093+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:22:38.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:22:38.177+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:22:38.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:22:38.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T06:23:08.595+0000] {processor.py:157} INFO - Started process (PID=96407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:23:08.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:23:08.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:23:08.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:23:08.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:23:08.621+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:23:08.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:23:08.631+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:23:08.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:23:08.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T06:23:39.028+0000] {processor.py:157} INFO - Started process (PID=96432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:23:39.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:23:39.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:23:39.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:23:39.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:23:39.059+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:23:39.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:23:39.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:23:39.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:23:39.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T06:24:09.465+0000] {processor.py:157} INFO - Started process (PID=96456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:24:09.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:24:09.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:24:09.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:24:09.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:24:09.504+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:24:09.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:24:09.516+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:24:09.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:24:09.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T06:24:39.934+0000] {processor.py:157} INFO - Started process (PID=96482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:24:39.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:24:39.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:24:39.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:24:39.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:24:39.965+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:24:39.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:24:39.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:24:39.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:24:40.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-07-26T06:25:10.552+0000] {processor.py:157} INFO - Started process (PID=96507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:25:10.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:25:10.557+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:25:10.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:25:10.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:25:10.584+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:25:10.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:25:10.665+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:25:10.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:25:10.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T06:25:41.102+0000] {processor.py:157} INFO - Started process (PID=96532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:25:41.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:25:41.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:25:41.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:25:41.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:25:41.138+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:25:41.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:25:41.217+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:25:41.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:25:41.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-26T06:26:11.805+0000] {processor.py:157} INFO - Started process (PID=96557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:26:11.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:26:11.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:26:11.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:26:11.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:26:11.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:26:11.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:26:11.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:26:11.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:26:11.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T06:26:42.255+0000] {processor.py:157} INFO - Started process (PID=96582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:26:42.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:26:42.256+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:26:42.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:26:42.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:26:42.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:26:42.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:26:42.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:26:42.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:26:42.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T06:27:12.739+0000] {processor.py:157} INFO - Started process (PID=96607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:27:12.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:27:12.743+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:27:12.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:27:12.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:27:12.774+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:27:12.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:27:12.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:27:12.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:27:12.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T06:27:43.228+0000] {processor.py:157} INFO - Started process (PID=96632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:27:43.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:27:43.232+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:27:43.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:27:43.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:27:43.271+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:27:43.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:27:43.285+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:27:43.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:27:43.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-07-26T06:28:13.991+0000] {processor.py:157} INFO - Started process (PID=96657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:28:13.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:28:13.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:28:13.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:28:14.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:28:14.024+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:28:14.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:28:14.107+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:28:14.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:28:14.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T06:28:44.643+0000] {processor.py:157} INFO - Started process (PID=96682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:28:44.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:28:44.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:28:44.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:28:44.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:28:44.741+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:28:44.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:28:44.749+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:28:44.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:28:44.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-26T06:29:15.216+0000] {processor.py:157} INFO - Started process (PID=96707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:29:15.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:29:15.219+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:29:15.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:29:15.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:29:15.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:29:15.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:29:15.257+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:29:15.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:29:15.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T06:29:45.648+0000] {processor.py:157} INFO - Started process (PID=96732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:29:45.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:29:45.653+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:29:45.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:29:45.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:29:45.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:29:45.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:29:45.691+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:29:45.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:29:45.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T06:30:16.111+0000] {processor.py:157} INFO - Started process (PID=96757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:30:16.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:30:16.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:30:16.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:30:16.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:30:16.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:30:16.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:30:16.152+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:30:16.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:30:16.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T06:30:46.629+0000] {processor.py:157} INFO - Started process (PID=96782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:30:46.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:30:46.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:30:46.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:30:46.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:30:46.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:30:46.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:30:46.768+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:30:46.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:30:46.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-26T06:31:17.312+0000] {processor.py:157} INFO - Started process (PID=96807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:31:17.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:31:17.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:31:17.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:31:17.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:31:17.354+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:31:17.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:31:17.432+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:31:17.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:31:17.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-26T06:31:48.008+0000] {processor.py:157} INFO - Started process (PID=96832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:31:48.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:31:48.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:31:48.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:31:48.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:31:48.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:31:48.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:31:48.049+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:31:48.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:31:48.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T06:32:18.503+0000] {processor.py:157} INFO - Started process (PID=96857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:32:18.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:32:18.507+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:32:18.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:32:18.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:32:18.534+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:32:18.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:32:18.544+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:32:18.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:32:18.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T06:32:48.901+0000] {processor.py:157} INFO - Started process (PID=96882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:32:48.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:32:48.907+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:32:48.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:32:48.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:32:48.945+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:32:48.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:32:48.962+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:32:48.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:32:48.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T06:33:19.316+0000] {processor.py:157} INFO - Started process (PID=96907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:33:19.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:33:19.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:33:19.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:33:19.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:33:19.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:33:19.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:33:19.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:33:19.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:33:19.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-07-26T06:33:50.123+0000] {processor.py:157} INFO - Started process (PID=96932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:33:50.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:33:50.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:33:50.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:33:50.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:33:50.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:33:50.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:33:50.452+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:33:50.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:33:50.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.372 seconds
[2024-07-26T06:34:20.808+0000] {processor.py:157} INFO - Started process (PID=96957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:34:20.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:34:20.813+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:34:20.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:34:20.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:34:20.847+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:34:20.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:34:20.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:34:20.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:34:20.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-26T06:34:51.367+0000] {processor.py:157} INFO - Started process (PID=96982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:34:51.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:34:51.370+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:34:51.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:34:51.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:34:51.406+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:34:51.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:34:51.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:34:51.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:34:51.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T06:35:21.795+0000] {processor.py:157} INFO - Started process (PID=97007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:35:21.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:35:21.801+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:35:21.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:35:21.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:35:21.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:35:21.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:35:21.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:35:21.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:35:21.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T06:35:52.231+0000] {processor.py:157} INFO - Started process (PID=97032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:35:52.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:35:52.233+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:35:52.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:35:52.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:35:52.298+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:35:52.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:35:52.313+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:35:52.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:35:52.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T06:36:22.689+0000] {processor.py:157} INFO - Started process (PID=97057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:36:22.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:36:22.693+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:36:22.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:36:22.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:36:22.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:36:22.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:36:22.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:36:22.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:36:22.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-07-26T06:36:53.437+0000] {processor.py:157} INFO - Started process (PID=97082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:36:53.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:36:53.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:36:53.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:36:53.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:36:53.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:36:53.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:36:53.555+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:36:53.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:36:53.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-26T06:37:24.059+0000] {processor.py:157} INFO - Started process (PID=97107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:37:24.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:37:24.065+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:37:24.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:37:24.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:37:24.214+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:37:24.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:37:24.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:37:24.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:37:24.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-07-26T06:37:54.697+0000] {processor.py:157} INFO - Started process (PID=97132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:37:54.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:37:54.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:37:54.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:37:54.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:37:54.734+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:37:54.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:37:54.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:37:54.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:37:54.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T06:38:25.158+0000] {processor.py:157} INFO - Started process (PID=97157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:38:25.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:38:25.161+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:38:25.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:38:25.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:38:25.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:38:25.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:38:25.217+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:38:25.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:38:25.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T06:38:55.673+0000] {processor.py:157} INFO - Started process (PID=97182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:38:55.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:38:55.675+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:38:55.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:38:55.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:38:55.706+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:38:55.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:38:55.720+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:38:55.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:38:55.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-07-26T06:39:26.324+0000] {processor.py:157} INFO - Started process (PID=97207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:39:26.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:39:26.331+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:39:26.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:39:26.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:39:26.372+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:39:26.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:39:26.460+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:39:26.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:39:26.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-26T06:39:56.866+0000] {processor.py:157} INFO - Started process (PID=97232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:39:56.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:39:56.869+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:39:56.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:39:56.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:39:56.907+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:39:56.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:39:57.022+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:39:57.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:39:57.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-26T06:40:27.530+0000] {processor.py:157} INFO - Started process (PID=97257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:40:27.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:40:27.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:40:27.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:40:27.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:40:27.674+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:40:27.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:40:27.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:40:27.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:40:27.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-26T06:40:58.255+0000] {processor.py:157} INFO - Started process (PID=97282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:40:58.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:40:58.260+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:40:58.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:40:58.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:40:58.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:40:58.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:40:58.304+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:40:58.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:40:58.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T06:41:29.113+0000] {processor.py:157} INFO - Started process (PID=97307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:41:29.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:41:29.125+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:41:29.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:41:29.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:41:29.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:41:29.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:41:29.197+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:41:29.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:41:29.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T06:41:59.675+0000] {processor.py:157} INFO - Started process (PID=97332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:41:59.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:41:59.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:41:59.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:41:59.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:41:59.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:41:59.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:41:59.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:41:59.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:41:59.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.211 seconds
[2024-07-26T06:42:30.406+0000] {processor.py:157} INFO - Started process (PID=97357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:42:30.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:42:30.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:42:30.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:42:30.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:42:30.437+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:42:30.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:42:30.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:42:30.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:42:30.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-26T06:43:00.892+0000] {processor.py:157} INFO - Started process (PID=97382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:43:00.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:43:00.895+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:43:00.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:43:00.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:43:00.919+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:43:00.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:43:01.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:43:01.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:43:01.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T06:43:31.452+0000] {processor.py:157} INFO - Started process (PID=97407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:43:31.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:43:31.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:43:31.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:43:31.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:43:31.499+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:43:31.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:43:31.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:43:31.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:43:31.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T06:44:01.932+0000] {processor.py:157} INFO - Started process (PID=97432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:44:01.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:44:01.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:44:01.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:44:01.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:44:01.966+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:44:01.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:44:01.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:44:01.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:44:01.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T06:44:32.303+0000] {processor.py:157} INFO - Started process (PID=97457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:44:32.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:44:32.307+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:44:32.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:44:32.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:44:32.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:44:32.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:44:32.346+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:44:32.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:44:32.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T06:45:02.735+0000] {processor.py:157} INFO - Started process (PID=97482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:45:02.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:45:02.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:45:02.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:45:02.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:45:02.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:45:02.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:45:02.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:45:02.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:45:02.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-26T06:45:33.285+0000] {processor.py:157} INFO - Started process (PID=97507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:45:33.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:45:33.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:45:33.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:45:33.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:45:33.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:45:33.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:45:33.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:45:33.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:45:33.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T06:46:03.824+0000] {processor.py:157} INFO - Started process (PID=97532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:46:03.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:46:03.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:46:03.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:46:03.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:46:03.925+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:46:03.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:46:03.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:46:03.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:46:03.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-26T06:46:34.487+0000] {processor.py:157} INFO - Started process (PID=97557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:46:34.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:46:34.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:46:34.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:46:34.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:46:34.530+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:46:34.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:46:34.545+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:46:34.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:46:34.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T06:47:04.899+0000] {processor.py:157} INFO - Started process (PID=97582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:47:04.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:47:04.902+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:47:04.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:47:04.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:47:04.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:47:04.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:47:04.947+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:47:04.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:47:04.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T06:47:35.311+0000] {processor.py:157} INFO - Started process (PID=97606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:47:35.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:47:35.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:47:35.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:47:35.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:47:35.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:47:35.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:47:35.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:47:35.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:47:35.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-07-26T06:48:06.068+0000] {processor.py:157} INFO - Started process (PID=97632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:48:06.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:48:06.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:48:06.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:48:06.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:48:06.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:48:06.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:48:06.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:48:06.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:48:06.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T06:48:36.557+0000] {processor.py:157} INFO - Started process (PID=97657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:48:36.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:48:36.564+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:48:36.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:48:36.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:48:36.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:48:36.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:48:36.772+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:48:36.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:48:36.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-07-26T06:49:07.268+0000] {processor.py:157} INFO - Started process (PID=97682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:49:07.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:49:07.272+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:49:07.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:49:07.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:49:07.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:49:07.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:49:07.375+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:49:07.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:49:07.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-26T06:49:37.745+0000] {processor.py:157} INFO - Started process (PID=97707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:49:37.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:49:37.751+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:49:37.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:49:37.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:49:37.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:49:37.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:49:37.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:49:37.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:49:37.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T06:50:08.205+0000] {processor.py:157} INFO - Started process (PID=97732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:50:08.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:50:08.208+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:50:08.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:50:08.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:50:08.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:50:08.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:50:08.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:50:08.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:50:08.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T06:50:38.530+0000] {processor.py:157} INFO - Started process (PID=97757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:50:38.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:50:38.532+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:50:38.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:50:38.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:50:38.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:50:38.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:50:38.568+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:50:38.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:50:38.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-07-26T06:51:09.305+0000] {processor.py:157} INFO - Started process (PID=97782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:51:09.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:51:09.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:51:09.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:51:09.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:51:09.338+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:51:09.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:51:09.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:51:09.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:51:09.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-26T06:51:39.886+0000] {processor.py:157} INFO - Started process (PID=97807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:51:39.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:51:39.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:51:39.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:51:39.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:51:39.999+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:51:39.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:51:40.006+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:51:40.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:51:40.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T06:52:10.512+0000] {processor.py:157} INFO - Started process (PID=97832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:52:10.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:52:10.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:52:10.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:52:10.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:52:10.641+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:52:10.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:52:10.649+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:52:10.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:52:10.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-26T06:52:41.109+0000] {processor.py:157} INFO - Started process (PID=97857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:52:41.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:52:41.113+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:52:41.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:52:41.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:52:41.138+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:52:41.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:52:41.148+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:52:41.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:52:41.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T06:53:11.535+0000] {processor.py:157} INFO - Started process (PID=97882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:53:11.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:53:11.539+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:53:11.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:53:11.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:53:11.567+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:53:11.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:53:11.579+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:53:11.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:53:11.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T06:53:41.957+0000] {processor.py:157} INFO - Started process (PID=97907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:53:41.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:53:41.961+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:53:41.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:53:41.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:53:41.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:53:41.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:53:42.075+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:53:42.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:53:42.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T06:54:12.478+0000] {processor.py:157} INFO - Started process (PID=97932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:54:12.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:54:12.482+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:54:12.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:54:12.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:54:12.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:54:12.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:54:12.615+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:54:12.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:54:12.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-26T06:54:43.168+0000] {processor.py:157} INFO - Started process (PID=97957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:54:43.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:54:43.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:54:43.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:54:43.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:54:43.281+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:54:43.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:54:43.288+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:54:43.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:54:43.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-26T06:55:13.680+0000] {processor.py:157} INFO - Started process (PID=97982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:55:13.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:55:13.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:55:13.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:55:13.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:55:13.707+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:55:13.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:55:13.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:55:13.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:55:13.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T06:55:44.117+0000] {processor.py:157} INFO - Started process (PID=98007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:55:44.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:55:44.121+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:55:44.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:55:44.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:55:44.151+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:55:44.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:55:44.163+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:55:44.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:55:44.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T06:56:14.508+0000] {processor.py:157} INFO - Started process (PID=98032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:56:14.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:56:14.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:56:14.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:56:14.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:56:14.539+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:56:14.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:56:14.549+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:56:14.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:56:14.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T06:56:45.173+0000] {processor.py:157} INFO - Started process (PID=98057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:56:45.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:56:45.177+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:56:45.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:56:45.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:56:45.205+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:56:45.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:56:45.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:56:45.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:56:45.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-26T06:57:15.665+0000] {processor.py:157} INFO - Started process (PID=98082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:57:15.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:57:15.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:57:15.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:57:15.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:57:15.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:57:15.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:57:15.775+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:57:15.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:57:15.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T06:57:46.308+0000] {processor.py:157} INFO - Started process (PID=98107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:57:46.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:57:46.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:57:46.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:57:46.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:57:46.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:57:46.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:57:46.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:57:46.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:57:46.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-26T06:58:16.829+0000] {processor.py:157} INFO - Started process (PID=98132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:58:16.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:58:16.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:58:16.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:58:16.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:58:16.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:58:16.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:58:16.885+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:58:16.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:58:16.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T06:58:47.231+0000] {processor.py:157} INFO - Started process (PID=98157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:58:47.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:58:47.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:58:47.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:58:47.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:58:47.267+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:58:47.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:58:47.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:58:47.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:58:47.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T06:59:17.614+0000] {processor.py:157} INFO - Started process (PID=98182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:59:17.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:59:17.618+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:59:17.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:59:17.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:59:17.653+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:59:17.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:59:17.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:59:17.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:59:17.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-26T06:59:48.299+0000] {processor.py:157} INFO - Started process (PID=98207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:59:48.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T06:59:48.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:59:48.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:59:48.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T06:59:48.330+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:59:48.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T06:59:48.414+0000] {logging_mixin.py:151} INFO - [2024-07-26T06:59:48.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T06:59:48.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T07:00:18.797+0000] {processor.py:157} INFO - Started process (PID=98232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:00:18.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:00:18.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:00:18.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:00:18.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:00:18.896+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:00:18.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:00:18.904+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:00:18.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:00:18.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T07:00:49.405+0000] {processor.py:157} INFO - Started process (PID=98257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:00:49.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:00:49.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:00:49.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:00:49.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:00:49.570+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:00:49.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:00:49.579+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:00:49.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:00:49.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-07-26T07:01:20.049+0000] {processor.py:157} INFO - Started process (PID=98282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:01:20.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:01:20.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:01:20.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:01:20.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:01:20.078+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:01:20.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:01:20.088+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:01:20.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:01:20.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T07:01:50.507+0000] {processor.py:157} INFO - Started process (PID=98307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:01:50.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:01:50.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:01:50.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:01:50.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:01:50.546+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:01:50.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:01:50.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:01:50.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:01:50.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T07:02:21.028+0000] {processor.py:157} INFO - Started process (PID=98332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:02:21.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:02:21.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:02:21.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:02:21.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:02:21.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:02:21.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:02:21.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:02:21.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:02:21.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-07-26T07:02:51.628+0000] {processor.py:157} INFO - Started process (PID=98357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:02:51.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:02:51.631+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:02:51.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:02:51.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:02:51.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:02:51.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:02:51.743+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:02:51.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:02:51.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T07:03:22.164+0000] {processor.py:157} INFO - Started process (PID=98382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:03:22.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:03:22.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:03:22.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:03:22.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:03:22.267+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:03:22.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:03:22.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:03:22.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:03:22.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-26T07:03:52.795+0000] {processor.py:157} INFO - Started process (PID=98407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:03:52.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:03:52.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:03:52.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:03:52.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:03:52.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:03:52.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:03:52.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:03:52.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:03:52.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T07:04:23.155+0000] {processor.py:157} INFO - Started process (PID=98432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:04:23.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:04:23.158+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:04:23.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:04:23.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:04:23.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:04:23.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:04:23.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:04:23.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:04:23.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T07:04:53.549+0000] {processor.py:157} INFO - Started process (PID=98457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:04:53.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:04:53.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:04:53.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:04:53.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:04:53.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:04:53.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:04:53.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:04:53.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:04:53.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T07:05:24.075+0000] {processor.py:157} INFO - Started process (PID=98482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:05:24.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:05:24.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:05:24.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:05:24.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:05:24.106+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:05:24.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:05:24.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:05:24.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:05:24.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-26T07:05:54.736+0000] {processor.py:157} INFO - Started process (PID=98507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:05:54.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:05:54.741+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:05:54.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:05:54.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:05:54.767+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:05:54.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:05:54.853+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:05:54.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:05:54.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T07:06:25.272+0000] {processor.py:157} INFO - Started process (PID=98532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:06:25.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:06:25.280+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:06:25.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:06:25.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:06:25.376+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:06:25.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:06:25.383+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:06:25.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:06:25.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T07:06:55.786+0000] {processor.py:157} INFO - Started process (PID=98557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:06:55.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:06:55.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:06:55.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:06:55.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:06:55.842+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:06:55.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:06:55.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:06:55.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:06:55.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T07:07:26.310+0000] {processor.py:157} INFO - Started process (PID=98582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:07:26.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:07:26.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:07:26.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:07:26.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:07:26.403+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:07:26.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:07:26.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:07:26.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:07:26.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-26T07:07:56.882+0000] {processor.py:157} INFO - Started process (PID=98607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:07:56.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:07:56.889+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:07:56.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:07:56.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:07:56.958+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:07:56.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:07:56.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:07:56.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:07:57.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.258 seconds
[2024-07-26T07:08:27.662+0000] {processor.py:157} INFO - Started process (PID=98632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:08:27.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:08:27.675+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:08:27.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:08:27.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:08:27.747+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:08:27.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:08:27.934+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:08:27.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:08:27.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.290 seconds
[2024-07-26T07:08:58.648+0000] {processor.py:157} INFO - Started process (PID=98657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:08:58.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:08:58.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:08:58.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:08:58.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:08:58.946+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:08:58.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:08:58.955+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:08:58.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:08:58.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.339 seconds
[2024-07-26T07:09:29.452+0000] {processor.py:157} INFO - Started process (PID=98682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:09:29.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:09:29.462+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:09:29.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:09:29.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:09:29.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:09:29.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:09:29.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:09:29.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:09:29.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.351 seconds
[2024-07-26T07:10:00.355+0000] {processor.py:157} INFO - Started process (PID=98707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:10:00.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:10:00.362+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:10:00.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:10:00.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:10:00.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:10:00.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:10:00.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:10:00.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:10:00.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T07:10:30.848+0000] {processor.py:157} INFO - Started process (PID=98732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:10:30.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:10:30.870+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:10:30.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:10:30.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:10:30.923+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:10:30.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:10:30.939+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:10:30.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:10:30.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-26T07:11:01.395+0000] {processor.py:157} INFO - Started process (PID=98757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:11:01.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:11:01.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:11:01.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:11:01.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:11:01.438+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:11:01.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:11:01.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:11:01.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:11:01.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-07-26T07:11:32.251+0000] {processor.py:157} INFO - Started process (PID=98782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:11:32.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:11:32.258+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:11:32.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:11:32.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:11:32.298+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:11:32.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:11:32.422+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:11:32.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:11:32.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-07-26T07:12:02.963+0000] {processor.py:157} INFO - Started process (PID=98807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:12:02.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:12:02.965+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:12:02.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:12:02.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:12:03.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:12:03.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:12:03.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:12:03.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:12:03.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-26T07:12:33.640+0000] {processor.py:157} INFO - Started process (PID=98832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:12:33.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:12:33.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:12:33.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:12:33.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:12:33.783+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:12:33.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:12:33.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:12:33.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:12:33.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-26T07:13:04.306+0000] {processor.py:157} INFO - Started process (PID=98857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:13:04.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:13:04.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:13:04.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:13:04.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:13:04.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:13:04.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:13:04.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:13:04.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:13:04.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T07:13:34.705+0000] {processor.py:157} INFO - Started process (PID=98882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:13:34.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:13:34.711+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:13:34.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:13:34.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:13:34.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:13:34.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:13:34.792+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:13:34.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:13:34.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T07:14:05.099+0000] {processor.py:157} INFO - Started process (PID=98907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:14:05.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:14:05.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:14:05.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:14:05.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:14:05.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:14:05.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:14:05.143+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:14:05.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:14:05.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T07:14:35.574+0000] {processor.py:157} INFO - Started process (PID=98932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:14:35.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:14:35.579+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:14:35.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:14:35.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:14:35.606+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:14:35.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:14:35.619+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:14:35.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:14:35.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T07:15:06.024+0000] {processor.py:157} INFO - Started process (PID=98957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:15:06.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:15:06.030+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:15:06.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:15:06.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:15:06.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:15:06.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:15:06.082+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:15:06.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:15:06.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T07:15:36.497+0000] {processor.py:157} INFO - Started process (PID=98981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:15:36.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:15:36.501+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:15:36.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:15:36.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:15:36.527+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:15:36.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:15:36.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:15:36.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:15:36.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T07:16:06.974+0000] {processor.py:157} INFO - Started process (PID=99007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:16:06.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:16:06.980+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:16:06.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:16:06.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:16:07.020+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:16:07.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:16:07.033+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:16:07.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:16:07.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T07:16:37.473+0000] {processor.py:157} INFO - Started process (PID=99032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:16:37.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:16:37.476+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:16:37.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:16:37.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:16:37.503+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:16:37.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:16:37.513+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:16:37.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:16:37.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T07:17:07.865+0000] {processor.py:157} INFO - Started process (PID=99057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:17:07.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:17:07.868+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:17:07.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:17:07.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:17:07.894+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:17:07.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:17:07.904+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:17:07.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:17:07.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T07:17:38.316+0000] {processor.py:157} INFO - Started process (PID=99082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:17:38.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:17:38.328+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:17:38.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:17:38.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:17:38.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:17:38.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:17:38.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:17:38.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:17:38.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T07:18:08.839+0000] {processor.py:157} INFO - Started process (PID=99107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:18:08.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:18:08.844+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:18:08.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:18:08.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:18:08.878+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:18:08.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:18:08.893+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:18:08.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:18:08.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T07:18:39.232+0000] {processor.py:157} INFO - Started process (PID=99132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:18:39.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:18:39.236+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:18:39.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:18:39.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:18:39.270+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:18:39.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:18:39.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:18:39.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:18:39.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T07:19:09.684+0000] {processor.py:157} INFO - Started process (PID=99157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:19:09.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:19:09.686+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:19:09.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:19:09.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:19:09.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:19:09.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:19:09.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:19:09.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:19:09.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T07:19:40.141+0000] {processor.py:157} INFO - Started process (PID=99182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:19:40.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:19:40.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:19:40.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:19:40.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:19:40.173+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:19:40.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:19:40.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:19:40.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:19:40.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T07:20:10.576+0000] {processor.py:157} INFO - Started process (PID=99207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:20:10.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:20:10.579+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:20:10.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:20:10.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:20:10.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:20:10.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:20:10.613+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:20:10.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:20:10.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T07:20:41.045+0000] {processor.py:157} INFO - Started process (PID=99231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:20:41.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:20:41.050+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:20:41.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:20:41.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:20:41.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:20:41.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:20:41.115+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:20:41.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:20:41.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T07:21:11.458+0000] {processor.py:157} INFO - Started process (PID=99257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:21:11.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:21:11.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:21:11.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:21:11.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:21:11.489+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:21:11.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:21:11.498+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:21:11.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:21:11.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T07:21:41.898+0000] {processor.py:157} INFO - Started process (PID=99282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:21:41.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:21:41.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:21:41.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:21:41.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:21:41.927+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:21:41.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:21:41.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:21:41.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:21:41.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T07:22:12.278+0000] {processor.py:157} INFO - Started process (PID=99307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:22:12.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:22:12.282+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:22:12.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:22:12.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:22:12.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:22:12.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:22:12.321+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:22:12.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:22:12.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T07:22:42.714+0000] {processor.py:157} INFO - Started process (PID=99332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:22:42.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:22:42.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:22:42.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:22:42.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:22:42.741+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:22:42.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:22:42.751+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:22:42.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:22:42.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T07:23:13.143+0000] {processor.py:157} INFO - Started process (PID=99357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:23:13.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:23:13.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:23:13.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:23:13.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:23:13.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:23:13.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:23:13.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:23:13.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:23:13.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T07:23:43.556+0000] {processor.py:157} INFO - Started process (PID=99382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:23:43.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:23:43.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:23:43.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:23:43.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:23:43.587+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:23:43.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:23:43.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:23:43.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:23:43.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T07:24:13.961+0000] {processor.py:157} INFO - Started process (PID=99407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:24:13.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:24:13.968+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:24:13.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:24:13.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:24:13.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:24:13.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:24:14.001+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:24:14.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:24:14.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T07:24:44.377+0000] {processor.py:157} INFO - Started process (PID=99432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:24:44.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:24:44.379+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:24:44.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:24:44.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:24:44.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:24:44.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:24:44.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:24:44.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:24:44.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T07:25:14.742+0000] {processor.py:157} INFO - Started process (PID=99457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:25:14.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:25:14.744+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:25:14.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:25:14.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:25:14.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:25:14.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:25:14.780+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:25:14.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:25:14.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T07:25:45.198+0000] {processor.py:157} INFO - Started process (PID=99482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:25:45.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:25:45.204+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:25:45.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:25:45.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:25:45.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:25:45.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:25:45.254+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:25:45.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:25:45.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T07:26:15.660+0000] {processor.py:157} INFO - Started process (PID=99506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:26:15.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:26:15.665+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:26:15.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:26:15.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:26:15.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:26:15.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:26:15.713+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:26:15.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:26:15.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T07:26:46.139+0000] {processor.py:157} INFO - Started process (PID=99532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:26:46.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:26:46.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:26:46.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:26:46.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:26:46.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:26:46.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:26:46.176+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:26:46.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:26:46.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T07:27:16.526+0000] {processor.py:157} INFO - Started process (PID=99557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:27:16.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:27:16.529+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:27:16.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:27:16.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:27:16.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:27:16.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:27:16.568+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:27:16.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:27:16.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T07:27:46.966+0000] {processor.py:157} INFO - Started process (PID=99582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:27:46.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:27:46.969+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:27:46.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:27:46.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:27:46.993+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:27:46.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:27:47.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:27:47.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:27:47.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T07:28:17.438+0000] {processor.py:157} INFO - Started process (PID=99607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:28:17.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:28:17.441+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:28:17.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:28:17.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:28:17.474+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:28:17.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:28:17.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:28:17.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:28:17.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T07:28:47.893+0000] {processor.py:157} INFO - Started process (PID=99632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:28:47.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:28:47.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:28:47.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:28:47.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:28:47.928+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:28:47.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:28:47.940+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:28:47.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:28:47.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T07:29:18.409+0000] {processor.py:157} INFO - Started process (PID=99657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:29:18.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:29:18.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:29:18.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:29:18.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:29:18.486+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:29:18.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:29:18.514+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:29:18.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:29:18.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T07:29:48.972+0000] {processor.py:157} INFO - Started process (PID=99682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:29:48.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:29:48.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:29:48.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:29:48.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:29:49.019+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:29:49.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:29:49.034+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:29:49.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:29:49.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T07:30:19.433+0000] {processor.py:157} INFO - Started process (PID=99707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:30:19.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:30:19.435+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:30:19.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:30:19.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:30:19.464+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:30:19.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:30:19.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:30:19.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:30:19.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T07:30:50.236+0000] {processor.py:157} INFO - Started process (PID=99732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:30:50.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:30:50.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:30:50.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:30:50.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:30:50.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:30:50.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:30:50.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:30:50.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:30:50.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T07:31:20.718+0000] {processor.py:157} INFO - Started process (PID=99757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:31:20.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:31:20.720+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:31:20.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:31:20.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:31:20.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:31:20.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:31:20.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:31:20.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:31:20.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-26T07:31:51.163+0000] {processor.py:157} INFO - Started process (PID=99782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:31:51.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:31:51.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:31:51.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:31:51.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:31:51.208+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:31:51.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:31:51.230+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:31:51.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:31:51.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T07:32:21.712+0000] {processor.py:157} INFO - Started process (PID=99806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:32:21.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:32:21.719+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:32:21.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:32:21.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:32:21.773+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:32:21.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:32:21.787+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:32:21.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:32:21.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T07:32:52.170+0000] {processor.py:157} INFO - Started process (PID=99832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:32:52.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:32:52.173+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:32:52.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:32:52.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:32:52.204+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:32:52.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:32:52.215+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:32:52.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:32:52.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T07:33:22.596+0000] {processor.py:157} INFO - Started process (PID=99856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:33:22.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:33:22.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:33:22.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:33:22.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:33:22.655+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:33:22.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:33:22.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:33:22.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:33:22.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T07:33:53.022+0000] {processor.py:157} INFO - Started process (PID=99882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:33:53.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:33:53.025+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:33:53.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:33:53.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:33:53.057+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:33:53.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:33:53.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:33:53.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:33:53.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T07:34:23.425+0000] {processor.py:157} INFO - Started process (PID=99907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:34:23.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:34:23.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:34:23.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:34:23.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:34:23.455+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:34:23.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:34:23.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:34:23.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:34:23.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T07:34:53.845+0000] {processor.py:157} INFO - Started process (PID=99932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:34:53.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:34:53.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:34:53.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:34:53.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:34:53.882+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:34:53.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:34:53.894+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:34:53.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:34:53.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T07:35:24.280+0000] {processor.py:157} INFO - Started process (PID=99957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:35:24.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:35:24.282+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:35:24.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:35:24.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:35:24.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:35:24.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:35:24.319+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:35:24.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:35:24.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T07:35:54.650+0000] {processor.py:157} INFO - Started process (PID=99982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:35:54.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:35:54.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:35:54.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:35:54.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:35:54.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:35:54.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:35:54.690+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:35:54.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:35:54.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T07:36:25.057+0000] {processor.py:157} INFO - Started process (PID=308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:36:25.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:36:25.059+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:36:25.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:36:25.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:36:25.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:36:25.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:36:25.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:36:25.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:36:25.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T07:36:55.547+0000] {processor.py:157} INFO - Started process (PID=333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:36:55.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:36:55.557+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:36:55.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:36:55.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:36:55.584+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:36:55.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:36:55.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:36:55.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:36:55.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T07:37:25.982+0000] {processor.py:157} INFO - Started process (PID=358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:37:25.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:37:25.987+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:37:25.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:37:26.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:37:26.041+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:37:26.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:37:26.054+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:37:26.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:37:26.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T07:37:56.480+0000] {processor.py:157} INFO - Started process (PID=383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:37:56.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:37:56.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:37:56.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:37:56.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:37:56.515+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:37:56.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:37:56.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:37:56.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:37:56.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T07:38:26.917+0000] {processor.py:157} INFO - Started process (PID=407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:38:26.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:38:26.920+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:38:26.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:38:26.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:38:26.955+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:38:26.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:38:26.967+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:38:26.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:38:26.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T07:38:57.375+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:38:57.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:38:57.379+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:38:57.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:38:57.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:38:57.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:38:57.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:38:57.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:38:57.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:38:57.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T07:39:27.812+0000] {processor.py:157} INFO - Started process (PID=458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:39:27.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:39:27.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:39:27.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:39:27.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:39:27.844+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:39:27.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:39:27.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:39:27.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:39:27.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T07:39:58.186+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:39:58.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:39:58.189+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:39:58.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:39:58.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:39:58.217+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:39:58.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:39:58.230+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:39:58.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:39:58.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T07:40:28.614+0000] {processor.py:157} INFO - Started process (PID=508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:40:28.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:40:28.619+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:40:28.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:40:28.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:40:28.656+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:40:28.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:40:28.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:40:28.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:40:28.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T07:40:59.049+0000] {processor.py:157} INFO - Started process (PID=533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:40:59.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:40:59.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:40:59.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:40:59.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:40:59.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:40:59.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:40:59.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:40:59.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:40:59.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T07:41:29.505+0000] {processor.py:157} INFO - Started process (PID=558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:41:29.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:41:29.508+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:41:29.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:41:29.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:41:29.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:41:29.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:41:29.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:41:29.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:41:29.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T07:41:59.975+0000] {processor.py:157} INFO - Started process (PID=583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:41:59.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:41:59.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:41:59.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:41:59.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:42:00.007+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:42:00.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:42:00.019+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:42:00.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:42:00.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T07:42:30.416+0000] {processor.py:157} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:42:30.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:42:30.419+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:42:30.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:42:30.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:42:30.447+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:42:30.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:42:30.460+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:42:30.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:42:30.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T07:43:00.829+0000] {processor.py:157} INFO - Started process (PID=633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:43:00.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:43:00.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:43:00.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:43:00.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:43:00.864+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:43:00.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:43:00.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:43:00.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:43:00.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T07:43:31.295+0000] {processor.py:157} INFO - Started process (PID=658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:43:31.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:43:31.301+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:43:31.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:43:31.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:43:31.339+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:43:31.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:43:31.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:43:31.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:43:31.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T07:44:01.734+0000] {processor.py:157} INFO - Started process (PID=683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:44:01.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:44:01.737+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:44:01.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:44:01.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:44:01.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:44:01.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:44:01.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:44:01.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:44:01.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T07:44:32.174+0000] {processor.py:157} INFO - Started process (PID=708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:44:32.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:44:32.177+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:44:32.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:44:32.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:44:32.206+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:44:32.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:44:32.217+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:44:32.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:44:32.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T07:45:02.601+0000] {processor.py:157} INFO - Started process (PID=733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:45:02.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:45:02.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:45:02.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:45:02.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:45:02.631+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:45:02.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:45:02.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:45:02.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:45:02.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T07:45:33.040+0000] {processor.py:157} INFO - Started process (PID=758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:45:33.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:45:33.046+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:45:33.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:45:33.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:45:33.083+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:45:33.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:45:33.095+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:45:33.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:45:33.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T07:46:03.481+0000] {processor.py:157} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:46:03.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:46:03.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:46:03.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:46:03.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:46:03.509+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:46:03.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:46:03.519+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:46:03.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:46:03.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T07:46:33.903+0000] {processor.py:157} INFO - Started process (PID=808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:46:33.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:46:33.907+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:46:33.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:46:33.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:46:33.936+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:46:33.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:46:33.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:46:33.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:46:33.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T07:47:04.359+0000] {processor.py:157} INFO - Started process (PID=833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:47:04.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:47:04.363+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:47:04.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:47:04.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:47:04.387+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:47:04.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:47:04.397+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:47:04.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:47:04.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T07:47:34.773+0000] {processor.py:157} INFO - Started process (PID=858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:47:34.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:47:34.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:47:34.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:47:34.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:47:34.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:47:34.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:47:34.816+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:47:34.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:47:34.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T07:48:05.219+0000] {processor.py:157} INFO - Started process (PID=883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:48:05.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:48:05.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:48:05.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:48:05.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:48:05.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:48:05.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:48:05.331+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:48:05.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:48:05.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T07:48:35.750+0000] {processor.py:157} INFO - Started process (PID=907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:48:35.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:48:35.755+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:48:35.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:48:35.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:48:35.805+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:48:35.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:48:35.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:48:35.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:48:35.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T07:49:06.285+0000] {processor.py:157} INFO - Started process (PID=933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:49:06.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:49:06.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:49:06.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:49:06.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:49:06.353+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:49:06.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:49:06.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:49:06.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:49:06.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T07:49:36.705+0000] {processor.py:157} INFO - Started process (PID=958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:49:36.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:49:36.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:49:36.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:49:36.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:49:36.807+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:49:36.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:49:36.836+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:49:36.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:49:36.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-26T07:50:07.276+0000] {processor.py:157} INFO - Started process (PID=983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:50:07.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:50:07.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:50:07.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:50:07.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:50:07.396+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:50:07.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:50:07.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:50:07.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:50:07.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-26T07:50:37.829+0000] {processor.py:157} INFO - Started process (PID=1008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:50:37.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:50:37.836+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:50:37.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:50:37.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:50:37.882+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:50:37.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:50:37.898+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:50:37.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:50:37.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T07:51:08.325+0000] {processor.py:157} INFO - Started process (PID=1033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:51:08.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:51:08.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:51:08.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:51:08.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:51:08.384+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:51:08.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:51:08.396+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:51:08.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:51:08.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T07:51:38.889+0000] {processor.py:157} INFO - Started process (PID=1058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:51:38.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:51:38.896+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:51:38.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:51:38.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:51:38.939+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:51:38.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:51:38.952+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:51:38.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:51:38.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-26T07:52:09.383+0000] {processor.py:157} INFO - Started process (PID=1083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:52:09.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:52:09.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:52:09.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:52:09.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:52:09.495+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:52:09.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:52:09.513+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:52:09.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:52:09.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-26T07:52:39.895+0000] {processor.py:157} INFO - Started process (PID=1108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:52:39.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:52:39.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:52:39.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:52:39.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:52:39.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:52:39.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:52:39.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:52:39.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:52:39.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T07:53:10.361+0000] {processor.py:157} INFO - Started process (PID=1133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:53:10.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:53:10.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:53:10.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:53:10.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:53:10.423+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:53:10.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:53:10.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:53:10.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:53:10.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T07:53:40.806+0000] {processor.py:157} INFO - Started process (PID=1158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:53:40.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:53:40.812+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:53:40.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:53:40.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:53:40.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:53:40.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:53:40.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:53:40.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:53:40.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T07:54:11.338+0000] {processor.py:157} INFO - Started process (PID=1183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:54:11.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:54:11.345+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:54:11.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:54:11.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:54:11.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:54:11.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:54:11.415+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:54:11.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:54:11.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T07:54:41.783+0000] {processor.py:157} INFO - Started process (PID=1208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:54:41.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:54:41.789+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:54:41.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:54:41.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:54:41.841+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:54:41.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:54:41.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:54:41.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:54:41.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T07:55:12.337+0000] {processor.py:157} INFO - Started process (PID=1233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:55:12.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:55:12.345+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:55:12.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:55:12.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:55:12.411+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:55:12.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:55:12.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:55:12.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:55:12.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T07:55:42.820+0000] {processor.py:157} INFO - Started process (PID=1258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:55:42.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:55:42.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:55:42.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:55:42.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:55:42.882+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:55:42.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:55:42.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:55:42.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:55:42.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T07:56:13.374+0000] {processor.py:157} INFO - Started process (PID=1283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:56:13.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:56:13.390+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:56:13.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:56:13.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:56:13.451+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:56:13.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:56:13.473+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:56:13.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:56:13.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T07:56:43.948+0000] {processor.py:157} INFO - Started process (PID=1308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:56:43.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:56:43.954+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:56:43.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:56:43.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:56:43.996+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:56:43.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:56:44.009+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:56:44.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:56:44.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T07:57:14.406+0000] {processor.py:157} INFO - Started process (PID=1333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:57:14.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:57:14.411+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:57:14.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:57:14.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:57:14.454+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:57:14.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:57:14.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:57:14.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:57:14.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T07:57:44.897+0000] {processor.py:157} INFO - Started process (PID=1358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:57:44.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:57:44.903+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:57:44.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:57:44.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:57:44.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:57:44.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:57:45.078+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:57:45.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:57:45.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-07-26T07:58:15.572+0000] {processor.py:157} INFO - Started process (PID=1383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:58:15.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:58:15.589+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:58:15.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:58:15.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:58:15.634+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:58:15.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:58:15.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:58:15.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:58:15.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T07:58:45.990+0000] {processor.py:157} INFO - Started process (PID=1408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:58:45.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:58:45.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:58:45.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:58:46.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:58:46.030+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:58:46.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:58:46.042+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:58:46.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:58:46.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T07:59:16.381+0000] {processor.py:157} INFO - Started process (PID=1433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:59:16.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:59:16.385+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:59:16.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:59:16.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:59:16.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:59:16.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:59:16.435+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:59:16.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:59:16.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T07:59:46.859+0000] {processor.py:157} INFO - Started process (PID=1458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:59:46.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T07:59:46.865+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:59:46.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:59:46.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T07:59:46.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:59:46.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T07:59:46.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T07:59:46.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T07:59:46.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T08:00:17.317+0000] {processor.py:157} INFO - Started process (PID=1483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:00:17.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:00:17.321+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:00:17.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:00:17.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:00:17.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:00:17.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:00:17.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:00:17.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:00:17.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T08:00:47.797+0000] {processor.py:157} INFO - Started process (PID=1508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:00:47.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:00:47.801+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:00:47.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:00:47.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:00:47.829+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:00:47.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:00:47.839+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:00:47.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:00:47.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T08:01:18.211+0000] {processor.py:157} INFO - Started process (PID=1533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:01:18.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:01:18.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:01:18.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:01:18.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:01:18.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:01:18.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:01:18.258+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:01:18.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:01:18.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T08:01:48.712+0000] {processor.py:157} INFO - Started process (PID=1557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:01:48.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:01:48.718+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:01:48.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:01:48.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:01:48.766+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:01:48.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:01:48.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:01:48.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:01:48.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T08:02:19.217+0000] {processor.py:157} INFO - Started process (PID=1583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:02:19.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:02:19.225+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:02:19.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:02:19.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:02:19.273+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:02:19.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:02:19.286+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:02:19.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:02:19.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T08:02:49.773+0000] {processor.py:157} INFO - Started process (PID=1608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:02:49.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:02:49.778+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:02:49.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:02:49.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:02:49.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:02:49.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:02:49.843+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:02:49.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:02:49.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T08:03:20.221+0000] {processor.py:157} INFO - Started process (PID=1633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:03:20.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:03:20.224+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:03:20.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:03:20.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:03:20.254+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:03:20.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:03:20.266+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:03:20.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:03:20.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T08:03:50.665+0000] {processor.py:157} INFO - Started process (PID=1658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:03:50.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:03:50.671+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:03:50.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:03:50.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:03:50.709+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:03:50.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:03:50.720+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:03:50.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:03:50.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T08:04:21.396+0000] {processor.py:157} INFO - Started process (PID=1683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:04:21.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:04:21.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:04:21.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:04:21.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:04:21.456+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:04:21.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:04:21.474+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:04:21.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:04:21.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T08:04:51.993+0000] {processor.py:157} INFO - Started process (PID=1708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:04:51.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:04:52.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:04:52.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:04:52.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:04:52.058+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:04:52.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:04:52.075+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:04:52.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:04:52.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T08:05:22.491+0000] {processor.py:157} INFO - Started process (PID=1733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:05:22.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:05:22.499+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:05:22.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:05:22.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:05:22.545+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:05:22.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:05:22.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:05:22.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:05:22.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T08:05:53.022+0000] {processor.py:157} INFO - Started process (PID=1758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:05:53.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:05:53.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:05:53.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:05:53.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:05:53.059+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:05:53.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:05:53.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:05:53.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:05:53.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T08:06:23.437+0000] {processor.py:157} INFO - Started process (PID=1783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:06:23.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:06:23.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:06:23.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:06:23.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:06:23.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:06:23.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:06:23.478+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:06:23.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:06:23.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T08:06:53.937+0000] {processor.py:157} INFO - Started process (PID=1808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:06:53.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:06:53.939+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:06:53.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:06:53.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:06:53.965+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:06:53.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:06:53.976+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:06:53.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:06:53.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T08:07:24.341+0000] {processor.py:157} INFO - Started process (PID=1833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:07:24.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:07:24.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:07:24.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:07:24.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:07:24.401+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:07:24.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:07:24.419+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:07:24.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:07:24.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T08:07:55.033+0000] {processor.py:157} INFO - Started process (PID=1857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:07:55.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:07:55.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:07:55.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:07:55.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:07:55.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:07:55.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:07:55.128+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:07:55.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:07:55.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-26T08:08:25.914+0000] {processor.py:157} INFO - Started process (PID=1883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:08:25.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:08:25.924+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:08:25.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:08:25.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:08:26.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:08:26.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:08:26.025+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:08:26.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:08:26.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-26T08:08:56.709+0000] {processor.py:157} INFO - Started process (PID=1908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:08:56.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:08:56.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:08:56.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:08:56.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:08:56.768+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:08:56.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:08:56.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:08:56.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:08:56.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T08:09:27.192+0000] {processor.py:157} INFO - Started process (PID=1933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:09:27.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:09:27.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:09:27.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:09:27.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:09:27.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:09:27.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:09:27.257+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:09:27.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:09:27.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T08:09:57.675+0000] {processor.py:157} INFO - Started process (PID=1958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:09:57.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:09:57.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:09:57.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:09:57.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:09:57.711+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:09:57.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:09:57.723+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:09:57.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:09:57.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T08:10:28.127+0000] {processor.py:157} INFO - Started process (PID=1983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:10:28.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:10:28.136+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:10:28.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:10:28.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:10:28.185+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:10:28.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:10:28.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:10:28.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:10:28.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T08:10:58.564+0000] {processor.py:157} INFO - Started process (PID=2008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:10:58.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:10:58.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:10:58.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:10:58.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:10:58.594+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:10:58.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:10:58.604+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:10:58.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:10:58.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T08:11:29.026+0000] {processor.py:157} INFO - Started process (PID=2033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:11:29.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:11:29.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:11:29.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:11:29.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:11:29.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:11:29.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:11:29.087+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:11:29.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:11:29.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T08:11:59.462+0000] {processor.py:157} INFO - Started process (PID=2058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:11:59.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:11:59.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:11:59.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:11:59.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:11:59.498+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:11:59.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:11:59.510+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:11:59.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:11:59.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T08:12:29.910+0000] {processor.py:157} INFO - Started process (PID=2083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:12:29.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:12:29.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:12:29.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:12:29.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:12:29.959+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:12:29.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:12:29.973+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:12:29.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:12:29.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T08:13:00.840+0000] {processor.py:157} INFO - Started process (PID=2108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:13:00.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:13:00.847+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:13:00.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:13:00.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:13:00.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:13:00.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:13:00.921+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:13:00.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:13:00.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T08:13:31.348+0000] {processor.py:157} INFO - Started process (PID=2133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:13:31.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:13:31.355+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:13:31.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:13:31.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:13:31.407+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:13:31.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:13:31.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:13:31.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:13:31.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T08:14:01.851+0000] {processor.py:157} INFO - Started process (PID=2158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:14:01.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:14:01.859+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:14:01.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:14:01.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:14:01.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:14:01.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:14:01.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:14:01.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:14:01.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T08:14:32.409+0000] {processor.py:157} INFO - Started process (PID=2183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:14:32.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:14:32.414+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:14:32.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:14:32.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:14:32.460+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:14:32.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:14:32.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:14:32.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:14:32.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T08:15:02.857+0000] {processor.py:157} INFO - Started process (PID=2208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:15:02.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:15:02.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:15:02.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:15:02.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:15:02.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:15:02.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:15:02.898+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:15:02.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:15:02.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T08:15:33.335+0000] {processor.py:157} INFO - Started process (PID=2231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:15:33.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:15:33.345+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:15:33.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:15:33.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:15:33.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:15:33.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:15:33.414+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:15:33.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:15:33.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T08:16:03.828+0000] {processor.py:157} INFO - Started process (PID=2258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:16:03.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:16:03.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:16:03.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:16:03.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:16:03.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:16:03.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:16:03.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:16:03.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:16:03.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T08:16:34.299+0000] {processor.py:157} INFO - Started process (PID=2283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:16:34.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:16:34.304+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:16:34.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:16:34.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:16:34.334+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:16:34.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:16:34.348+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:16:34.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:16:34.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T08:17:04.725+0000] {processor.py:157} INFO - Started process (PID=2307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:17:04.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:17:04.733+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:17:04.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:17:04.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:17:04.783+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:17:04.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:17:04.801+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:17:04.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:17:04.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T08:17:35.145+0000] {processor.py:157} INFO - Started process (PID=2333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:17:35.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:17:35.151+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:17:35.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:17:35.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:17:35.188+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:17:35.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:17:35.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:17:35.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:17:35.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T08:18:05.625+0000] {processor.py:157} INFO - Started process (PID=2357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:18:05.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:18:05.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:18:05.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:18:05.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:18:05.694+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:18:05.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:18:05.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:18:05.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:18:05.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T08:18:36.181+0000] {processor.py:157} INFO - Started process (PID=2383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:18:36.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:18:36.192+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:18:36.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:18:36.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:18:36.277+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:18:36.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:18:36.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:18:36.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:18:36.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T08:19:06.724+0000] {processor.py:157} INFO - Started process (PID=2408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:19:06.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:19:06.730+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:19:06.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:19:06.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:19:06.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:19:06.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:19:06.795+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:19:06.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:19:06.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T08:19:37.195+0000] {processor.py:157} INFO - Started process (PID=2433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:19:37.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:19:37.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:19:37.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:19:37.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:19:37.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:19:37.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:19:37.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:19:37.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:19:37.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T08:20:07.836+0000] {processor.py:157} INFO - Started process (PID=2458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:20:07.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:20:07.844+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:20:07.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:20:07.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:20:07.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:20:07.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:20:07.920+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:20:07.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:20:07.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-26T08:20:38.256+0000] {processor.py:157} INFO - Started process (PID=2483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:20:38.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:20:38.263+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:20:38.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:20:38.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:20:38.313+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:20:38.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:20:38.326+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:20:38.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:20:38.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T08:21:08.763+0000] {processor.py:157} INFO - Started process (PID=2508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:21:08.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:21:08.771+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:21:08.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:21:08.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:21:08.813+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:21:08.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:21:08.825+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:21:08.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:21:08.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T08:21:39.211+0000] {processor.py:157} INFO - Started process (PID=2533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:21:39.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:21:39.218+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:21:39.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:21:39.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:21:39.242+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:21:39.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:21:39.254+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:21:39.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:21:39.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T08:22:09.668+0000] {processor.py:157} INFO - Started process (PID=2558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:22:09.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:22:09.671+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:22:09.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:22:09.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:22:09.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:22:09.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:22:09.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:22:09.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:22:09.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T08:22:40.066+0000] {processor.py:157} INFO - Started process (PID=2583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:22:40.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:22:40.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:22:40.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:22:40.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:22:40.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:22:40.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:22:40.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:22:40.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:22:40.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T08:23:10.484+0000] {processor.py:157} INFO - Started process (PID=2608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:23:10.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:23:10.489+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:23:10.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:23:10.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:23:10.521+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:23:10.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:23:10.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:23:10.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:23:10.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T08:23:40.938+0000] {processor.py:157} INFO - Started process (PID=2632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:23:40.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:23:40.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:23:40.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:23:40.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:23:41.016+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:23:41.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:23:41.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:23:41.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:23:41.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T08:24:11.465+0000] {processor.py:157} INFO - Started process (PID=2658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:24:11.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:24:11.471+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:24:11.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:24:11.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:24:11.514+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:24:11.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:24:11.527+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:24:11.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:24:11.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T08:24:41.983+0000] {processor.py:157} INFO - Started process (PID=2683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:24:41.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:24:41.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:24:41.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:24:42.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:24:42.042+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:24:42.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:24:42.057+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:24:42.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:24:42.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T08:25:12.484+0000] {processor.py:157} INFO - Started process (PID=2708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:25:12.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:25:12.490+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:25:12.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:25:12.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:25:12.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:25:12.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:25:12.585+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:25:12.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:25:12.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-26T08:25:43.022+0000] {processor.py:157} INFO - Started process (PID=2733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:25:43.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:25:43.026+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:25:43.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:25:43.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:25:43.057+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:25:43.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:25:43.069+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:25:43.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:25:43.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T08:26:13.642+0000] {processor.py:157} INFO - Started process (PID=2757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:26:13.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:26:13.648+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:26:13.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:26:13.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:26:13.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:26:13.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:26:13.723+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:26:13.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:26:13.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T08:26:44.094+0000] {processor.py:157} INFO - Started process (PID=2783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:26:44.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:26:44.097+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:26:44.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:26:44.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:26:44.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:26:44.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:26:44.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:26:44.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:26:44.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T08:27:14.529+0000] {processor.py:157} INFO - Started process (PID=2807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:27:14.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:27:14.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:27:14.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:27:14.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:27:14.606+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:27:14.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:27:14.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:27:14.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:27:14.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-26T08:27:45.060+0000] {processor.py:157} INFO - Started process (PID=2833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:27:45.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:27:45.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:27:45.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:27:45.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:27:45.094+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:27:45.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:27:45.104+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:27:45.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:27:45.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T08:28:15.481+0000] {processor.py:157} INFO - Started process (PID=2858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:28:15.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:28:15.491+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:28:15.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:28:15.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:28:15.569+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:28:15.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:28:15.607+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:28:15.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:28:15.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-26T08:28:46.063+0000] {processor.py:157} INFO - Started process (PID=2883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:28:46.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:28:46.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:28:46.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:28:46.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:28:46.170+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:28:46.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:28:46.190+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:28:46.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:28:46.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-26T08:29:16.610+0000] {processor.py:157} INFO - Started process (PID=2908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:29:16.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:29:16.618+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:29:16.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:29:16.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:29:16.660+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:29:16.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:29:16.673+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:29:16.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:29:16.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T08:29:47.054+0000] {processor.py:157} INFO - Started process (PID=2933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:29:47.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:29:47.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:29:47.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:29:47.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:29:47.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:29:47.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:29:47.095+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:29:47.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:29:47.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T08:30:17.467+0000] {processor.py:157} INFO - Started process (PID=2958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:30:17.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:30:17.473+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:30:17.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:30:17.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:30:17.516+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:30:17.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:30:17.531+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:30:17.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:30:17.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T08:30:47.931+0000] {processor.py:157} INFO - Started process (PID=2983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:30:47.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:30:47.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:30:47.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:30:47.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:30:47.960+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:30:47.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:30:47.970+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:30:47.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:30:47.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T08:31:18.394+0000] {processor.py:157} INFO - Started process (PID=3008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:31:18.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:31:18.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:31:18.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:31:18.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:31:18.458+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:31:18.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:31:18.474+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:31:18.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:31:18.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T08:31:49.122+0000] {processor.py:157} INFO - Started process (PID=3033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:31:49.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:31:49.128+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:31:49.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:31:49.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:31:49.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:31:49.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:31:49.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:31:49.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:31:49.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T08:32:19.534+0000] {processor.py:157} INFO - Started process (PID=3058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:32:19.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:32:19.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:32:19.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:32:19.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:32:19.570+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:32:19.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:32:19.582+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:32:19.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:32:19.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T08:32:50.012+0000] {processor.py:157} INFO - Started process (PID=3083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:32:50.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:32:50.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:32:50.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:32:50.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:32:50.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:32:50.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:32:50.057+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:32:50.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:32:50.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T08:33:20.346+0000] {processor.py:157} INFO - Started process (PID=3108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:33:20.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:33:20.349+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:33:20.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:33:20.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:33:20.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:33:20.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:33:20.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:33:20.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:33:20.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T08:33:50.717+0000] {processor.py:157} INFO - Started process (PID=3133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:33:50.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:33:50.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:33:50.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:33:50.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:33:50.750+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:33:50.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:33:50.763+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:33:50.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:33:50.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T08:34:21.199+0000] {processor.py:157} INFO - Started process (PID=3158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:34:21.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:34:21.210+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:34:21.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:34:21.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:34:21.267+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:34:21.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:34:21.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:34:21.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:34:21.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T08:34:51.675+0000] {processor.py:157} INFO - Started process (PID=3183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:34:51.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:34:51.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:34:51.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:34:51.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:34:51.706+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:34:51.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:34:51.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:34:51.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:34:51.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T08:35:22.060+0000] {processor.py:157} INFO - Started process (PID=3208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:35:22.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:35:22.063+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:35:22.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:35:22.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:35:22.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:35:22.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:35:22.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:35:22.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:35:22.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T08:35:52.439+0000] {processor.py:157} INFO - Started process (PID=3233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:35:52.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:35:52.441+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:35:52.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:35:52.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:35:52.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:35:52.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:35:52.481+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:35:52.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:35:52.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T08:36:22.875+0000] {processor.py:157} INFO - Started process (PID=3257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:36:22.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:36:22.885+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:36:22.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:36:22.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:36:22.932+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:36:22.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:36:22.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:36:22.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:36:22.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T08:36:53.385+0000] {processor.py:157} INFO - Started process (PID=3283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:36:53.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:36:53.389+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:36:53.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:36:53.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:36:53.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:36:53.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:36:53.432+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:36:53.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:36:53.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T08:37:24.036+0000] {processor.py:157} INFO - Started process (PID=3307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:37:24.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:37:24.069+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:37:24.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:37:24.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:37:24.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:37:24.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:37:24.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:37:24.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:37:24.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.439 seconds
[2024-07-26T08:37:54.894+0000] {processor.py:157} INFO - Started process (PID=3333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:37:54.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:37:54.904+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:37:54.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:37:54.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:37:54.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:37:54.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:37:55.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:37:55.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:37:55.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-26T08:38:25.463+0000] {processor.py:157} INFO - Started process (PID=3358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:38:25.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:38:25.471+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:38:25.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:38:25.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:38:25.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:38:25.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:38:25.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:38:25.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:38:25.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T08:38:56.056+0000] {processor.py:157} INFO - Started process (PID=3383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:38:56.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:38:56.069+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:38:56.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:38:56.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:38:56.122+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:38:56.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:38:56.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:38:56.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:38:56.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T08:39:26.527+0000] {processor.py:157} INFO - Started process (PID=3408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:39:26.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:39:26.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:39:26.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:39:26.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:39:26.587+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:39:26.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:39:26.601+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:39:26.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:39:26.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T08:39:56.982+0000] {processor.py:157} INFO - Started process (PID=3433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:39:56.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:39:56.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:39:56.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:39:57.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:39:57.033+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:39:57.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:39:57.049+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:39:57.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:39:57.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T08:40:27.434+0000] {processor.py:157} INFO - Started process (PID=3458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:40:27.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:40:27.438+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:40:27.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:40:27.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:40:27.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:40:27.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:40:27.478+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:40:27.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:40:27.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T08:40:57.884+0000] {processor.py:157} INFO - Started process (PID=3483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:40:57.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:40:57.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:40:57.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:40:57.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:40:57.928+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:40:57.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:40:57.940+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:40:57.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:40:57.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T08:41:28.359+0000] {processor.py:157} INFO - Started process (PID=3508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:41:28.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:41:28.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:41:28.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:41:28.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:41:28.389+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:41:28.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:41:28.397+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:41:28.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:41:28.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T08:41:58.759+0000] {processor.py:157} INFO - Started process (PID=3533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:41:58.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:41:58.762+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:41:58.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:41:58.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:41:58.788+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:41:58.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:41:58.799+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:41:58.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:41:58.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T08:42:29.186+0000] {processor.py:157} INFO - Started process (PID=3558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:42:29.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:42:29.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:42:29.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:42:29.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:42:29.231+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:42:29.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:42:29.248+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:42:29.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:42:29.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T08:42:59.637+0000] {processor.py:157} INFO - Started process (PID=3583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:42:59.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:42:59.639+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:42:59.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:42:59.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:42:59.659+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:42:59.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:42:59.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:42:59.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:42:59.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-26T08:43:30.028+0000] {processor.py:157} INFO - Started process (PID=3608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:43:30.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:43:30.030+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:43:30.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:43:30.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:43:30.058+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:43:30.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:43:30.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:43:30.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:43:30.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T08:44:00.502+0000] {processor.py:157} INFO - Started process (PID=3633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:44:00.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:44:00.505+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:44:00.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:44:00.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:44:00.534+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:44:00.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:44:00.544+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:44:00.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:44:00.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T08:44:30.867+0000] {processor.py:157} INFO - Started process (PID=3658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:44:30.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:44:30.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:44:30.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:44:30.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:44:30.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:44:30.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:44:30.923+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:44:30.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:44:30.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T08:45:01.323+0000] {processor.py:157} INFO - Started process (PID=3683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:45:01.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:45:01.326+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:45:01.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:45:01.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:45:01.354+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:45:01.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:45:01.364+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:45:01.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:45:01.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T08:45:31.821+0000] {processor.py:157} INFO - Started process (PID=3708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:45:31.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:45:31.823+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:45:31.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:45:31.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:45:31.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:45:31.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:45:31.865+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:45:31.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:45:31.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T08:46:02.538+0000] {processor.py:157} INFO - Started process (PID=3733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:46:02.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:46:02.556+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:46:02.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:46:02.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:46:02.601+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:46:02.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:46:02.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:46:02.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:46:02.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T08:46:55.501+0000] {processor.py:157} INFO - Started process (PID=3760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:46:55.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T08:46:55.509+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:46:55.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:46:55.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T08:46:55.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:46:55.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T08:46:55.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T08:46:55.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T08:46:55.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T09:03:51.473+0000] {processor.py:157} INFO - Started process (PID=3785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:03:51.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:03:51.494+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:03:51.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:03:51.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:03:51.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:03:51.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:03:51.608+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:03:51.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:03:51.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-26T09:04:22.100+0000] {processor.py:157} INFO - Started process (PID=3810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:04:22.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:04:22.117+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:04:22.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:04:22.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:04:22.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:04:22.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:04:22.182+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:04:22.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:04:22.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-26T09:04:52.583+0000] {processor.py:157} INFO - Started process (PID=3835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:04:52.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:04:52.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:04:52.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:04:52.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:04:52.613+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:04:52.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:04:52.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:04:52.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:04:52.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T09:05:23.001+0000] {processor.py:157} INFO - Started process (PID=3860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:05:23.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:05:23.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:05:23.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:05:23.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:05:23.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:05:23.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:05:23.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:05:23.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:05:23.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-26T09:05:53.533+0000] {processor.py:157} INFO - Started process (PID=3885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:05:53.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:05:53.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:05:53.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:05:53.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:05:53.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:05:53.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:05:53.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:05:53.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:05:53.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T09:06:23.910+0000] {processor.py:157} INFO - Started process (PID=3910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:06:23.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:06:23.924+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:06:23.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:06:23.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:06:23.973+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:06:23.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:06:23.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:06:23.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:06:23.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T09:06:54.380+0000] {processor.py:157} INFO - Started process (PID=3935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:06:54.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:06:54.383+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:06:54.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:06:54.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:06:54.415+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:06:54.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:06:54.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:06:54.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:06:54.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T09:07:24.790+0000] {processor.py:157} INFO - Started process (PID=3960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:07:24.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:07:24.792+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:07:24.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:07:24.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:07:24.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:07:24.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:07:24.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:07:24.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:07:24.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T09:24:02.231+0000] {processor.py:157} INFO - Started process (PID=3985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:24:02.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:24:02.241+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:24:02.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:24:02.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:24:02.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:24:02.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:24:02.297+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:24:02.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:24:02.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T09:24:32.767+0000] {processor.py:157} INFO - Started process (PID=4010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:24:32.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:24:32.773+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:24:32.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:24:32.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:24:32.815+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:24:32.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:24:32.830+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:24:32.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:24:32.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T09:25:03.274+0000] {processor.py:157} INFO - Started process (PID=4037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:25:03.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:25:03.277+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:25:03.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:25:03.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:25:03.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:25:03.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:25:03.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:25:03.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:25:03.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T09:25:33.694+0000] {processor.py:157} INFO - Started process (PID=4062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:25:33.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:25:33.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:25:33.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:25:33.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:25:33.733+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:25:33.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:25:33.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:25:33.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:25:33.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T09:41:16.449+0000] {processor.py:157} INFO - Started process (PID=4089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:41:16.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:41:16.452+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:41:16.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:41:16.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:41:16.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:41:16.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:41:16.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:41:16.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:41:16.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T09:41:46.962+0000] {processor.py:157} INFO - Started process (PID=4114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:41:46.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:41:46.971+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:41:46.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:41:46.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:41:47.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:41:47.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:41:47.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:41:47.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:41:47.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T09:42:17.557+0000] {processor.py:157} INFO - Started process (PID=4139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:42:17.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:42:17.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:42:17.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:42:17.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:42:17.588+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:42:17.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:42:17.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:42:17.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:42:17.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T09:42:47.988+0000] {processor.py:157} INFO - Started process (PID=4164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:42:47.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:42:47.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:42:47.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:42:48.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:42:48.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:42:48.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:42:48.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:42:48.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:42:48.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T09:43:18.538+0000] {processor.py:157} INFO - Started process (PID=4189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:43:18.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:43:18.541+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:43:18.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:43:18.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:43:18.569+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:43:18.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:43:18.582+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:43:18.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:43:18.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T09:43:49.027+0000] {processor.py:157} INFO - Started process (PID=4214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:43:49.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:43:49.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:43:49.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:43:49.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:43:49.058+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:43:49.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:43:49.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:43:49.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:43:49.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T09:44:19.509+0000] {processor.py:157} INFO - Started process (PID=4239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:44:19.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:44:19.515+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:44:19.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:44:19.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:44:19.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:44:19.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:44:19.562+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:44:19.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:44:19.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T09:44:49.964+0000] {processor.py:157} INFO - Started process (PID=4264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:44:49.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:44:49.968+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:44:49.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:44:49.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:44:49.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:44:49.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:44:50.007+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:44:50.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:44:50.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T09:45:20.450+0000] {processor.py:157} INFO - Started process (PID=4289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:45:20.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:45:20.454+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:45:20.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:45:20.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:45:20.485+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:45:20.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:45:20.496+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:45:20.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:45:20.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T09:45:50.894+0000] {processor.py:157} INFO - Started process (PID=4314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:45:50.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:45:50.899+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:45:50.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:45:50.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:45:50.925+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:45:50.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:45:50.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:45:50.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:45:50.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T09:46:21.322+0000] {processor.py:157} INFO - Started process (PID=4339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:46:21.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:46:21.329+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:46:21.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:46:21.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:46:21.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:46:21.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:46:21.380+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:46:21.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:46:21.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T09:46:51.852+0000] {processor.py:157} INFO - Started process (PID=4364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:46:51.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:46:51.856+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:46:51.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:46:51.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:46:51.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:46:51.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:46:51.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:46:51.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:46:51.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T09:47:22.314+0000] {processor.py:157} INFO - Started process (PID=4389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:47:22.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:47:22.316+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:47:22.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:47:22.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:47:22.348+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:47:22.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:47:22.360+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:47:22.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:47:22.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T09:47:52.812+0000] {processor.py:157} INFO - Started process (PID=4414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:47:52.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:47:52.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:47:52.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:47:52.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:47:52.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:47:52.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:47:52.869+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:47:52.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:47:52.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T09:48:23.308+0000] {processor.py:157} INFO - Started process (PID=4439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:48:23.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:48:23.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:48:23.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:48:23.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:48:23.330+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:48:23.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:48:23.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:48:23.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:48:23.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-26T09:48:53.820+0000] {processor.py:157} INFO - Started process (PID=4464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:48:53.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:48:53.824+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:48:53.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:48:53.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:48:53.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:48:53.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:48:53.868+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:48:53.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:48:53.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T09:49:24.319+0000] {processor.py:157} INFO - Started process (PID=4489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:49:24.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:49:24.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:49:24.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:49:24.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:49:24.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:49:24.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:49:24.362+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:49:24.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:49:24.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T09:49:54.822+0000] {processor.py:157} INFO - Started process (PID=4514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:49:54.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:49:54.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:49:54.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:49:54.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:49:54.865+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:49:54.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:49:54.880+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:49:54.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:49:54.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T09:50:25.318+0000] {processor.py:157} INFO - Started process (PID=4539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:50:25.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:50:25.321+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:50:25.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:50:25.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:50:25.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:50:25.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:50:25.365+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:50:25.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:50:25.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T09:50:55.834+0000] {processor.py:157} INFO - Started process (PID=4564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:50:55.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:50:55.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:50:55.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:50:55.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:50:55.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:50:55.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:50:55.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:50:55.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:50:55.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T09:51:26.336+0000] {processor.py:157} INFO - Started process (PID=4589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:51:26.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:51:26.339+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:51:26.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:51:26.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:51:26.371+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:51:26.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:51:26.381+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:51:26.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:51:26.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T09:51:56.708+0000] {processor.py:157} INFO - Started process (PID=4613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:51:56.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:51:56.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:51:56.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:51:56.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:51:56.759+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:51:56.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:51:56.771+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:51:56.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:51:56.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T09:52:27.230+0000] {processor.py:157} INFO - Started process (PID=4639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:52:27.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:52:27.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:52:27.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:52:27.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:52:27.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:52:27.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:52:27.272+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:52:27.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:52:27.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T09:52:57.680+0000] {processor.py:157} INFO - Started process (PID=4664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:52:57.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:52:57.685+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:52:57.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:52:57.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:52:57.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:52:57.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:52:57.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:52:57.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:52:57.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T09:53:28.136+0000] {processor.py:157} INFO - Started process (PID=4689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:53:28.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:53:28.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:53:28.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:53:28.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:53:28.180+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:53:28.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:53:28.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:53:28.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:53:28.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T09:53:58.630+0000] {processor.py:157} INFO - Started process (PID=4714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:53:58.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:53:58.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:53:58.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:53:58.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:53:58.664+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:53:58.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:53:58.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:53:58.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:53:58.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T09:54:29.069+0000] {processor.py:157} INFO - Started process (PID=4738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:54:29.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:54:29.074+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:54:29.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:54:29.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:54:29.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:54:29.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:54:29.122+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:54:29.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:54:29.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T09:54:59.544+0000] {processor.py:157} INFO - Started process (PID=4764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:54:59.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:54:59.550+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:54:59.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:54:59.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:54:59.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:54:59.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:54:59.582+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:54:59.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:54:59.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T09:55:30.055+0000] {processor.py:157} INFO - Started process (PID=4789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:55:30.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:55:30.059+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:55:30.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:55:30.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:55:30.088+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:55:30.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:55:30.099+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:55:30.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:55:30.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T09:56:00.521+0000] {processor.py:157} INFO - Started process (PID=4814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:56:00.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:56:00.525+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:56:00.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:56:00.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:56:00.563+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:56:00.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:56:00.573+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:56:00.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:56:00.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T09:56:31.046+0000] {processor.py:157} INFO - Started process (PID=4839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:56:31.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:56:31.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:56:31.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:56:31.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:56:31.082+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:56:31.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:56:31.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:56:31.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:56:31.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T09:57:01.577+0000] {processor.py:157} INFO - Started process (PID=4864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:57:01.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:57:01.580+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:57:01.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:57:01.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:57:01.619+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:57:01.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:57:01.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:57:01.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:57:01.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T09:57:32.067+0000] {processor.py:157} INFO - Started process (PID=4889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:57:32.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:57:32.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:57:32.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:57:32.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:57:32.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:57:32.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:57:32.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:57:32.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:57:32.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T09:58:02.611+0000] {processor.py:157} INFO - Started process (PID=4914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:58:02.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:58:02.614+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:58:02.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:58:02.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:58:02.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:58:02.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:58:02.655+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:58:02.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:58:02.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T09:58:33.080+0000] {processor.py:157} INFO - Started process (PID=4939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:58:33.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:58:33.083+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:58:33.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:58:33.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:58:33.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:58:33.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:58:33.122+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:58:33.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:58:33.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T09:59:03.538+0000] {processor.py:157} INFO - Started process (PID=4964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:59:03.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:59:03.545+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:59:03.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:59:03.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:59:03.582+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:59:03.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:59:03.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:59:03.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:59:03.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T09:59:33.981+0000] {processor.py:157} INFO - Started process (PID=4989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:59:33.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T09:59:33.983+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:59:33.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:59:33.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T09:59:34.009+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:59:34.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T09:59:34.020+0000] {logging_mixin.py:151} INFO - [2024-07-26T09:59:34.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T09:59:34.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T10:00:04.508+0000] {processor.py:157} INFO - Started process (PID=5014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:00:04.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:00:04.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:00:04.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:00:04.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:00:04.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:00:04.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:00:04.547+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:00:04.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:00:04.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T10:00:35.123+0000] {processor.py:157} INFO - Started process (PID=5037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:00:35.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:00:35.129+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:00:35.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:00:35.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:00:35.168+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:00:35.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:00:35.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:00:35.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:00:35.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T10:01:05.660+0000] {processor.py:157} INFO - Started process (PID=5064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:01:05.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:01:05.664+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:01:05.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:01:05.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:01:05.694+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:01:05.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:01:05.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:01:05.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:01:05.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T10:01:36.082+0000] {processor.py:157} INFO - Started process (PID=5088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:01:36.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:01:36.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:01:36.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:01:36.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:01:36.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:01:36.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:01:36.130+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:01:36.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:01:36.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T10:02:06.609+0000] {processor.py:157} INFO - Started process (PID=5114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:02:06.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:02:06.613+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:02:06.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:02:06.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:02:06.642+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:02:06.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:02:06.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:02:06.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:02:06.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T10:02:37.093+0000] {processor.py:157} INFO - Started process (PID=5139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:02:37.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:02:37.097+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:02:37.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:02:37.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:02:37.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:02:37.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:02:37.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:02:37.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:02:37.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T10:03:07.531+0000] {processor.py:157} INFO - Started process (PID=5164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:03:07.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:03:07.536+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:03:07.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:03:07.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:03:07.569+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:03:07.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:03:07.581+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:03:07.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:03:07.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T10:03:38.049+0000] {processor.py:157} INFO - Started process (PID=5189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:03:38.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:03:38.055+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:03:38.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:03:38.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:03:38.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:03:38.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:03:38.099+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:03:38.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:03:38.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T10:04:08.467+0000] {processor.py:157} INFO - Started process (PID=5214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:04:08.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:04:08.470+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:04:08.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:04:08.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:04:08.503+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:04:08.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:04:08.516+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:04:08.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:04:08.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T10:04:38.933+0000] {processor.py:157} INFO - Started process (PID=5239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:04:38.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:04:38.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:04:38.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:04:38.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:04:38.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:04:38.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:04:38.974+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:04:38.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:04:38.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T10:05:09.361+0000] {processor.py:157} INFO - Started process (PID=5264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:05:09.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:05:09.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:05:09.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:05:09.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:05:09.406+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:05:09.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:05:09.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:05:09.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:05:09.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T10:05:39.859+0000] {processor.py:157} INFO - Started process (PID=5289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:05:39.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:05:39.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:05:39.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:05:39.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:05:39.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:05:39.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:05:39.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:05:39.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:05:39.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T10:06:10.287+0000] {processor.py:157} INFO - Started process (PID=5314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:06:10.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:06:10.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:06:10.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:06:10.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:06:10.325+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:06:10.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:06:10.335+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:06:10.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:06:10.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T10:06:40.769+0000] {processor.py:157} INFO - Started process (PID=5339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:06:40.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:06:40.774+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:06:40.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:06:40.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:06:40.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:06:40.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:06:40.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:06:40.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:06:40.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T10:07:11.284+0000] {processor.py:157} INFO - Started process (PID=5364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:07:11.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:07:11.288+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:07:11.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:07:11.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:07:11.325+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:07:11.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:07:11.338+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:07:11.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:07:11.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T10:07:41.784+0000] {processor.py:157} INFO - Started process (PID=5389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:07:41.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:07:41.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:07:41.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:07:41.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:07:41.848+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:07:41.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:07:41.859+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:07:41.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:07:41.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T10:08:12.274+0000] {processor.py:157} INFO - Started process (PID=5414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:08:12.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:08:12.277+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:08:12.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:08:12.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:08:12.304+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:08:12.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:08:12.314+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:08:12.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:08:12.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T10:08:42.699+0000] {processor.py:157} INFO - Started process (PID=5439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:08:42.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:08:42.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:08:42.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:08:42.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:08:42.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:08:42.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:08:42.750+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:08:42.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:08:42.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T10:09:13.210+0000] {processor.py:157} INFO - Started process (PID=5464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:09:13.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:09:13.214+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:09:13.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:09:13.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:09:13.251+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:09:13.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:09:13.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:09:13.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:09:13.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T10:09:43.689+0000] {processor.py:157} INFO - Started process (PID=5489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:09:43.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:09:43.693+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:09:43.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:09:43.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:09:43.723+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:09:43.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:09:43.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:09:43.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:09:43.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T10:10:14.131+0000] {processor.py:157} INFO - Started process (PID=5514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:10:14.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:10:14.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:10:14.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:10:14.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:10:14.162+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:10:14.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:10:14.173+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:10:14.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:10:14.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T10:10:44.539+0000] {processor.py:157} INFO - Started process (PID=5539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:10:44.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:10:44.542+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:10:44.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:10:44.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:10:44.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:10:44.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:10:44.585+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:10:44.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:10:44.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T10:11:15.035+0000] {processor.py:157} INFO - Started process (PID=5564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:11:15.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:11:15.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:11:15.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:11:15.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:11:15.074+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:11:15.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:11:15.085+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:11:15.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:11:15.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T10:11:45.504+0000] {processor.py:157} INFO - Started process (PID=5589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:11:45.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:11:45.506+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:11:45.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:11:45.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:11:45.527+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:11:45.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:11:45.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:11:45.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:11:45.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-26T10:12:16.020+0000] {processor.py:157} INFO - Started process (PID=5614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:12:16.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:12:16.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:12:16.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:12:16.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:12:16.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:12:16.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:12:16.075+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:12:16.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:12:16.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T10:12:46.558+0000] {processor.py:157} INFO - Started process (PID=5639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:12:46.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:12:46.562+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:12:46.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:12:46.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:12:46.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:12:46.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:12:46.610+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:12:46.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:12:46.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T10:13:17.014+0000] {processor.py:157} INFO - Started process (PID=5664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:13:17.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:13:17.018+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:13:17.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:13:17.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:13:17.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:13:17.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:13:17.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:13:17.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:13:17.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T10:13:47.527+0000] {processor.py:157} INFO - Started process (PID=5689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:13:47.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:13:47.534+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:13:47.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:13:47.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:13:47.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:13:47.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:13:47.583+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:13:47.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:13:47.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T10:14:17.960+0000] {processor.py:157} INFO - Started process (PID=5714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:14:17.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:14:17.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:14:17.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:14:17.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:14:17.997+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:14:17.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:14:18.007+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:14:18.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:14:18.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T10:14:48.450+0000] {processor.py:157} INFO - Started process (PID=5739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:14:48.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:14:48.454+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:14:48.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:14:48.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:14:48.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:14:48.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:14:48.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:14:48.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:14:48.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T10:15:18.858+0000] {processor.py:157} INFO - Started process (PID=5764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:15:18.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:15:18.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:15:18.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:15:18.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:15:18.924+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:15:18.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:15:18.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:15:18.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:15:18.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T10:15:49.440+0000] {processor.py:157} INFO - Started process (PID=5789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:15:49.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:15:49.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:15:49.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:15:49.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:15:49.472+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:15:49.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:15:49.485+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:15:49.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:15:49.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T10:16:19.818+0000] {processor.py:157} INFO - Started process (PID=5814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:16:19.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:16:19.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:16:19.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:16:19.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:16:19.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:16:19.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:16:19.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:16:19.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:16:19.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T10:16:50.356+0000] {processor.py:157} INFO - Started process (PID=5839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:16:50.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:16:50.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:16:50.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:16:50.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:16:50.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:16:50.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:16:50.415+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:16:50.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:16:50.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T10:17:20.888+0000] {processor.py:157} INFO - Started process (PID=5864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:17:20.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:17:20.891+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:17:20.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:17:20.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:17:20.917+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:17:20.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:17:20.927+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:17:20.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:17:20.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T10:17:51.379+0000] {processor.py:157} INFO - Started process (PID=5889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:17:51.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:17:51.384+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:17:51.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:17:51.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:17:51.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:17:51.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:17:51.425+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:17:51.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:17:51.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T10:18:21.833+0000] {processor.py:157} INFO - Started process (PID=5913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:18:21.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:18:21.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:18:21.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:18:21.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:18:21.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:18:21.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:18:21.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:18:21.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:18:21.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T10:18:52.361+0000] {processor.py:157} INFO - Started process (PID=5939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:18:52.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:18:52.364+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:18:52.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:18:52.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:18:52.390+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:18:52.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:18:52.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:18:52.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:18:52.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T10:19:22.868+0000] {processor.py:157} INFO - Started process (PID=5964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:19:22.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:19:22.871+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:19:22.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:19:22.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:19:22.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:19:22.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:19:22.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:19:22.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:19:22.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T10:19:53.283+0000] {processor.py:157} INFO - Started process (PID=5989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:19:53.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:19:53.287+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:19:53.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:19:53.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:19:53.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:19:53.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:19:53.335+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:19:53.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:19:53.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T10:20:23.756+0000] {processor.py:157} INFO - Started process (PID=6013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:20:23.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:20:23.758+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:20:23.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:20:23.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:20:23.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:20:23.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:20:23.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:20:23.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:20:23.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T10:20:54.163+0000] {processor.py:157} INFO - Started process (PID=6039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:20:54.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:20:54.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:20:54.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:20:54.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:20:54.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:20:54.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:20:54.205+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:20:54.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:20:54.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T10:21:24.645+0000] {processor.py:157} INFO - Started process (PID=6064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:21:24.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:21:24.650+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:21:24.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:21:24.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:21:24.689+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:21:24.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:21:24.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:21:24.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:21:24.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T10:21:55.150+0000] {processor.py:157} INFO - Started process (PID=6088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:21:55.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:21:55.153+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:21:55.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:21:55.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:21:55.178+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:21:55.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:21:55.192+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:21:55.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:21:55.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T10:22:25.625+0000] {processor.py:157} INFO - Started process (PID=6114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:22:25.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:22:25.630+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:22:25.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:22:25.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:22:25.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:22:25.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:22:25.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:22:25.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:22:25.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T10:22:56.085+0000] {processor.py:157} INFO - Started process (PID=6139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:22:56.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:22:56.089+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:22:56.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:22:56.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:22:56.129+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:22:56.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:22:56.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:22:56.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:22:56.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T10:23:26.586+0000] {processor.py:157} INFO - Started process (PID=6164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:23:26.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:23:26.589+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:23:26.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:23:26.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:23:26.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:23:26.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:23:26.627+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:23:26.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:23:26.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T10:23:57.085+0000] {processor.py:157} INFO - Started process (PID=6189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:23:57.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:23:57.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:23:57.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:23:57.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:23:57.121+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:23:57.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:23:57.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:23:57.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:23:57.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T10:24:27.544+0000] {processor.py:157} INFO - Started process (PID=6214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:24:27.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:24:27.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:24:27.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:24:27.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:24:27.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:24:27.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:24:27.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:24:27.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:24:27.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T10:24:58.034+0000] {processor.py:157} INFO - Started process (PID=6239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:24:58.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:24:58.036+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:24:58.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:24:58.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:24:58.061+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:24:58.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:24:58.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:24:58.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:24:58.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T10:25:28.538+0000] {processor.py:157} INFO - Started process (PID=6264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:25:28.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:25:28.541+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:25:28.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:25:28.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:25:28.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:25:28.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:25:28.584+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:25:28.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:25:28.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T10:25:59.005+0000] {processor.py:157} INFO - Started process (PID=6289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:25:59.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:25:59.012+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:25:59.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:25:59.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:25:59.056+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:25:59.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:25:59.068+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:25:59.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:25:59.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T10:26:29.530+0000] {processor.py:157} INFO - Started process (PID=6314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:26:29.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:26:29.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:26:29.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:26:29.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:26:29.573+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:26:29.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:26:29.583+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:26:29.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:26:29.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T10:27:00.285+0000] {processor.py:157} INFO - Started process (PID=6339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:27:00.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:27:00.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:27:00.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:27:00.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:27:00.644+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:27:00.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:27:00.734+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:27:00.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:27:00.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.543 seconds
[2024-07-26T10:27:31.714+0000] {processor.py:157} INFO - Started process (PID=6364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:27:31.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:27:31.730+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:27:31.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:27:31.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:27:31.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:27:31.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:27:31.799+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:27:31.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:27:31.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T10:28:02.178+0000] {processor.py:157} INFO - Started process (PID=6389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:28:02.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:28:02.185+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:28:02.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:28:02.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:28:02.224+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:28:02.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:28:02.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:28:02.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:28:02.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T10:28:32.665+0000] {processor.py:157} INFO - Started process (PID=6414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:28:32.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:28:32.669+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:28:32.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:28:32.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:28:32.699+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:28:32.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:28:32.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:28:32.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:28:32.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T10:29:03.070+0000] {processor.py:157} INFO - Started process (PID=6439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:29:03.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:29:03.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:29:03.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:29:03.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:29:03.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:29:03.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:29:03.116+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:29:03.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:29:03.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T10:29:33.487+0000] {processor.py:157} INFO - Started process (PID=6464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:29:33.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:29:33.490+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:29:33.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:29:33.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:29:33.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:29:33.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:29:33.527+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:29:33.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:29:33.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T10:30:03.875+0000] {processor.py:157} INFO - Started process (PID=6489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:30:03.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:30:03.881+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:30:03.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:30:03.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:30:03.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:30:03.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:30:03.927+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:30:03.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:30:03.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T10:30:34.341+0000] {processor.py:157} INFO - Started process (PID=6514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:30:34.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:30:34.346+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:30:34.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:30:34.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:30:34.389+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:30:34.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:30:34.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:30:34.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:30:34.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T10:31:04.770+0000] {processor.py:157} INFO - Started process (PID=6539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:31:04.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:31:04.772+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:31:04.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:31:04.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:31:04.805+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:31:04.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:31:04.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:31:04.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:31:04.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T10:31:35.289+0000] {processor.py:157} INFO - Started process (PID=6564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:31:35.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:31:35.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:31:35.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:31:35.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:31:35.331+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:31:35.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:31:35.344+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:31:35.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:31:35.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T10:32:05.761+0000] {processor.py:157} INFO - Started process (PID=6589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:32:05.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:32:05.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:32:05.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:32:05.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:32:05.791+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:32:05.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:32:05.801+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:32:05.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:32:05.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T10:32:36.177+0000] {processor.py:157} INFO - Started process (PID=6614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:32:36.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:32:36.180+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:32:36.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:32:36.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:32:36.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:32:36.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:32:36.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:32:36.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:32:36.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T10:33:06.587+0000] {processor.py:157} INFO - Started process (PID=6639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:33:06.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:33:06.589+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:33:06.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:33:06.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:33:06.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:33:06.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:33:06.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:33:06.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:33:06.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T10:33:36.989+0000] {processor.py:157} INFO - Started process (PID=6664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:33:36.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:33:36.993+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:33:36.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:33:37.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:33:37.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:33:37.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:33:37.039+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:33:37.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:33:37.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T10:34:07.577+0000] {processor.py:157} INFO - Started process (PID=6689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:34:07.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:34:07.585+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:34:07.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:34:07.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:34:07.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:34:07.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:34:07.689+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:34:07.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:34:07.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T10:34:38.139+0000] {processor.py:157} INFO - Started process (PID=6714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:34:38.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:34:38.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:34:38.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:34:38.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:34:38.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:34:38.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:34:38.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:34:38.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:34:38.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T10:35:08.703+0000] {processor.py:157} INFO - Started process (PID=6739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:35:08.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:35:08.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:35:08.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:35:08.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:35:08.773+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:35:08.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:35:08.795+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:35:08.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:35:08.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T10:35:39.216+0000] {processor.py:157} INFO - Started process (PID=6764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:35:39.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:35:39.221+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:35:39.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:35:39.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:35:39.268+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:35:39.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:35:39.287+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:35:39.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:35:39.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T10:36:09.787+0000] {processor.py:157} INFO - Started process (PID=6789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:36:09.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:36:09.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:36:09.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:36:09.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:36:09.867+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:36:09.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:36:09.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:36:09.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:36:09.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T10:36:40.338+0000] {processor.py:157} INFO - Started process (PID=6814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:36:40.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:36:40.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:36:40.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:36:40.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:36:40.434+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:36:40.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:36:40.453+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:36:40.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:36:40.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-26T10:37:10.951+0000] {processor.py:157} INFO - Started process (PID=6838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:37:10.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:37:10.961+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:37:10.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:37:10.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:37:11.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:37:11.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:37:11.064+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:37:11.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:37:11.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-26T10:37:41.415+0000] {processor.py:157} INFO - Started process (PID=6864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:37:41.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:37:41.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:37:41.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:37:41.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:37:41.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:37:41.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:37:41.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:37:41.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:37:41.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T10:38:11.952+0000] {processor.py:157} INFO - Started process (PID=6889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:38:11.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:38:11.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:38:11.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:38:11.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:38:12.030+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:38:12.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:38:12.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:38:12.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:38:12.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T10:38:42.503+0000] {processor.py:157} INFO - Started process (PID=6914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:38:42.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:38:42.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:38:42.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:38:42.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:38:42.580+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:38:42.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:38:42.610+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:38:42.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:38:42.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T10:39:13.106+0000] {processor.py:157} INFO - Started process (PID=6939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:39:13.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:39:13.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:39:13.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:39:13.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:39:13.177+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:39:13.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:39:13.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:39:13.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:39:13.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-26T10:39:43.630+0000] {processor.py:157} INFO - Started process (PID=6964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:39:43.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:39:43.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:39:43.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:39:43.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:39:43.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:39:43.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:39:43.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:39:43.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:39:43.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-07-26T10:40:14.284+0000] {processor.py:157} INFO - Started process (PID=6989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:40:14.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:40:14.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:40:14.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:40:14.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:40:14.359+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:40:14.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:40:14.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:40:14.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:40:14.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T10:40:44.845+0000] {processor.py:157} INFO - Started process (PID=7013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:40:44.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:40:44.851+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:40:44.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:40:44.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:40:44.903+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:40:44.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:40:44.919+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:40:44.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:40:44.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T10:41:15.318+0000] {processor.py:157} INFO - Started process (PID=7039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:41:15.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:41:15.326+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:41:15.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:41:15.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:41:15.375+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:41:15.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:41:15.403+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:41:15.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:41:15.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T10:41:45.767+0000] {processor.py:157} INFO - Started process (PID=7064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:41:45.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:41:45.774+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:41:45.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:41:45.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:41:45.821+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:41:45.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:41:45.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:41:45.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:41:45.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T10:42:16.298+0000] {processor.py:157} INFO - Started process (PID=7089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:42:16.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:42:16.305+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:42:16.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:42:16.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:42:16.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:42:16.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:42:16.397+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:42:16.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:42:16.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-26T10:42:46.822+0000] {processor.py:157} INFO - Started process (PID=7114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:42:46.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:42:46.829+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:42:46.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:42:46.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:42:46.893+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:42:46.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:42:46.908+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:42:46.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:42:46.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-26T10:43:17.377+0000] {processor.py:157} INFO - Started process (PID=7139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:43:17.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:43:17.387+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:43:17.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:43:17.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:43:17.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:43:17.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:43:17.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:43:17.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:43:17.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T10:43:47.939+0000] {processor.py:157} INFO - Started process (PID=7164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:43:47.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:43:47.946+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:43:47.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:43:47.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:43:48.007+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:43:48.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:43:48.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:43:48.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:43:48.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-26T10:44:18.490+0000] {processor.py:157} INFO - Started process (PID=7189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:44:18.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:44:18.499+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:44:18.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:44:18.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:44:18.574+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:44:18.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:44:18.599+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:44:18.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:44:18.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-26T10:44:49.106+0000] {processor.py:157} INFO - Started process (PID=7214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:44:49.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:44:49.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:44:49.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:44:49.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:44:49.174+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:44:49.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:44:49.205+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:44:49.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:44:49.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T10:45:19.662+0000] {processor.py:157} INFO - Started process (PID=7239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:45:19.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:45:19.672+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:45:19.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:45:19.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:45:19.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:45:19.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:45:19.747+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:45:19.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:45:19.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-26T10:45:50.134+0000] {processor.py:157} INFO - Started process (PID=7264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:45:50.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:45:50.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:45:50.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:45:50.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:45:50.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:45:50.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:45:50.237+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:45:50.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:45:50.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-26T10:46:20.702+0000] {processor.py:157} INFO - Started process (PID=7289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:46:20.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:46:20.712+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:46:20.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:46:20.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:46:20.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:46:20.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:46:20.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:46:20.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:46:20.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-26T10:46:51.257+0000] {processor.py:157} INFO - Started process (PID=7314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:46:51.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:46:51.268+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:46:51.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:46:51.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:46:51.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:46:51.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:46:51.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:46:51.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:46:51.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-26T10:47:21.809+0000] {processor.py:157} INFO - Started process (PID=7339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:47:21.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:47:21.817+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:47:21.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:47:21.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:47:21.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:47:21.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:47:21.881+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:47:21.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:47:21.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T10:47:52.388+0000] {processor.py:157} INFO - Started process (PID=7364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:47:52.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:47:52.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:47:52.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:47:52.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:47:52.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:47:52.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:47:52.482+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:47:52.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:47:52.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-26T10:48:22.931+0000] {processor.py:157} INFO - Started process (PID=7389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:48:22.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:48:22.940+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:48:22.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:48:22.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:48:22.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:48:22.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:48:23.008+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:48:23.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:48:23.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T10:48:53.455+0000] {processor.py:157} INFO - Started process (PID=7414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:48:53.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:48:53.474+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:48:53.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:48:53.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:48:53.562+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:48:53.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:48:53.583+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:48:53.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:48:53.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-26T10:49:24.064+0000] {processor.py:157} INFO - Started process (PID=7439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:49:24.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:49:24.074+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:49:24.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:49:24.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:49:24.133+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:49:24.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:49:24.153+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:49:24.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:49:24.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-26T10:49:54.621+0000] {processor.py:157} INFO - Started process (PID=7464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:49:54.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:49:54.633+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:49:54.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:49:54.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:49:54.693+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:49:54.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:49:54.711+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:49:54.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:49:54.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-26T10:50:25.196+0000] {processor.py:157} INFO - Started process (PID=7489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:50:25.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:50:25.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:50:25.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:50:25.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:50:25.282+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:50:25.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:50:25.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:50:25.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:50:25.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T10:50:55.748+0000] {processor.py:157} INFO - Started process (PID=7514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:50:55.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:50:55.759+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:50:55.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:50:55.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:50:55.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:50:55.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:50:55.844+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:50:55.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:50:55.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-26T10:51:26.411+0000] {processor.py:157} INFO - Started process (PID=7538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:51:26.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:51:26.418+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:51:26.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:51:26.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:51:26.480+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:51:26.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:51:26.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:51:26.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:51:26.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T10:51:56.948+0000] {processor.py:157} INFO - Started process (PID=7564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:51:56.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:51:56.957+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:51:56.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:51:56.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:51:57.036+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:51:57.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:51:57.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:51:57.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:51:57.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T10:52:27.559+0000] {processor.py:157} INFO - Started process (PID=7589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:52:27.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:52:27.570+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:52:27.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:52:27.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:52:27.657+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:52:27.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:52:27.683+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:52:27.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:52:27.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-07-26T10:52:58.213+0000] {processor.py:157} INFO - Started process (PID=7614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:52:58.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:52:58.221+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:52:58.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:52:58.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:52:58.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:52:58.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:52:58.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:52:58.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:52:58.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-26T10:53:28.823+0000] {processor.py:157} INFO - Started process (PID=7639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:53:28.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:53:28.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:53:28.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:53:28.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:53:28.896+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:53:28.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:53:28.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:53:28.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:53:28.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-26T10:53:59.348+0000] {processor.py:157} INFO - Started process (PID=7664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:53:59.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:53:59.355+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:53:59.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:53:59.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:53:59.415+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:53:59.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:53:59.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:53:59.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:53:59.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-26T10:54:29.876+0000] {processor.py:157} INFO - Started process (PID=7689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:54:29.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:54:29.887+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:54:29.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:54:29.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:54:29.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:54:29.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:54:29.974+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:54:29.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:54:29.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-26T10:55:00.459+0000] {processor.py:157} INFO - Started process (PID=7714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:55:00.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:55:00.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:55:00.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:55:00.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:55:00.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:55:00.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:55:00.575+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:55:00.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:55:00.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-26T10:55:30.962+0000] {processor.py:157} INFO - Started process (PID=7738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:55:30.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:55:30.970+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:55:30.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:55:31.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:55:31.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:55:31.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:55:31.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:55:31.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:55:31.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-26T10:56:01.499+0000] {processor.py:157} INFO - Started process (PID=7764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:56:01.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:56:01.507+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:56:01.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:56:01.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:56:01.575+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:56:01.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:56:01.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:56:01.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:56:01.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-26T10:56:32.010+0000] {processor.py:157} INFO - Started process (PID=7789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:56:32.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:56:32.018+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:56:32.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:56:32.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:56:32.087+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:56:32.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:56:32.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:56:32.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:56:32.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T10:57:02.592+0000] {processor.py:157} INFO - Started process (PID=7814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:57:02.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:57:02.607+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:57:02.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:57:02.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:57:02.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:57:02.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:57:02.718+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:57:02.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:57:02.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-26T10:57:33.153+0000] {processor.py:157} INFO - Started process (PID=7839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:57:33.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:57:33.162+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:57:33.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:57:33.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:57:33.231+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:57:33.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:57:33.254+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:57:33.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:57:33.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-26T10:58:03.732+0000] {processor.py:157} INFO - Started process (PID=7864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:58:03.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:58:03.743+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:58:03.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:58:03.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:58:03.826+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:58:03.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:58:03.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:58:03.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:58:03.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-26T10:58:34.261+0000] {processor.py:157} INFO - Started process (PID=7889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:58:34.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:58:34.265+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:58:34.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:58:34.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:58:34.333+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:58:34.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:58:34.353+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:58:34.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:58:34.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-26T10:59:04.818+0000] {processor.py:157} INFO - Started process (PID=7914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:59:04.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:59:04.824+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:59:04.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:59:04.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:59:04.888+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:59:04.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:59:04.906+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:59:04.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:59:04.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-26T10:59:35.434+0000] {processor.py:157} INFO - Started process (PID=7939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:59:35.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T10:59:35.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:59:35.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:59:35.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T10:59:35.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:59:35.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T10:59:35.542+0000] {logging_mixin.py:151} INFO - [2024-07-26T10:59:35.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T10:59:35.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-26T11:00:05.972+0000] {processor.py:157} INFO - Started process (PID=7964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:00:05.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:00:05.980+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:00:05.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:00:06.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:00:06.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:00:06.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:00:06.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:00:06.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:00:06.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-26T11:00:36.548+0000] {processor.py:157} INFO - Started process (PID=7988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:00:36.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:00:36.567+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:00:36.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:00:36.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:00:36.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:00:36.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:00:36.669+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:00:36.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:00:36.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-26T11:01:07.156+0000] {processor.py:157} INFO - Started process (PID=8013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:01:07.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:01:07.165+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:01:07.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:01:07.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:01:07.227+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:01:07.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:01:07.250+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:01:07.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:01:07.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-26T11:01:37.699+0000] {processor.py:157} INFO - Started process (PID=8039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:01:37.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:01:37.707+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:01:37.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:01:37.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:01:37.748+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:01:37.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:01:37.766+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:01:37.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:01:37.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T11:02:08.128+0000] {processor.py:157} INFO - Started process (PID=8064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:02:08.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:02:08.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:02:08.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:02:08.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:02:08.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:02:08.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:02:08.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:02:08.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:02:08.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T11:02:38.623+0000] {processor.py:157} INFO - Started process (PID=8088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:02:38.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:02:38.631+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:02:38.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:02:38.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:02:38.709+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:02:38.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:02:38.731+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:02:38.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:02:38.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-26T11:03:09.254+0000] {processor.py:157} INFO - Started process (PID=8113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:03:09.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:03:09.263+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:03:09.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:03:09.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:03:09.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:03:09.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:03:09.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:03:09.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:03:09.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-26T11:03:39.795+0000] {processor.py:157} INFO - Started process (PID=8138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:03:39.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:03:39.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:03:39.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:03:39.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:03:39.873+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:03:39.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:03:39.893+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:03:39.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:03:39.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-26T11:04:10.331+0000] {processor.py:157} INFO - Started process (PID=8164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:04:10.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:04:10.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:04:10.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:04:10.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:04:10.435+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:04:10.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:04:10.472+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:04:10.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:04:10.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-07-26T11:04:40.923+0000] {processor.py:157} INFO - Started process (PID=8189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:04:40.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:04:40.932+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:04:40.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:04:40.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:04:41.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:04:41.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:04:41.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:04:41.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:04:41.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-26T11:05:11.524+0000] {processor.py:157} INFO - Started process (PID=8214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:05:11.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:05:11.549+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:05:11.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:05:11.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:05:11.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:05:11.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:05:11.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:05:11.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:05:11.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-26T11:05:41.980+0000] {processor.py:157} INFO - Started process (PID=8239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:05:41.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:05:41.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:05:41.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:05:42.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:05:42.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:05:42.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:05:42.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:05:42.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:05:42.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T11:06:12.552+0000] {processor.py:157} INFO - Started process (PID=8264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:06:12.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:06:12.577+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:06:12.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:06:12.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:06:12.636+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:06:12.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:06:12.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:06:12.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:06:12.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-26T11:06:43.096+0000] {processor.py:157} INFO - Started process (PID=8289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:06:43.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:06:43.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:06:43.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:06:43.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:06:43.167+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:06:43.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:06:43.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:06:43.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:06:43.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T11:07:13.631+0000] {processor.py:157} INFO - Started process (PID=8314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:07:13.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:07:13.640+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:07:13.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:07:13.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:07:13.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:07:13.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:07:13.730+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:07:13.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:07:13.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-26T11:07:44.183+0000] {processor.py:157} INFO - Started process (PID=8339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:07:44.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:07:44.188+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:07:44.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:07:44.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:07:44.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:07:44.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:07:44.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:07:44.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:07:44.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T11:08:14.743+0000] {processor.py:157} INFO - Started process (PID=8364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:08:14.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:08:14.750+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:08:14.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:08:14.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:08:14.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:08:14.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:08:14.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:08:14.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:08:14.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-26T11:08:45.249+0000] {processor.py:157} INFO - Started process (PID=8389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:08:45.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:08:45.257+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:08:45.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:08:45.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:08:45.329+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:08:45.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:08:45.348+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:08:45.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:08:45.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T11:09:15.785+0000] {processor.py:157} INFO - Started process (PID=8414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:09:15.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:09:15.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:09:15.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:09:15.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:09:15.892+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:09:15.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:09:15.912+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:09:15.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:09:15.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-26T11:09:46.280+0000] {processor.py:157} INFO - Started process (PID=8439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:09:46.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:09:46.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:09:46.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:09:46.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:09:46.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:09:46.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:09:46.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:09:46.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:09:46.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T11:10:16.849+0000] {processor.py:157} INFO - Started process (PID=8464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:10:16.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:10:16.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:10:16.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:10:16.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:10:16.918+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:10:16.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:10:16.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:10:16.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:10:16.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T11:10:47.351+0000] {processor.py:157} INFO - Started process (PID=8489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:10:47.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:10:47.358+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:10:47.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:10:47.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:10:47.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:10:47.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:10:47.436+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:10:47.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:10:47.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-26T11:11:17.898+0000] {processor.py:157} INFO - Started process (PID=8514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:11:17.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:11:17.906+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:11:17.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:11:17.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:11:17.969+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:11:17.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:11:17.991+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:11:17.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:11:18.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-26T11:11:48.452+0000] {processor.py:157} INFO - Started process (PID=8539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:11:48.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:11:48.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:11:48.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:11:48.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:11:48.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:11:48.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:11:48.569+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:11:48.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:11:48.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-07-26T11:12:19.060+0000] {processor.py:157} INFO - Started process (PID=8564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:12:19.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:12:19.068+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:12:19.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:12:19.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:12:19.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:12:19.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:12:19.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:12:19.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:12:19.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T11:12:49.567+0000] {processor.py:157} INFO - Started process (PID=8589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:12:49.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:12:49.580+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:12:49.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:12:49.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:12:49.670+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:12:49.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:12:49.695+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:12:49.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:12:49.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-07-26T11:13:20.190+0000] {processor.py:157} INFO - Started process (PID=8613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:13:20.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:13:20.197+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:13:20.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:13:20.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:13:20.244+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:13:20.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:13:20.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:13:20.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:13:20.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-26T11:13:50.708+0000] {processor.py:157} INFO - Started process (PID=8639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:13:50.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:13:50.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:13:50.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:13:50.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:13:50.789+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:13:50.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:13:50.811+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:13:50.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:13:50.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T11:14:21.330+0000] {processor.py:157} INFO - Started process (PID=8664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:14:21.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:14:21.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:14:21.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:14:21.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:14:21.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:14:21.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:14:21.437+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:14:21.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:14:21.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-26T11:14:52.003+0000] {processor.py:157} INFO - Started process (PID=8689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:14:52.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:14:52.010+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:14:52.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:14:52.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:14:52.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:14:52.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:14:52.084+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:14:52.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:14:52.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T11:15:22.406+0000] {processor.py:157} INFO - Started process (PID=8714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:15:22.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:15:22.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:15:22.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:15:22.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:15:22.458+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:15:22.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:15:22.479+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:15:22.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:15:22.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T11:15:52.925+0000] {processor.py:157} INFO - Started process (PID=8739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:15:52.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:15:52.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:15:52.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:15:52.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:15:52.966+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:15:52.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:15:52.983+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:15:52.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:15:52.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T11:16:23.393+0000] {processor.py:157} INFO - Started process (PID=8764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:16:23.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:16:23.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:16:23.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:16:23.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:16:23.491+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:16:23.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:16:23.523+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:16:23.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:16:23.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-26T11:16:53.990+0000] {processor.py:157} INFO - Started process (PID=8789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:16:54.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:16:54.009+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:16:54.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:16:54.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:16:54.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:16:54.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:16:54.103+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:16:54.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:16:54.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-26T11:17:24.537+0000] {processor.py:157} INFO - Started process (PID=8814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:17:24.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:17:24.550+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:17:24.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:17:24.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:17:24.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:17:24.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:17:24.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:17:24.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:17:24.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T11:17:55.111+0000] {processor.py:157} INFO - Started process (PID=8839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:17:55.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:17:55.135+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:17:55.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:17:55.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:17:55.190+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:17:55.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:17:55.210+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:17:55.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:17:55.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-26T11:18:25.685+0000] {processor.py:157} INFO - Started process (PID=8864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:18:25.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:18:25.692+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:18:25.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:18:25.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:18:25.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:18:25.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:18:25.763+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:18:25.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:18:25.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T11:18:56.193+0000] {processor.py:157} INFO - Started process (PID=8889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:18:56.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:18:56.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:18:56.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:18:56.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:18:56.255+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:18:56.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:18:56.290+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:18:56.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:18:56.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T11:19:26.858+0000] {processor.py:157} INFO - Started process (PID=8914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:19:26.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:19:26.866+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:19:26.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:19:26.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:19:26.950+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:19:26.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:19:26.972+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:19:26.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:19:26.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-26T11:19:57.416+0000] {processor.py:157} INFO - Started process (PID=8939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:19:57.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:19:57.435+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:19:57.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:19:57.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:19:57.506+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:19:57.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:19:57.522+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:19:57.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:19:57.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-26T11:20:28.207+0000] {processor.py:157} INFO - Started process (PID=8964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:20:28.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:20:28.215+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:20:28.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:20:28.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:20:28.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:20:28.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:20:28.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:20:28.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:20:28.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-26T11:20:58.683+0000] {processor.py:157} INFO - Started process (PID=8989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:20:58.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:20:58.694+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:20:58.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:20:58.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:20:58.749+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:20:58.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:20:58.766+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:20:58.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:20:58.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T11:21:29.173+0000] {processor.py:157} INFO - Started process (PID=9014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:21:29.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:21:29.178+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:21:29.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:21:29.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:21:29.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:21:29.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:21:29.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:21:29.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:21:29.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T11:21:59.594+0000] {processor.py:157} INFO - Started process (PID=9039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:21:59.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:21:59.598+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:21:59.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:21:59.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:21:59.679+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:21:59.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:21:59.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:21:59.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:21:59.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-26T11:22:30.143+0000] {processor.py:157} INFO - Started process (PID=9064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:22:30.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:22:30.152+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:22:30.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:22:30.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:22:30.184+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:22:30.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:22:30.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:22:30.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:22:30.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T11:23:00.741+0000] {processor.py:157} INFO - Started process (PID=9089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:23:00.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:23:00.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:23:00.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:23:00.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:23:00.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:23:00.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:23:00.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:23:00.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:23:00.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-26T11:23:31.197+0000] {processor.py:157} INFO - Started process (PID=9114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:23:31.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:23:31.201+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:23:31.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:23:31.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:23:31.239+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:23:31.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:23:31.255+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:23:31.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:23:31.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T11:24:01.706+0000] {processor.py:157} INFO - Started process (PID=9139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:24:01.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:24:01.719+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:24:01.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:24:01.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:24:01.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:24:01.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:24:01.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:24:01.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:24:01.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-26T11:24:32.326+0000] {processor.py:157} INFO - Started process (PID=9164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:24:32.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:24:32.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:24:32.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:24:32.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:24:32.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:24:32.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:24:32.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:24:32.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:24:32.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-26T11:25:02.923+0000] {processor.py:157} INFO - Started process (PID=9189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:25:02.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:25:02.931+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:25:02.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:25:02.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:25:02.998+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:25:02.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:25:03.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:25:03.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:25:03.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-26T11:25:33.549+0000] {processor.py:157} INFO - Started process (PID=9213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:25:33.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:25:33.557+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:25:33.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:25:33.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:25:33.622+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:25:33.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:25:33.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:25:33.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:25:33.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-26T11:26:04.122+0000] {processor.py:157} INFO - Started process (PID=9239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:26:04.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:26:04.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:26:04.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:26:04.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:26:04.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:26:04.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:26:04.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:26:04.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:26:04.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-26T11:26:34.738+0000] {processor.py:157} INFO - Started process (PID=9264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:26:34.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:26:34.747+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:26:34.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:26:34.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:26:34.828+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:26:34.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:26:34.866+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:26:34.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:26:34.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-26T11:27:05.341+0000] {processor.py:157} INFO - Started process (PID=9289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:27:05.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:27:05.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:27:05.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:27:05.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:27:05.393+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:27:05.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:27:05.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:27:05.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:27:05.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T11:27:35.833+0000] {processor.py:157} INFO - Started process (PID=9314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:27:35.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:27:35.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:27:35.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:27:35.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:27:35.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:27:35.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:27:35.932+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:27:35.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:27:35.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-26T11:28:06.416+0000] {processor.py:157} INFO - Started process (PID=9339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:28:06.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:28:06.423+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:28:06.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:28:06.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:28:06.493+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:28:06.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:28:06.521+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:28:06.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:28:06.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T11:28:36.904+0000] {processor.py:157} INFO - Started process (PID=9364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:28:36.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:28:36.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:28:36.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:28:36.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:28:37.014+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:28:37.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:28:37.034+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:28:37.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:28:37.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-26T11:29:07.527+0000] {processor.py:157} INFO - Started process (PID=9389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:29:07.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:29:07.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:29:07.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:29:07.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:29:07.612+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:29:07.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:29:07.634+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:29:07.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:29:07.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-26T11:29:38.118+0000] {processor.py:157} INFO - Started process (PID=9412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:29:38.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:29:38.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:29:38.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:29:38.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:29:38.220+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:29:38.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:29:38.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:29:38.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:29:38.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-26T11:30:08.747+0000] {processor.py:157} INFO - Started process (PID=9438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:30:08.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:30:08.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:30:08.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:30:08.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:30:08.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:30:08.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:30:08.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:30:08.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:30:08.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-26T11:30:39.268+0000] {processor.py:157} INFO - Started process (PID=9464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:30:39.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:30:39.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:30:39.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:30:39.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:30:39.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:30:39.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:30:39.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:30:39.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:30:39.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-26T11:31:09.829+0000] {processor.py:157} INFO - Started process (PID=9488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:31:09.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:31:09.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:31:09.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:31:09.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:31:09.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:31:09.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:31:09.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:31:09.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:31:09.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-26T11:31:40.400+0000] {processor.py:157} INFO - Started process (PID=9514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:31:40.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:31:40.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:31:40.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:31:40.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:31:40.513+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:31:40.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:31:40.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:31:40.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:31:40.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-26T11:32:11.030+0000] {processor.py:157} INFO - Started process (PID=9539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:32:11.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:32:11.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:32:11.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:32:11.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:32:11.101+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:32:11.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:32:11.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:32:11.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:32:11.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-26T11:32:41.583+0000] {processor.py:157} INFO - Started process (PID=9563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:32:41.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:32:41.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:32:41.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:32:41.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:32:41.655+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:32:41.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:32:41.689+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:32:41.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:32:41.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-26T11:33:12.153+0000] {processor.py:157} INFO - Started process (PID=9589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:33:12.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:33:12.160+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:33:12.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:33:12.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:33:12.239+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:33:12.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:33:12.260+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:33:12.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:33:12.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-26T11:33:42.675+0000] {processor.py:157} INFO - Started process (PID=9614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:33:42.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:33:42.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:33:42.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:33:42.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:33:42.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:33:42.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:33:42.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:33:42.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:33:42.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-26T11:34:13.245+0000] {processor.py:157} INFO - Started process (PID=9639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:34:13.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:34:13.255+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:34:13.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:34:13.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:34:13.331+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:34:13.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:34:13.352+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:34:13.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:34:13.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-26T11:34:43.749+0000] {processor.py:157} INFO - Started process (PID=9664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:34:43.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:34:43.756+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:34:43.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:34:43.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:34:43.812+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:34:43.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:34:43.830+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:34:43.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:34:43.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-26T11:35:14.233+0000] {processor.py:157} INFO - Started process (PID=9689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:35:14.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:35:14.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:35:14.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:35:14.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:35:14.301+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:35:14.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:35:14.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:35:14.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:35:14.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-26T11:35:44.778+0000] {processor.py:157} INFO - Started process (PID=9714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:35:44.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:35:44.787+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:35:44.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:35:44.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:35:44.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:35:44.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:35:44.856+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:35:44.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:35:44.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T11:36:15.236+0000] {processor.py:157} INFO - Started process (PID=9739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:36:15.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:36:15.241+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:36:15.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:36:15.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:36:15.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:36:15.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:36:15.307+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:36:15.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:36:15.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T11:36:45.849+0000] {processor.py:157} INFO - Started process (PID=9764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:36:45.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:36:45.854+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:36:45.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:36:45.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:36:45.909+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:36:45.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:36:45.928+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:36:45.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:36:45.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T11:37:16.328+0000] {processor.py:157} INFO - Started process (PID=9789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:37:16.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:37:16.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:37:16.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:37:16.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:37:16.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:37:16.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:37:16.370+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:37:16.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:37:16.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T11:37:46.758+0000] {processor.py:157} INFO - Started process (PID=9814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:37:46.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:37:46.765+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:37:46.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:37:46.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:37:46.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:37:46.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:37:46.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:37:46.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:37:46.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T11:38:17.314+0000] {processor.py:157} INFO - Started process (PID=9839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:38:17.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:38:17.320+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:38:17.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:38:17.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:38:17.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:38:17.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:38:17.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:38:17.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:38:17.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T11:38:47.710+0000] {processor.py:157} INFO - Started process (PID=9864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:38:47.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:38:47.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:38:47.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:38:47.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:38:47.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:38:47.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:38:47.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:38:47.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:38:47.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T11:53:53.608+0000] {processor.py:157} INFO - Started process (PID=9891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:53:53.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:53:53.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:53:53.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:53:53.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:53:53.637+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:53:53.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:53:53.649+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:53:53.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:53:53.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T11:54:24.100+0000] {processor.py:157} INFO - Started process (PID=9916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:54:24.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:54:24.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:54:24.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:54:24.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:54:24.165+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:54:24.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:54:24.179+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:54:24.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:54:24.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T11:54:54.634+0000] {processor.py:157} INFO - Started process (PID=9941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:54:54.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:54:54.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:54:54.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:54:54.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:54:54.665+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:54:54.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:54:54.675+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:54:54.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:54:54.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T11:55:25.159+0000] {processor.py:157} INFO - Started process (PID=9966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:55:25.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:55:25.171+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:55:25.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:55:25.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:55:25.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:55:25.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:55:25.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:55:25.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:55:25.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-26T11:55:55.621+0000] {processor.py:157} INFO - Started process (PID=9991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:55:55.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:55:55.624+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:55:55.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:55:55.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:55:55.647+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:55:55.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:55:55.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:55:55.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:55:55.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T11:56:26.106+0000] {processor.py:157} INFO - Started process (PID=10016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:56:26.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:56:26.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:56:26.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:56:26.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:56:26.146+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:56:26.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:56:26.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:56:26.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:56:26.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T11:56:56.555+0000] {processor.py:157} INFO - Started process (PID=10041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:56:56.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:56:56.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:56:56.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:56:56.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:56:56.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:56:56.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:56:56.621+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:56:56.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:56:56.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T11:57:27.074+0000] {processor.py:157} INFO - Started process (PID=10066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:57:27.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:57:27.079+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:57:27.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:57:27.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:57:27.112+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:57:27.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:57:27.125+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:57:27.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:57:27.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T11:57:57.612+0000] {processor.py:157} INFO - Started process (PID=10091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:57:57.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:57:57.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:57:57.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:57:57.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:57:57.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:57:57.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:57:57.653+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:57:57.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:57:57.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T11:58:28.056+0000] {processor.py:157} INFO - Started process (PID=10116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:58:28.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:58:28.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:58:28.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:58:28.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:58:28.087+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:58:28.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:58:28.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:58:28.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:58:28.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T11:58:58.528+0000] {processor.py:157} INFO - Started process (PID=10141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:58:58.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:58:58.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:58:58.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:58:58.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:58:58.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:58:58.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:58:58.575+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:58:58.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:58:58.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T11:59:28.982+0000] {processor.py:157} INFO - Started process (PID=10166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:59:28.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:59:28.985+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:59:28.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:59:28.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:59:29.016+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:59:29.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:59:29.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:59:29.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:59:29.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T11:59:59.516+0000] {processor.py:157} INFO - Started process (PID=10191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:59:59.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T11:59:59.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:59:59.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:59:59.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T11:59:59.545+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:59:59.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T11:59:59.556+0000] {logging_mixin.py:151} INFO - [2024-07-26T11:59:59.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T11:59:59.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T12:00:29.988+0000] {processor.py:157} INFO - Started process (PID=10216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:00:29.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:00:29.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:00:29.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:00:30.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:00:30.030+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:00:30.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:00:30.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:00:30.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:00:30.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T12:01:00.532+0000] {processor.py:157} INFO - Started process (PID=10241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:01:00.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:01:00.536+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:01:00.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:01:00.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:01:00.562+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:01:00.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:01:00.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:01:00.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:01:00.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T12:01:30.877+0000] {processor.py:157} INFO - Started process (PID=10266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:01:30.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:01:30.880+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:01:30.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:01:30.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:01:30.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:01:30.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:01:30.914+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:01:30.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:01:30.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T12:02:01.365+0000] {processor.py:157} INFO - Started process (PID=10291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:02:01.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:02:01.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:02:01.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:02:01.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:02:01.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:02:01.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:02:01.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:02:01.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:02:01.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T12:02:31.788+0000] {processor.py:157} INFO - Started process (PID=10316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:02:31.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:02:31.791+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:02:31.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:02:31.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:02:31.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:02:31.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:02:31.835+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:02:31.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:02:31.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T12:03:02.323+0000] {processor.py:157} INFO - Started process (PID=10339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:03:02.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:03:02.328+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:03:02.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:03:02.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:03:02.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:03:02.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:03:02.383+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:03:02.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:03:02.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T12:03:32.833+0000] {processor.py:157} INFO - Started process (PID=10366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:03:32.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:03:32.837+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:03:32.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:03:32.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:03:32.864+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:03:32.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:03:32.874+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:03:32.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:03:32.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T12:04:03.248+0000] {processor.py:157} INFO - Started process (PID=10391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:04:03.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:04:03.251+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:04:03.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:04:03.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:04:03.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:04:03.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:04:03.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:04:03.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:04:03.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T12:04:33.746+0000] {processor.py:157} INFO - Started process (PID=10416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:04:33.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:04:33.750+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:04:33.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:04:33.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:04:33.779+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:04:33.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:04:33.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:04:33.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:04:33.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T12:05:04.199+0000] {processor.py:157} INFO - Started process (PID=10441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:05:04.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:05:04.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:05:04.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:05:04.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:05:04.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:05:04.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:05:04.255+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:05:04.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:05:04.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T12:05:34.697+0000] {processor.py:157} INFO - Started process (PID=10465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:05:34.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:05:34.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:05:34.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:05:34.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:05:34.728+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:05:34.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:05:34.739+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:05:34.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:05:34.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T12:06:05.118+0000] {processor.py:157} INFO - Started process (PID=10490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:06:05.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:06:05.120+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:06:05.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:06:05.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:06:05.143+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:06:05.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:06:05.152+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:06:05.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:06:05.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-26T12:06:35.582+0000] {processor.py:157} INFO - Started process (PID=10516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:06:35.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:06:35.585+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:06:35.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:06:35.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:06:35.615+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:06:35.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:06:35.625+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:06:35.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:06:35.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T12:07:06.038+0000] {processor.py:157} INFO - Started process (PID=10541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:07:06.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:07:06.042+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:07:06.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:07:06.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:07:06.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:07:06.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:07:06.085+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:07:06.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:07:06.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T12:07:36.465+0000] {processor.py:157} INFO - Started process (PID=10566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:07:36.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:07:36.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:07:36.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:07:36.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:07:36.501+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:07:36.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:07:36.514+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:07:36.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:07:36.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T12:08:06.992+0000] {processor.py:157} INFO - Started process (PID=10590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:08:06.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:08:06.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:08:06.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:08:07.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:08:07.019+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:08:07.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:08:07.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:08:07.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:08:07.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T12:08:37.407+0000] {processor.py:157} INFO - Started process (PID=10616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:08:37.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:08:37.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:08:37.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:08:37.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:08:37.445+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:08:37.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:08:37.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:08:37.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:08:37.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T12:09:07.880+0000] {processor.py:157} INFO - Started process (PID=10641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:09:07.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:09:07.885+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:09:07.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:09:07.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:09:07.918+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:09:07.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:09:07.930+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:09:07.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:09:07.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T12:15:26.000+0000] {processor.py:157} INFO - Started process (PID=10668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:15:26.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:15:26.012+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:15:26.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:15:26.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:15:26.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:15:26.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:15:26.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:15:26.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:15:26.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-26T12:15:56.798+0000] {processor.py:157} INFO - Started process (PID=10692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:15:56.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:15:56.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:15:56.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:15:56.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:15:56.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:15:56.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:15:56.875+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:15:56.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:15:56.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T12:16:27.339+0000] {processor.py:157} INFO - Started process (PID=10718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:16:27.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:16:27.341+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:16:27.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:16:27.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:16:27.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:16:27.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:16:27.379+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:16:27.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:16:27.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T12:16:57.895+0000] {processor.py:157} INFO - Started process (PID=10743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:16:57.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:16:57.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:16:57.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:16:57.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:16:57.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:16:57.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:16:57.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:16:57.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:16:57.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T12:17:28.355+0000] {processor.py:157} INFO - Started process (PID=10768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:17:28.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:17:28.357+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:17:28.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:17:28.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:17:28.386+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:17:28.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:17:28.396+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:17:28.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:17:28.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T12:17:58.810+0000] {processor.py:157} INFO - Started process (PID=10793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:17:58.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:17:58.817+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:17:58.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:17:58.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:17:58.839+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:17:58.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:17:58.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:17:58.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:17:58.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T12:18:29.301+0000] {processor.py:157} INFO - Started process (PID=10818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:18:29.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:18:29.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:18:29.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:18:29.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:18:29.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:18:29.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:18:29.358+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:18:29.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:18:29.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T12:18:59.835+0000] {processor.py:157} INFO - Started process (PID=10843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:18:59.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:18:59.838+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:18:59.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:18:59.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:18:59.865+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:18:59.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:18:59.875+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:18:59.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:18:59.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T12:34:23.460+0000] {processor.py:157} INFO - Started process (PID=10868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:34:23.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:34:23.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:34:23.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:34:23.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:34:23.507+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:34:23.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:34:23.521+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:34:23.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:34:23.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T12:34:54.090+0000] {processor.py:157} INFO - Started process (PID=10893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:34:54.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:34:54.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:34:54.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:34:54.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:34:54.157+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:34:54.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:34:54.175+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:34:54.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:34:54.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T12:35:24.519+0000] {processor.py:157} INFO - Started process (PID=10918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:35:24.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:35:24.524+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:35:24.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:35:24.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:35:24.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:35:24.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:35:24.572+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:35:24.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:35:24.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T12:35:54.999+0000] {processor.py:157} INFO - Started process (PID=10943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:35:55.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:35:55.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:35:55.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:35:55.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:35:55.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:35:55.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:35:55.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:35:55.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:35:55.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T12:36:25.501+0000] {processor.py:157} INFO - Started process (PID=10968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:36:25.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:36:25.504+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:36:25.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:36:25.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:36:25.530+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:36:25.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:36:25.540+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:36:25.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:36:25.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T12:36:56.023+0000] {processor.py:157} INFO - Started process (PID=10993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:36:56.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:36:56.026+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:36:56.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:36:56.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:36:56.055+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:36:56.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:36:56.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:36:56.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:36:56.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T12:37:26.487+0000] {processor.py:157} INFO - Started process (PID=11018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:37:26.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:37:26.489+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:37:26.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:37:26.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:37:26.508+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:37:26.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:37:26.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:37:26.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:37:26.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-26T12:37:57.065+0000] {processor.py:157} INFO - Started process (PID=11042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:37:57.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:37:57.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:37:57.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:37:57.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:37:57.110+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:37:57.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:37:57.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:37:57.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:37:57.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T12:38:27.559+0000] {processor.py:157} INFO - Started process (PID=11068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:38:27.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:38:27.563+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:38:27.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:38:27.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:38:27.590+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:38:27.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:38:27.601+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:38:27.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:38:27.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T12:38:58.056+0000] {processor.py:157} INFO - Started process (PID=11093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:38:58.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:38:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:38:58.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:38:58.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:38:58.093+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:38:58.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:38:58.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:38:58.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:38:58.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T12:39:28.556+0000] {processor.py:157} INFO - Started process (PID=11118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:39:28.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:39:28.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:39:28.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:39:28.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:39:28.585+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:39:28.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:39:28.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:39:28.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:39:28.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T12:39:59.139+0000] {processor.py:157} INFO - Started process (PID=11143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:39:59.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:39:59.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:39:59.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:39:59.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:39:59.168+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:39:59.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:39:59.179+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:39:59.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:39:59.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T12:40:29.596+0000] {processor.py:157} INFO - Started process (PID=11168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:40:29.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:40:29.598+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:40:29.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:40:29.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:40:29.619+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:40:29.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:40:29.629+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:40:29.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:40:29.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-26T12:41:00.079+0000] {processor.py:157} INFO - Started process (PID=11193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:41:00.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:41:00.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:41:00.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:41:00.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:41:00.133+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:41:00.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:41:00.153+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:41:00.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:41:00.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T12:41:30.632+0000] {processor.py:157} INFO - Started process (PID=11218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:41:30.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:41:30.636+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:41:30.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:41:30.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:41:30.660+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:41:30.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:41:30.670+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:41:30.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:41:30.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T12:42:01.213+0000] {processor.py:157} INFO - Started process (PID=11243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:42:01.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:42:01.220+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:42:01.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:42:01.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:42:01.246+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:42:01.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:42:01.257+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:42:01.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:42:01.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T12:42:31.732+0000] {processor.py:157} INFO - Started process (PID=11268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:42:31.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:42:31.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:42:31.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:42:31.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:42:31.773+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:42:31.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:42:31.784+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:42:31.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:42:31.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T12:43:02.298+0000] {processor.py:157} INFO - Started process (PID=11293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:43:02.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:43:02.301+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:43:02.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:43:02.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:43:02.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:43:02.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:43:02.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:43:02.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:43:02.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T12:43:32.723+0000] {processor.py:157} INFO - Started process (PID=11318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:43:32.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:43:32.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:43:32.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:43:32.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:43:32.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:43:32.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:43:32.763+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:43:32.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:43:32.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T12:44:03.272+0000] {processor.py:157} INFO - Started process (PID=11343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:44:03.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:44:03.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:44:03.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:44:03.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:44:03.311+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:44:03.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:44:03.321+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:44:03.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:44:03.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T12:44:33.800+0000] {processor.py:157} INFO - Started process (PID=11368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:44:33.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:44:33.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:44:33.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:44:33.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:44:33.835+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:44:33.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:44:33.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:44:33.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:44:33.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T12:45:04.208+0000] {processor.py:157} INFO - Started process (PID=11393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:45:04.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:45:04.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:45:04.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:45:04.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:45:04.236+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:45:04.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:45:04.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:45:04.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:45:04.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T12:45:34.680+0000] {processor.py:157} INFO - Started process (PID=11418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:45:34.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:45:34.688+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:45:34.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:45:34.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:45:34.718+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:45:34.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:45:34.729+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:45:34.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:45:34.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T12:46:05.195+0000] {processor.py:157} INFO - Started process (PID=11442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:46:05.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:46:05.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:46:05.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:46:05.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:46:05.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:46:05.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:46:05.252+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:46:05.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:46:05.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T12:46:35.712+0000] {processor.py:157} INFO - Started process (PID=11468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:46:35.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:46:35.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:46:35.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:46:35.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:46:35.738+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:46:35.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:46:35.747+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:46:35.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:46:35.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T12:47:06.192+0000] {processor.py:157} INFO - Started process (PID=11493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:47:06.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:47:06.194+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:47:06.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:47:06.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:47:06.224+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:47:06.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:47:06.234+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:47:06.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:47:06.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T12:47:36.677+0000] {processor.py:157} INFO - Started process (PID=11518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:47:36.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:47:36.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:47:36.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:47:36.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:47:36.725+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:47:36.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:47:36.749+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:47:36.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:47:36.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T12:48:07.147+0000] {processor.py:157} INFO - Started process (PID=11543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:48:07.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:48:07.154+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:48:07.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:48:07.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:48:07.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:48:07.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:48:07.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:48:07.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:48:07.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T12:48:37.583+0000] {processor.py:157} INFO - Started process (PID=11568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:48:37.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:48:37.587+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:48:37.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:48:37.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:48:37.621+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:48:37.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:48:37.630+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:48:37.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:48:37.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T12:49:08.116+0000] {processor.py:157} INFO - Started process (PID=11593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:49:08.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:49:08.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:49:08.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:49:08.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:49:08.151+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:49:08.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:49:08.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:49:08.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:49:08.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T12:49:38.633+0000] {processor.py:157} INFO - Started process (PID=11618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:49:38.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:49:38.636+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:49:38.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:49:38.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:49:38.665+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:49:38.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:49:38.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:49:38.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:49:38.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T12:50:09.174+0000] {processor.py:157} INFO - Started process (PID=11643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:50:09.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:50:09.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:50:09.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:50:09.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:50:09.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:50:09.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:50:09.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:50:09.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:50:09.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-26T12:51:23.490+0000] {processor.py:157} INFO - Started process (PID=11670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:51:23.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:51:23.493+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:51:23.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:51:23.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:51:23.522+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:51:23.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:51:23.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:51:23.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:51:23.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T12:52:21.608+0000] {processor.py:157} INFO - Started process (PID=11695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:52:21.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:52:21.611+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:52:21.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:52:21.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:52:21.637+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:52:21.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:52:21.647+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:52:21.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:52:21.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T12:52:51.964+0000] {processor.py:157} INFO - Started process (PID=11720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:52:51.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:52:51.967+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:52:51.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:52:51.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:52:52.001+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:52:52.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:52:52.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:52:52.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:52:52.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T12:57:16.634+0000] {processor.py:157} INFO - Started process (PID=11745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:57:16.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:57:16.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:57:16.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:57:16.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:57:16.679+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:57:16.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:57:16.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:57:16.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:57:16.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T12:57:47.256+0000] {processor.py:157} INFO - Started process (PID=11770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:57:47.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:57:47.261+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:57:47.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:57:47.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:57:47.299+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:57:47.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:57:47.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:57:47.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:57:47.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T12:58:17.763+0000] {processor.py:157} INFO - Started process (PID=11795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:58:17.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:58:17.767+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:58:17.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:58:17.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:58:17.799+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:58:17.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:58:17.808+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:58:17.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:58:17.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T12:58:48.197+0000] {processor.py:157} INFO - Started process (PID=11820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:58:48.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:58:48.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:58:48.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:58:48.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:58:48.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:58:48.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:58:48.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:58:48.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:58:48.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T12:59:18.574+0000] {processor.py:157} INFO - Started process (PID=11845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:59:18.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:59:18.577+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:59:18.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:59:18.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:59:18.606+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:59:18.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:59:18.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:59:18.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:59:18.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T12:59:48.961+0000] {processor.py:157} INFO - Started process (PID=11870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:59:48.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T12:59:48.965+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:59:48.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:59:48.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T12:59:48.996+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:59:48.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T12:59:49.007+0000] {logging_mixin.py:151} INFO - [2024-07-26T12:59:49.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T12:59:49.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T13:00:28.321+0000] {processor.py:157} INFO - Started process (PID=11895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:00:28.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:00:28.327+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:00:28.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:00:28.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:00:28.403+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:00:28.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:00:28.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:00:28.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:00:28.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-26T13:00:58.832+0000] {processor.py:157} INFO - Started process (PID=11920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:00:58.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:00:58.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:00:58.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:00:58.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:00:58.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:00:58.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:00:58.866+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:00:58.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:00:58.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-26T13:15:53.969+0000] {processor.py:157} INFO - Started process (PID=11944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:15:53.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:15:53.975+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:15:53.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:15:54.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:15:54.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:15:54.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:15:54.054+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:15:54.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:15:54.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T13:16:24.484+0000] {processor.py:157} INFO - Started process (PID=11970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:16:24.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:16:24.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:16:24.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:16:24.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:16:24.512+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:16:24.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:16:24.521+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:16:24.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:16:24.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T13:17:23.723+0000] {processor.py:157} INFO - Started process (PID=11997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:17:23.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:17:23.729+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:17:23.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:17:23.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:17:23.759+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:17:23.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:17:23.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:17:23.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:17:23.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T13:33:03.481+0000] {processor.py:157} INFO - Started process (PID=12022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:33:03.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:33:03.488+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:33:03.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:33:03.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:33:03.530+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:33:03.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:33:03.550+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:33:03.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:33:03.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T13:33:34.046+0000] {processor.py:157} INFO - Started process (PID=12047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:33:34.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:33:34.054+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:33:34.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:33:34.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:33:34.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:33:34.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:33:34.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:33:34.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:33:34.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-26T13:34:04.582+0000] {processor.py:157} INFO - Started process (PID=12072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:34:04.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:34:04.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:34:04.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:34:04.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:34:04.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:34:04.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:34:04.618+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:34:04.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:34:04.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T13:34:34.997+0000] {processor.py:157} INFO - Started process (PID=12097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:34:34.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:34:35.000+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:34:34.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:34:35.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:34:35.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:34:35.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:34:35.050+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:34:35.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:34:35.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T13:35:05.466+0000] {processor.py:157} INFO - Started process (PID=12122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:35:05.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:35:05.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:35:05.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:35:05.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:35:05.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:35:05.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:35:05.506+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:35:05.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:35:05.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T13:51:54.375+0000] {processor.py:157} INFO - Started process (PID=12146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:51:54.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:51:54.379+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:51:54.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:51:54.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:51:54.441+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:51:54.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:51:54.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:51:54.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:51:54.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-26T13:52:24.886+0000] {processor.py:157} INFO - Started process (PID=12172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:52:24.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:52:24.891+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:52:24.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:52:24.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:52:24.923+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:52:24.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:52:24.936+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:52:24.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:52:24.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T13:52:55.421+0000] {processor.py:157} INFO - Started process (PID=12197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:52:55.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:52:55.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:52:55.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:52:55.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:52:55.455+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:52:55.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:52:55.469+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:52:55.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:52:55.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T13:53:25.898+0000] {processor.py:157} INFO - Started process (PID=12222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:53:25.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:53:25.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:53:25.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:53:25.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:53:25.931+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:53:25.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:53:25.944+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:53:25.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:53:25.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T13:53:56.415+0000] {processor.py:157} INFO - Started process (PID=12247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:53:56.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T13:53:56.416+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:53:56.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:53:56.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T13:53:56.448+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:53:56.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T13:53:56.462+0000] {logging_mixin.py:151} INFO - [2024-07-26T13:53:56.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T13:53:56.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T14:09:58.475+0000] {processor.py:157} INFO - Started process (PID=12273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:09:58.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:09:58.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:09:58.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:09:58.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:09:58.554+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:09:58.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:09:58.573+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:09:58.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:09:58.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-26T14:10:29.183+0000] {processor.py:157} INFO - Started process (PID=12298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:10:29.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:10:29.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:10:29.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:10:29.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:10:29.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:10:29.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:10:29.225+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:10:29.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:10:29.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T14:10:59.668+0000] {processor.py:157} INFO - Started process (PID=12323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:10:59.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:10:59.673+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:10:59.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:10:59.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:10:59.706+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:10:59.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:10:59.718+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:10:59.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:10:59.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T14:11:30.235+0000] {processor.py:157} INFO - Started process (PID=12348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:11:30.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:11:30.239+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:11:30.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:11:30.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:11:30.269+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:11:30.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:11:30.281+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:11:30.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:11:30.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T14:12:00.651+0000] {processor.py:157} INFO - Started process (PID=12373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:12:00.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:12:00.654+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:12:00.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:12:00.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:12:00.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:12:00.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:12:00.694+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:12:00.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:12:00.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T14:27:51.768+0000] {processor.py:157} INFO - Started process (PID=12400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:27:51.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:27:51.770+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:27:51.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:27:51.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:27:51.795+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:27:51.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:27:51.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:27:51.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:27:51.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T14:28:22.216+0000] {processor.py:157} INFO - Started process (PID=12424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:28:22.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:28:22.221+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:28:22.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:28:22.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:28:22.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:28:22.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:28:22.271+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:28:22.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:28:22.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T14:36:45.212+0000] {processor.py:157} INFO - Started process (PID=12451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:36:45.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:36:45.215+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:36:45.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:36:45.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:36:45.273+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:36:45.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:36:45.295+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:36:45.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:36:45.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-26T14:37:15.805+0000] {processor.py:157} INFO - Started process (PID=12477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:37:15.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:37:15.816+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:37:15.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:37:15.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:37:15.862+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:37:15.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:37:15.878+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:37:15.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:37:15.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T14:37:46.343+0000] {processor.py:157} INFO - Started process (PID=12502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:37:46.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:37:46.345+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:37:46.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:37:46.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:37:46.375+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:37:46.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:37:46.386+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:37:46.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:37:46.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T14:38:16.841+0000] {processor.py:157} INFO - Started process (PID=12527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:38:16.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:38:16.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:38:16.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:38:16.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:38:16.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:38:16.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:38:16.899+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:38:16.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:38:16.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T14:38:47.254+0000] {processor.py:157} INFO - Started process (PID=12552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:38:47.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:38:47.257+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:38:47.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:38:47.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:38:47.281+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:38:47.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:38:47.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:38:47.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:38:47.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T14:39:17.699+0000] {processor.py:157} INFO - Started process (PID=12577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:39:17.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:39:17.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:39:17.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:39:17.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:39:17.733+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:39:17.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:39:17.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:39:17.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:39:17.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T14:39:48.102+0000] {processor.py:157} INFO - Started process (PID=12602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:39:48.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:39:48.106+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:39:48.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:39:48.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:39:48.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:39:48.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:39:48.155+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:39:48.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:39:48.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T14:40:18.620+0000] {processor.py:157} INFO - Started process (PID=12627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:40:18.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:40:18.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:40:18.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:40:18.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:40:18.654+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:40:18.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:40:18.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:40:18.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:40:18.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T14:40:49.055+0000] {processor.py:157} INFO - Started process (PID=12652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:40:49.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:40:49.058+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:40:49.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:40:49.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:40:49.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:40:49.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:40:49.104+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:40:49.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:40:49.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T14:41:19.500+0000] {processor.py:157} INFO - Started process (PID=12677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:41:19.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:41:19.507+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:41:19.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:41:19.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:41:19.534+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:41:19.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:41:19.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:41:19.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:41:19.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T14:41:49.900+0000] {processor.py:157} INFO - Started process (PID=12702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:41:49.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:41:49.904+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:41:49.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:41:49.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:41:49.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:41:49.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:41:49.950+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:41:49.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:41:49.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T14:42:20.366+0000] {processor.py:157} INFO - Started process (PID=12727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:42:20.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:42:20.382+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:42:20.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:42:20.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:42:20.453+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:42:20.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:42:20.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:42:20.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:42:20.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-26T14:42:50.927+0000] {processor.py:157} INFO - Started process (PID=12752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:42:50.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:42:50.933+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:42:50.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:42:50.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:42:50.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:42:50.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:42:51.001+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:42:51.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:42:51.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T14:43:21.522+0000] {processor.py:157} INFO - Started process (PID=12777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:43:21.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:43:21.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:43:21.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:43:21.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:43:21.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:43:21.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:43:21.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:43:21.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:43:21.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T14:43:52.019+0000] {processor.py:157} INFO - Started process (PID=12802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:43:52.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:43:52.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:43:52.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:43:52.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:43:52.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:43:52.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:43:52.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:43:52.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:43:52.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T14:44:22.583+0000] {processor.py:157} INFO - Started process (PID=12827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:44:22.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:44:22.589+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:44:22.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:44:22.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:44:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:44:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:44:22.656+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:44:22.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:44:22.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T14:44:53.033+0000] {processor.py:157} INFO - Started process (PID=12852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:44:53.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:44:53.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:44:53.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:44:53.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:44:53.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:44:53.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:44:53.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:44:53.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:44:53.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T14:45:23.605+0000] {processor.py:157} INFO - Started process (PID=12877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:45:23.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:45:23.610+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:45:23.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:45:23.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:45:23.662+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:45:23.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:45:23.675+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:45:23.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:45:23.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T14:45:54.120+0000] {processor.py:157} INFO - Started process (PID=12902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:45:54.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:45:54.123+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:45:54.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:45:54.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:45:54.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:45:54.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:45:54.184+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:45:54.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:45:54.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T14:46:24.673+0000] {processor.py:157} INFO - Started process (PID=12927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:46:24.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:46:24.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:46:24.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:46:24.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:46:24.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:46:24.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:46:24.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:46:24.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:46:24.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T14:46:55.174+0000] {processor.py:157} INFO - Started process (PID=12951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:46:55.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:46:55.180+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:46:55.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:46:55.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:46:55.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:46:55.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:46:55.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:46:55.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:46:55.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T14:47:25.728+0000] {processor.py:157} INFO - Started process (PID=12977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:47:25.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:47:25.732+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:47:25.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:47:25.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:47:25.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:47:25.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:47:25.855+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:47:25.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:47:25.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-26T14:47:56.247+0000] {processor.py:157} INFO - Started process (PID=13002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:47:56.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:47:56.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:47:56.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:47:56.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:47:56.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:47:56.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:47:56.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:47:56.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:47:56.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T14:48:26.757+0000] {processor.py:157} INFO - Started process (PID=13027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:48:26.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:48:26.762+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:48:26.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:48:26.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:48:26.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:48:26.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:48:26.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:48:26.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:48:26.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T14:48:57.217+0000] {processor.py:157} INFO - Started process (PID=13052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:48:57.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:48:57.219+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:48:57.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:48:57.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:48:57.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:48:57.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:48:57.258+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:48:57.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:48:57.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T14:49:27.770+0000] {processor.py:157} INFO - Started process (PID=13077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:49:27.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:49:27.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:49:27.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:49:27.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:49:27.821+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:49:27.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:49:27.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:49:27.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:49:27.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T14:49:58.168+0000] {processor.py:157} INFO - Started process (PID=13102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:49:58.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:49:58.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:49:58.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:49:58.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:49:58.197+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:49:58.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:49:58.209+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:49:58.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:49:58.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T14:50:28.600+0000] {processor.py:157} INFO - Started process (PID=13127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:50:28.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:50:28.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:50:28.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:50:28.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:50:28.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:50:28.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:50:28.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:50:28.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:50:28.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T14:50:59.114+0000] {processor.py:157} INFO - Started process (PID=13152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:50:59.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:50:59.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:50:59.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:50:59.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:50:59.150+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:50:59.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:50:59.163+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:50:59.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:50:59.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T14:51:29.667+0000] {processor.py:157} INFO - Started process (PID=13177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:51:29.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:51:29.673+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:51:29.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:51:29.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:51:29.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:51:29.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:51:29.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:51:29.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:51:29.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T14:52:00.126+0000] {processor.py:157} INFO - Started process (PID=13202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:52:00.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:52:00.130+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:52:00.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:52:00.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:52:00.161+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:52:00.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:52:00.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:52:00.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:52:00.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T14:52:30.709+0000] {processor.py:157} INFO - Started process (PID=13225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:52:30.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:52:30.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:52:30.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:52:30.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:52:30.808+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:52:30.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:52:30.826+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:52:30.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:52:30.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-26T14:53:01.259+0000] {processor.py:157} INFO - Started process (PID=13252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:53:01.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:53:01.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:53:01.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:53:01.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:53:01.314+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:53:01.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:53:01.328+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:53:01.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:53:01.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T14:53:31.789+0000] {processor.py:157} INFO - Started process (PID=13275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:53:31.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:53:31.795+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:53:31.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:53:31.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:53:31.841+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:53:31.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:53:31.867+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:53:31.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:53:31.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-26T14:54:02.382+0000] {processor.py:157} INFO - Started process (PID=13302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:54:02.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:54:02.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:54:02.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:54:02.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:54:02.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:54:02.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:54:02.463+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:54:02.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:54:02.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T14:54:32.925+0000] {processor.py:157} INFO - Started process (PID=13327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:54:32.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:54:32.936+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:54:32.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:54:32.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:54:32.990+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:54:32.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:54:33.004+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:54:33.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:54:33.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-26T14:55:03.479+0000] {processor.py:157} INFO - Started process (PID=13352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:55:03.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:55:03.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:55:03.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:55:03.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:55:03.554+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:55:03.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:55:03.571+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:55:03.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:55:03.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-26T14:55:34.048+0000] {processor.py:157} INFO - Started process (PID=13377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:55:34.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:55:34.050+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:55:34.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:55:34.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:55:34.083+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:55:34.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:55:34.093+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:55:34.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:55:34.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T14:56:04.419+0000] {processor.py:157} INFO - Started process (PID=13402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:56:04.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:56:04.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:56:04.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:56:04.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:56:04.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:56:04.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:56:04.489+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:56:04.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:56:04.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T14:56:34.987+0000] {processor.py:157} INFO - Started process (PID=13425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:56:34.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:56:34.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:56:34.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:56:35.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:56:35.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:56:35.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:56:35.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:56:35.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:56:35.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T14:57:05.422+0000] {processor.py:157} INFO - Started process (PID=13452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:57:05.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:57:05.436+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:57:05.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:57:05.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:57:05.470+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:57:05.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:57:05.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:57:05.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:57:05.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T14:57:35.877+0000] {processor.py:157} INFO - Started process (PID=13477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:57:35.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:57:35.881+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:57:35.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:57:35.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:57:35.919+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:57:35.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:57:35.931+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:57:35.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:57:35.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T14:58:06.376+0000] {processor.py:157} INFO - Started process (PID=13502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:58:06.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:58:06.380+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:58:06.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:58:06.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:58:06.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:58:06.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:58:06.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:58:06.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:58:06.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T14:58:36.920+0000] {processor.py:157} INFO - Started process (PID=13527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:58:36.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:58:36.926+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:58:36.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:58:36.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:58:36.987+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:58:36.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:58:37.000+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:58:37.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:58:37.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T14:59:07.390+0000] {processor.py:157} INFO - Started process (PID=13552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:59:07.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:59:07.395+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:59:07.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:59:07.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:59:07.444+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:59:07.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:59:07.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:59:07.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:59:07.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-26T14:59:37.926+0000] {processor.py:157} INFO - Started process (PID=13577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:59:37.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T14:59:37.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:59:37.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:59:37.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T14:59:38.014+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:59:38.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T14:59:38.034+0000] {logging_mixin.py:151} INFO - [2024-07-26T14:59:38.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T14:59:38.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-26T15:00:08.540+0000] {processor.py:157} INFO - Started process (PID=13602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:00:08.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:00:08.547+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:00:08.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:00:08.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:00:08.605+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:00:08.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:00:08.618+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:00:08.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:00:08.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T15:00:39.136+0000] {processor.py:157} INFO - Started process (PID=13627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:00:39.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:00:39.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:00:39.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:00:39.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:00:39.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:00:39.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:00:39.244+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:00:39.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:00:39.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-26T15:01:09.693+0000] {processor.py:157} INFO - Started process (PID=13652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:01:09.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:01:09.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:01:09.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:01:09.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:01:09.736+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:01:09.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:01:09.749+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:01:09.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:01:09.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T15:01:40.153+0000] {processor.py:157} INFO - Started process (PID=13677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:01:40.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:01:40.155+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:01:40.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:01:40.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:01:40.180+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:01:40.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:01:40.190+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:01:40.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:01:40.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T15:02:10.627+0000] {processor.py:157} INFO - Started process (PID=13702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:02:10.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:02:10.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:02:10.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:02:10.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:02:10.671+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:02:10.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:02:10.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:02:10.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:02:10.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T15:02:41.146+0000] {processor.py:157} INFO - Started process (PID=13727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:02:41.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:02:41.153+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:02:41.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:02:41.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:02:41.180+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:02:41.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:02:41.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:02:41.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:02:41.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T15:03:11.631+0000] {processor.py:157} INFO - Started process (PID=13752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:03:11.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:03:11.637+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:03:11.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:03:11.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:03:11.682+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:03:11.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:03:11.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:03:11.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:03:11.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T15:03:42.109+0000] {processor.py:157} INFO - Started process (PID=13777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:03:42.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:03:42.112+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:03:42.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:03:42.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:03:42.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:03:42.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:03:42.161+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:03:42.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:03:42.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T15:04:12.608+0000] {processor.py:157} INFO - Started process (PID=13802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:04:12.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:04:12.618+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:04:12.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:04:12.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:04:12.699+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:04:12.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:04:12.712+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:04:12.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:04:12.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-26T15:04:43.156+0000] {processor.py:157} INFO - Started process (PID=13827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:04:43.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:04:43.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:04:43.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:04:43.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:04:43.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:04:43.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:04:43.209+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:04:43.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:04:43.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T15:05:13.626+0000] {processor.py:157} INFO - Started process (PID=13852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:05:13.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:05:13.634+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:05:13.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:05:13.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:05:13.695+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:05:13.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:05:13.709+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:05:13.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:05:13.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T15:05:44.138+0000] {processor.py:157} INFO - Started process (PID=13877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:05:44.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:05:44.143+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:05:44.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:05:44.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:05:44.180+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:05:44.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:05:44.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:05:44.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:05:44.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T15:06:14.596+0000] {processor.py:157} INFO - Started process (PID=13902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:06:14.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:06:14.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:06:14.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:06:14.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:06:14.644+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:06:14.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:06:14.656+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:06:14.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:06:14.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T15:06:45.045+0000] {processor.py:157} INFO - Started process (PID=13927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:06:45.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:06:45.052+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:06:45.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:06:45.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:06:45.074+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:06:45.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:06:45.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:06:45.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:06:45.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T15:07:15.569+0000] {processor.py:157} INFO - Started process (PID=13952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:07:15.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:07:15.573+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:07:15.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:07:15.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:07:15.604+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:07:15.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:07:15.614+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:07:15.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:07:15.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T15:07:45.939+0000] {processor.py:157} INFO - Started process (PID=13977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:07:45.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:07:45.943+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:07:45.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:07:45.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:07:45.981+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:07:45.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:07:45.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:07:45.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:07:46.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T15:08:16.416+0000] {processor.py:157} INFO - Started process (PID=14001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:08:16.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:08:16.430+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:08:16.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:08:16.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:08:16.541+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:08:16.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:08:16.571+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:08:16.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:08:16.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-07-26T15:08:47.133+0000] {processor.py:157} INFO - Started process (PID=14027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:08:47.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:08:47.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:08:47.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:08:47.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:08:47.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:08:47.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:08:47.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:08:47.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:08:47.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T15:09:17.645+0000] {processor.py:157} INFO - Started process (PID=14052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:09:17.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:09:17.648+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:09:17.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:09:17.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:09:17.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:09:17.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:09:17.687+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:09:17.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:09:17.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T15:09:48.102+0000] {processor.py:157} INFO - Started process (PID=14077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:09:48.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:09:48.106+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:09:48.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:09:48.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:09:48.143+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:09:48.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:09:48.155+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:09:48.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:09:48.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T15:10:18.599+0000] {processor.py:157} INFO - Started process (PID=14102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:10:18.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:10:18.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:10:18.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:10:18.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:10:18.630+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:10:18.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:10:18.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:10:18.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:10:18.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T15:10:49.033+0000] {processor.py:157} INFO - Started process (PID=14127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:10:49.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:10:49.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:10:49.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:10:49.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:10:49.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:10:49.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:10:49.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:10:49.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:10:49.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T15:11:19.560+0000] {processor.py:157} INFO - Started process (PID=14151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:11:19.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:11:19.570+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:11:19.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:11:19.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:11:19.608+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:11:19.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:11:19.620+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:11:19.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:11:19.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-26T15:11:50.064+0000] {processor.py:157} INFO - Started process (PID=14177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:11:50.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:11:50.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:11:50.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:11:50.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:11:50.093+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:11:50.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:11:50.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:11:50.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:11:50.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T15:12:20.512+0000] {processor.py:157} INFO - Started process (PID=14202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:12:20.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:12:20.520+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:12:20.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:12:20.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:12:20.541+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:12:20.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:12:20.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:12:20.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:12:20.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T15:12:50.908+0000] {processor.py:157} INFO - Started process (PID=14227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:12:50.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:12:50.913+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:12:50.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:12:50.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:12:50.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:12:50.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:12:50.966+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:12:50.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:12:50.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T15:13:21.342+0000] {processor.py:157} INFO - Started process (PID=14252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:13:21.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:13:21.344+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:13:21.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:13:21.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:13:21.372+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:13:21.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:13:21.381+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:13:21.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:13:21.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T15:13:51.917+0000] {processor.py:157} INFO - Started process (PID=14276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:13:51.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:13:51.926+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:13:51.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:13:51.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:13:52.001+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:13:52.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:13:52.043+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:13:52.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:13:52.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-07-26T15:14:22.544+0000] {processor.py:157} INFO - Started process (PID=14302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:14:22.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:14:22.551+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:14:22.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:14:22.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:14:22.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:14:22.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:14:22.614+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:14:22.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:14:22.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T15:14:53.080+0000] {processor.py:157} INFO - Started process (PID=14326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:14:53.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:14:53.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:14:53.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:14:53.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:14:53.152+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:14:53.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:14:53.168+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:14:53.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:14:53.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T15:15:23.627+0000] {processor.py:157} INFO - Started process (PID=14352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:15:23.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:15:23.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:15:23.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:15:23.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:15:23.686+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:15:23.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:15:23.699+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:15:23.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:15:23.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T15:15:54.165+0000] {processor.py:157} INFO - Started process (PID=14375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:15:54.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:15:54.171+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:15:54.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:15:54.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:15:54.248+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:15:54.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:15:54.261+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:15:54.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:15:54.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-26T15:16:24.714+0000] {processor.py:157} INFO - Started process (PID=14402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:16:24.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:16:24.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:16:24.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:16:24.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:16:24.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:16:24.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:16:24.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:16:24.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:16:24.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T15:16:55.161+0000] {processor.py:157} INFO - Started process (PID=14427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:16:55.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:16:55.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:16:55.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:16:55.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:16:55.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:16:55.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:16:55.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:16:55.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:16:55.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T15:17:25.696+0000] {processor.py:157} INFO - Started process (PID=14451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:17:25.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:17:25.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:17:25.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:17:25.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:17:25.756+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:17:25.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:17:25.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:17:25.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:17:25.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T15:17:56.188+0000] {processor.py:157} INFO - Started process (PID=14477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:17:56.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:17:56.196+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:17:56.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:17:56.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:17:56.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:17:56.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:17:56.225+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:17:56.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:17:56.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T15:18:26.713+0000] {processor.py:157} INFO - Started process (PID=14502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:18:26.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:18:26.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:18:26.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:18:26.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:18:26.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:18:26.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:18:26.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:18:26.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:18:26.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:18:57.128+0000] {processor.py:157} INFO - Started process (PID=14527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:18:57.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:18:57.130+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:18:57.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:18:57.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:18:57.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:18:57.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:18:57.170+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:18:57.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:18:57.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T15:19:27.561+0000] {processor.py:157} INFO - Started process (PID=14551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:19:27.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:19:27.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:19:27.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:19:27.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:19:27.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:19:27.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:19:27.642+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:19:27.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:19:27.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-26T15:19:58.046+0000] {processor.py:157} INFO - Started process (PID=14577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:19:58.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:19:58.053+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:19:58.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:19:58.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:19:58.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:19:58.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:19:58.086+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:19:58.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:19:58.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T15:20:28.532+0000] {processor.py:157} INFO - Started process (PID=14602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:20:28.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:20:28.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:20:28.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:20:28.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:20:28.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:20:28.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:20:28.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:20:28.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:20:28.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T15:20:59.057+0000] {processor.py:157} INFO - Started process (PID=14627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:20:59.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:20:59.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:20:59.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:20:59.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:20:59.087+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:20:59.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:20:59.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:20:59.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:20:59.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T15:21:29.555+0000] {processor.py:157} INFO - Started process (PID=14652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:21:29.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:21:29.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:21:29.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:21:29.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:21:29.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:21:29.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:21:29.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:21:29.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:21:29.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T15:22:00.115+0000] {processor.py:157} INFO - Started process (PID=14677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:22:00.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:22:00.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:22:00.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:22:00.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:22:00.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:22:00.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:22:00.154+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:22:00.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:22:00.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:22:30.556+0000] {processor.py:157} INFO - Started process (PID=14702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:22:30.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:22:30.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:22:30.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:22:30.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:22:30.595+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:22:30.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:22:30.608+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:22:30.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:22:30.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T15:23:01.116+0000] {processor.py:157} INFO - Started process (PID=14727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:23:01.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:23:01.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:23:01.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:23:01.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:23:01.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:23:01.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:23:01.157+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:23:01.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:23:01.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T15:23:31.566+0000] {processor.py:157} INFO - Started process (PID=14752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:23:31.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:23:31.570+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:23:31.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:23:31.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:23:31.605+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:23:31.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:23:31.622+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:23:31.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:23:31.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T15:24:02.070+0000] {processor.py:157} INFO - Started process (PID=14777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:24:02.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:24:02.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:24:02.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:24:02.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:24:02.099+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:24:02.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:24:02.110+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:24:02.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:24:02.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:24:32.497+0000] {processor.py:157} INFO - Started process (PID=14802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:24:32.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:24:32.500+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:24:32.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:24:32.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:24:32.525+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:24:32.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:24:32.535+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:24:32.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:24:32.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T15:25:03.062+0000] {processor.py:157} INFO - Started process (PID=14827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:25:03.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:25:03.065+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:25:03.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:25:03.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:25:03.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:25:03.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:25:03.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:25:03.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:25:03.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T15:25:33.574+0000] {processor.py:157} INFO - Started process (PID=14851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:25:33.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:25:33.578+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:25:33.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:25:33.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:25:33.633+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:25:33.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:25:33.648+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:25:33.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:25:33.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T15:26:04.106+0000] {processor.py:157} INFO - Started process (PID=14877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:26:04.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:26:04.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:26:04.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:26:04.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:26:04.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:26:04.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:26:04.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:26:04.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:26:04.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T15:26:34.645+0000] {processor.py:157} INFO - Started process (PID=14902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:26:34.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:26:34.648+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:26:34.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:26:34.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:26:34.680+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:26:34.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:26:34.689+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:26:34.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:26:34.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T15:27:05.154+0000] {processor.py:157} INFO - Started process (PID=14927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:27:05.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:27:05.158+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:27:05.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:27:05.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:27:05.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:27:05.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:27:05.196+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:27:05.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:27:05.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T15:27:35.660+0000] {processor.py:157} INFO - Started process (PID=14952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:27:35.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:27:35.670+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:27:35.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:27:35.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:27:35.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:27:35.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:27:35.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:27:35.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:27:35.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T15:28:06.237+0000] {processor.py:157} INFO - Started process (PID=14977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:28:06.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:28:06.241+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:28:06.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:28:06.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:28:06.277+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:28:06.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:28:06.292+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:28:06.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:28:06.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T15:28:36.806+0000] {processor.py:157} INFO - Started process (PID=15002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:28:36.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:28:36.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:28:36.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:28:36.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:28:36.835+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:28:36.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:28:36.846+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:28:36.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:28:36.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T15:29:07.283+0000] {processor.py:157} INFO - Started process (PID=15027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:29:07.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:29:07.286+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:29:07.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:29:07.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:29:07.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:29:07.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:29:07.328+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:29:07.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:29:07.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T15:29:37.751+0000] {processor.py:157} INFO - Started process (PID=15052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:29:37.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:29:37.755+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:29:37.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:29:37.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:29:37.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:29:37.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:29:37.811+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:29:37.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:29:37.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T15:30:08.276+0000] {processor.py:157} INFO - Started process (PID=15077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:30:08.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:30:08.278+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:30:08.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:30:08.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:30:08.311+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:30:08.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:30:08.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:30:08.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:30:08.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T15:30:38.756+0000] {processor.py:157} INFO - Started process (PID=15102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:30:38.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:30:38.758+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:30:38.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:30:38.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:30:38.795+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:30:38.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:30:38.807+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:30:38.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:30:38.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T15:31:09.221+0000] {processor.py:157} INFO - Started process (PID=15127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:31:09.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:31:09.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:31:09.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:31:09.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:31:09.260+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:31:09.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:31:09.272+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:31:09.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:31:09.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T15:31:39.724+0000] {processor.py:157} INFO - Started process (PID=15152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:31:39.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:31:39.728+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:31:39.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:31:39.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:31:39.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:31:39.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:31:39.766+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:31:39.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:31:39.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T15:32:10.197+0000] {processor.py:157} INFO - Started process (PID=15177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:32:10.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:32:10.201+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:32:10.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:32:10.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:32:10.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:32:10.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:32:10.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:32:10.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:32:10.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T15:32:40.609+0000] {processor.py:157} INFO - Started process (PID=15202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:32:40.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:32:40.612+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:32:40.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:32:40.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:32:40.642+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:32:40.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:32:40.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:32:40.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:32:40.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:33:11.156+0000] {processor.py:157} INFO - Started process (PID=15227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:33:11.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:33:11.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:33:11.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:33:11.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:33:11.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:33:11.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:33:11.200+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:33:11.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:33:11.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T15:33:41.691+0000] {processor.py:157} INFO - Started process (PID=15251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:33:41.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:33:41.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:33:41.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:33:41.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:33:41.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:33:41.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:33:41.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:33:41.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:33:41.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T15:34:12.208+0000] {processor.py:157} INFO - Started process (PID=15277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:34:12.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:34:12.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:34:12.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:34:12.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:34:12.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:34:12.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:34:12.252+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:34:12.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:34:12.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T15:34:42.713+0000] {processor.py:157} INFO - Started process (PID=15302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:34:42.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:34:42.719+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:34:42.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:34:42.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:34:42.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:34:42.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:34:42.775+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:34:42.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:34:42.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T15:35:13.244+0000] {processor.py:157} INFO - Started process (PID=15327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:35:13.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:35:13.252+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:35:13.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:35:13.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:35:13.277+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:35:13.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:35:13.290+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:35:13.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:35:13.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T15:35:43.708+0000] {processor.py:157} INFO - Started process (PID=15352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:35:43.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:35:43.712+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:35:43.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:35:43.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:35:43.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:35:43.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:35:43.786+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:35:43.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:35:43.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T15:36:14.220+0000] {processor.py:157} INFO - Started process (PID=15377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:36:14.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:36:14.224+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:36:14.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:36:14.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:36:14.249+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:36:14.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:36:14.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:36:14.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:36:14.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T15:36:44.699+0000] {processor.py:157} INFO - Started process (PID=15402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:36:44.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:36:44.709+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:36:44.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:36:44.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:36:44.746+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:36:44.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:36:44.761+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:36:44.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:36:44.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T15:37:15.176+0000] {processor.py:157} INFO - Started process (PID=15427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:37:15.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:37:15.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:37:15.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:37:15.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:37:15.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:37:15.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:37:15.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:37:15.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:37:15.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T15:37:45.754+0000] {processor.py:157} INFO - Started process (PID=15452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:37:45.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:37:45.758+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:37:45.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:37:45.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:37:45.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:37:45.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:37:45.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:37:45.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:37:45.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T15:38:16.105+0000] {processor.py:157} INFO - Started process (PID=15477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:38:16.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:38:16.113+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:38:16.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:38:16.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:38:16.135+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:38:16.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:38:16.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:38:16.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:38:16.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T15:38:46.690+0000] {processor.py:157} INFO - Started process (PID=15502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:38:46.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:38:46.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:38:46.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:38:46.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:38:46.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:38:46.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:38:46.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:38:46.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:38:46.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T15:39:17.186+0000] {processor.py:157} INFO - Started process (PID=15527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:39:17.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:39:17.189+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:39:17.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:39:17.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:39:17.219+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:39:17.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:39:17.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:39:17.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:39:17.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T15:39:47.655+0000] {processor.py:157} INFO - Started process (PID=15552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:39:47.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:39:47.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:39:47.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:39:47.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:39:47.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:39:47.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:39:47.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:39:47.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:39:47.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T15:40:18.099+0000] {processor.py:157} INFO - Started process (PID=15577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:40:18.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:40:18.101+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:40:18.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:40:18.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:40:18.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:40:18.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:40:18.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:40:18.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:40:18.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T15:40:48.654+0000] {processor.py:157} INFO - Started process (PID=15601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:40:48.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:40:48.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:40:48.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:40:48.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:40:48.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:40:48.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:40:48.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:40:48.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:40:48.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T15:41:19.174+0000] {processor.py:157} INFO - Started process (PID=15627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:41:19.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:41:19.176+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:41:19.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:41:19.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:41:19.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:41:19.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:41:19.212+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:41:19.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:41:19.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:41:49.745+0000] {processor.py:157} INFO - Started process (PID=15652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:41:49.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:41:49.753+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:41:49.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:41:49.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:41:49.773+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:41:49.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:41:49.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:41:49.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:41:49.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T15:42:20.239+0000] {processor.py:157} INFO - Started process (PID=15677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:42:20.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:42:20.242+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:42:20.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:42:20.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:42:20.270+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:42:20.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:42:20.280+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:42:20.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:42:20.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T15:42:50.698+0000] {processor.py:157} INFO - Started process (PID=15702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:42:50.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:42:50.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:42:50.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:42:50.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:42:50.738+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:42:50.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:42:50.751+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:42:50.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:42:50.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T15:43:21.227+0000] {processor.py:157} INFO - Started process (PID=15727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:43:21.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:43:21.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:43:21.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:43:21.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:43:21.251+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:43:21.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:43:21.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:43:21.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:43:21.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T15:43:51.692+0000] {processor.py:157} INFO - Started process (PID=15752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:43:51.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:43:51.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:43:51.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:43:51.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:43:51.736+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:43:51.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:43:51.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:43:51.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:43:51.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T15:44:22.295+0000] {processor.py:157} INFO - Started process (PID=15777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:44:22.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:44:22.303+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:44:22.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:44:22.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:44:22.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:44:22.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:44:22.333+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:44:22.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:44:22.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:44:52.970+0000] {processor.py:157} INFO - Started process (PID=15802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:44:52.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:44:52.974+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:44:52.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:44:52.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:44:53.012+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:44:53.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:44:53.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:44:53.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:44:53.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T15:45:23.376+0000] {processor.py:157} INFO - Started process (PID=15827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:45:23.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:45:23.380+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:45:23.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:45:23.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:45:23.416+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:45:23.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:45:23.429+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:45:23.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:45:23.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T15:45:53.967+0000] {processor.py:157} INFO - Started process (PID=15852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:45:53.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:45:53.970+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:45:53.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:45:53.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:45:53.999+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:45:53.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:45:54.009+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:45:54.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:45:54.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:46:24.425+0000] {processor.py:157} INFO - Started process (PID=15877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:46:24.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:46:24.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:46:24.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:46:24.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:46:24.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:46:24.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:46:24.459+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:46:24.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:46:24.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-26T15:46:54.889+0000] {processor.py:157} INFO - Started process (PID=15902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:46:54.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:46:54.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:46:54.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:46:54.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:46:54.916+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:46:54.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:46:54.924+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:46:54.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:46:54.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T15:47:25.406+0000] {processor.py:157} INFO - Started process (PID=15927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:47:25.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:47:25.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:47:25.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:47:25.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:47:25.445+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:47:25.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:47:25.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:47:25.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:47:25.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T15:47:55.974+0000] {processor.py:157} INFO - Started process (PID=15952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:47:55.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:47:55.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:47:55.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:47:55.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:47:56.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:47:56.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:47:56.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:47:56.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:47:56.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T15:48:26.448+0000] {processor.py:157} INFO - Started process (PID=15977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:48:26.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:48:26.451+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:48:26.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:48:26.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:48:26.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:48:26.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:48:26.505+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:48:26.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:48:26.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T15:48:57.001+0000] {processor.py:157} INFO - Started process (PID=16002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:48:57.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:48:57.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:48:57.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:48:57.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:48:57.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:48:57.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:48:57.041+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:48:57.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:48:57.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:49:27.444+0000] {processor.py:157} INFO - Started process (PID=16027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:49:27.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:49:27.446+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:49:27.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:49:27.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:49:27.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:49:27.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:49:27.488+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:49:27.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:49:27.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T15:49:57.965+0000] {processor.py:157} INFO - Started process (PID=16052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:49:57.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:49:57.968+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:49:57.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:49:57.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:49:57.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:49:57.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:49:58.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:49:58.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:49:58.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T15:50:28.400+0000] {processor.py:157} INFO - Started process (PID=16077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:50:28.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:50:28.405+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:50:28.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:50:28.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:50:28.433+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:50:28.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:50:28.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:50:28.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:50:28.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T15:50:58.833+0000] {processor.py:157} INFO - Started process (PID=16102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:50:58.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:50:58.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:50:58.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:50:58.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:50:58.883+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:50:58.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:50:58.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:50:58.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:50:58.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T15:51:29.403+0000] {processor.py:157} INFO - Started process (PID=16127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:51:29.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:51:29.405+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:51:29.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:51:29.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:51:29.430+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:51:29.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:51:29.440+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:51:29.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:51:29.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T15:51:59.814+0000] {processor.py:157} INFO - Started process (PID=16152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:51:59.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:51:59.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:51:59.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:51:59.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:51:59.847+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:51:59.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:51:59.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:51:59.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:51:59.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T15:52:30.277+0000] {processor.py:157} INFO - Started process (PID=16177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:52:30.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:52:30.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:52:30.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:52:30.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:52:30.305+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:52:30.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:52:30.316+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:52:30.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:52:30.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T15:53:00.823+0000] {processor.py:157} INFO - Started process (PID=16202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:53:00.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:53:00.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:53:00.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:53:00.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:53:00.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:53:00.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:53:00.862+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:53:00.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:53:00.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T15:53:31.335+0000] {processor.py:157} INFO - Started process (PID=16227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:53:31.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:53:31.338+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:53:31.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:53:31.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:53:31.373+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:53:31.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:53:31.386+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:53:31.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:53:31.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T15:54:01.813+0000] {processor.py:157} INFO - Started process (PID=16252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:54:01.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:54:01.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:54:01.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:54:01.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:54:01.839+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:54:01.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:54:01.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:54:01.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:54:01.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T15:54:32.292+0000] {processor.py:157} INFO - Started process (PID=16277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:54:32.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:54:32.297+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:54:32.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:54:32.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:54:32.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:54:32.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:54:32.333+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:54:32.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:54:32.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T15:55:02.837+0000] {processor.py:157} INFO - Started process (PID=16302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:55:02.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:55:02.846+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:55:02.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:55:02.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:55:02.868+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:55:02.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:55:02.877+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:55:02.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:55:02.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T15:55:33.401+0000] {processor.py:157} INFO - Started process (PID=16327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:55:33.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:55:33.406+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:55:33.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:55:33.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:55:33.431+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:55:33.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:55:33.442+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:55:33.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:55:33.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:56:03.869+0000] {processor.py:157} INFO - Started process (PID=16352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:56:03.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:56:03.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:56:03.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:56:03.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:56:03.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:56:03.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:56:03.917+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:56:03.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:56:03.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T15:56:34.390+0000] {processor.py:157} INFO - Started process (PID=16377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:56:34.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:56:34.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:56:34.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:56:34.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:56:34.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:56:34.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:56:34.430+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:56:34.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:56:34.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:57:04.882+0000] {processor.py:157} INFO - Started process (PID=16402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:57:04.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:57:04.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:57:04.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:57:04.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:57:04.912+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:57:04.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:57:04.921+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:57:04.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:57:04.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T15:57:35.300+0000] {processor.py:157} INFO - Started process (PID=16427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:57:35.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:57:35.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:57:35.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:57:35.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:57:35.335+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:57:35.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:57:35.345+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:57:35.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:57:35.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T15:58:05.842+0000] {processor.py:157} INFO - Started process (PID=16452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:58:05.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:58:05.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:58:05.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:58:05.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:58:05.888+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:58:05.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:58:05.902+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:58:05.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:58:05.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T15:58:36.406+0000] {processor.py:157} INFO - Started process (PID=16477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:58:36.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:58:36.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:58:36.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:58:36.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:58:36.433+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:58:36.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:58:36.445+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:58:36.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:58:36.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T15:59:07.003+0000] {processor.py:157} INFO - Started process (PID=16502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:59:07.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:59:07.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:59:07.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:59:07.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:59:07.029+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:59:07.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:59:07.040+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:59:07.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:59:07.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T15:59:37.542+0000] {processor.py:157} INFO - Started process (PID=16527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:59:37.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T15:59:37.546+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:59:37.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:59:37.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T15:59:37.579+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:59:37.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T15:59:37.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T15:59:37.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T15:59:37.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T16:00:08.046+0000] {processor.py:157} INFO - Started process (PID=16552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:00:08.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:00:08.052+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:00:08.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:00:08.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:00:08.087+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:00:08.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:00:08.097+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:00:08.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:00:08.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T16:00:38.545+0000] {processor.py:157} INFO - Started process (PID=16577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:00:38.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:00:38.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:00:38.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:00:38.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:00:38.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:00:38.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:00:38.587+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:00:38.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:00:38.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:01:09.050+0000] {processor.py:157} INFO - Started process (PID=16602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:01:09.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:01:09.055+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:01:09.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:01:09.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:01:09.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:01:09.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:01:09.120+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:01:09.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:01:09.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T16:01:39.664+0000] {processor.py:157} INFO - Started process (PID=16627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:01:39.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:01:39.667+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:01:39.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:01:39.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:01:39.693+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:01:39.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:01:39.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:01:39.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:01:39.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T16:02:10.106+0000] {processor.py:157} INFO - Started process (PID=16652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:02:10.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:02:10.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:02:10.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:02:10.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:02:10.135+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:02:10.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:02:10.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:02:10.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:02:10.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:02:40.525+0000] {processor.py:157} INFO - Started process (PID=16677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:02:40.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:02:40.529+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:02:40.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:02:40.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:02:40.567+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:02:40.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:02:40.582+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:02:40.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:02:40.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T16:03:11.074+0000] {processor.py:157} INFO - Started process (PID=16702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:03:11.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:03:11.079+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:03:11.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:03:11.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:03:11.106+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:03:11.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:03:11.117+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:03:11.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:03:11.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T16:03:41.493+0000] {processor.py:157} INFO - Started process (PID=16727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:03:41.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:03:41.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:03:41.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:03:41.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:03:41.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:03:41.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:03:41.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:03:41.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:03:41.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T16:04:11.995+0000] {processor.py:157} INFO - Started process (PID=16752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:04:11.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:04:11.998+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:04:11.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:04:12.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:04:12.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:04:12.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:04:12.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:04:12.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:04:12.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:04:42.383+0000] {processor.py:157} INFO - Started process (PID=16777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:04:42.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:04:42.385+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:04:42.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:04:42.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:04:42.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:04:42.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:04:42.433+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:04:42.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:04:42.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T16:05:13.001+0000] {processor.py:157} INFO - Started process (PID=16802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:05:13.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:05:13.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:05:13.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:05:13.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:05:13.033+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:05:13.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:05:13.043+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:05:13.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:05:13.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:05:43.501+0000] {processor.py:157} INFO - Started process (PID=16827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:05:43.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:05:43.507+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:05:43.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:05:43.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:05:43.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:05:43.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:05:43.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:05:43.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:05:43.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T16:06:14.062+0000] {processor.py:157} INFO - Started process (PID=16852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:06:14.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:06:14.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:06:14.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:06:14.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:06:14.163+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:06:14.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:06:14.182+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:06:14.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:06:14.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-26T16:06:44.665+0000] {processor.py:157} INFO - Started process (PID=16877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:06:44.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:06:44.689+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:06:44.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:06:44.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:06:44.748+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:06:44.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:06:44.762+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:06:44.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:06:44.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-26T16:07:15.228+0000] {processor.py:157} INFO - Started process (PID=16902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:07:15.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:07:15.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:07:15.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:07:15.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:07:15.434+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:07:15.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:07:15.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:07:15.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:07:15.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.293 seconds
[2024-07-26T16:07:45.951+0000] {processor.py:157} INFO - Started process (PID=16926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:07:45.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:07:45.958+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:07:45.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:07:45.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:07:46.002+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:07:46.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:07:46.016+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:07:46.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:07:46.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T16:08:16.360+0000] {processor.py:157} INFO - Started process (PID=16952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:08:16.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:08:16.364+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:08:16.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:08:16.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:08:16.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:08:16.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:08:16.401+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:08:16.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:08:16.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:08:46.864+0000] {processor.py:157} INFO - Started process (PID=16977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:08:46.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:08:46.871+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:08:46.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:08:46.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:08:46.908+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:08:46.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:08:46.920+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:08:46.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:08:46.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T16:09:17.363+0000] {processor.py:157} INFO - Started process (PID=17002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:09:17.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:09:17.371+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:09:17.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:09:17.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:09:17.390+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:09:17.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:09:17.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:09:17.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:09:17.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:09:47.749+0000] {processor.py:157} INFO - Started process (PID=17027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:09:47.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:09:47.751+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:09:47.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:09:47.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:09:47.783+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:09:47.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:09:47.792+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:09:47.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:09:47.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T16:10:18.149+0000] {processor.py:157} INFO - Started process (PID=17052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:10:18.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:10:18.157+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:10:18.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:10:18.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:10:18.185+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:10:18.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:10:18.197+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:10:18.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:10:18.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T16:10:48.635+0000] {processor.py:157} INFO - Started process (PID=17077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:10:48.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:10:48.637+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:10:48.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:10:48.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:10:48.663+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:10:48.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:10:48.675+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:10:48.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:10:48.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T16:11:19.045+0000] {processor.py:157} INFO - Started process (PID=17102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:11:19.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:11:19.047+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:11:19.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:11:19.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:11:19.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:11:19.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:11:19.089+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:11:19.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:11:19.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T16:11:49.515+0000] {processor.py:157} INFO - Started process (PID=17127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:11:49.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:11:49.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:11:49.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:11:49.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:11:49.547+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:11:49.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:11:49.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:11:49.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:11:49.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T16:12:19.992+0000] {processor.py:157} INFO - Started process (PID=17152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:12:19.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:12:19.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:12:19.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:12:20.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:12:20.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:12:20.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:12:20.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:12:20.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:12:20.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T16:12:50.429+0000] {processor.py:157} INFO - Started process (PID=17177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:12:50.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:12:50.432+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:12:50.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:12:50.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:12:50.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:12:50.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:12:50.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:12:50.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:12:50.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T16:13:20.858+0000] {processor.py:157} INFO - Started process (PID=17202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:13:20.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:13:20.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:13:20.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:13:20.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:13:20.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:13:20.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:13:20.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:13:20.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:13:20.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T16:13:51.365+0000] {processor.py:157} INFO - Started process (PID=17227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:13:51.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:13:51.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:13:51.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:13:51.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:13:51.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:13:51.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:13:51.429+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:13:51.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:13:51.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T16:14:21.846+0000] {processor.py:157} INFO - Started process (PID=17252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:14:21.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:14:21.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:14:21.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:14:21.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:14:21.883+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:14:21.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:14:21.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:14:21.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:14:21.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T16:14:52.357+0000] {processor.py:157} INFO - Started process (PID=17277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:14:52.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:14:52.361+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:14:52.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:14:52.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:14:52.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:14:52.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:14:52.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:14:52.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:14:52.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T16:15:22.900+0000] {processor.py:157} INFO - Started process (PID=17302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:15:22.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:15:22.903+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:15:22.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:15:22.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:15:22.941+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:15:22.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:15:22.966+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:15:22.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:15:22.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T16:15:53.394+0000] {processor.py:157} INFO - Started process (PID=17327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:15:53.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:15:53.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:15:53.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:15:53.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:15:53.428+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:15:53.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:15:53.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:15:53.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:15:53.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T16:16:23.830+0000] {processor.py:157} INFO - Started process (PID=17352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:16:23.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:16:23.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:16:23.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:16:23.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:16:23.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:16:23.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:16:23.870+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:16:23.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:16:23.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T16:16:54.262+0000] {processor.py:157} INFO - Started process (PID=17377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:16:54.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:16:54.266+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:16:54.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:16:54.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:16:54.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:16:54.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:16:54.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:16:54.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:16:54.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T16:17:24.681+0000] {processor.py:157} INFO - Started process (PID=17402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:17:24.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:17:24.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:17:24.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:17:24.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:17:24.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:17:24.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:17:24.720+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:17:24.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:17:24.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T16:17:55.102+0000] {processor.py:157} INFO - Started process (PID=17427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:17:55.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:17:55.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:17:55.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:17:55.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:17:55.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:17:55.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:17:55.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:17:55.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:17:55.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T16:18:25.572+0000] {processor.py:157} INFO - Started process (PID=17452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:18:25.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:18:25.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:18:25.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:18:25.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:18:25.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:18:25.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:18:25.614+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:18:25.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:18:25.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T16:18:56.006+0000] {processor.py:157} INFO - Started process (PID=17477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:18:56.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:18:56.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:18:56.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:18:56.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:18:56.035+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:18:56.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:18:56.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:18:56.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:18:56.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T16:19:26.622+0000] {processor.py:157} INFO - Started process (PID=17502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:19:26.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:19:26.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:19:26.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:19:26.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:19:26.651+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:19:26.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:19:26.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:19:26.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:19:26.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T16:19:57.105+0000] {processor.py:157} INFO - Started process (PID=17526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:19:57.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:19:57.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:19:57.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:19:57.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:19:57.135+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:19:57.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:19:57.146+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:19:57.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:19:57.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:20:27.524+0000] {processor.py:157} INFO - Started process (PID=17552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:20:27.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:20:27.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:20:27.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:20:27.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:20:27.557+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:20:27.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:20:27.568+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:20:27.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:20:27.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T16:20:58.046+0000] {processor.py:157} INFO - Started process (PID=17577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:20:58.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:20:58.049+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:20:58.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:20:58.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:20:58.079+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:20:58.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:20:58.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:20:58.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:20:58.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T16:21:28.663+0000] {processor.py:157} INFO - Started process (PID=17602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:21:28.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:21:28.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:21:28.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:21:28.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:21:28.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:21:28.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:21:28.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:21:28.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:21:28.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T16:21:59.108+0000] {processor.py:157} INFO - Started process (PID=17627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:21:59.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:21:59.113+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:21:59.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:21:59.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:21:59.129+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:21:59.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:21:59.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:21:59.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:21:59.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-26T16:22:29.633+0000] {processor.py:157} INFO - Started process (PID=17652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:22:29.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:22:29.641+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:22:29.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:22:29.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:22:29.662+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:22:29.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:22:29.671+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:22:29.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:22:29.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T16:23:00.068+0000] {processor.py:157} INFO - Started process (PID=17677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:23:00.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:23:00.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:23:00.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:23:00.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:23:00.103+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:23:00.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:23:00.116+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:23:00.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:23:00.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T16:23:30.588+0000] {processor.py:157} INFO - Started process (PID=17702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:23:30.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:23:30.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:23:30.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:23:30.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:23:30.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:23:30.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:23:30.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:23:30.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:23:30.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T16:24:01.091+0000] {processor.py:157} INFO - Started process (PID=17727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:24:01.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:24:01.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:24:01.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:24:01.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:24:01.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:24:01.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:24:01.174+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:24:01.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:24:01.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T16:24:31.631+0000] {processor.py:157} INFO - Started process (PID=17752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:24:31.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:24:31.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:24:31.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:24:31.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:24:31.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:24:31.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:24:31.686+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:24:31.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:24:31.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T16:25:02.110+0000] {processor.py:157} INFO - Started process (PID=17777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:25:02.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:25:02.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:25:02.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:25:02.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:25:02.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:25:02.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:25:02.160+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:25:02.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:25:02.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T16:25:32.599+0000] {processor.py:157} INFO - Started process (PID=17802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:25:32.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:25:32.604+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:25:32.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:25:32.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:25:32.645+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:25:32.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:25:32.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:25:32.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:25:32.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T16:26:03.122+0000] {processor.py:157} INFO - Started process (PID=17827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:26:03.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:26:03.127+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:26:03.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:26:03.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:26:03.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:26:03.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:26:03.199+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:26:03.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:26:03.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-26T16:26:33.622+0000] {processor.py:157} INFO - Started process (PID=17852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:26:33.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:26:33.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:26:33.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:26:33.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:26:33.656+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:26:33.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:26:33.667+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:26:33.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:26:33.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T16:27:04.126+0000] {processor.py:157} INFO - Started process (PID=17877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:27:04.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:27:04.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:27:04.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:27:04.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:27:04.154+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:27:04.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:27:04.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:27:04.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:27:04.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T16:27:34.659+0000] {processor.py:157} INFO - Started process (PID=17902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:27:34.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:27:34.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:27:34.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:27:34.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:27:34.746+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:27:34.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:27:34.761+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:27:34.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:27:34.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-26T16:28:05.157+0000] {processor.py:157} INFO - Started process (PID=17927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:28:05.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:28:05.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:28:05.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:28:05.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:28:05.207+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:28:05.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:28:05.226+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:28:05.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:28:05.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T16:28:35.572+0000] {processor.py:157} INFO - Started process (PID=17952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:28:35.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:28:35.575+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:28:35.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:28:35.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:28:35.606+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:28:35.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:28:35.619+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:28:35.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:28:35.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T16:29:06.026+0000] {processor.py:157} INFO - Started process (PID=17977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:29:06.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:29:06.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:29:06.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:29:06.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:29:06.057+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:29:06.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:29:06.069+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:29:06.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:29:06.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T16:29:36.478+0000] {processor.py:157} INFO - Started process (PID=18002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:29:36.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:29:36.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:29:36.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:29:36.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:29:36.525+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:29:36.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:29:36.537+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:29:36.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:29:36.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T16:30:06.986+0000] {processor.py:157} INFO - Started process (PID=18027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:30:06.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:30:06.990+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:30:06.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:30:07.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:30:07.016+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:30:07.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:30:07.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:30:07.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:30:07.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:30:37.368+0000] {processor.py:157} INFO - Started process (PID=18052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:30:37.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:30:37.371+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:30:37.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:30:37.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:30:37.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:30:37.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:30:37.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:30:37.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:30:37.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T16:31:07.752+0000] {processor.py:157} INFO - Started process (PID=18076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:31:07.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:31:07.757+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:31:07.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:31:07.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:31:07.797+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:31:07.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:31:07.811+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:31:07.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:31:07.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T16:31:38.199+0000] {processor.py:157} INFO - Started process (PID=18102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:31:38.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:31:38.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:31:38.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:31:38.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:31:38.227+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:31:38.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:31:38.237+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:31:38.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:31:38.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T16:32:08.638+0000] {processor.py:157} INFO - Started process (PID=18127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:32:08.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:32:08.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:32:08.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:32:08.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:32:08.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:32:08.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:32:08.687+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:32:08.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:32:08.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T16:32:39.159+0000] {processor.py:157} INFO - Started process (PID=18152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:32:39.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:32:39.166+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:32:39.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:32:39.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:32:39.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:32:39.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:32:39.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:32:39.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:32:39.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T16:33:09.569+0000] {processor.py:157} INFO - Started process (PID=18177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:33:09.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:33:09.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:33:09.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:33:09.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:33:09.607+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:33:09.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:33:09.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:33:09.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:33:09.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T16:33:40.074+0000] {processor.py:157} INFO - Started process (PID=18202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:33:40.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:33:40.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:33:40.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:33:40.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:33:40.106+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:33:40.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:33:40.121+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:33:40.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:33:40.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T16:34:10.662+0000] {processor.py:157} INFO - Started process (PID=18227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:34:10.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:34:10.670+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:34:10.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:34:10.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:34:10.746+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:34:10.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:34:10.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:34:10.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:34:10.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-26T16:34:41.261+0000] {processor.py:157} INFO - Started process (PID=18252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:34:41.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:34:41.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:34:41.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:34:41.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:34:41.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:34:41.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:34:41.303+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:34:41.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:34:41.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T16:35:11.714+0000] {processor.py:157} INFO - Started process (PID=18277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:35:11.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:35:11.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:35:11.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:35:11.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:35:11.739+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:35:11.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:35:11.749+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:35:11.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:35:11.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T16:35:42.217+0000] {processor.py:157} INFO - Started process (PID=18302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:35:42.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:35:42.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:35:42.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:35:42.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:35:42.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:35:42.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:35:42.315+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:35:42.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:35:42.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-26T16:36:12.732+0000] {processor.py:157} INFO - Started process (PID=18327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:36:12.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:36:12.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:36:12.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:36:12.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:36:12.794+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:36:12.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:36:12.811+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:36:12.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:36:12.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T16:36:43.240+0000] {processor.py:157} INFO - Started process (PID=18352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:36:43.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:36:43.244+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:36:43.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:36:43.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:36:43.280+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:36:43.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:36:43.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:36:43.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:36:43.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T16:37:13.712+0000] {processor.py:157} INFO - Started process (PID=18377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:37:13.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:37:13.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:37:13.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:37:13.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:37:13.739+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:37:13.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:37:13.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:37:13.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:37:13.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T16:37:44.184+0000] {processor.py:157} INFO - Started process (PID=18402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:37:44.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:37:44.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:37:44.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:37:44.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:37:44.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:37:44.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:37:44.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:37:44.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:37:44.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T16:38:14.643+0000] {processor.py:157} INFO - Started process (PID=18426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:38:14.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:38:14.655+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:38:14.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:38:14.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:38:14.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:38:14.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:38:14.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:38:14.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:38:14.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T16:38:45.194+0000] {processor.py:157} INFO - Started process (PID=18452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:38:45.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:38:45.204+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:38:45.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:38:45.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:38:45.254+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:38:45.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:38:45.268+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:38:45.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:38:45.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T16:39:15.798+0000] {processor.py:157} INFO - Started process (PID=18477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:39:15.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:39:15.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:39:15.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:39:15.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:39:15.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:39:15.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:39:15.856+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:39:15.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:39:15.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T16:39:46.383+0000] {processor.py:157} INFO - Started process (PID=18502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:39:46.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:39:46.398+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:39:46.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:39:46.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:39:46.464+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:39:46.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:39:46.481+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:39:46.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:39:46.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-26T16:40:16.959+0000] {processor.py:157} INFO - Started process (PID=18527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:40:16.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:40:16.965+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:40:16.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:40:16.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:40:17.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:40:17.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:40:17.038+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:40:17.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:40:17.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T16:40:47.482+0000] {processor.py:157} INFO - Started process (PID=18552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:40:47.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:40:47.489+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:40:47.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:40:47.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:40:47.524+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:40:47.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:40:47.539+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:40:47.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:40:47.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T16:41:18.068+0000] {processor.py:157} INFO - Started process (PID=18577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:41:18.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:41:18.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:41:18.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:41:18.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:41:18.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:41:18.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:41:18.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:41:18.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:41:18.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T16:41:48.604+0000] {processor.py:157} INFO - Started process (PID=18602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:41:48.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:41:48.609+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:41:48.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:41:48.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:41:48.679+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:41:48.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:41:48.692+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:41:48.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:41:48.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-26T16:42:19.098+0000] {processor.py:157} INFO - Started process (PID=18627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:42:19.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:42:19.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:42:19.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:42:19.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:42:19.135+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:42:19.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:42:19.148+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:42:19.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:42:19.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T16:42:49.592+0000] {processor.py:157} INFO - Started process (PID=18652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:42:49.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:42:49.604+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:42:49.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:42:49.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:42:49.662+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:42:49.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:42:49.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:42:49.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:42:49.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T16:43:20.076+0000] {processor.py:157} INFO - Started process (PID=18677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:43:20.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:43:20.081+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:43:20.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:43:20.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:43:20.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:43:20.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:43:20.145+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:43:20.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:43:20.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T16:43:50.544+0000] {processor.py:157} INFO - Started process (PID=18702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:43:50.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:43:50.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:43:50.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:43:50.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:43:50.588+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:43:50.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:43:50.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:43:50.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:43:50.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T16:44:21.046+0000] {processor.py:157} INFO - Started process (PID=18727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:44:21.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:44:21.052+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:44:21.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:44:21.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:44:21.104+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:44:21.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:44:21.121+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:44:21.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:44:21.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T16:44:51.646+0000] {processor.py:157} INFO - Started process (PID=18751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:44:51.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:44:51.656+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:44:51.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:44:51.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:44:51.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:44:51.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:44:51.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:44:51.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:44:51.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T16:45:22.182+0000] {processor.py:157} INFO - Started process (PID=18777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:45:22.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:45:22.200+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:45:22.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:45:22.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:45:22.246+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:45:22.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:45:22.259+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:45:22.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:45:22.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-26T16:45:52.818+0000] {processor.py:157} INFO - Started process (PID=18802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:45:52.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:45:52.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:45:52.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:45:52.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:45:52.911+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:45:52.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:45:52.933+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:45:52.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:45:52.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-26T16:46:23.454+0000] {processor.py:157} INFO - Started process (PID=18827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:46:23.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:46:23.463+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:46:23.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:46:23.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:46:23.515+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:46:23.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:46:23.529+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:46:23.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:46:23.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T16:46:54.022+0000] {processor.py:157} INFO - Started process (PID=18851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:46:54.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:46:54.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:46:54.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:46:54.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:46:54.082+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:46:54.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:46:54.094+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:46:54.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:46:54.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T16:47:24.580+0000] {processor.py:157} INFO - Started process (PID=18877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:47:24.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:47:24.591+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:47:24.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:47:24.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:47:24.645+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:47:24.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:47:24.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:47:24.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:47:24.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-26T16:47:55.207+0000] {processor.py:157} INFO - Started process (PID=18902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:47:55.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:47:55.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:47:55.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:47:55.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:47:55.260+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:47:55.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:47:55.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:47:55.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:47:55.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T16:48:25.801+0000] {processor.py:157} INFO - Started process (PID=18927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:48:25.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:48:25.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:48:25.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:48:25.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:48:25.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:48:25.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:48:25.866+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:48:25.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:48:25.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T16:48:56.310+0000] {processor.py:157} INFO - Started process (PID=18952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:48:56.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:48:56.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:48:56.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:48:56.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:48:56.338+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:48:56.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:48:56.348+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:48:56.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:48:56.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T16:49:27.015+0000] {processor.py:157} INFO - Started process (PID=18977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:49:27.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:49:27.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:49:27.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:49:27.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:49:27.074+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:49:27.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:49:27.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:49:27.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:49:27.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-26T16:49:57.818+0000] {processor.py:157} INFO - Started process (PID=19002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:49:57.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T16:49:57.821+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:49:57.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:49:57.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T16:49:57.851+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:49:57.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T16:49:57.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T16:49:57.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T16:49:57.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:05:17.591+0000] {processor.py:157} INFO - Started process (PID=19027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:05:17.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:05:17.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:05:17.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:05:17.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:05:17.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:05:17.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:05:17.652+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:05:17.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:05:17.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T17:05:48.063+0000] {processor.py:157} INFO - Started process (PID=19054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:05:48.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:05:48.068+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:05:48.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:05:48.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:05:48.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:05:48.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:05:48.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:05:48.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:05:48.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T17:06:18.599+0000] {processor.py:157} INFO - Started process (PID=19079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:06:18.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:06:18.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:06:18.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:06:18.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:06:18.629+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:06:18.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:06:18.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:06:18.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:06:18.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:06:49.079+0000] {processor.py:157} INFO - Started process (PID=19104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:06:49.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:06:49.082+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:06:49.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:06:49.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:06:49.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:06:49.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:06:49.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:06:49.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:06:49.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T17:07:19.590+0000] {processor.py:157} INFO - Started process (PID=19129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:07:19.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:07:19.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:07:19.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:07:19.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:07:19.637+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:07:19.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:07:19.655+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:07:19.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:07:19.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T17:07:50.086+0000] {processor.py:157} INFO - Started process (PID=19154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:07:50.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:07:50.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:07:50.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:07:50.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:07:50.121+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:07:50.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:07:50.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:07:50.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:07:50.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T17:08:20.481+0000] {processor.py:157} INFO - Started process (PID=19179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:08:20.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:08:20.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:08:20.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:08:20.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:08:20.516+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:08:20.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:08:20.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:08:20.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:08:20.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T17:08:50.992+0000] {processor.py:157} INFO - Started process (PID=19204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:08:50.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:08:50.998+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:08:50.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:08:51.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:08:51.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:08:51.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:08:51.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:08:51.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:08:51.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T17:09:21.516+0000] {processor.py:157} INFO - Started process (PID=19229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:09:21.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:09:21.520+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:09:21.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:09:21.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:09:21.547+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:09:21.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:09:21.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:09:21.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:09:21.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T17:09:51.932+0000] {processor.py:157} INFO - Started process (PID=19254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:09:51.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:09:51.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:09:51.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:09:51.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:09:51.967+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:09:51.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:09:51.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:09:51.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:09:51.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:10:22.411+0000] {processor.py:157} INFO - Started process (PID=19279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:10:22.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:10:22.419+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:10:22.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:10:22.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:10:22.454+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:10:22.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:10:22.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:10:22.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:10:22.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T17:10:52.845+0000] {processor.py:157} INFO - Started process (PID=19304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:10:52.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:10:52.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:10:52.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:10:52.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:10:52.879+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:10:52.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:10:52.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:10:52.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:10:52.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T17:11:23.259+0000] {processor.py:157} INFO - Started process (PID=19329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:11:23.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:11:23.263+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:11:23.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:11:23.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:11:23.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:11:23.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:11:23.304+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:11:23.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:11:23.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T17:11:53.730+0000] {processor.py:157} INFO - Started process (PID=19354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:11:53.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:11:53.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:11:53.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:11:53.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:11:53.773+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:11:53.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:11:53.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:11:53.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:11:53.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T17:12:24.194+0000] {processor.py:157} INFO - Started process (PID=19379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:12:24.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:12:24.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:12:24.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:12:24.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:12:24.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:12:24.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:12:24.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:12:24.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:12:24.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T17:12:54.658+0000] {processor.py:157} INFO - Started process (PID=19404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:12:54.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:12:54.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:12:54.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:12:54.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:12:54.695+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:12:54.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:12:54.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:12:54.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:12:54.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T17:13:25.068+0000] {processor.py:157} INFO - Started process (PID=19429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:13:25.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:13:25.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:13:25.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:13:25.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:13:25.135+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:13:25.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:13:25.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:13:25.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:13:25.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T17:13:55.644+0000] {processor.py:157} INFO - Started process (PID=19454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:13:55.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:13:55.647+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:13:55.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:13:55.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:13:55.679+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:13:55.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:13:55.692+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:13:55.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:13:55.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T17:14:26.070+0000] {processor.py:157} INFO - Started process (PID=19479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:14:26.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:14:26.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:14:26.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:14:26.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:14:26.098+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:14:26.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:14:26.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:14:26.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:14:26.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T17:14:56.540+0000] {processor.py:157} INFO - Started process (PID=19504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:14:56.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:14:56.543+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:14:56.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:14:56.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:14:56.571+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:14:56.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:14:56.583+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:14:56.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:14:56.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T17:15:27.108+0000] {processor.py:157} INFO - Started process (PID=19529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:15:27.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:15:27.113+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:15:27.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:15:27.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:15:27.170+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:15:27.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:15:27.182+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:15:27.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:15:27.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T17:15:57.603+0000] {processor.py:157} INFO - Started process (PID=19554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:15:57.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:15:57.608+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:15:57.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:15:57.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:15:57.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:15:57.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:15:57.645+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:15:57.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:15:57.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T17:16:28.086+0000] {processor.py:157} INFO - Started process (PID=19579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:16:28.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:16:28.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:16:28.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:16:28.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:16:28.127+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:16:28.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:16:28.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:16:28.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:16:28.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T17:16:58.593+0000] {processor.py:157} INFO - Started process (PID=19604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:16:58.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:16:58.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:16:58.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:16:58.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:16:58.628+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:16:58.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:16:58.641+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:16:58.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:16:58.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T17:17:29.024+0000] {processor.py:157} INFO - Started process (PID=19629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:17:29.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:17:29.028+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:17:29.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:17:29.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:17:29.056+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:17:29.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:17:29.069+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:17:29.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:17:29.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T17:17:59.391+0000] {processor.py:157} INFO - Started process (PID=19654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:17:59.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:17:59.395+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:17:59.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:17:59.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:17:59.430+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:17:59.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:17:59.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:17:59.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:17:59.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T17:18:29.903+0000] {processor.py:157} INFO - Started process (PID=19679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:18:29.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:18:29.907+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:18:29.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:18:29.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:18:29.943+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:18:29.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:18:29.956+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:18:29.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:18:29.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T17:19:00.345+0000] {processor.py:157} INFO - Started process (PID=19704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:19:00.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:19:00.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:19:00.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:19:00.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:19:00.388+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:19:00.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:19:00.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:19:00.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:19:00.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T17:19:30.857+0000] {processor.py:157} INFO - Started process (PID=19729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:19:30.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:19:30.861+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:19:30.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:19:30.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:19:30.892+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:19:30.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:19:30.904+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:19:30.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:19:30.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T17:20:01.303+0000] {processor.py:157} INFO - Started process (PID=19754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:20:01.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:20:01.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:20:01.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:20:01.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:20:01.334+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:20:01.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:20:01.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:20:01.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:20:01.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T17:20:31.747+0000] {processor.py:157} INFO - Started process (PID=19779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:20:31.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:20:31.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:20:31.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:20:31.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:20:31.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:20:31.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:20:31.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:20:31.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:20:31.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T17:21:02.216+0000] {processor.py:157} INFO - Started process (PID=19804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:21:02.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:21:02.220+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:21:02.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:21:02.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:21:02.244+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:21:02.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:21:02.254+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:21:02.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:21:02.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T17:21:32.655+0000] {processor.py:157} INFO - Started process (PID=19829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:21:32.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:21:32.659+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:21:32.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:21:32.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:21:32.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:21:32.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:21:32.694+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:21:32.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:21:32.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T17:22:03.183+0000] {processor.py:157} INFO - Started process (PID=19854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:22:03.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:22:03.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:22:03.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:22:03.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:22:03.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:22:03.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:22:03.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:22:03.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:22:03.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T17:22:33.583+0000] {processor.py:157} INFO - Started process (PID=19879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:22:33.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:22:33.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:22:33.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:22:33.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:22:33.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:22:33.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:22:33.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:22:33.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:22:33.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T17:23:04.089+0000] {processor.py:157} INFO - Started process (PID=19904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:23:04.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:23:04.096+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:23:04.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:23:04.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:23:04.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:23:04.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:23:04.146+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:23:04.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:23:04.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T17:23:34.555+0000] {processor.py:157} INFO - Started process (PID=19929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:23:34.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:23:34.559+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:23:34.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:23:34.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:23:34.588+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:23:34.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:23:34.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:23:34.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:23:34.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T17:24:05.075+0000] {processor.py:157} INFO - Started process (PID=19954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:24:05.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:24:05.078+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:24:05.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:24:05.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:24:05.105+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:24:05.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:24:05.116+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:24:05.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:24:05.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T17:24:35.554+0000] {processor.py:157} INFO - Started process (PID=19979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:24:35.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:24:35.557+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:24:35.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:24:35.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:24:35.594+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:24:35.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:24:35.606+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:24:35.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:24:35.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T17:25:05.959+0000] {processor.py:157} INFO - Started process (PID=20004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:25:05.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:25:05.962+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:25:05.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:25:05.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:25:05.990+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:25:05.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:25:06.002+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:25:06.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:25:06.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T17:25:36.444+0000] {processor.py:157} INFO - Started process (PID=20029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:25:36.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:25:36.453+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:25:36.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:25:36.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:25:36.494+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:25:36.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:25:36.505+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:25:36.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:25:36.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T17:26:06.883+0000] {processor.py:157} INFO - Started process (PID=20054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:26:06.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:26:06.887+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:26:06.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:26:06.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:26:06.924+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:26:06.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:26:06.936+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:26:06.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:26:06.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T17:26:37.398+0000] {processor.py:157} INFO - Started process (PID=20079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:26:37.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:26:37.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:26:37.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:26:37.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:26:37.425+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:26:37.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:26:37.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:26:37.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:26:37.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T17:27:07.784+0000] {processor.py:157} INFO - Started process (PID=20104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:27:07.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:27:07.787+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:27:07.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:27:07.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:27:07.811+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:27:07.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:27:07.823+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:27:07.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:27:07.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T17:27:38.246+0000] {processor.py:157} INFO - Started process (PID=20129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:27:38.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:27:38.249+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:27:38.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:27:38.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:27:38.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:27:38.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:27:38.288+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:27:38.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:27:38.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T17:28:08.696+0000] {processor.py:157} INFO - Started process (PID=20153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:28:08.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:28:08.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:28:08.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:28:08.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:28:08.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:28:08.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:28:08.782+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:28:08.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:28:08.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T17:28:39.289+0000] {processor.py:157} INFO - Started process (PID=20179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:28:39.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:28:39.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:28:39.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:28:39.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:28:39.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:28:39.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:28:39.333+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:28:39.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:28:39.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:29:09.772+0000] {processor.py:157} INFO - Started process (PID=20204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:29:09.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:29:09.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:29:09.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:29:09.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:29:09.815+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:29:09.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:29:09.829+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:29:09.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:29:09.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T17:29:40.288+0000] {processor.py:157} INFO - Started process (PID=20229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:29:40.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:29:40.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:29:40.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:29:40.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:29:40.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:29:40.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:29:40.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:29:40.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:29:40.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T17:30:10.737+0000] {processor.py:157} INFO - Started process (PID=20254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:30:10.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:30:10.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:30:10.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:30:10.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:30:10.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:30:10.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:30:10.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:30:10.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:30:10.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T17:30:41.189+0000] {processor.py:157} INFO - Started process (PID=20279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:30:41.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:30:41.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:30:41.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:30:41.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:30:41.223+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:30:41.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:30:41.236+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:30:41.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:30:41.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T17:31:11.695+0000] {processor.py:157} INFO - Started process (PID=20304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:31:11.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:31:11.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:31:11.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:31:11.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:31:11.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:31:11.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:31:11.736+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:31:11.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:31:11.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T17:31:42.081+0000] {processor.py:157} INFO - Started process (PID=20329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:31:42.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:31:42.083+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:31:42.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:31:42.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:31:42.106+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:31:42.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:31:42.116+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:31:42.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:31:42.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-26T17:32:12.513+0000] {processor.py:157} INFO - Started process (PID=20354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:32:12.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:32:12.518+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:32:12.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:32:12.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:32:12.555+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:32:12.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:32:12.567+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:32:12.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:32:12.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T17:32:43.006+0000] {processor.py:157} INFO - Started process (PID=20379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:32:43.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:32:43.010+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:32:43.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:32:43.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:32:43.041+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:32:43.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:32:43.055+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:32:43.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:32:43.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T17:33:13.496+0000] {processor.py:157} INFO - Started process (PID=20404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:33:13.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:33:13.501+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:33:13.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:33:13.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:33:13.530+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:33:13.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:33:13.542+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:33:13.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:33:13.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T17:33:43.953+0000] {processor.py:157} INFO - Started process (PID=20429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:33:43.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:33:43.958+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:33:43.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:33:43.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:33:43.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:33:43.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:33:44.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:33:44.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:33:44.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T17:34:14.456+0000] {processor.py:157} INFO - Started process (PID=20454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:34:14.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:34:14.464+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:34:14.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:34:14.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:34:14.507+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:34:14.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:34:14.520+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:34:14.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:34:14.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T17:34:44.962+0000] {processor.py:157} INFO - Started process (PID=20479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:34:44.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:34:44.965+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:34:44.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:34:44.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:34:44.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:34:44.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:34:45.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:34:45.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:34:45.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T17:35:15.433+0000] {processor.py:157} INFO - Started process (PID=20504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:35:15.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:35:15.436+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:35:15.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:35:15.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:35:15.470+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:35:15.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:35:15.486+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:35:15.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:35:15.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T17:35:45.928+0000] {processor.py:157} INFO - Started process (PID=20529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:35:45.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:35:45.933+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:35:45.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:35:45.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:35:45.968+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:35:45.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:35:45.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:35:45.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:35:45.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T17:36:16.371+0000] {processor.py:157} INFO - Started process (PID=20554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:36:16.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:36:16.376+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:36:16.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:36:16.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:36:16.429+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:36:16.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:36:16.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:36:16.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:36:16.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-26T17:36:46.881+0000] {processor.py:157} INFO - Started process (PID=20579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:36:46.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:36:46.884+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:36:46.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:36:46.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:36:46.916+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:36:46.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:36:46.928+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:36:46.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:36:46.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T17:37:17.359+0000] {processor.py:157} INFO - Started process (PID=20604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:37:17.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:37:17.362+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:37:17.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:37:17.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:37:17.395+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:37:17.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:37:17.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:37:17.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:37:17.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T17:37:47.878+0000] {processor.py:157} INFO - Started process (PID=20629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:37:47.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:37:47.883+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:37:47.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:37:47.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:37:47.913+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:37:47.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:37:47.927+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:37:47.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:37:47.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T17:38:18.289+0000] {processor.py:157} INFO - Started process (PID=20654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:38:18.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:38:18.292+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:38:18.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:38:18.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:38:18.316+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:38:18.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:38:18.326+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:38:18.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:38:18.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-26T17:38:48.764+0000] {processor.py:157} INFO - Started process (PID=20678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:38:48.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:38:48.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:38:48.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:38:48.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:38:48.815+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:38:48.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:38:48.828+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:38:48.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:38:48.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T17:39:19.210+0000] {processor.py:157} INFO - Started process (PID=20704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:39:19.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:39:19.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:39:19.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:39:19.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:39:19.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:39:19.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:39:19.250+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:39:19.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:39:19.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T17:39:49.700+0000] {processor.py:157} INFO - Started process (PID=20729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:39:49.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:39:49.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:39:49.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:39:49.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:39:49.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:39:49.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:39:49.758+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:39:49.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:39:49.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T17:40:20.152+0000] {processor.py:157} INFO - Started process (PID=20754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:40:20.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:40:20.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:40:20.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:40:20.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:40:20.188+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:40:20.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:40:20.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:40:20.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:40:20.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T17:40:50.582+0000] {processor.py:157} INFO - Started process (PID=20779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:40:50.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:40:50.585+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:40:50.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:40:50.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:40:50.611+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:40:50.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:40:50.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:40:50.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:40:50.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T17:41:21.090+0000] {processor.py:157} INFO - Started process (PID=20804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:41:21.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:41:21.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:41:21.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:41:21.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:41:21.160+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:41:21.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:41:21.173+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:41:21.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:41:21.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-26T17:41:51.599+0000] {processor.py:157} INFO - Started process (PID=20829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:41:51.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:41:51.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:41:51.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:41:51.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:41:51.628+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:41:51.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:41:51.641+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:41:51.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:41:51.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T17:42:22.243+0000] {processor.py:157} INFO - Started process (PID=20854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:42:22.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:42:22.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:42:22.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:42:22.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:42:22.287+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:42:22.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:42:22.301+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:42:22.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:42:22.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T17:42:52.737+0000] {processor.py:157} INFO - Started process (PID=20879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:42:52.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:42:52.741+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:42:52.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:42:52.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:42:52.771+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:42:52.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:42:52.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:42:52.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:42:52.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:43:23.239+0000] {processor.py:157} INFO - Started process (PID=20904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:43:23.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:43:23.244+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:43:23.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:43:23.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:43:23.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:43:23.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:43:23.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:43:23.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:43:23.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T17:43:53.759+0000] {processor.py:157} INFO - Started process (PID=20928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:43:53.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:43:53.765+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:43:53.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:43:53.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:43:53.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:43:53.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:43:53.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:43:53.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:43:53.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T17:44:24.261+0000] {processor.py:157} INFO - Started process (PID=20954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:44:24.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:44:24.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:44:24.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:44:24.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:44:24.290+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:44:24.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:44:24.300+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:44:24.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:44:24.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T17:44:54.710+0000] {processor.py:157} INFO - Started process (PID=20979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:44:54.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:44:54.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:44:54.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:44:54.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:44:54.733+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:44:54.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:44:54.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:44:54.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:44:54.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-26T17:45:25.234+0000] {processor.py:157} INFO - Started process (PID=21004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:45:25.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:45:25.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:45:25.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:45:25.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:45:25.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:45:25.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:45:25.307+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:45:25.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:45:25.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T17:45:55.772+0000] {processor.py:157} INFO - Started process (PID=21029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:45:55.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:45:55.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:45:55.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:45:55.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:45:55.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:45:55.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:45:55.815+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:45:55.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:45:55.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T17:46:26.255+0000] {processor.py:157} INFO - Started process (PID=21054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:46:26.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:46:26.258+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:46:26.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:46:26.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:46:26.287+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:46:26.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:46:26.298+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:46:26.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:46:26.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T17:46:56.798+0000] {processor.py:157} INFO - Started process (PID=21079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:46:56.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:46:56.802+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:46:56.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:46:56.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:46:56.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:46:56.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:46:56.870+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:46:56.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:46:56.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-26T17:47:27.274+0000] {processor.py:157} INFO - Started process (PID=21104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:47:27.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:47:27.278+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:47:27.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:47:27.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:47:27.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:47:27.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:47:27.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:47:27.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:47:27.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:47:57.780+0000] {processor.py:157} INFO - Started process (PID=21129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:47:57.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:47:57.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:47:57.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:47:57.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:47:57.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:47:57.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:47:57.825+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:47:57.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:47:57.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T17:48:28.325+0000] {processor.py:157} INFO - Started process (PID=21154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:48:28.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:48:28.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:48:28.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:48:28.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:48:28.380+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:48:28.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:48:28.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:48:28.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:48:28.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T17:48:58.857+0000] {processor.py:157} INFO - Started process (PID=21179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:48:58.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:48:58.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:48:58.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:48:58.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:48:58.889+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:48:58.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:48:58.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:48:58.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:48:58.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T17:49:29.265+0000] {processor.py:157} INFO - Started process (PID=21204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:49:29.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:49:29.269+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:49:29.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:49:29.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:49:29.295+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:49:29.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:49:29.304+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:49:29.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:49:29.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T17:49:59.715+0000] {processor.py:157} INFO - Started process (PID=21229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:49:59.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:49:59.718+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:49:59.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:49:59.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:49:59.748+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:49:59.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:49:59.760+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:49:59.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:49:59.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T17:50:30.153+0000] {processor.py:157} INFO - Started process (PID=21254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:50:30.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:50:30.159+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:50:30.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:50:30.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:50:30.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:50:30.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:50:30.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:50:30.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:50:30.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T17:51:00.673+0000] {processor.py:157} INFO - Started process (PID=21279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:51:00.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:51:00.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:51:00.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:51:00.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:51:00.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:51:00.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:51:00.724+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:51:00.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:51:00.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T17:51:31.112+0000] {processor.py:157} INFO - Started process (PID=21304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:51:31.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:51:31.116+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:51:31.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:51:31.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:51:31.138+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:51:31.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:51:31.150+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:51:31.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:51:31.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T17:52:01.529+0000] {processor.py:157} INFO - Started process (PID=21329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:52:01.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:52:01.533+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:52:01.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:52:01.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:52:01.561+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:52:01.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:52:01.575+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:52:01.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:52:01.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T17:52:32.009+0000] {processor.py:157} INFO - Started process (PID=21354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:52:32.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:52:32.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:52:32.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:52:32.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:52:32.041+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:52:32.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:52:32.052+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:52:32.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:52:32.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:53:02.429+0000] {processor.py:157} INFO - Started process (PID=21379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:53:02.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:53:02.431+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:53:02.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:53:02.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:53:02.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:53:02.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:53:02.470+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:53:02.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:53:02.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T17:53:32.910+0000] {processor.py:157} INFO - Started process (PID=21404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:53:32.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:53:32.916+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:53:32.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:53:32.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:53:32.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:53:32.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:53:32.966+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:53:32.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:53:32.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T17:54:03.347+0000] {processor.py:157} INFO - Started process (PID=21429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:54:03.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:54:03.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:54:03.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:54:03.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:54:03.379+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:54:03.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:54:03.390+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:54:03.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:54:03.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T17:54:33.827+0000] {processor.py:157} INFO - Started process (PID=21454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:54:33.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:54:33.828+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:54:33.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:54:33.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:54:33.853+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:54:33.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:54:33.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:54:33.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:54:33.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T17:55:04.173+0000] {processor.py:157} INFO - Started process (PID=21478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:55:04.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:55:04.177+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:55:04.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:55:04.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:55:04.212+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:55:04.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:55:04.224+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:55:04.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:55:04.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T17:55:34.680+0000] {processor.py:157} INFO - Started process (PID=21504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:55:34.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:55:34.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:55:34.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:55:34.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:55:34.714+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:55:34.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:55:34.724+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:55:34.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:55:34.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T17:56:05.225+0000] {processor.py:157} INFO - Started process (PID=21529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:56:05.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:56:05.232+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:56:05.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:56:05.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:56:05.270+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:56:05.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:56:05.285+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:56:05.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:56:05.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T17:56:35.667+0000] {processor.py:157} INFO - Started process (PID=21554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:56:35.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:56:35.669+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:56:35.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:56:35.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:56:35.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:56:35.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:56:35.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:56:35.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:56:35.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T17:57:06.165+0000] {processor.py:157} INFO - Started process (PID=21579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:57:06.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:57:06.168+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:57:06.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:57:06.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:57:06.196+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:57:06.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:57:06.206+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:57:06.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:57:06.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T17:57:36.632+0000] {processor.py:157} INFO - Started process (PID=21604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:57:36.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:57:36.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:57:36.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:57:36.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:57:36.667+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:57:36.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:57:36.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:57:36.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:57:36.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T17:58:07.079+0000] {processor.py:157} INFO - Started process (PID=21628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:58:07.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:58:07.084+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:58:07.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:58:07.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:58:07.127+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:58:07.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:58:07.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:58:07.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:58:07.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T17:58:37.561+0000] {processor.py:157} INFO - Started process (PID=21654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:58:37.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:58:37.563+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:58:37.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:58:37.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:58:37.591+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:58:37.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:58:37.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:58:37.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:58:37.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T17:59:08.015+0000] {processor.py:157} INFO - Started process (PID=21679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:59:08.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:59:08.023+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:59:08.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:59:08.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:59:08.065+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:59:08.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:59:08.081+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:59:08.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:59:08.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T17:59:38.523+0000] {processor.py:157} INFO - Started process (PID=21704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:59:38.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T17:59:38.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:59:38.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:59:38.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T17:59:38.556+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:59:38.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T17:59:38.566+0000] {logging_mixin.py:151} INFO - [2024-07-26T17:59:38.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T17:59:38.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T18:00:08.966+0000] {processor.py:157} INFO - Started process (PID=21729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:00:08.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:00:08.972+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:00:08.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:00:08.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:00:09.008+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:00:09.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:00:09.022+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:00:09.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:00:09.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T18:00:39.445+0000] {processor.py:157} INFO - Started process (PID=21754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:00:39.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:00:39.448+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:00:39.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:00:39.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:00:39.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:00:39.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:00:39.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:00:39.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:00:39.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T18:01:09.924+0000] {processor.py:157} INFO - Started process (PID=21779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:01:09.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:01:09.927+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:01:09.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:01:09.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:01:09.959+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:01:09.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:01:09.969+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:01:09.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:01:09.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T18:01:40.444+0000] {processor.py:157} INFO - Started process (PID=21804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:01:40.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:01:40.448+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:01:40.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:01:40.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:01:40.474+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:01:40.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:01:40.484+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:01:40.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:01:40.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T18:02:10.871+0000] {processor.py:157} INFO - Started process (PID=21829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:02:10.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:02:10.877+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:02:10.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:02:10.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:02:10.913+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:02:10.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:02:10.926+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:02:10.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:02:10.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T18:02:41.325+0000] {processor.py:157} INFO - Started process (PID=21854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:02:41.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:02:41.330+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:02:41.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:02:41.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:02:41.359+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:02:41.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:02:41.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:02:41.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:02:41.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T18:03:11.771+0000] {processor.py:157} INFO - Started process (PID=21879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:03:11.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:03:11.774+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:03:11.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:03:11.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:03:11.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:03:11.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:03:11.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:03:11.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:03:11.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T18:03:42.264+0000] {processor.py:157} INFO - Started process (PID=21904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:03:42.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:03:42.270+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:03:42.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:03:42.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:03:42.307+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:03:42.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:03:42.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:03:42.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:03:42.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T18:04:12.775+0000] {processor.py:157} INFO - Started process (PID=21929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:04:12.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:04:12.779+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:04:12.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:04:12.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:04:12.811+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:04:12.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:04:12.827+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:04:12.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:04:12.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T18:04:43.229+0000] {processor.py:157} INFO - Started process (PID=21954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:04:43.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:04:43.231+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:04:43.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:04:43.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:04:43.257+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:04:43.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:04:43.267+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:04:43.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:04:43.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T18:05:13.659+0000] {processor.py:157} INFO - Started process (PID=21979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:05:13.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:05:13.662+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:05:13.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:05:13.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:05:13.691+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:05:13.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:05:13.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:05:13.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:05:13.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T18:05:44.111+0000] {processor.py:157} INFO - Started process (PID=22004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:05:44.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:05:44.118+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:05:44.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:05:44.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:05:44.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:05:44.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:05:44.168+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:05:44.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:05:44.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T18:06:14.658+0000] {processor.py:157} INFO - Started process (PID=22029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:06:14.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:06:14.664+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:06:14.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:06:14.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:06:14.704+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:06:14.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:06:14.717+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:06:14.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:06:14.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T18:22:45.841+0000] {processor.py:157} INFO - Started process (PID=22054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:22:45.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:22:45.847+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:22:45.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:22:45.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:22:45.943+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:22:45.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:22:45.970+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:22:45.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:22:45.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-26T18:39:28.382+0000] {processor.py:157} INFO - Started process (PID=22081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:39:28.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:39:28.404+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:39:28.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:39:28.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:39:28.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:39:28.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:39:28.465+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:39:28.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:39:28.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-26T18:39:59.075+0000] {processor.py:157} INFO - Started process (PID=22108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:39:59.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:39:59.084+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:39:59.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:39:59.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:39:59.128+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:39:59.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:39:59.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:39:59.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:39:59.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T18:40:29.515+0000] {processor.py:157} INFO - Started process (PID=22133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:40:29.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:40:29.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:40:29.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:40:29.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:40:29.540+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:40:29.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:40:29.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:40:29.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:40:29.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-26T18:40:59.949+0000] {processor.py:157} INFO - Started process (PID=22158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:40:59.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:40:59.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:40:59.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:40:59.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:40:59.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:40:59.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:40:59.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:40:59.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:40:59.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T18:41:30.446+0000] {processor.py:157} INFO - Started process (PID=22182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:41:30.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:41:30.452+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:41:30.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:41:30.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:41:30.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:41:30.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:41:30.500+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:41:30.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:41:30.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T18:50:13.918+0000] {processor.py:157} INFO - Started process (PID=22208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:50:13.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:50:13.920+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:50:13.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:50:13.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:50:13.944+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:50:13.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:50:13.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:50:13.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:50:13.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T18:50:44.446+0000] {processor.py:157} INFO - Started process (PID=22233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:50:44.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:50:44.451+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:50:44.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:50:44.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:50:44.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:50:44.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:50:44.524+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:50:44.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:50:44.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T18:51:14.945+0000] {processor.py:157} INFO - Started process (PID=22258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:51:14.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:51:14.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:51:14.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:51:14.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:51:14.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:51:14.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:51:14.990+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:51:14.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:51:15.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T18:51:45.405+0000] {processor.py:157} INFO - Started process (PID=22283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:51:45.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:51:45.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:51:45.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:51:45.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:51:45.434+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:51:45.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:51:45.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:51:45.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:51:45.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T18:52:15.827+0000] {processor.py:157} INFO - Started process (PID=22308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:52:15.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:52:15.830+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:52:15.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:52:15.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:52:15.862+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:52:15.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:52:15.874+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:52:15.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:52:15.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T18:52:46.370+0000] {processor.py:157} INFO - Started process (PID=22333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:52:46.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:52:46.374+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:52:46.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:52:46.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:52:46.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:52:46.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:52:46.413+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:52:46.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:52:46.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T18:53:16.836+0000] {processor.py:157} INFO - Started process (PID=22358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:53:16.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:53:16.842+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:53:16.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:53:16.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:53:16.871+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:53:16.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:53:16.881+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:53:16.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:53:16.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T18:53:47.348+0000] {processor.py:157} INFO - Started process (PID=22383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:53:47.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:53:47.352+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:53:47.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:53:47.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:53:47.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:53:47.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:53:47.386+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:53:47.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:53:47.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T18:54:17.821+0000] {processor.py:157} INFO - Started process (PID=22408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:54:17.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:54:17.826+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:54:17.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:54:17.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:54:17.864+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:54:17.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:54:17.877+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:54:17.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:54:17.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T18:54:48.389+0000] {processor.py:157} INFO - Started process (PID=22433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:54:48.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:54:48.393+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:54:48.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:54:48.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:54:48.451+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:54:48.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:54:48.465+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:54:48.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:54:48.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-26T18:55:18.956+0000] {processor.py:157} INFO - Started process (PID=22458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:55:18.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:55:18.975+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:55:18.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:55:18.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:55:19.014+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:55:19.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:55:19.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:55:19.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:55:19.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T18:55:49.491+0000] {processor.py:157} INFO - Started process (PID=22483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:55:49.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:55:49.497+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:55:49.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:55:49.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:55:49.542+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:55:49.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:55:49.561+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:55:49.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:55:49.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-26T18:56:20.019+0000] {processor.py:157} INFO - Started process (PID=22508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:56:20.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:56:20.022+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:56:20.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:56:20.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:56:20.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:56:20.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:56:20.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:56:20.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:56:20.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T18:56:50.437+0000] {processor.py:157} INFO - Started process (PID=22533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:56:50.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:56:50.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:56:50.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:56:50.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:56:50.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:56:50.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:56:50.478+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:56:50.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:56:50.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T18:57:20.891+0000] {processor.py:157} INFO - Started process (PID=22558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:57:20.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:57:20.893+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:57:20.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:57:20.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:57:20.925+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:57:20.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:57:20.934+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:57:20.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:57:20.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T18:57:51.309+0000] {processor.py:157} INFO - Started process (PID=22583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:57:51.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:57:51.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:57:51.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:57:51.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:57:51.343+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:57:51.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:57:51.352+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:57:51.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:57:51.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T18:58:21.798+0000] {processor.py:157} INFO - Started process (PID=22608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:58:21.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:58:21.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:58:21.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:58:21.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:58:21.838+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:58:21.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:58:21.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:58:21.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:58:21.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T18:58:52.242+0000] {processor.py:157} INFO - Started process (PID=22633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:58:52.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:58:52.245+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:58:52.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:58:52.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:58:52.278+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:58:52.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:58:52.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:58:52.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:58:52.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T18:59:22.686+0000] {processor.py:157} INFO - Started process (PID=22658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:59:22.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:59:22.689+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:59:22.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:59:22.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:59:22.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:59:22.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:59:22.726+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:59:22.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:59:22.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T18:59:53.101+0000] {processor.py:157} INFO - Started process (PID=22683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:59:53.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T18:59:53.103+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:59:53.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:59:53.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T18:59:53.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:59:53.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T18:59:53.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T18:59:53.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T18:59:53.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T19:00:23.574+0000] {processor.py:157} INFO - Started process (PID=22708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:00:23.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:00:23.578+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:00:23.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:00:23.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:00:23.610+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:00:23.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:00:23.620+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:00:23.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:00:23.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:00:54.015+0000] {processor.py:157} INFO - Started process (PID=22732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:00:54.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:00:54.017+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:00:54.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:00:54.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:00:54.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:00:54.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:00:54.059+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:00:54.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:00:54.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:01:24.426+0000] {processor.py:157} INFO - Started process (PID=22758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:01:24.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:01:24.430+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:01:24.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:01:24.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:01:24.459+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:01:24.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:01:24.470+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:01:24.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:01:24.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T19:01:54.950+0000] {processor.py:157} INFO - Started process (PID=22783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:01:54.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:01:54.954+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:01:54.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:01:54.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:01:54.981+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:01:54.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:01:54.991+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:01:54.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:01:55.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:02:25.418+0000] {processor.py:157} INFO - Started process (PID=22808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:02:25.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:02:25.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:02:25.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:02:25.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:02:25.450+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:02:25.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:02:25.459+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:02:25.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:02:25.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:02:55.869+0000] {processor.py:157} INFO - Started process (PID=22833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:02:55.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:02:55.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:02:55.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:02:55.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:02:55.901+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:02:55.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:02:55.911+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:02:55.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:02:55.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:03:26.335+0000] {processor.py:157} INFO - Started process (PID=22858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:03:26.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:03:26.339+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:03:26.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:03:26.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:03:26.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:03:26.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:03:26.389+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:03:26.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:03:26.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T19:03:56.780+0000] {processor.py:157} INFO - Started process (PID=22883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:03:56.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:03:56.784+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:03:56.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:03:56.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:03:56.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:03:56.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:03:56.821+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:03:56.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:03:56.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:04:27.249+0000] {processor.py:157} INFO - Started process (PID=22908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:04:27.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:04:27.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:04:27.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:04:27.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:04:27.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:04:27.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:04:27.296+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:04:27.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:04:27.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T19:04:57.688+0000] {processor.py:157} INFO - Started process (PID=22932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:04:57.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:04:57.692+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:04:57.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:04:57.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:04:57.731+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:04:57.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:04:57.743+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:04:57.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:04:57.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T19:05:28.209+0000] {processor.py:157} INFO - Started process (PID=22958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:05:28.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:05:28.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:05:28.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:05:28.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:05:28.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:05:28.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:05:28.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:05:28.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:05:28.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T19:05:58.678+0000] {processor.py:157} INFO - Started process (PID=22983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:05:58.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:05:58.681+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:05:58.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:05:58.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:05:58.707+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:05:58.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:05:58.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:05:58.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:05:58.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T19:06:29.127+0000] {processor.py:157} INFO - Started process (PID=23008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:06:29.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:06:29.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:06:29.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:06:29.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:06:29.158+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:06:29.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:06:29.169+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:06:29.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:06:29.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:06:59.579+0000] {processor.py:157} INFO - Started process (PID=23033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:06:59.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:06:59.583+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:06:59.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:06:59.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:06:59.611+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:06:59.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:06:59.621+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:06:59.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:06:59.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:07:30.042+0000] {processor.py:157} INFO - Started process (PID=23058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:07:30.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:07:30.046+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:07:30.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:07:30.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:07:30.074+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:07:30.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:07:30.083+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:07:30.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:07:30.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:08:00.502+0000] {processor.py:157} INFO - Started process (PID=23083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:08:00.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:08:00.504+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:08:00.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:08:00.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:08:00.534+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:08:00.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:08:00.548+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:08:00.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:08:00.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T19:08:30.949+0000] {processor.py:157} INFO - Started process (PID=23108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:08:30.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:08:30.954+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:08:30.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:08:30.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:08:30.990+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:08:30.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:08:31.004+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:08:31.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:08:31.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T19:09:01.424+0000] {processor.py:157} INFO - Started process (PID=23133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:09:01.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:09:01.428+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:09:01.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:09:01.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:09:01.456+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:09:01.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:09:01.471+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:09:01.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:09:01.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T19:09:31.854+0000] {processor.py:157} INFO - Started process (PID=23158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:09:31.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:09:31.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:09:31.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:09:31.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:09:31.884+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:09:31.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:09:31.894+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:09:31.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:09:31.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:10:02.345+0000] {processor.py:157} INFO - Started process (PID=23183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:10:02.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:10:02.349+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:10:02.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:10:02.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:10:02.377+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:10:02.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:10:02.388+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:10:02.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:10:02.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T19:10:32.828+0000] {processor.py:157} INFO - Started process (PID=23208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:10:32.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:10:32.834+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:10:32.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:10:32.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:10:32.894+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:10:32.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:10:32.909+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:10:32.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:10:32.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-26T19:11:03.333+0000] {processor.py:157} INFO - Started process (PID=23233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:11:03.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:11:03.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:11:03.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:11:03.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:11:03.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:11:03.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:11:03.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:11:03.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:11:03.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:11:33.763+0000] {processor.py:157} INFO - Started process (PID=23258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:11:33.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:11:33.767+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:11:33.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:11:33.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:11:33.799+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:11:33.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:11:33.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:11:33.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:11:33.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T19:12:04.214+0000] {processor.py:157} INFO - Started process (PID=23283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:12:04.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:12:04.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:12:04.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:12:04.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:12:04.261+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:12:04.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:12:04.274+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:12:04.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:12:04.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-26T19:12:34.689+0000] {processor.py:157} INFO - Started process (PID=23308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:12:34.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:12:34.691+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:12:34.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:12:34.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:12:34.712+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:12:34.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:12:34.722+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:12:34.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:12:34.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-26T19:13:05.186+0000] {processor.py:157} INFO - Started process (PID=23333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:13:05.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:13:05.189+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:13:05.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:13:05.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:13:05.216+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:13:05.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:13:05.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:13:05.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:13:05.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:13:35.693+0000] {processor.py:157} INFO - Started process (PID=23358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:13:35.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:13:35.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:13:35.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:13:35.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:13:35.722+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:13:35.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:13:35.731+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:13:35.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:13:35.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T19:14:06.096+0000] {processor.py:157} INFO - Started process (PID=23382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:14:06.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:14:06.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:14:06.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:14:06.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:14:06.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:14:06.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:14:06.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:14:06.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:14:06.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T19:14:36.645+0000] {processor.py:157} INFO - Started process (PID=23408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:14:36.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:14:36.651+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:14:36.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:14:36.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:14:36.705+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:14:36.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:14:36.718+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:14:36.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:14:36.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T19:15:07.121+0000] {processor.py:157} INFO - Started process (PID=23433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:15:07.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:15:07.125+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:15:07.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:15:07.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:15:07.156+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:15:07.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:15:07.166+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:15:07.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:15:07.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T19:15:37.593+0000] {processor.py:157} INFO - Started process (PID=23458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:15:37.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:15:37.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:15:37.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:15:37.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:15:37.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:15:37.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:15:37.637+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:15:37.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:15:37.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:16:07.985+0000] {processor.py:157} INFO - Started process (PID=23483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:16:07.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:16:07.988+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:16:07.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:16:07.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:16:08.012+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:16:08.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:16:08.022+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:16:08.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:16:08.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T19:16:38.419+0000] {processor.py:157} INFO - Started process (PID=23508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:16:38.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:16:38.422+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:16:38.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:16:38.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:16:38.450+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:16:38.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:16:38.462+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:16:38.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:16:38.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:17:08.844+0000] {processor.py:157} INFO - Started process (PID=23533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:17:08.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:17:08.848+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:17:08.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:17:08.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:17:08.874+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:17:08.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:17:08.883+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:17:08.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:17:08.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:17:39.281+0000] {processor.py:157} INFO - Started process (PID=23558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:17:39.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:17:39.286+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:17:39.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:17:39.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:17:39.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:17:39.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:17:39.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:17:39.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:17:39.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T19:18:09.749+0000] {processor.py:157} INFO - Started process (PID=23583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:18:09.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:18:09.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:18:09.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:18:09.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:18:09.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:18:09.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:18:09.786+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:18:09.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:18:09.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T19:18:40.198+0000] {processor.py:157} INFO - Started process (PID=23608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:18:40.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:18:40.203+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:18:40.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:18:40.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:18:40.229+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:18:40.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:18:40.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:18:40.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:18:40.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:19:10.672+0000] {processor.py:157} INFO - Started process (PID=23633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:19:10.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:19:10.675+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:19:10.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:19:10.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:19:10.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:19:10.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:19:10.711+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:19:10.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:19:10.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T19:19:41.060+0000] {processor.py:157} INFO - Started process (PID=23658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:19:41.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:19:41.064+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:19:41.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:19:41.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:19:41.088+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:19:41.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:19:41.099+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:19:41.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:19:41.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T19:20:11.467+0000] {processor.py:157} INFO - Started process (PID=23683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:20:11.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:20:11.471+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:20:11.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:20:11.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:20:11.500+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:20:11.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:20:11.512+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:20:11.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:20:11.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:20:41.895+0000] {processor.py:157} INFO - Started process (PID=23708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:20:41.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:20:41.899+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:20:41.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:20:41.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:20:41.926+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:20:41.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:20:41.938+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:20:41.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:20:41.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:21:12.345+0000] {processor.py:157} INFO - Started process (PID=23733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:21:12.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:21:12.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:21:12.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:21:12.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:21:12.388+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:21:12.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:21:12.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:21:12.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:21:12.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T19:21:42.847+0000] {processor.py:157} INFO - Started process (PID=23758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:21:42.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:21:42.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:21:42.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:21:42.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:21:42.883+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:21:42.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:21:42.895+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:21:42.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:21:42.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T19:22:13.242+0000] {processor.py:157} INFO - Started process (PID=23783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:22:13.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:22:13.245+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:22:13.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:22:13.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:22:13.271+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:22:13.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:22:13.280+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:22:13.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:22:13.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T19:22:43.713+0000] {processor.py:157} INFO - Started process (PID=23808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:22:43.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:22:43.716+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:22:43.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:22:43.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:22:43.743+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:22:43.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:22:43.754+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:22:43.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:22:43.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T19:23:14.198+0000] {processor.py:157} INFO - Started process (PID=23833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:23:14.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:23:14.202+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:23:14.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:23:14.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:23:14.227+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:23:14.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:23:14.236+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:23:14.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:23:14.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T19:23:44.665+0000] {processor.py:157} INFO - Started process (PID=23858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:23:44.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:23:44.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:23:44.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:23:44.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:23:44.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:23:44.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:23:44.706+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:23:44.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:23:44.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:24:15.128+0000] {processor.py:157} INFO - Started process (PID=23883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:24:15.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:24:15.132+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:24:15.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:24:15.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:24:15.161+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:24:15.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:24:15.174+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:24:15.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:24:15.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T19:24:45.603+0000] {processor.py:157} INFO - Started process (PID=23908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:24:45.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:24:45.608+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:24:45.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:24:45.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:24:45.648+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:24:45.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:24:45.662+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:24:45.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:24:45.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T19:25:16.121+0000] {processor.py:157} INFO - Started process (PID=23933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:25:16.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:25:16.126+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:25:16.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:25:16.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:25:16.155+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:25:16.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:25:16.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:25:16.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:25:16.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:25:46.533+0000] {processor.py:157} INFO - Started process (PID=23958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:25:46.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:25:46.536+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:25:46.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:25:46.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:25:46.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:25:46.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:25:46.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:25:46.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:25:46.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:26:17.061+0000] {processor.py:157} INFO - Started process (PID=23983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:26:17.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:26:17.070+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:26:17.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:26:17.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:26:17.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:26:17.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:26:17.122+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:26:17.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:26:17.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T19:26:47.474+0000] {processor.py:157} INFO - Started process (PID=24008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:26:47.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:26:47.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:26:47.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:26:47.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:26:47.501+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:26:47.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:26:47.514+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:26:47.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:26:47.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:27:17.914+0000] {processor.py:157} INFO - Started process (PID=24033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:27:17.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:27:17.917+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:27:17.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:27:17.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:27:17.945+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:27:17.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:27:17.954+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:27:17.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:27:17.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T19:27:48.355+0000] {processor.py:157} INFO - Started process (PID=24058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:27:48.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:27:48.360+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:27:48.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:27:48.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:27:48.387+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:27:48.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:27:48.397+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:27:48.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:27:48.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:28:18.768+0000] {processor.py:157} INFO - Started process (PID=24083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:28:18.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:28:18.772+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:28:18.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:28:18.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:28:18.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:28:18.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:28:18.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:28:18.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:28:18.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:28:49.265+0000] {processor.py:157} INFO - Started process (PID=24108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:28:49.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:28:49.268+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:28:49.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:28:49.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:28:49.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:28:49.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:28:49.311+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:28:49.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:28:49.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T19:29:19.659+0000] {processor.py:157} INFO - Started process (PID=24133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:29:19.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:29:19.662+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:29:19.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:29:19.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:29:19.687+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:29:19.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:29:19.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:29:19.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:29:19.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T19:29:50.144+0000] {processor.py:157} INFO - Started process (PID=24158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:29:50.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:29:50.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:29:50.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:29:50.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:29:50.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:29:50.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:29:50.194+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:29:50.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:29:50.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T19:30:20.595+0000] {processor.py:157} INFO - Started process (PID=24183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:30:20.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:30:20.598+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:30:20.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:30:20.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:30:20.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:30:20.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:30:20.634+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:30:20.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:30:20.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:30:51.073+0000] {processor.py:157} INFO - Started process (PID=24208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:30:51.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:30:51.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:30:51.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:30:51.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:30:51.103+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:30:51.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:30:51.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:30:51.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:30:51.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:31:21.502+0000] {processor.py:157} INFO - Started process (PID=24233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:31:21.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:31:21.506+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:31:21.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:31:21.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:31:21.532+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:31:21.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:31:21.542+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:31:21.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:31:21.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:31:51.976+0000] {processor.py:157} INFO - Started process (PID=24258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:31:51.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:31:51.981+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:31:51.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:31:51.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:31:52.012+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:31:52.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:31:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:31:52.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:31:52.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T19:32:22.438+0000] {processor.py:157} INFO - Started process (PID=24283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:32:22.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:32:22.443+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:32:22.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:32:22.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:32:22.485+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:32:22.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:32:22.499+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:32:22.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:32:22.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T19:32:52.919+0000] {processor.py:157} INFO - Started process (PID=24308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:32:52.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:32:52.924+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:32:52.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:32:52.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:32:52.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:32:52.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:32:52.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:32:52.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:32:52.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:33:23.435+0000] {processor.py:157} INFO - Started process (PID=24333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:33:23.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:33:23.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:33:23.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:33:23.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:33:23.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:33:23.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:33:23.476+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:33:23.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:33:23.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:33:53.842+0000] {processor.py:157} INFO - Started process (PID=24358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:33:53.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:33:53.848+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:33:53.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:33:53.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:33:53.867+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:33:53.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:33:53.875+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:33:53.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:33:53.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-26T19:34:24.301+0000] {processor.py:157} INFO - Started process (PID=24383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:34:24.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:34:24.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:34:24.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:34:24.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:34:24.344+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:34:24.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:34:24.358+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:34:24.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:34:24.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T19:34:54.793+0000] {processor.py:157} INFO - Started process (PID=24408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:34:54.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:34:54.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:34:54.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:34:54.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:34:54.831+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:34:54.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:34:54.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:34:54.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:34:54.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T19:35:25.326+0000] {processor.py:157} INFO - Started process (PID=24433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:35:25.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:35:25.329+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:35:25.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:35:25.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:35:25.365+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:35:25.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:35:25.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:35:25.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:35:25.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T19:35:55.801+0000] {processor.py:157} INFO - Started process (PID=24458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:35:55.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:35:55.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:35:55.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:35:55.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:35:55.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:35:55.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:35:55.843+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:35:55.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:35:55.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:36:26.290+0000] {processor.py:157} INFO - Started process (PID=24483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:36:26.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:36:26.297+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:36:26.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:36:26.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:36:26.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:36:26.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:36:26.348+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:36:26.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:36:26.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T19:36:56.759+0000] {processor.py:157} INFO - Started process (PID=24508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:36:56.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:36:56.763+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:36:56.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:36:56.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:36:56.793+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:36:56.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:36:56.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:36:56.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:36:56.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:37:27.179+0000] {processor.py:157} INFO - Started process (PID=24533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:37:27.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:37:27.184+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:37:27.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:37:27.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:37:27.215+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:37:27.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:37:27.227+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:37:27.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:37:27.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T19:37:57.670+0000] {processor.py:157} INFO - Started process (PID=24558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:37:57.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:37:57.677+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:37:57.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:37:57.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:37:57.708+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:37:57.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:37:57.719+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:37:57.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:37:57.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T19:38:28.121+0000] {processor.py:157} INFO - Started process (PID=24583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:38:28.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:38:28.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:38:28.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:38:28.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:38:28.161+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:38:28.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:38:28.174+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:38:28.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:38:28.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T19:38:58.629+0000] {processor.py:157} INFO - Started process (PID=24608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:38:58.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:38:58.631+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:38:58.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:38:58.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:38:58.661+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:38:58.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:38:58.672+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:38:58.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:38:58.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:39:29.073+0000] {processor.py:157} INFO - Started process (PID=24633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:39:29.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:39:29.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:39:29.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:39:29.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:39:29.108+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:39:29.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:39:29.117+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:39:29.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:39:29.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:39:59.584+0000] {processor.py:157} INFO - Started process (PID=24658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:39:59.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:39:59.589+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:39:59.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:39:59.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:39:59.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:39:59.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:39:59.643+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:39:59.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:39:59.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T19:40:30.128+0000] {processor.py:157} INFO - Started process (PID=24683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:40:30.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:40:30.133+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:40:30.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:40:30.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:40:30.178+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:40:30.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:40:30.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:40:30.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:40:30.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-26T19:41:00.614+0000] {processor.py:157} INFO - Started process (PID=24708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:41:00.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:41:00.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:41:00.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:41:00.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:41:00.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:41:00.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:41:00.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:41:00.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:41:00.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T19:41:31.119+0000] {processor.py:157} INFO - Started process (PID=24733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:41:31.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:41:31.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:41:31.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:41:31.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:41:31.161+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:41:31.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:41:31.173+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:41:31.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:41:31.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T19:42:01.628+0000] {processor.py:157} INFO - Started process (PID=24758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:42:01.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:42:01.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:42:01.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:42:01.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:42:01.664+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:42:01.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:42:01.674+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:42:01.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:42:01.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T19:42:32.099+0000] {processor.py:157} INFO - Started process (PID=24783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:42:32.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:42:32.103+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:42:32.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:42:32.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:42:32.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:42:32.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:42:32.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:42:32.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:42:32.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:43:02.560+0000] {processor.py:157} INFO - Started process (PID=24808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:43:02.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:43:02.564+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:43:02.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:43:02.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:43:02.592+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:43:02.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:43:02.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:43:02.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:43:02.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T19:43:32.960+0000] {processor.py:157} INFO - Started process (PID=24833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:43:32.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:43:32.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:43:32.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:43:32.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:43:32.989+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:43:32.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:43:32.999+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:43:32.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:43:33.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:44:03.448+0000] {processor.py:157} INFO - Started process (PID=24858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:44:03.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:44:03.453+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:44:03.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:44:03.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:44:03.493+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:44:03.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:44:03.506+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:44:03.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:44:03.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T19:44:33.990+0000] {processor.py:157} INFO - Started process (PID=24883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:44:33.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:44:33.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:44:33.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:44:34.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:44:34.022+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:44:34.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:44:34.032+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:44:34.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:44:34.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T19:45:04.397+0000] {processor.py:157} INFO - Started process (PID=24908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:45:04.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:45:04.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:45:04.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:45:04.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:45:04.428+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:45:04.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:45:04.439+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:45:04.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:45:04.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:45:34.915+0000] {processor.py:157} INFO - Started process (PID=24933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:45:34.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:45:34.919+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:45:34.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:45:34.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:45:34.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:45:34.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:45:34.959+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:45:34.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:45:34.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T19:46:05.337+0000] {processor.py:157} INFO - Started process (PID=24958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:46:05.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:46:05.341+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:46:05.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:46:05.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:46:05.380+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:46:05.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:46:05.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:46:05.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:46:05.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T19:46:35.867+0000] {processor.py:157} INFO - Started process (PID=24983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:46:35.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:46:35.869+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:46:35.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:46:35.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:46:35.898+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:46:35.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:46:35.913+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:46:35.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:46:35.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T19:47:06.304+0000] {processor.py:157} INFO - Started process (PID=25008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:47:06.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:47:06.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:47:06.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:47:06.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:47:06.330+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:47:06.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:47:06.342+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:47:06.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:47:06.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T19:47:36.807+0000] {processor.py:157} INFO - Started process (PID=25033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:47:36.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:47:36.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:47:36.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:47:36.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:47:36.838+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:47:36.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:47:36.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:47:36.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:47:36.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:48:07.279+0000] {processor.py:157} INFO - Started process (PID=25058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:48:07.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:48:07.288+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:48:07.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:48:07.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:48:07.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:48:07.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:48:07.337+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:48:07.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:48:07.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T19:48:37.798+0000] {processor.py:157} INFO - Started process (PID=25083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:48:37.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:48:37.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:48:37.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:48:37.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:48:37.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:48:37.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:48:37.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:48:37.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:48:37.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T19:49:08.273+0000] {processor.py:157} INFO - Started process (PID=25108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:49:08.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:49:08.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:49:08.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:49:08.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:49:08.310+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:49:08.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:49:08.321+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:49:08.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:49:08.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T19:49:38.740+0000] {processor.py:157} INFO - Started process (PID=25133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:49:38.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:49:38.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:49:38.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:49:38.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:49:38.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:49:38.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:49:38.786+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:49:38.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:49:38.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T19:50:09.193+0000] {processor.py:157} INFO - Started process (PID=25158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:50:09.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:50:09.197+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:50:09.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:50:09.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:50:09.239+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:50:09.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:50:09.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:50:09.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:50:09.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-26T19:50:39.664+0000] {processor.py:157} INFO - Started process (PID=25183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:50:39.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:50:39.667+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:50:39.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:50:39.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:50:39.693+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:50:39.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:50:39.706+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:50:39.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:50:39.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T19:51:10.184+0000] {processor.py:157} INFO - Started process (PID=25208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:51:10.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:51:10.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:51:10.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:51:10.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:51:10.217+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:51:10.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:51:10.228+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:51:10.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:51:10.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T19:51:40.617+0000] {processor.py:157} INFO - Started process (PID=25233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:51:40.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:51:40.621+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:51:40.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:51:40.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:51:40.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:51:40.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:51:40.655+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:51:40.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:51:40.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T19:52:11.145+0000] {processor.py:157} INFO - Started process (PID=25257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:52:11.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:52:11.151+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:52:11.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:52:11.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:52:11.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:52:11.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:52:11.205+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:52:11.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:52:11.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T19:52:41.640+0000] {processor.py:157} INFO - Started process (PID=25283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:52:41.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:52:41.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:52:41.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:52:41.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:52:41.667+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:52:41.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:52:41.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:52:41.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:52:41.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T19:53:12.110+0000] {processor.py:157} INFO - Started process (PID=25308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:53:12.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:53:12.113+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:53:12.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:53:12.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:53:12.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:53:12.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:53:12.151+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:53:12.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:53:12.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T19:53:42.604+0000] {processor.py:157} INFO - Started process (PID=25333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:53:42.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:53:42.611+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:53:42.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:53:42.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:53:42.642+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:53:42.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:53:42.653+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:53:42.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:53:42.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T19:54:13.041+0000] {processor.py:157} INFO - Started process (PID=25358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:54:13.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:54:13.045+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:54:13.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:54:13.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:54:13.071+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:54:13.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:54:13.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:54:13.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:54:13.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T19:54:43.497+0000] {processor.py:157} INFO - Started process (PID=25383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:54:43.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:54:43.502+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:54:43.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:54:43.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:54:43.584+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:54:43.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:54:43.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:54:43.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:54:43.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-26T19:55:13.940+0000] {processor.py:157} INFO - Started process (PID=25408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:55:13.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:55:13.942+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:55:13.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:55:13.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:55:13.973+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:55:13.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:55:13.985+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:55:13.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:55:13.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T19:55:44.472+0000] {processor.py:157} INFO - Started process (PID=25433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:55:44.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:55:44.478+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:55:44.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:55:44.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:55:44.513+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:55:44.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:55:44.524+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:55:44.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:55:44.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T19:56:14.943+0000] {processor.py:157} INFO - Started process (PID=25458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:56:14.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:56:14.946+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:56:14.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:56:14.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:56:14.979+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:56:14.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:56:14.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:56:14.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:56:15.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T19:56:45.424+0000] {processor.py:157} INFO - Started process (PID=25483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:56:45.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:56:45.426+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:56:45.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:56:45.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:56:45.456+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:56:45.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:56:45.466+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:56:45.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:56:45.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:57:15.919+0000] {processor.py:157} INFO - Started process (PID=25508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:57:15.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:57:15.921+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:57:15.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:57:15.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:57:15.944+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:57:15.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:57:15.956+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:57:15.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:57:15.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T19:57:46.365+0000] {processor.py:157} INFO - Started process (PID=25533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:57:46.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:57:46.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:57:46.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:57:46.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:57:46.406+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:57:46.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:57:46.417+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:57:46.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:57:46.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T19:58:16.896+0000] {processor.py:157} INFO - Started process (PID=25558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:58:16.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:58:16.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:58:16.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:58:16.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:58:16.925+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:58:16.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:58:16.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:58:16.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:58:16.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T19:58:47.318+0000] {processor.py:157} INFO - Started process (PID=25583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:58:47.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:58:47.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:58:47.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:58:47.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:58:47.356+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:58:47.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:58:47.366+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:58:47.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:58:47.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T19:59:17.761+0000] {processor.py:157} INFO - Started process (PID=25608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:59:17.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:59:17.766+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:59:17.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:59:17.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:59:17.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:59:17.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:59:17.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:59:17.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:59:17.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T19:59:48.258+0000] {processor.py:157} INFO - Started process (PID=25633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:59:48.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T19:59:48.262+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:59:48.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:59:48.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T19:59:48.291+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:59:48.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T19:59:48.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T19:59:48.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T19:59:48.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T20:00:18.764+0000] {processor.py:157} INFO - Started process (PID=25658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:00:18.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:00:18.771+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:00:18.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:00:18.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:00:18.807+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:00:18.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:00:18.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:00:18.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:00:18.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T20:00:49.243+0000] {processor.py:157} INFO - Started process (PID=25683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:00:49.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:00:49.245+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:00:49.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:00:49.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:00:49.267+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:00:49.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:00:49.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:00:49.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:00:49.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-26T20:01:19.682+0000] {processor.py:157} INFO - Started process (PID=25708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:01:19.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:01:19.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:01:19.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:01:19.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:01:19.712+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:01:19.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:01:19.725+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:01:19.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:01:19.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T20:01:50.183+0000] {processor.py:157} INFO - Started process (PID=25733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:01:50.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:01:50.187+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:01:50.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:01:50.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:01:50.238+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:01:50.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:01:50.248+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:01:50.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:01:50.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T20:02:20.620+0000] {processor.py:157} INFO - Started process (PID=25758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:02:20.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:02:20.622+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:02:20.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:02:20.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:02:20.650+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:02:20.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:02:20.664+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:02:20.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:02:20.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T20:02:51.137+0000] {processor.py:157} INFO - Started process (PID=25783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:02:51.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:02:51.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:02:51.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:02:51.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:02:51.169+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:02:51.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:02:51.181+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:02:51.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:02:51.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:03:21.641+0000] {processor.py:157} INFO - Started process (PID=25808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:03:21.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:03:21.647+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:03:21.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:03:21.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:03:21.684+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:03:21.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:03:21.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:03:21.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:03:21.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T20:03:52.157+0000] {processor.py:157} INFO - Started process (PID=25833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:03:52.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:03:52.160+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:03:52.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:03:52.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:03:52.185+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:03:52.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:03:52.198+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:03:52.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:03:52.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T20:04:22.556+0000] {processor.py:157} INFO - Started process (PID=25858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:04:22.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:04:22.560+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:04:22.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:04:22.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:04:22.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:04:22.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:04:22.596+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:04:22.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:04:22.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T20:04:53.070+0000] {processor.py:157} INFO - Started process (PID=25883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:04:53.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:04:53.073+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:04:53.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:04:53.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:04:53.101+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:04:53.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:04:53.112+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:04:53.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:04:53.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T20:05:23.524+0000] {processor.py:157} INFO - Started process (PID=25908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:05:23.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:05:23.528+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:05:23.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:05:23.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:05:23.564+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:05:23.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:05:23.574+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:05:23.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:05:23.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T20:05:54.074+0000] {processor.py:157} INFO - Started process (PID=25933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:05:54.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:05:54.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:05:54.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:05:54.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:05:54.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:05:54.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:05:54.122+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:05:54.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:05:54.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T20:06:24.464+0000] {processor.py:157} INFO - Started process (PID=25958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:06:24.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:06:24.468+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:06:24.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:06:24.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:06:24.496+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:06:24.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:06:24.510+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:06:24.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:06:24.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T20:06:54.913+0000] {processor.py:157} INFO - Started process (PID=25983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:06:54.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:06:54.920+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:06:54.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:06:54.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:06:54.953+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:06:54.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:06:54.963+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:06:54.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:06:54.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T20:07:25.361+0000] {processor.py:157} INFO - Started process (PID=26008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:07:25.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:07:25.364+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:07:25.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:07:25.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:07:25.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:07:25.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:07:25.412+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:07:25.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:07:25.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T20:07:55.862+0000] {processor.py:157} INFO - Started process (PID=26033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:07:55.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:07:55.865+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:07:55.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:07:55.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:07:55.893+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:07:55.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:07:55.907+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:07:55.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:07:55.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T20:08:26.448+0000] {processor.py:157} INFO - Started process (PID=26058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:08:26.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:08:26.453+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:08:26.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:08:26.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:08:26.490+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:08:26.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:08:26.502+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:08:26.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:08:26.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T20:08:56.954+0000] {processor.py:157} INFO - Started process (PID=26083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:08:56.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:08:56.957+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:08:56.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:08:56.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:08:56.990+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:08:56.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:08:57.003+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:08:57.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:08:57.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T20:09:27.406+0000] {processor.py:157} INFO - Started process (PID=26108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:09:27.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:09:27.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:09:27.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:09:27.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:09:27.448+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:09:27.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:09:27.459+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:09:27.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:09:27.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T20:09:57.934+0000] {processor.py:157} INFO - Started process (PID=26133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:09:57.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:09:57.943+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:09:57.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:09:57.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:09:57.975+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:09:57.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:09:57.993+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:09:57.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:09:58.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T20:10:28.546+0000] {processor.py:157} INFO - Started process (PID=26158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:10:28.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:10:28.553+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:10:28.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:10:28.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:10:28.588+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:10:28.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:10:28.597+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:10:28.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:10:28.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T20:10:59.048+0000] {processor.py:157} INFO - Started process (PID=26183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:10:59.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:10:59.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:10:59.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:10:59.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:10:59.085+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:10:59.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:10:59.098+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:10:59.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:10:59.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T20:11:29.561+0000] {processor.py:157} INFO - Started process (PID=26208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:11:29.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:11:29.567+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:11:29.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:11:29.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:11:29.601+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:11:29.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:11:29.611+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:11:29.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:11:29.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T20:12:00.052+0000] {processor.py:157} INFO - Started process (PID=26233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:12:00.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:12:00.055+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:12:00.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:12:00.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:12:00.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:12:00.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:12:00.102+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:12:00.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:12:00.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T20:12:30.573+0000] {processor.py:157} INFO - Started process (PID=26258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:12:30.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:12:30.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:12:30.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:12:30.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:12:30.604+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:12:30.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:12:30.617+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:12:30.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:12:30.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T20:13:00.978+0000] {processor.py:157} INFO - Started process (PID=26283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:13:00.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:13:00.981+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:13:00.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:13:00.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:13:01.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:13:01.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:13:01.021+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:13:01.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:13:01.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T20:13:31.397+0000] {processor.py:157} INFO - Started process (PID=26308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:13:31.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:13:31.400+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:13:31.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:13:31.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:13:31.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:13:31.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:13:31.437+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:13:31.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:13:31.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T20:14:01.817+0000] {processor.py:157} INFO - Started process (PID=26333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:14:01.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:14:01.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:14:01.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:14:01.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:14:01.846+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:14:01.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:14:01.856+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:14:01.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:14:01.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T20:14:32.365+0000] {processor.py:157} INFO - Started process (PID=26358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:14:32.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:14:32.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:14:32.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:14:32.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:14:32.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:14:32.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:14:32.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:14:32.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:14:32.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-26T20:15:02.803+0000] {processor.py:157} INFO - Started process (PID=26383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:15:02.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:15:02.808+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:15:02.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:15:02.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:15:02.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:15:02.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:15:02.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:15:02.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:15:02.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T20:15:33.369+0000] {processor.py:157} INFO - Started process (PID=26408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:15:33.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:15:33.372+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:15:33.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:15:33.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:15:33.397+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:15:33.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:15:33.407+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:15:33.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:15:33.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T20:16:03.811+0000] {processor.py:157} INFO - Started process (PID=26433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:16:03.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:16:03.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:16:03.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:16:03.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:16:03.839+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:16:03.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:16:03.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:16:03.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:16:03.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T20:16:34.361+0000] {processor.py:157} INFO - Started process (PID=26458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:16:34.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:16:34.365+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:16:34.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:16:34.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:16:34.394+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:16:34.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:16:34.404+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:16:34.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:16:34.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T20:17:04.854+0000] {processor.py:157} INFO - Started process (PID=26483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:17:04.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:17:04.858+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:17:04.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:17:04.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:17:04.897+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:17:04.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:17:04.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:17:04.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:17:04.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T20:17:35.349+0000] {processor.py:157} INFO - Started process (PID=26508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:17:35.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:17:35.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:17:35.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:17:35.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:17:35.381+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:17:35.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:17:35.392+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:17:35.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:17:35.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T20:18:05.819+0000] {processor.py:157} INFO - Started process (PID=26533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:18:05.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:18:05.828+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:18:05.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:18:05.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:18:05.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:18:05.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:18:05.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:18:05.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:18:05.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T20:18:36.215+0000] {processor.py:157} INFO - Started process (PID=26558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:18:36.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:18:36.220+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:18:36.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:18:36.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:18:36.247+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:18:36.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:18:36.260+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:18:36.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:18:36.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T20:19:06.644+0000] {processor.py:157} INFO - Started process (PID=26583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:19:06.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:19:06.648+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:19:06.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:19:06.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:19:06.679+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:19:06.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:19:06.688+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:19:06.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:19:06.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:19:37.146+0000] {processor.py:157} INFO - Started process (PID=26608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:19:37.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:19:37.150+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:19:37.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:19:37.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:19:37.176+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:19:37.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:19:37.186+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:19:37.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:19:37.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T20:20:07.673+0000] {processor.py:157} INFO - Started process (PID=26633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:20:07.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:20:07.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:20:07.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:20:07.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:20:07.729+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:20:07.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:20:07.742+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:20:07.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:20:07.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-26T20:20:38.138+0000] {processor.py:157} INFO - Started process (PID=26658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:20:38.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:20:38.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:20:38.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:20:38.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:20:38.157+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:20:38.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:20:38.166+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:20:38.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:20:38.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.038 seconds
[2024-07-26T20:21:08.651+0000] {processor.py:157} INFO - Started process (PID=26683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:21:08.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:21:08.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:21:08.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:21:08.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:21:08.686+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:21:08.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:21:08.696+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:21:08.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:21:08.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T20:21:39.150+0000] {processor.py:157} INFO - Started process (PID=26708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:21:39.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:21:39.154+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:21:39.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:21:39.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:21:39.183+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:21:39.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:21:39.195+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:21:39.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:21:39.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T20:22:09.559+0000] {processor.py:157} INFO - Started process (PID=26733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:22:09.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:22:09.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:22:09.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:22:09.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:22:09.602+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:22:09.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:22:09.614+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:22:09.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:22:09.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T20:22:40.022+0000] {processor.py:157} INFO - Started process (PID=26758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:22:40.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:22:40.025+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:22:40.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:22:40.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:22:40.051+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:22:40.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:22:40.061+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:22:40.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:22:40.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T20:23:10.416+0000] {processor.py:157} INFO - Started process (PID=26783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:23:10.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:23:10.419+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:23:10.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:23:10.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:23:10.452+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:23:10.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:23:10.463+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:23:10.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:23:10.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T20:23:40.864+0000] {processor.py:157} INFO - Started process (PID=26808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:23:40.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:23:40.870+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:23:40.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:23:40.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:23:40.916+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:23:40.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:23:40.932+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:23:40.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:23:40.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T20:24:11.302+0000] {processor.py:157} INFO - Started process (PID=26833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:24:11.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:24:11.303+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:24:11.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:24:11.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:24:11.325+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:24:11.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:24:11.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:24:11.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:24:11.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-26T20:24:41.784+0000] {processor.py:157} INFO - Started process (PID=26858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:24:41.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:24:41.786+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:24:41.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:24:41.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:24:41.816+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:24:41.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:24:41.825+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:24:41.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:24:41.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T20:25:12.278+0000] {processor.py:157} INFO - Started process (PID=26883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:25:12.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:25:12.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:25:12.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:25:12.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:25:12.311+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:25:12.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:25:12.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:25:12.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:25:12.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T20:25:42.693+0000] {processor.py:157} INFO - Started process (PID=26908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:25:42.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:25:42.699+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:25:42.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:25:42.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:25:42.740+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:25:42.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:25:42.755+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:25:42.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:25:42.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-26T20:26:13.132+0000] {processor.py:157} INFO - Started process (PID=26933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:26:13.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:26:13.134+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:26:13.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:26:13.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:26:13.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:26:13.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:26:13.174+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:26:13.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:26:13.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:26:43.653+0000] {processor.py:157} INFO - Started process (PID=26958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:26:43.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:26:43.658+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:26:43.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:26:43.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:26:43.686+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:26:43.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:26:43.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:26:43.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:26:43.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T20:27:14.069+0000] {processor.py:157} INFO - Started process (PID=26983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:27:14.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:27:14.072+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:27:14.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:27:14.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:27:14.131+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:27:14.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:27:14.144+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:27:14.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:27:14.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-26T20:27:44.549+0000] {processor.py:157} INFO - Started process (PID=27008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:27:44.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:27:44.554+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:27:44.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:27:44.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:27:44.579+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:27:44.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:27:44.588+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:27:44.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:27:44.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T20:28:15.031+0000] {processor.py:157} INFO - Started process (PID=27033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:28:15.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:28:15.034+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:28:15.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:28:15.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:28:15.066+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:28:15.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:28:15.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:28:15.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:28:15.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T20:28:45.443+0000] {processor.py:157} INFO - Started process (PID=27058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:28:45.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:28:45.447+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:28:45.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:28:45.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:28:45.482+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:28:45.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:28:45.494+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:28:45.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:28:45.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T20:29:15.975+0000] {processor.py:157} INFO - Started process (PID=27083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:29:15.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:29:15.979+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:29:15.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:29:15.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:29:16.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:29:16.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:29:16.021+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:29:16.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:29:16.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T20:29:46.446+0000] {processor.py:157} INFO - Started process (PID=27108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:29:46.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:29:46.449+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:29:46.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:29:46.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:29:46.477+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:29:46.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:29:46.490+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:29:46.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:29:46.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T20:30:16.895+0000] {processor.py:157} INFO - Started process (PID=27133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:30:16.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:30:16.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:30:16.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:30:16.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:30:16.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:30:16.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:30:16.940+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:30:16.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:30:16.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:30:47.365+0000] {processor.py:157} INFO - Started process (PID=27158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:30:47.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:30:47.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:30:47.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:30:47.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:30:47.409+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:30:47.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:30:47.424+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:30:47.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:30:47.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T20:31:17.842+0000] {processor.py:157} INFO - Started process (PID=27183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:31:17.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:31:17.847+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:31:17.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:31:17.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:31:17.875+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:31:17.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:31:17.884+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:31:17.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:31:17.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T20:31:48.297+0000] {processor.py:157} INFO - Started process (PID=27208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:31:48.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:31:48.302+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:31:48.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:31:48.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:31:48.334+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:31:48.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:31:48.344+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:31:48.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:31:48.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T20:32:18.757+0000] {processor.py:157} INFO - Started process (PID=27233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:32:18.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:32:18.766+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:32:18.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:32:18.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:32:18.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:32:18.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:32:18.799+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:32:18.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:32:18.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T20:32:49.270+0000] {processor.py:157} INFO - Started process (PID=27258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:32:49.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:32:49.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:32:49.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:32:49.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:32:49.311+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:32:49.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:32:49.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:32:49.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:32:49.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T20:33:19.699+0000] {processor.py:157} INFO - Started process (PID=27283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:33:19.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:33:19.703+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:33:19.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:33:19.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:33:19.736+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:33:19.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:33:19.746+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:33:19.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:33:19.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T20:33:50.237+0000] {processor.py:157} INFO - Started process (PID=27308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:33:50.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:33:50.241+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:33:50.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:33:50.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:33:50.268+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:33:50.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:33:50.279+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:33:50.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:33:50.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T20:34:20.805+0000] {processor.py:157} INFO - Started process (PID=27332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:34:20.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:34:20.814+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:34:20.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:34:20.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:34:20.869+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:34:20.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:34:20.898+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:34:20.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:34:20.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-26T20:34:51.334+0000] {processor.py:157} INFO - Started process (PID=27358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:34:51.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:34:51.341+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:34:51.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:34:51.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:34:51.395+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:34:51.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:34:51.407+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:34:51.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:34:51.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-26T20:35:21.815+0000] {processor.py:157} INFO - Started process (PID=27383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:35:21.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:35:21.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:35:21.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:35:21.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:35:21.849+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:35:21.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:35:21.860+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:35:21.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:35:21.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T20:35:52.284+0000] {processor.py:157} INFO - Started process (PID=27408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:35:52.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:35:52.287+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:35:52.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:35:52.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:35:52.315+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:35:52.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:35:52.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:35:52.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:35:52.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T20:36:22.789+0000] {processor.py:157} INFO - Started process (PID=27433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:36:22.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:36:22.795+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:36:22.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:36:22.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:36:22.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:36:22.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:36:22.846+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:36:22.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:36:22.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T20:36:53.233+0000] {processor.py:157} INFO - Started process (PID=27458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:36:53.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:36:53.237+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:36:53.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:36:53.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:36:53.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:36:53.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:36:53.275+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:36:53.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:36:53.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T20:37:23.784+0000] {processor.py:157} INFO - Started process (PID=27483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:37:23.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:37:23.788+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:37:23.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:37:23.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:37:23.824+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:37:23.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:37:23.835+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:37:23.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:37:23.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T20:37:54.285+0000] {processor.py:157} INFO - Started process (PID=27508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:37:54.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:37:54.290+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:37:54.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:37:54.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:37:54.318+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:37:54.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:37:54.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:37:54.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:37:54.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T20:38:24.805+0000] {processor.py:157} INFO - Started process (PID=27532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:38:24.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:38:24.810+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:38:24.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:38:24.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:38:24.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:38:24.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:38:24.886+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:38:24.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:38:24.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T20:38:55.309+0000] {processor.py:157} INFO - Started process (PID=27558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:38:55.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:38:55.312+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:38:55.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:38:55.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:38:55.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:38:55.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:38:55.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:38:55.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:38:55.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T20:39:25.866+0000] {processor.py:157} INFO - Started process (PID=27583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:39:25.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:39:25.892+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:39:25.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:39:25.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:39:25.939+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:39:25.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:39:25.967+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:39:25.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:39:25.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-26T20:39:56.374+0000] {processor.py:157} INFO - Started process (PID=27608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:39:56.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:39:56.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:39:56.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:39:56.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:39:56.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:39:56.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:39:56.418+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:39:56.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:39:56.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:40:26.955+0000] {processor.py:157} INFO - Started process (PID=27632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:40:26.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:40:26.961+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:40:26.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:40:26.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:40:27.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:40:27.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:40:27.037+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:40:27.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:40:27.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-26T20:40:57.426+0000] {processor.py:157} INFO - Started process (PID=27658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:40:57.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:40:57.429+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:40:57.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:40:57.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:40:57.455+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:40:57.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:40:57.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:40:57.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:40:57.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T20:41:27.915+0000] {processor.py:157} INFO - Started process (PID=27683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:41:27.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:41:27.919+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:41:27.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:41:27.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:41:27.946+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:41:27.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:41:27.960+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:41:27.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:41:27.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T20:41:58.386+0000] {processor.py:157} INFO - Started process (PID=27707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:41:58.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:41:58.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:41:58.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:41:58.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:41:58.452+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:41:58.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:41:58.465+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:41:58.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:41:58.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-26T20:42:28.913+0000] {processor.py:157} INFO - Started process (PID=27733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:42:28.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:42:28.917+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:42:28.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:42:28.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:42:28.950+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:42:28.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:42:28.961+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:42:28.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:42:28.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T20:42:59.357+0000] {processor.py:157} INFO - Started process (PID=27758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:42:59.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:42:59.360+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:42:59.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:42:59.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:42:59.393+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:42:59.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:42:59.402+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:42:59.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:42:59.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:43:29.791+0000] {processor.py:157} INFO - Started process (PID=27783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:43:29.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:43:29.794+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:43:29.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:43:29.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:43:29.819+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:43:29.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:43:29.830+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:43:29.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:43:29.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T20:44:00.251+0000] {processor.py:157} INFO - Started process (PID=27808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:44:00.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:44:00.255+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:44:00.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:44:00.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:44:00.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:44:00.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:44:00.308+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:44:00.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:44:00.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T20:44:30.816+0000] {processor.py:157} INFO - Started process (PID=27833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:44:30.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:44:30.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:44:30.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:44:30.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:44:30.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:44:30.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:44:30.863+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:44:30.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:44:30.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T20:45:01.289+0000] {processor.py:157} INFO - Started process (PID=27858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:45:01.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:45:01.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:45:01.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:45:01.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:45:01.323+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:45:01.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:45:01.332+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:45:01.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:45:01.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T20:45:31.802+0000] {processor.py:157} INFO - Started process (PID=27883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:45:31.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:45:31.808+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:45:31.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:45:31.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:45:31.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:45:31.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:45:31.856+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:45:31.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:45:31.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T20:46:02.281+0000] {processor.py:157} INFO - Started process (PID=27908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:46:02.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:46:02.289+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:46:02.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:46:02.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:46:02.316+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:46:02.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:46:02.326+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:46:02.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:46:02.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T20:46:32.774+0000] {processor.py:157} INFO - Started process (PID=27933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:46:32.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:46:32.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:46:32.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:46:32.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:46:32.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:46:32.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:46:32.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:46:32.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:46:32.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:47:03.286+0000] {processor.py:157} INFO - Started process (PID=27958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:47:03.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:47:03.290+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:47:03.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:47:03.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:47:03.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:47:03.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:47:03.327+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:47:03.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:47:03.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T20:47:33.750+0000] {processor.py:157} INFO - Started process (PID=27983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:47:33.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:47:33.755+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:47:33.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:47:33.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:47:33.792+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:47:33.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:47:33.806+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:47:33.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:47:33.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T20:48:04.248+0000] {processor.py:157} INFO - Started process (PID=28008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:48:04.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:48:04.251+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:48:04.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:48:04.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:48:04.282+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:48:04.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:48:04.293+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:48:04.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:48:04.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T20:48:34.655+0000] {processor.py:157} INFO - Started process (PID=28033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:48:34.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:48:34.657+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:48:34.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:48:34.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:48:34.685+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:48:34.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:48:34.695+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:48:34.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:48:34.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T20:49:05.106+0000] {processor.py:157} INFO - Started process (PID=28058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:49:05.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:49:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:49:05.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:49:05.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:49:05.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:49:05.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:49:05.151+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:49:05.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:49:05.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T20:49:35.572+0000] {processor.py:157} INFO - Started process (PID=28083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:49:35.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:49:35.576+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:49:35.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:49:35.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:49:35.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:49:35.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:49:35.629+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:49:35.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:49:35.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T20:50:06.108+0000] {processor.py:157} INFO - Started process (PID=28108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:50:06.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:50:06.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:50:06.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:50:06.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:50:06.142+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:50:06.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:50:06.158+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:50:06.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:50:06.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T20:50:36.511+0000] {processor.py:157} INFO - Started process (PID=28133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:50:36.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:50:36.514+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:50:36.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:50:36.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:50:36.539+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:50:36.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:50:36.547+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:50:36.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:50:36.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T20:51:06.920+0000] {processor.py:157} INFO - Started process (PID=28158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:51:06.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:51:06.923+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:51:06.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:51:06.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:51:06.955+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:51:06.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:51:06.965+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:51:06.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:51:06.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:51:37.403+0000] {processor.py:157} INFO - Started process (PID=28183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:51:37.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:51:37.408+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:51:37.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:51:37.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:51:37.437+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:51:37.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:51:37.447+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:51:37.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:51:37.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T20:52:07.894+0000] {processor.py:157} INFO - Started process (PID=28208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:52:07.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T20:52:07.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:52:07.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:52:07.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T20:52:07.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:52:07.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T20:52:07.948+0000] {logging_mixin.py:151} INFO - [2024-07-26T20:52:07.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T20:52:07.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T21:07:12.995+0000] {processor.py:157} INFO - Started process (PID=28233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:07:13.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:07:13.011+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:07:13.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:07:13.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:07:13.052+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:07:13.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:07:13.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:07:13.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:07:13.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-26T21:07:43.505+0000] {processor.py:157} INFO - Started process (PID=28259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:07:43.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:07:43.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:07:43.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:07:43.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:07:43.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:07:43.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:07:43.574+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:07:43.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:07:43.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-26T21:08:14.052+0000] {processor.py:157} INFO - Started process (PID=28285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:08:14.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:08:14.061+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:08:14.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:08:14.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:08:14.084+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:08:14.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:08:14.093+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:08:14.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:08:14.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T21:25:03.054+0000] {processor.py:157} INFO - Started process (PID=28310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:25:03.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:25:03.060+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:25:03.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:25:03.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:25:03.141+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:25:03.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:25:03.166+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:25:03.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:25:03.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-26T21:25:33.755+0000] {processor.py:157} INFO - Started process (PID=28337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:25:33.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:25:33.759+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:25:33.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:25:33.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:25:33.820+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:25:33.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:25:33.833+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:25:33.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:25:33.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-26T21:42:09.425+0000] {processor.py:157} INFO - Started process (PID=28363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:42:09.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:42:09.431+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:42:09.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:42:09.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:42:09.499+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:42:09.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:42:09.538+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:42:09.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:42:09.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-26T21:42:40.060+0000] {processor.py:157} INFO - Started process (PID=28388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:42:40.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:42:40.077+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:42:40.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:42:40.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:42:40.130+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:42:40.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:42:40.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:42:40.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:42:40.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T21:43:10.547+0000] {processor.py:157} INFO - Started process (PID=28414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:43:10.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:43:10.552+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:43:10.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:43:10.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:43:10.578+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:43:10.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:43:10.593+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:43:10.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:43:10.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T21:43:40.984+0000] {processor.py:157} INFO - Started process (PID=28439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:43:40.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:43:40.986+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:43:40.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:43:40.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:43:41.013+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:43:41.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:43:41.025+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:43:41.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:43:41.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T21:44:11.403+0000] {processor.py:157} INFO - Started process (PID=28464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:44:11.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:44:11.410+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:44:11.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:44:11.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:44:11.450+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:44:11.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:44:11.463+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:44:11.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:44:11.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T21:44:41.926+0000] {processor.py:157} INFO - Started process (PID=28489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:44:41.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:44:41.929+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:44:41.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:44:41.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:44:41.958+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:44:41.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:44:41.968+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:44:41.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:44:41.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T21:45:12.322+0000] {processor.py:157} INFO - Started process (PID=28514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:45:12.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:45:12.324+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:45:12.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:45:12.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:45:12.351+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:45:12.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:45:12.363+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:45:12.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:45:12.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T21:45:42.799+0000] {processor.py:157} INFO - Started process (PID=28539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:45:42.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:45:42.803+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:45:42.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:45:42.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:45:42.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:45:42.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:45:42.842+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:45:42.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:45:42.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T21:46:13.241+0000] {processor.py:157} INFO - Started process (PID=28564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:46:13.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:46:13.246+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:46:13.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:46:13.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:46:13.274+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:46:13.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:46:13.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:46:13.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:46:13.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T21:46:43.693+0000] {processor.py:157} INFO - Started process (PID=28589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:46:43.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:46:43.701+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:46:43.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:46:43.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:46:43.724+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:46:43.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:46:43.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:46:43.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:46:43.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T21:47:14.169+0000] {processor.py:157} INFO - Started process (PID=28614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:47:14.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:47:14.172+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:47:14.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:47:14.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:47:14.208+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:47:14.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:47:14.219+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:47:14.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:47:14.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T21:47:44.584+0000] {processor.py:157} INFO - Started process (PID=28639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:47:44.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:47:44.586+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:47:44.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:47:44.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:47:44.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:47:44.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:47:44.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:47:44.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:47:44.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T21:48:15.017+0000] {processor.py:157} INFO - Started process (PID=28664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:48:15.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:48:15.020+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:48:15.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:48:15.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:48:15.050+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:48:15.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:48:15.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:48:15.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:48:15.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T21:48:45.482+0000] {processor.py:157} INFO - Started process (PID=28689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:48:45.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:48:45.485+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:48:45.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:48:45.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:48:45.517+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:48:45.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:48:45.529+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:48:45.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:48:45.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T21:49:15.999+0000] {processor.py:157} INFO - Started process (PID=28714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:49:16.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:49:16.002+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:49:16.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:49:16.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:49:16.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:49:16.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:49:16.042+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:49:16.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:49:16.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T21:49:46.477+0000] {processor.py:157} INFO - Started process (PID=28739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:49:46.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:49:46.481+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:49:46.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:49:46.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:49:46.511+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:49:46.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:49:46.522+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:49:46.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:49:46.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T21:50:16.974+0000] {processor.py:157} INFO - Started process (PID=28764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:50:16.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:50:16.977+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:50:16.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:50:16.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:50:17.004+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:50:17.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:50:17.015+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:50:17.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:50:17.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T21:50:47.481+0000] {processor.py:157} INFO - Started process (PID=28789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:50:47.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:50:47.487+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:50:47.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:50:47.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:50:47.514+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:50:47.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:50:47.526+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:50:47.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:50:47.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T21:51:17.957+0000] {processor.py:157} INFO - Started process (PID=28814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:51:17.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:51:17.961+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:51:17.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:51:17.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:51:17.998+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:51:17.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:51:18.010+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:51:18.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:51:18.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T21:51:48.435+0000] {processor.py:157} INFO - Started process (PID=28839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:51:48.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:51:48.438+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:51:48.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:51:48.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:51:48.464+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:51:48.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:51:48.475+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:51:48.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:51:48.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T21:52:18.912+0000] {processor.py:157} INFO - Started process (PID=28864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:52:18.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:52:18.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:52:18.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:52:18.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:52:18.945+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:52:18.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:52:18.956+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:52:18.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:52:18.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T21:52:49.353+0000] {processor.py:157} INFO - Started process (PID=28889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:52:49.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:52:49.355+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:52:49.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:52:49.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:52:49.382+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:52:49.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:52:49.391+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:52:49.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:52:49.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T21:53:19.803+0000] {processor.py:157} INFO - Started process (PID=28914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:53:19.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:53:19.809+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:53:19.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:53:19.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:53:19.845+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:53:19.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:53:19.857+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:53:19.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:53:19.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T21:53:50.262+0000] {processor.py:157} INFO - Started process (PID=28939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:53:50.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:53:50.266+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:53:50.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:53:50.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:53:50.296+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:53:50.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:53:50.306+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:53:50.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:53:50.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T21:54:20.735+0000] {processor.py:157} INFO - Started process (PID=28964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:54:20.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:54:20.738+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:54:20.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:54:20.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:54:20.763+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:54:20.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:54:20.777+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:54:20.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:54:20.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T21:54:51.174+0000] {processor.py:157} INFO - Started process (PID=28989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:54:51.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:54:51.178+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:54:51.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:54:51.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:54:51.213+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:54:51.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:54:51.223+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:54:51.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:54:51.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T21:55:21.676+0000] {processor.py:157} INFO - Started process (PID=29014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:55:21.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:55:21.679+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:55:21.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:55:21.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:55:21.711+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:55:21.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:55:21.723+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:55:21.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:55:21.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T21:55:52.116+0000] {processor.py:157} INFO - Started process (PID=29039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:55:52.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:55:52.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:55:52.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:55:52.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:55:52.147+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:55:52.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:55:52.162+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:55:52.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:55:52.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T21:56:22.635+0000] {processor.py:157} INFO - Started process (PID=29064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:56:22.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:56:22.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:56:22.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:56:22.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:56:22.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:56:22.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:56:22.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:56:22.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:56:22.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T21:56:53.041+0000] {processor.py:157} INFO - Started process (PID=29089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:56:53.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:56:53.048+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:56:53.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:56:53.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:56:53.091+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:56:53.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:56:53.104+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:56:53.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:56:53.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-26T21:57:23.574+0000] {processor.py:157} INFO - Started process (PID=29114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:57:23.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:57:23.581+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:57:23.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:57:23.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:57:23.614+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:57:23.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:57:23.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:57:23.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:57:23.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-26T21:57:53.949+0000] {processor.py:157} INFO - Started process (PID=29139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:57:53.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:57:53.959+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:57:53.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:57:53.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:57:53.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:57:53.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:57:54.005+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:57:54.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:57:54.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T21:58:24.461+0000] {processor.py:157} INFO - Started process (PID=29164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:58:24.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:58:24.465+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:58:24.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:58:24.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:58:24.493+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:58:24.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:58:24.505+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:58:24.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:58:24.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T21:58:54.873+0000] {processor.py:157} INFO - Started process (PID=29189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:58:54.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:58:54.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:58:54.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:58:54.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:58:54.900+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:58:54.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:58:54.910+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:58:54.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:58:54.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T21:59:25.306+0000] {processor.py:157} INFO - Started process (PID=29214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:59:25.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:59:25.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:59:25.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:59:25.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:59:25.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:59:25.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:59:25.360+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:59:25.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:59:25.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T21:59:55.758+0000] {processor.py:157} INFO - Started process (PID=29239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:59:55.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T21:59:55.761+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:59:55.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:59:55.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T21:59:55.785+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:59:55.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T21:59:55.796+0000] {logging_mixin.py:151} INFO - [2024-07-26T21:59:55.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T21:59:55.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T22:00:26.207+0000] {processor.py:157} INFO - Started process (PID=29264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:00:26.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:00:26.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:00:26.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:00:26.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:00:26.240+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:00:26.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:00:26.250+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:00:26.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:00:26.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T22:00:56.717+0000] {processor.py:157} INFO - Started process (PID=29289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:00:56.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:00:56.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:00:56.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:00:56.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:00:56.749+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:00:56.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:00:56.762+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:00:56.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:00:56.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:01:27.158+0000] {processor.py:157} INFO - Started process (PID=29314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:01:27.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:01:27.164+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:01:27.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:01:27.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:01:27.191+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:01:27.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:01:27.200+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:01:27.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:01:27.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T22:01:57.651+0000] {processor.py:157} INFO - Started process (PID=29339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:01:57.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:01:57.655+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:01:57.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:01:57.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:01:57.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:01:57.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:01:57.712+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:01:57.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:01:57.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T22:02:28.112+0000] {processor.py:157} INFO - Started process (PID=29364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:02:28.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:02:28.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:02:28.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:02:28.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:02:28.137+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:02:28.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:02:28.149+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:02:28.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:02:28.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T22:02:58.613+0000] {processor.py:157} INFO - Started process (PID=29389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:02:58.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:02:58.616+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:02:58.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:02:58.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:02:58.646+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:02:58.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:02:58.656+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:02:58.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:02:58.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T22:03:29.076+0000] {processor.py:157} INFO - Started process (PID=29414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:03:29.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:03:29.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:03:29.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:03:29.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:03:29.107+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:03:29.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:03:29.119+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:03:29.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:03:29.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T22:03:59.548+0000] {processor.py:157} INFO - Started process (PID=29439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:03:59.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:03:59.553+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:03:59.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:03:59.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:03:59.587+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:03:59.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:03:59.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:03:59.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:03:59.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-26T22:04:30.017+0000] {processor.py:157} INFO - Started process (PID=29464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:04:30.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:04:30.022+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:04:30.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:04:30.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:04:30.047+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:04:30.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:04:30.058+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:04:30.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:04:30.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T22:05:00.459+0000] {processor.py:157} INFO - Started process (PID=29489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:05:00.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:05:00.463+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:05:00.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:05:00.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:05:00.492+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:05:00.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:05:00.503+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:05:00.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:05:00.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:05:30.938+0000] {processor.py:157} INFO - Started process (PID=29514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:05:30.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:05:30.942+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:05:30.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:05:30.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:05:30.975+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:05:30.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:05:30.986+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:05:30.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:05:30.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T22:06:01.339+0000] {processor.py:157} INFO - Started process (PID=29539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:06:01.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:06:01.342+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:06:01.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:06:01.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:06:01.368+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:06:01.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:06:01.379+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:06:01.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:06:01.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T22:06:31.797+0000] {processor.py:157} INFO - Started process (PID=29564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:06:31.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:06:31.800+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:06:31.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:06:31.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:06:31.830+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:06:31.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:06:31.840+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:06:31.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:06:31.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:07:02.272+0000] {processor.py:157} INFO - Started process (PID=29589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:07:02.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:07:02.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:07:02.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:07:02.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:07:02.315+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:07:02.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:07:02.331+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:07:02.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:07:02.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T22:07:32.728+0000] {processor.py:157} INFO - Started process (PID=29614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:07:32.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:07:32.735+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:07:32.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:07:32.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:07:32.761+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:07:32.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:07:32.772+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:07:32.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:07:32.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T22:08:03.238+0000] {processor.py:157} INFO - Started process (PID=29639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:08:03.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:08:03.243+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:08:03.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:08:03.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:08:03.276+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:08:03.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:08:03.286+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:08:03.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:08:03.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T22:08:33.728+0000] {processor.py:157} INFO - Started process (PID=29664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:08:33.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:08:33.731+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:08:33.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:08:33.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:08:33.758+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:08:33.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:08:33.768+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:08:33.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:08:33.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T22:09:04.220+0000] {processor.py:157} INFO - Started process (PID=29689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:09:04.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:09:04.225+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:09:04.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:09:04.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:09:04.258+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:09:04.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:09:04.269+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:09:04.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:09:04.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T22:09:34.563+0000] {processor.py:157} INFO - Started process (PID=29714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:09:34.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:09:34.565+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:09:34.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:09:34.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:09:34.594+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:09:34.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:09:34.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:09:34.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:09:34.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T22:10:05.035+0000] {processor.py:157} INFO - Started process (PID=29739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:10:05.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:10:05.042+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:10:05.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:10:05.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:10:05.067+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:10:05.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:10:05.076+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:10:05.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:10:05.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T22:10:35.512+0000] {processor.py:157} INFO - Started process (PID=29764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:10:35.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:10:35.516+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:10:35.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:10:35.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:10:35.546+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:10:35.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:10:35.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:10:35.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:10:35.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:11:05.992+0000] {processor.py:157} INFO - Started process (PID=29789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:11:05.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:11:05.996+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:11:05.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:11:06.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:11:06.031+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:11:06.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:11:06.043+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:11:06.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:11:06.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T22:11:36.462+0000] {processor.py:157} INFO - Started process (PID=29814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:11:36.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:11:36.467+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:11:36.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:11:36.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:11:36.495+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:11:36.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:11:36.508+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:11:36.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:11:36.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T22:12:06.911+0000] {processor.py:157} INFO - Started process (PID=29839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:12:06.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:12:06.918+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:12:06.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:12:06.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:12:06.945+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:12:06.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:12:06.957+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:12:06.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:12:06.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:12:37.374+0000] {processor.py:157} INFO - Started process (PID=29864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:12:37.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:12:37.376+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:12:37.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:12:37.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:12:37.404+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:12:37.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:12:37.416+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:12:37.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:12:37.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T22:13:07.816+0000] {processor.py:157} INFO - Started process (PID=29889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:13:07.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:13:07.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:13:07.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:13:07.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:13:07.850+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:13:07.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:13:07.859+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:13:07.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:13:07.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T22:13:38.267+0000] {processor.py:157} INFO - Started process (PID=29914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:13:38.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:13:38.272+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:13:38.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:13:38.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:13:38.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:13:38.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:13:38.322+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:13:38.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:13:38.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T22:14:08.757+0000] {processor.py:157} INFO - Started process (PID=29939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:14:08.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:14:08.761+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:14:08.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:14:08.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:14:08.790+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:14:08.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:14:08.804+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:14:08.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:14:08.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T22:14:39.250+0000] {processor.py:157} INFO - Started process (PID=29964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:14:39.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:14:39.253+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:14:39.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:14:39.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:14:39.283+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:14:39.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:14:39.294+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:14:39.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:14:39.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:15:09.749+0000] {processor.py:157} INFO - Started process (PID=29989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:15:09.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:15:09.753+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:15:09.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:15:09.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:15:09.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:15:09.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:15:09.792+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:15:09.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:15:09.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T22:15:40.188+0000] {processor.py:157} INFO - Started process (PID=30014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:15:40.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:15:40.193+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:15:40.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:15:40.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:15:40.219+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:15:40.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:15:40.230+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:15:40.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:15:40.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:16:10.621+0000] {processor.py:157} INFO - Started process (PID=30039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:16:10.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:16:10.623+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:16:10.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:16:10.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:16:10.650+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:16:10.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:16:10.660+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:16:10.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:16:10.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T22:16:41.079+0000] {processor.py:157} INFO - Started process (PID=30064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:16:41.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:16:41.082+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:16:41.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:16:41.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:16:41.111+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:16:41.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:16:41.121+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:16:41.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:16:41.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T22:17:11.479+0000] {processor.py:157} INFO - Started process (PID=30089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:17:11.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:17:11.483+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:17:11.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:17:11.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:17:11.520+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:17:11.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:17:11.532+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:17:11.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:17:11.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T22:17:41.932+0000] {processor.py:157} INFO - Started process (PID=30114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:17:41.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:17:41.937+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:17:41.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:17:41.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:17:41.967+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:17:41.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:17:41.978+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:17:41.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:17:41.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:18:12.418+0000] {processor.py:157} INFO - Started process (PID=30139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:18:12.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:18:12.422+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:18:12.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:18:12.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:18:12.447+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:18:12.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:18:12.457+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:18:12.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:18:12.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T22:18:42.862+0000] {processor.py:157} INFO - Started process (PID=30164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:18:42.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:18:42.868+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:18:42.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:18:42.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:18:42.896+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:18:42.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:18:42.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:18:42.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:18:42.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T22:19:13.332+0000] {processor.py:157} INFO - Started process (PID=30189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:19:13.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:19:13.338+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:19:13.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:19:13.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:19:13.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:19:13.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:19:13.380+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:19:13.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:19:13.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T22:19:43.822+0000] {processor.py:157} INFO - Started process (PID=30214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:19:43.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:19:43.825+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:19:43.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:19:43.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:19:43.859+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:19:43.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:19:43.872+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:19:43.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:19:43.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-26T22:20:14.346+0000] {processor.py:157} INFO - Started process (PID=30239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:20:14.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:20:14.350+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:20:14.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:20:14.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:20:14.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:20:14.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:20:14.389+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:20:14.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:20:14.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T22:20:44.873+0000] {processor.py:157} INFO - Started process (PID=30264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:20:44.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:20:44.882+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:20:44.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:20:44.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:20:44.905+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:20:44.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:20:44.915+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:20:44.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:20:44.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-26T22:21:15.300+0000] {processor.py:157} INFO - Started process (PID=30289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:21:15.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:21:15.305+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:21:15.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:21:15.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:21:15.336+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:21:15.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:21:15.347+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:21:15.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:21:15.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:21:45.741+0000] {processor.py:157} INFO - Started process (PID=30314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:21:45.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:21:45.745+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:21:45.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:21:45.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:21:45.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:21:45.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:21:45.791+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:21:45.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:21:45.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T22:22:16.171+0000] {processor.py:157} INFO - Started process (PID=30339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:22:16.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:22:16.175+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:22:16.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:22:16.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:22:16.204+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:22:16.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:22:16.214+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:22:16.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:22:16.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T22:22:46.662+0000] {processor.py:157} INFO - Started process (PID=30364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:22:46.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:22:46.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:22:46.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:22:46.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:22:46.697+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:22:46.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:22:46.710+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:22:46.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:22:46.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T22:23:17.134+0000] {processor.py:157} INFO - Started process (PID=30389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:23:17.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:23:17.136+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:23:17.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:23:17.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:23:17.166+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:23:17.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:23:17.174+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:23:17.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:23:17.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T22:23:47.593+0000] {processor.py:157} INFO - Started process (PID=30414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:23:47.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:23:47.598+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:23:47.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:23:47.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:23:47.626+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:23:47.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:23:47.636+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:23:47.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:23:47.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:24:18.099+0000] {processor.py:157} INFO - Started process (PID=30439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:24:18.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:24:18.103+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:24:18.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:24:18.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:24:18.136+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:24:18.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:24:18.146+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:24:18.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:24:18.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T22:24:48.552+0000] {processor.py:157} INFO - Started process (PID=30464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:24:48.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:24:48.556+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:24:48.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:24:48.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:24:48.588+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:24:48.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:24:48.600+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:24:48.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:24:48.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T22:25:19.023+0000] {processor.py:157} INFO - Started process (PID=30489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:25:19.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:25:19.029+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:25:19.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:25:19.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:25:19.068+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:25:19.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:25:19.080+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:25:19.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:25:19.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T22:25:49.445+0000] {processor.py:157} INFO - Started process (PID=30514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:25:49.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:25:49.450+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:25:49.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:25:49.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:25:49.481+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:25:49.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:25:49.496+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:25:49.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:25:49.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-26T22:26:19.930+0000] {processor.py:157} INFO - Started process (PID=30539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:26:19.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:26:19.935+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:26:19.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:26:19.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:26:19.964+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:26:19.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:26:19.976+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:26:19.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:26:19.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T22:26:50.344+0000] {processor.py:157} INFO - Started process (PID=30564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:26:50.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:26:50.346+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:26:50.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:26:50.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:26:50.371+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:26:50.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:26:50.381+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:26:50.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:26:50.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-26T22:27:20.872+0000] {processor.py:157} INFO - Started process (PID=30589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:27:20.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:27:20.876+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:27:20.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:27:20.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:27:20.920+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:27:20.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:27:20.933+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:27:20.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:27:20.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-26T22:27:51.395+0000] {processor.py:157} INFO - Started process (PID=30614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:27:51.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:27:51.399+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:27:51.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:27:51.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:27:51.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:27:51.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:27:51.438+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:27:51.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:27:51.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T22:28:21.826+0000] {processor.py:157} INFO - Started process (PID=30639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:28:21.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:28:21.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:28:21.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:28:21.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:28:21.866+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:28:21.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:28:21.882+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:28:21.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:28:21.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-26T22:28:52.354+0000] {processor.py:157} INFO - Started process (PID=30664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:28:52.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:28:52.359+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:28:52.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:28:52.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:28:52.386+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:28:52.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:28:52.397+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:28:52.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:28:52.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:29:22.729+0000] {processor.py:157} INFO - Started process (PID=30689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:29:22.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:29:22.733+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:29:22.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:29:22.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:29:22.760+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:29:22.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:29:22.769+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:29:22.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:29:22.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-26T22:29:53.233+0000] {processor.py:157} INFO - Started process (PID=30714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:29:53.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:29:53.242+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:29:53.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:29:53.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:29:53.264+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:29:53.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:29:53.273+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:29:53.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:29:53.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T22:30:23.667+0000] {processor.py:157} INFO - Started process (PID=30739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:30:23.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:30:23.669+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:30:23.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:30:23.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:30:23.702+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:30:23.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:30:23.715+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:30:23.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:30:23.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T22:30:54.179+0000] {processor.py:157} INFO - Started process (PID=30764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:30:54.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:30:54.182+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:30:54.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:30:54.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:30:54.211+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:30:54.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:30:54.222+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:30:54.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:30:54.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T22:31:24.634+0000] {processor.py:157} INFO - Started process (PID=30789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:31:24.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:31:24.638+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:31:24.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:31:24.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:31:24.668+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:31:24.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:31:24.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:31:24.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:31:24.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:31:55.134+0000] {processor.py:157} INFO - Started process (PID=30814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:31:55.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:31:55.140+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:31:55.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:31:55.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:31:55.171+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:31:55.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:31:55.182+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:31:55.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:31:55.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T22:32:25.627+0000] {processor.py:157} INFO - Started process (PID=30839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:32:25.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:32:25.632+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:32:25.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:32:25.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:32:25.666+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:32:25.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:32:25.678+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:32:25.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:32:25.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-26T22:32:56.077+0000] {processor.py:157} INFO - Started process (PID=30864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:32:56.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:32:56.081+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:32:56.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:32:56.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:32:56.110+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:32:56.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:32:56.120+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:32:56.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:32:56.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T22:33:26.593+0000] {processor.py:157} INFO - Started process (PID=30889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:33:26.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:33:26.599+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:33:26.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:33:26.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:33:26.629+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:33:26.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:33:26.640+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:33:26.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:33:26.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-26T22:33:57.119+0000] {processor.py:157} INFO - Started process (PID=30914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:33:57.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:33:57.124+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:33:57.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:33:57.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:33:57.171+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:33:57.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:33:57.184+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:33:57.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:33:57.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-26T22:34:27.591+0000] {processor.py:157} INFO - Started process (PID=30939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:34:27.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:34:27.593+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:34:27.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:34:27.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:34:27.620+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:34:27.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:34:27.635+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:34:27.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:34:27.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:34:58.059+0000] {processor.py:157} INFO - Started process (PID=30964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:34:58.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:34:58.062+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:34:58.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:34:58.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:34:58.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:34:58.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:34:58.114+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:34:58.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:34:58.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-26T22:35:28.524+0000] {processor.py:157} INFO - Started process (PID=30989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:35:28.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:35:28.530+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:35:28.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:35:28.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:35:28.558+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:35:28.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:35:28.567+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:35:28.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:35:28.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:35:58.949+0000] {processor.py:157} INFO - Started process (PID=31014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:35:58.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:35:58.952+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:35:58.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:35:58.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:35:58.979+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:35:58.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:35:58.995+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:35:58.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:35:59.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-26T22:36:29.362+0000] {processor.py:157} INFO - Started process (PID=31039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:36:29.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:36:29.365+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:36:29.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:36:29.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:36:29.388+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:36:29.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:36:29.398+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:36:29.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:36:29.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T22:36:59.815+0000] {processor.py:157} INFO - Started process (PID=31064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:36:59.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:36:59.818+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:36:59.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:36:59.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:36:59.852+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:36:59.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:36:59.865+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:36:59.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:36:59.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-26T22:37:30.336+0000] {processor.py:157} INFO - Started process (PID=31089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:37:30.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:37:30.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:37:30.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:37:30.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:37:30.369+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:37:30.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:37:30.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:37:30.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:37:30.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T22:38:00.775+0000] {processor.py:157} INFO - Started process (PID=31113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:38:00.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:38:00.779+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:38:00.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:38:00.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:38:00.807+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:38:00.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:38:00.816+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:38:00.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:38:00.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:38:31.262+0000] {processor.py:157} INFO - Started process (PID=31139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:38:31.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:38:31.266+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:38:31.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:38:31.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:38:31.295+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:38:31.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:38:31.304+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:38:31.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:38:31.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-26T22:39:01.740+0000] {processor.py:157} INFO - Started process (PID=31164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:39:01.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:39:01.743+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:39:01.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:39:01.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:39:01.781+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:39:01.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:39:01.794+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:39:01.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:39:01.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-26T22:39:32.189+0000] {processor.py:157} INFO - Started process (PID=31189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:39:32.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:39:32.192+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:39:32.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:39:32.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:39:32.220+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:39:32.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:39:32.232+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:39:32.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:39:32.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T22:40:02.652+0000] {processor.py:157} INFO - Started process (PID=31214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:40:02.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:40:02.657+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:40:02.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:40:02.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:40:02.683+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:40:02.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:40:02.698+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:40:02.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:40:02.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T22:40:33.063+0000] {processor.py:157} INFO - Started process (PID=31239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:40:33.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:40:33.065+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:40:33.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:40:33.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:40:33.090+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:40:33.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:40:33.100+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:40:33.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:40:33.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-26T22:41:03.479+0000] {processor.py:157} INFO - Started process (PID=31264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:41:03.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:41:03.482+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:41:03.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:41:03.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:41:03.508+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:41:03.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:41:03.521+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:41:03.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:41:03.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-26T22:41:33.987+0000] {processor.py:157} INFO - Started process (PID=31289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:41:33.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:41:33.994+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:41:33.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:41:34.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:41:34.018+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:41:34.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:41:34.027+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:41:34.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:41:34.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-26T22:42:04.373+0000] {processor.py:157} INFO - Started process (PID=31314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:42:04.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:42:04.378+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:42:04.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:42:04.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:42:04.421+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:42:04.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:42:04.455+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:42:04.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:42:04.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-26T22:42:34.868+0000] {processor.py:157} INFO - Started process (PID=31339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:42:34.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:42:34.870+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:42:34.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:42:34.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:42:34.899+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:42:34.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:42:34.913+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:42:34.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:42:34.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-26T22:43:05.280+0000] {processor.py:157} INFO - Started process (PID=31364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:43:05.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:43:05.284+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:43:05.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:43:05.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:43:05.309+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:43:05.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:43:05.319+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:43:05.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:43:05.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T22:43:35.755+0000] {processor.py:157} INFO - Started process (PID=31389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:43:35.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:43:35.764+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:43:35.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:43:35.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:43:35.808+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:43:35.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:43:35.822+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:43:35.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:43:35.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-26T22:51:32.988+0000] {processor.py:157} INFO - Started process (PID=31414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:51:32.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:51:32.992+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:51:32.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:51:33.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:51:33.059+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:51:33.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:51:33.081+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:51:33.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:51:33.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-26T22:52:03.650+0000] {processor.py:157} INFO - Started process (PID=31440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:52:03.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:52:03.676+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:52:03.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:52:03.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:52:03.721+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:52:03.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:52:03.752+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:52:03.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:52:03.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-26T22:52:34.203+0000] {processor.py:157} INFO - Started process (PID=31466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:52:34.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:52:34.206+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:52:34.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:52:34.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:52:34.235+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:52:34.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:52:34.245+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:52:34.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:52:34.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-26T22:53:04.580+0000] {processor.py:157} INFO - Started process (PID=31491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:53:04.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:53:04.585+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:53:04.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:53:04.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:53:04.622+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:53:04.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:53:04.636+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:53:04.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:53:04.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-26T22:53:35.070+0000] {processor.py:157} INFO - Started process (PID=31516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:53:35.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:53:35.075+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:53:35.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:53:35.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:53:35.107+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:53:35.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:53:35.117+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:53:35.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:53:35.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-26T22:54:05.562+0000] {processor.py:157} INFO - Started process (PID=31541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:54:05.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:54:05.569+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:54:05.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:54:05.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:54:05.603+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:54:05.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:54:05.615+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:54:05.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:54:05.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T22:54:35.962+0000] {processor.py:157} INFO - Started process (PID=31566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:54:35.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:54:35.966+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:54:35.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:54:35.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:54:35.991+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:54:35.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:54:36.001+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:54:36.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:54:36.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-26T22:55:06.383+0000] {processor.py:157} INFO - Started process (PID=31591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:55:06.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T22:55:06.387+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:55:06.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:55:06.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T22:55:06.418+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:55:06.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T22:55:06.427+0000] {logging_mixin.py:151} INFO - [2024-07-26T22:55:06.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T22:55:06.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-26T23:12:26.274+0000] {processor.py:157} INFO - Started process (PID=31618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:12:26.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T23:12:26.277+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:12:26.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:12:26.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:12:26.313+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:12:26.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T23:12:26.340+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:12:26.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T23:12:26.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-26T23:12:56.818+0000] {processor.py:157} INFO - Started process (PID=31642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:12:56.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T23:12:56.824+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:12:56.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:12:56.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:12:56.890+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:12:56.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T23:12:56.903+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:12:56.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T23:12:56.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-26T23:13:27.276+0000] {processor.py:157} INFO - Started process (PID=31668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:13:27.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T23:13:27.280+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:13:27.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:13:27.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:13:27.307+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:13:27.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T23:13:27.317+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:13:27.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T23:13:27.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-26T23:29:26.769+0000] {processor.py:157} INFO - Started process (PID=31693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:29:26.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T23:29:26.776+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:29:26.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:29:26.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:29:26.816+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:29:26.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T23:29:26.832+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:29:26.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T23:29:26.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-26T23:29:57.360+0000] {processor.py:157} INFO - Started process (PID=31717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:29:57.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T23:29:57.367+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:29:57.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:29:57.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:29:57.420+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:29:57.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T23:29:57.432+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:29:57.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T23:29:57.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-26T23:47:15.748+0000] {processor.py:157} INFO - Started process (PID=31743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:47:15.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-26T23:47:15.760+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:47:15.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:47:15.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-26T23:47:15.825+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:47:15.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-26T23:47:15.851+0000] {logging_mixin.py:151} INFO - [2024-07-26T23:47:15.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-26T23:47:15.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
