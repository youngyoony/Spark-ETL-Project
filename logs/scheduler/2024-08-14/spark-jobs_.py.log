[2024-08-14T00:54:29.574+0000] {processor.py:157} INFO - Started process (PID=39492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T00:54:29.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T00:54:29.595+0000] {logging_mixin.py:151} INFO - [2024-08-14T00:54:29.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T00:54:29.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T00:54:29.877+0000] {logging_mixin.py:151} INFO - [2024-08-14T00:54:29.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T00:54:29.914+0000] {logging_mixin.py:151} INFO - [2024-08-14T00:54:29.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-14T00:54:29.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.366 seconds
[2024-08-14T00:55:00.188+0000] {processor.py:157} INFO - Started process (PID=40323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T00:55:00.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T00:55:00.194+0000] {logging_mixin.py:151} INFO - [2024-08-14T00:55:00.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T00:55:00.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T00:55:00.260+0000] {logging_mixin.py:151} INFO - [2024-08-14T00:55:00.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T00:55:00.279+0000] {logging_mixin.py:151} INFO - [2024-08-14T00:55:00.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-14T00:55:00.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-14T01:55:26.543+0000] {processor.py:157} INFO - Started process (PID=40333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T01:55:26.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T01:55:26.555+0000] {logging_mixin.py:151} INFO - [2024-08-14T01:55:26.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T01:55:26.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T01:55:26.678+0000] {logging_mixin.py:151} INFO - [2024-08-14T01:55:26.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T01:55:26.713+0000] {logging_mixin.py:151} INFO - [2024-08-14T01:55:26.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T01:55:26.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.211 seconds
[2024-08-14T01:55:57.002+0000] {processor.py:157} INFO - Started process (PID=40343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T01:55:57.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T01:55:57.016+0000] {logging_mixin.py:151} INFO - [2024-08-14T01:55:57.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T01:55:57.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T01:55:57.071+0000] {logging_mixin.py:151} INFO - [2024-08-14T01:55:57.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T01:55:57.092+0000] {logging_mixin.py:151} INFO - [2024-08-14T01:55:57.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T01:55:57.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-14T02:44:27.309+0000] {processor.py:157} INFO - Started process (PID=40353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T02:44:27.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T02:44:27.319+0000] {logging_mixin.py:151} INFO - [2024-08-14T02:44:27.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T02:44:27.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T02:44:27.391+0000] {logging_mixin.py:151} INFO - [2024-08-14T02:44:27.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T02:44:27.425+0000] {logging_mixin.py:151} INFO - [2024-08-14T02:44:27.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T02:44:27.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-14T02:56:53.789+0000] {processor.py:157} INFO - Started process (PID=40364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T02:56:53.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T02:56:53.798+0000] {logging_mixin.py:151} INFO - [2024-08-14T02:56:53.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T02:56:53.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T02:56:53.873+0000] {logging_mixin.py:151} INFO - [2024-08-14T02:56:53.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T02:56:53.895+0000] {logging_mixin.py:151} INFO - [2024-08-14T02:56:53.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T02:56:53.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-14T03:47:25.677+0000] {processor.py:157} INFO - Started process (PID=40374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T03:47:25.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T03:47:25.683+0000] {logging_mixin.py:151} INFO - [2024-08-14T03:47:25.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T03:47:25.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T03:47:25.735+0000] {logging_mixin.py:151} INFO - [2024-08-14T03:47:25.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T03:47:25.749+0000] {logging_mixin.py:151} INFO - [2024-08-14T03:47:25.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T03:47:25.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-14T03:57:51.826+0000] {processor.py:157} INFO - Started process (PID=40385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T03:57:51.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T03:57:51.834+0000] {logging_mixin.py:151} INFO - [2024-08-14T03:57:51.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T03:57:51.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T03:57:51.912+0000] {logging_mixin.py:151} INFO - [2024-08-14T03:57:51.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T03:57:51.945+0000] {logging_mixin.py:151} INFO - [2024-08-14T03:57:51.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T03:57:51.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-14T04:32:17.987+0000] {processor.py:157} INFO - Started process (PID=40395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T04:32:17.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T04:32:17.996+0000] {logging_mixin.py:151} INFO - [2024-08-14T04:32:17.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T04:32:18.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T04:32:18.054+0000] {logging_mixin.py:151} INFO - [2024-08-14T04:32:18.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T04:32:18.067+0000] {logging_mixin.py:151} INFO - [2024-08-14T04:32:18.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T04:32:18.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-14T04:58:49.544+0000] {processor.py:157} INFO - Started process (PID=40407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T04:58:49.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T04:58:49.550+0000] {logging_mixin.py:151} INFO - [2024-08-14T04:58:49.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T04:58:49.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T04:58:49.609+0000] {logging_mixin.py:151} INFO - [2024-08-14T04:58:49.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T04:58:49.629+0000] {logging_mixin.py:151} INFO - [2024-08-14T04:58:49.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T04:58:49.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-14T05:14:30.864+0000] {processor.py:157} INFO - Started process (PID=40417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T05:14:30.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T05:14:30.870+0000] {logging_mixin.py:151} INFO - [2024-08-14T05:14:30.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T05:14:30.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T05:14:30.915+0000] {logging_mixin.py:151} INFO - [2024-08-14T05:14:30.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T05:14:30.928+0000] {logging_mixin.py:151} INFO - [2024-08-14T05:14:30.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T05:14:30.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-14T05:59:44.480+0000] {processor.py:157} INFO - Started process (PID=40426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T05:59:44.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T05:59:44.486+0000] {logging_mixin.py:151} INFO - [2024-08-14T05:59:44.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T05:59:44.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T05:59:44.539+0000] {logging_mixin.py:151} INFO - [2024-08-14T05:59:44.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T05:59:44.558+0000] {logging_mixin.py:151} INFO - [2024-08-14T05:59:44.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T05:59:44.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-14T06:00:14.837+0000] {processor.py:157} INFO - Started process (PID=40436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T06:00:14.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T06:00:14.865+0000] {logging_mixin.py:151} INFO - [2024-08-14T06:00:14.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T06:00:14.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T06:00:14.925+0000] {logging_mixin.py:151} INFO - [2024-08-14T06:00:14.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T06:00:14.949+0000] {logging_mixin.py:151} INFO - [2024-08-14T06:00:14.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T06:00:14.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-14T07:43:07.832+0000] {processor.py:157} INFO - Started process (PID=40448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T07:43:07.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T07:43:07.841+0000] {logging_mixin.py:151} INFO - [2024-08-14T07:43:07.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T07:43:07.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T07:43:07.909+0000] {logging_mixin.py:151} INFO - [2024-08-14T07:43:07.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T07:43:07.933+0000] {logging_mixin.py:151} INFO - [2024-08-14T07:43:07.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T07:43:07.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-14T07:54:05.016+0000] {processor.py:157} INFO - Started process (PID=40458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T07:54:05.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T07:54:05.024+0000] {logging_mixin.py:151} INFO - [2024-08-14T07:54:05.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T07:54:05.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T07:54:05.066+0000] {logging_mixin.py:151} INFO - [2024-08-14T07:54:05.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T07:54:05.080+0000] {logging_mixin.py:151} INFO - [2024-08-14T07:54:05.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T07:54:05.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-14T08:27:56.095+0000] {processor.py:157} INFO - Started process (PID=40469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T08:27:56.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T08:27:56.107+0000] {logging_mixin.py:151} INFO - [2024-08-14T08:27:56.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T08:27:56.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T08:27:56.253+0000] {logging_mixin.py:151} INFO - [2024-08-14T08:27:56.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T08:27:56.308+0000] {logging_mixin.py:151} INFO - [2024-08-14T08:27:56.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T08:27:56.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.261 seconds
[2024-08-14T10:01:02.811+0000] {processor.py:157} INFO - Started process (PID=40478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:01:02.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T10:01:02.817+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:01:02.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:01:02.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:01:02.862+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:01:02.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T10:01:02.875+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:01:02.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T10:01:02.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-14T10:01:33.124+0000] {processor.py:157} INFO - Started process (PID=40488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:01:33.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T10:01:33.132+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:01:33.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:01:33.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:01:33.188+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:01:33.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T10:01:33.204+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:01:33.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T10:01:33.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-14T10:54:27.011+0000] {processor.py:157} INFO - Started process (PID=40501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:54:27.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T10:54:27.025+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:54:27.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:54:27.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T10:54:27.115+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:54:27.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T10:54:27.146+0000] {logging_mixin.py:151} INFO - [2024-08-14T10:54:27.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T10:54:27.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-14T12:33:17.123+0000] {processor.py:157} INFO - Started process (PID=40511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T12:33:17.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T12:33:17.128+0000] {logging_mixin.py:151} INFO - [2024-08-14T12:33:17.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T12:33:17.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T12:33:17.171+0000] {logging_mixin.py:151} INFO - [2024-08-14T12:33:17.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T12:33:17.189+0000] {logging_mixin.py:151} INFO - [2024-08-14T12:33:17.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T12:33:17.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-14T13:00:23.884+0000] {processor.py:157} INFO - Started process (PID=40522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:00:23.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:00:23.893+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:00:23.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:00:23.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:00:23.962+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:00:23.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:00:23.981+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:00:23.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:00:24.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-14T13:02:07.199+0000] {processor.py:157} INFO - Started process (PID=40533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:02:07.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:02:07.213+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:02:07.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:02:07.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:02:07.275+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:02:07.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:02:07.293+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:02:07.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:02:07.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-14T13:02:37.450+0000] {processor.py:157} INFO - Started process (PID=40543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:02:37.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:02:37.456+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:02:37.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:02:37.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:02:37.490+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:02:37.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:02:37.499+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:02:37.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:02:37.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-14T13:03:11.517+0000] {processor.py:157} INFO - Started process (PID=40553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:03:11.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:03:11.521+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:03:11.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:03:11.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:03:11.570+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:03:11.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:03:11.583+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:03:11.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:03:11.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-14T13:09:45.434+0000] {processor.py:157} INFO - Started process (PID=40565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:09:45.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:09:45.438+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:09:45.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:09:45.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:09:45.459+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:09:45.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:09:45.469+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:09:45.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:09:45.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-14T13:10:15.764+0000] {processor.py:157} INFO - Started process (PID=40574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:10:15.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:10:15.772+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:10:15.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:10:15.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:10:15.832+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:10:15.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:10:15.845+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:10:15.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:10:15.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-14T13:22:14.771+0000] {processor.py:157} INFO - Started process (PID=40585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:22:14.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:22:14.785+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:22:14.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:22:14.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:22:14.861+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:22:14.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:22:14.898+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:22:14.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:22:14.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-14T13:22:45.180+0000] {processor.py:157} INFO - Started process (PID=40595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:22:45.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:22:45.187+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:22:45.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:22:45.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:22:45.226+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:22:45.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:22:45.240+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:22:45.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:22:45.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-14T13:23:15.533+0000] {processor.py:157} INFO - Started process (PID=40605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:23:15.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:23:15.539+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:23:15.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:23:15.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:23:15.579+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:23:15.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:23:15.596+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:23:15.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:23:15.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-14T13:23:45.928+0000] {processor.py:157} INFO - Started process (PID=40615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:23:45.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:23:45.935+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:23:45.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:23:45.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:23:45.995+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:23:45.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:23:46.011+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:23:46.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:23:46.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-14T13:24:16.214+0000] {processor.py:157} INFO - Started process (PID=40625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:24:16.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:24:16.218+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:24:16.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:24:16.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:24:16.258+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:24:16.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:24:16.271+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:24:16.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:24:16.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-14T13:24:46.481+0000] {processor.py:157} INFO - Started process (PID=40635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:24:46.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:24:46.487+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:24:46.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:24:46.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:24:46.530+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:24:46.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:24:46.546+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:24:46.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:24:46.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-14T13:25:16.825+0000] {processor.py:157} INFO - Started process (PID=40645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:25:16.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:25:16.833+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:25:16.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:25:16.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:25:16.906+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:25:16.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:25:16.929+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:25:16.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:25:16.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-14T13:25:47.191+0000] {processor.py:157} INFO - Started process (PID=40655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:25:47.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:25:47.196+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:25:47.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:25:47.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:25:47.256+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:25:47.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:25:47.273+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:25:47.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:25:47.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-14T13:26:17.465+0000] {processor.py:157} INFO - Started process (PID=40665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:26:17.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:26:17.474+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:26:17.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:26:17.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:26:17.600+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:26:17.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:26:17.619+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:26:17.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:26:17.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-14T13:26:47.963+0000] {processor.py:157} INFO - Started process (PID=40675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:26:47.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:26:47.972+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:26:47.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:26:48.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:26:48.069+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:26:48.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:26:48.100+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:26:48.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:26:48.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-14T13:27:18.329+0000] {processor.py:157} INFO - Started process (PID=40685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:27:18.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:27:18.335+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:27:18.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:27:18.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:27:18.394+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:27:18.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:27:18.408+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:27:18.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:27:18.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-14T13:27:48.601+0000] {processor.py:157} INFO - Started process (PID=40694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:27:48.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:27:48.611+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:27:48.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:27:48.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:27:48.698+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:27:48.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:27:48.730+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:27:48.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:27:48.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-14T13:28:18.965+0000] {processor.py:157} INFO - Started process (PID=40705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:28:18.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:28:18.973+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:28:18.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:28:19.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:28:19.064+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:28:19.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:28:19.093+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:28:19.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:28:19.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-14T13:28:49.314+0000] {processor.py:157} INFO - Started process (PID=40715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:28:49.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:28:49.323+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:28:49.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:28:49.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:28:49.390+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:28:49.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:28:49.406+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:28:49.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:28:49.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-14T13:29:19.747+0000] {processor.py:157} INFO - Started process (PID=40725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:29:19.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:29:19.773+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:29:19.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:29:19.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:29:19.871+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:29:19.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:29:19.890+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:29:19.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:29:19.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-14T13:29:50.122+0000] {processor.py:157} INFO - Started process (PID=40735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:29:50.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:29:50.135+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:29:50.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:29:50.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:29:50.226+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:29:50.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:29:50.247+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:29:50.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:29:50.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-14T13:30:20.655+0000] {processor.py:157} INFO - Started process (PID=40745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:30:20.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:30:20.682+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:30:20.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:30:20.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:30:20.745+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:30:20.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:30:20.764+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:30:20.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:30:20.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-14T13:30:51.103+0000] {processor.py:157} INFO - Started process (PID=40753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:30:51.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:30:51.113+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:30:51.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:30:51.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:30:51.200+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:30:51.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:30:51.224+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:30:51.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:30:51.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-14T13:31:21.404+0000] {processor.py:157} INFO - Started process (PID=40765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:31:21.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:31:21.415+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:31:21.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:31:21.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:31:21.516+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:31:21.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:31:21.536+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:31:21.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:31:21.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-14T13:31:51.767+0000] {processor.py:157} INFO - Started process (PID=40774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:31:51.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:31:51.776+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:31:51.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:31:51.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:31:51.847+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:31:51.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:31:51.872+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:31:51.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:31:51.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-14T13:32:22.258+0000] {processor.py:157} INFO - Started process (PID=40785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:32:22.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:32:22.265+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:32:22.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:32:22.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:32:22.317+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:32:22.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:32:22.334+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:32:22.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:32:22.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-14T13:32:52.549+0000] {processor.py:157} INFO - Started process (PID=40795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:32:52.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:32:52.556+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:32:52.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:32:52.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:32:52.609+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:32:52.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:32:52.639+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:32:52.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:32:52.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-14T13:33:22.865+0000] {processor.py:157} INFO - Started process (PID=40805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:33:22.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:33:22.872+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:33:22.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:33:22.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:33:22.915+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:33:22.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:33:22.931+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:33:22.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:33:22.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-14T13:33:53.167+0000] {processor.py:157} INFO - Started process (PID=40814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:33:53.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:33:53.175+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:33:53.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:33:53.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:33:53.223+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:33:53.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:33:53.238+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:33:53.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:33:53.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-14T13:34:23.623+0000] {processor.py:157} INFO - Started process (PID=40825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:34:23.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:34:23.638+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:34:23.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:34:23.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:34:23.720+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:34:23.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:34:23.740+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:34:23.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:34:23.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-14T13:34:54.022+0000] {processor.py:157} INFO - Started process (PID=40835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:34:54.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:34:54.050+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:34:54.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:34:54.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:34:54.107+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:34:54.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:34:54.145+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:34:54.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:34:54.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-14T13:35:24.293+0000] {processor.py:157} INFO - Started process (PID=40845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:35:24.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:35:24.302+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:35:24.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:35:24.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:35:24.350+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:35:24.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:35:24.368+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:35:24.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:35:24.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-14T13:35:54.611+0000] {processor.py:157} INFO - Started process (PID=40855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:35:54.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:35:54.618+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:35:54.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:35:54.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:35:54.650+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:35:54.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:35:54.661+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:35:54.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:35:54.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-14T13:36:24.984+0000] {processor.py:157} INFO - Started process (PID=40864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:36:24.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:36:24.989+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:36:24.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:36:25.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:36:25.034+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:36:25.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:36:25.048+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:36:25.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:36:25.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-14T13:36:55.404+0000] {processor.py:157} INFO - Started process (PID=40875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:36:55.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:36:55.422+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:36:55.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:36:55.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:36:55.469+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:36:55.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:36:55.491+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:36:55.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:36:55.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-14T13:37:25.724+0000] {processor.py:157} INFO - Started process (PID=40885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:37:25.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:37:25.728+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:37:25.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:37:25.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:37:25.755+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:37:25.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:37:25.766+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:37:25.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:37:25.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-14T13:37:56.450+0000] {processor.py:157} INFO - Started process (PID=40895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:37:56.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:37:56.459+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:37:56.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:37:56.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:37:56.534+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:37:56.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:37:56.556+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:37:56.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:37:56.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-14T13:38:28.923+0000] {processor.py:157} INFO - Started process (PID=40905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:38:28.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:38:28.930+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:38:28.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:38:28.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:38:29.002+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:38:29.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:38:29.017+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:38:29.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:38:29.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-14T13:38:59.259+0000] {processor.py:157} INFO - Started process (PID=40915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:38:59.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:38:59.267+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:38:59.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:38:59.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:38:59.330+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:38:59.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:38:59.348+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:38:59.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:38:59.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-14T13:39:29.675+0000] {processor.py:157} INFO - Started process (PID=40925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:39:29.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:39:29.683+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:39:29.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:39:29.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:39:29.727+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:39:29.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:39:29.743+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:39:29.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:39:29.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-14T13:40:00.027+0000] {processor.py:157} INFO - Started process (PID=40935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:40:00.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:40:00.029+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:40:00.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:40:00.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:40:00.053+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:40:00.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:40:00.067+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:40:00.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:40:00.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-14T13:40:30.345+0000] {processor.py:157} INFO - Started process (PID=40945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:40:30.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:40:30.350+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:40:30.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:40:30.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:40:30.384+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:40:30.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:40:30.396+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:40:30.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:40:30.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-14T13:41:00.699+0000] {processor.py:157} INFO - Started process (PID=40955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:41:00.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:41:00.711+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:41:00.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:41:00.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:41:00.774+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:41:00.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:41:00.792+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:41:00.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:41:00.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-14T13:41:31.032+0000] {processor.py:157} INFO - Started process (PID=40965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:41:31.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:41:31.035+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:41:31.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:41:31.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:41:31.063+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:41:31.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:41:31.078+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:41:31.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:41:31.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-14T13:42:01.351+0000] {processor.py:157} INFO - Started process (PID=40975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:42:01.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:42:01.355+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:42:01.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:42:01.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:42:01.382+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:42:01.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:42:01.393+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:42:01.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:42:01.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-14T13:42:31.692+0000] {processor.py:157} INFO - Started process (PID=40985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:42:31.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:42:31.712+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:42:31.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:42:31.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:42:31.771+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:42:31.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:42:31.787+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:42:31.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:42:31.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-14T13:43:02.056+0000] {processor.py:157} INFO - Started process (PID=40995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:43:02.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:43:02.061+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:43:02.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:43:02.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:43:02.124+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:43:02.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:43:02.140+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:43:02.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:43:02.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-14T13:43:32.354+0000] {processor.py:157} INFO - Started process (PID=41005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:43:32.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:43:32.360+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:43:32.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:43:32.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:43:32.456+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:43:32.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:43:32.476+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:43:32.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:43:32.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-14T13:44:02.706+0000] {processor.py:157} INFO - Started process (PID=41015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:44:02.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:44:02.717+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:44:02.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:44:02.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:44:02.771+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:44:02.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:44:02.798+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:44:02.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:44:02.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-14T13:44:33.083+0000] {processor.py:157} INFO - Started process (PID=41025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:44:33.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:44:33.088+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:44:33.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:44:33.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:44:33.158+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:44:33.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:44:33.174+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:44:33.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:44:33.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-14T13:45:03.482+0000] {processor.py:157} INFO - Started process (PID=41035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:45:03.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:45:03.484+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:45:03.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:45:03.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:45:03.512+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:45:03.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:45:03.521+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:45:03.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:45:03.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T13:45:33.798+0000] {processor.py:157} INFO - Started process (PID=41045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:45:33.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:45:33.801+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:45:33.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:45:33.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:45:33.828+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:45:33.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:45:33.838+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:45:33.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:45:33.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-14T13:46:04.151+0000] {processor.py:157} INFO - Started process (PID=41055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:46:04.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:46:04.157+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:46:04.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:46:04.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:46:04.196+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:46:04.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:46:04.209+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:46:04.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:46:04.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-14T13:46:34.482+0000] {processor.py:157} INFO - Started process (PID=41065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:46:34.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:46:34.485+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:46:34.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:46:34.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:46:34.511+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:46:34.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:46:34.523+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:46:34.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:46:34.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T13:47:04.828+0000] {processor.py:157} INFO - Started process (PID=41075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:47:04.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:47:04.832+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:47:04.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:47:04.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:47:04.859+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:47:04.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:47:04.869+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:47:04.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:47:04.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-14T13:47:35.166+0000] {processor.py:157} INFO - Started process (PID=41085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:47:35.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:47:35.168+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:47:35.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:47:35.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:47:35.199+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:47:35.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:47:35.209+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:47:35.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:47:35.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-14T13:48:05.461+0000] {processor.py:157} INFO - Started process (PID=41095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:48:05.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:48:05.464+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:48:05.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:48:05.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:48:05.491+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:48:05.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:48:05.501+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:48:05.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:48:05.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-14T13:48:35.741+0000] {processor.py:157} INFO - Started process (PID=41105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:48:35.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:48:35.754+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:48:35.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:48:35.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:48:35.813+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:48:35.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:48:35.828+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:48:35.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:48:35.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-14T13:49:06.129+0000] {processor.py:157} INFO - Started process (PID=41115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:49:06.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:49:06.134+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:49:06.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:49:06.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:49:06.162+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:49:06.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:49:06.172+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:49:06.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:49:06.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-14T13:49:36.444+0000] {processor.py:157} INFO - Started process (PID=41124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:49:36.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:49:36.450+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:49:36.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:49:36.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:49:36.487+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:49:36.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:49:36.499+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:49:36.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:49:36.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-14T13:50:06.750+0000] {processor.py:157} INFO - Started process (PID=41135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:50:06.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:50:06.756+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:50:06.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:50:06.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:50:06.793+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:50:06.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:50:06.807+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:50:06.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:50:06.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-14T13:50:37.133+0000] {processor.py:157} INFO - Started process (PID=41145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:50:37.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:50:37.140+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:50:37.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:50:37.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:50:37.174+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:50:37.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:50:37.185+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:50:37.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:50:37.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-14T13:51:07.422+0000] {processor.py:157} INFO - Started process (PID=41155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:51:07.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:51:07.425+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:51:07.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:51:07.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:51:07.464+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:51:07.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:51:07.477+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:51:07.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:51:07.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-14T13:51:37.747+0000] {processor.py:157} INFO - Started process (PID=41165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:51:37.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:51:37.760+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:51:37.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:51:37.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:51:37.810+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:51:37.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:51:37.828+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:51:37.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:51:37.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-14T13:52:08.037+0000] {processor.py:157} INFO - Started process (PID=41175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:52:08.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:52:08.042+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:52:08.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:52:08.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:52:08.070+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:52:08.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:52:08.080+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:52:08.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:52:08.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-14T13:52:38.386+0000] {processor.py:157} INFO - Started process (PID=41185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:52:38.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:52:38.391+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:52:38.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:52:38.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:52:38.427+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:52:38.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:52:38.441+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:52:38.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:52:38.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-14T13:53:08.717+0000] {processor.py:157} INFO - Started process (PID=41195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:53:08.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:53:08.720+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:53:08.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:53:08.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:53:08.750+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:53:08.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:53:08.763+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:53:08.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:53:08.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-14T13:53:39.059+0000] {processor.py:157} INFO - Started process (PID=41205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:53:39.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:53:39.062+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:53:39.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:53:39.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:53:39.089+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:53:39.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:53:39.100+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:53:39.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:53:39.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-14T13:54:09.342+0000] {processor.py:157} INFO - Started process (PID=41215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:54:09.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:54:09.347+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:54:09.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:54:09.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:54:09.392+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:54:09.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:54:09.404+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:54:09.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:54:09.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-14T13:54:39.679+0000] {processor.py:157} INFO - Started process (PID=41225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:54:39.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:54:39.682+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:54:39.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:54:39.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:54:39.708+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:54:39.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:54:39.719+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:54:39.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:54:39.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-14T13:55:10.015+0000] {processor.py:157} INFO - Started process (PID=41235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:55:10.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:55:10.018+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:55:10.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:55:10.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:55:10.046+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:55:10.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:55:10.056+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:55:10.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:55:10.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T13:55:40.302+0000] {processor.py:157} INFO - Started process (PID=41245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:55:40.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:55:40.306+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:55:40.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:55:40.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:55:40.335+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:55:40.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:55:40.345+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:55:40.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:55:40.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-14T13:56:10.638+0000] {processor.py:157} INFO - Started process (PID=41255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:56:10.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:56:10.640+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:56:10.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:56:10.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:56:10.670+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:56:10.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:56:10.681+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:56:10.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:56:10.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-14T13:56:40.956+0000] {processor.py:157} INFO - Started process (PID=41265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:56:40.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:56:40.959+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:56:40.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:56:40.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:56:40.987+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:56:40.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:56:40.997+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:56:40.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:56:41.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T13:57:11.359+0000] {processor.py:157} INFO - Started process (PID=41275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:57:11.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T13:57:11.366+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:57:11.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:57:11.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T13:57:11.413+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:57:11.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T13:57:11.427+0000] {logging_mixin.py:151} INFO - [2024-08-14T13:57:11.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T13:57:11.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-14T14:08:18.212+0000] {processor.py:157} INFO - Started process (PID=41285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:08:18.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:08:18.217+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:08:18.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:08:18.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:08:18.323+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:08:18.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:08:18.363+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:08:18.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:08:18.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-14T14:08:48.739+0000] {processor.py:157} INFO - Started process (PID=41297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:08:48.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:08:48.746+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:08:48.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:08:48.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:08:48.817+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:08:48.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:08:48.833+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:08:48.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:08:48.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-14T14:09:19.319+0000] {processor.py:157} INFO - Started process (PID=41306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:09:19.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:09:19.336+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:09:19.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:09:19.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:09:19.403+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:09:19.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:09:19.420+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:09:19.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:09:19.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-14T14:25:00.525+0000] {processor.py:157} INFO - Started process (PID=41319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:25:00.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:25:00.530+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:25:00.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:25:00.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:25:00.662+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:25:00.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:25:00.699+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:25:00.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:25:00.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-14T14:25:30.894+0000] {processor.py:157} INFO - Started process (PID=41329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:25:30.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:25:30.904+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:25:30.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:25:30.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:25:30.965+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:25:30.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:25:30.987+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:25:30.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:25:31.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-14T14:26:01.378+0000] {processor.py:157} INFO - Started process (PID=41339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:26:01.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:26:01.381+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:26:01.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:26:01.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:26:01.408+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:26:01.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:26:01.423+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:26:01.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:26:01.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-14T14:26:31.861+0000] {processor.py:157} INFO - Started process (PID=41349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:26:31.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:26:31.866+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:26:31.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:26:31.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:26:31.906+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:26:31.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:26:31.921+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:26:31.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:26:31.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-14T14:27:02.241+0000] {processor.py:157} INFO - Started process (PID=41359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:27:02.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:27:02.242+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:27:02.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:27:02.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:27:02.266+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:27:02.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:27:02.276+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:27:02.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:27:02.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-14T14:27:32.630+0000] {processor.py:157} INFO - Started process (PID=41369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:27:32.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:27:32.633+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:27:32.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:27:32.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:27:32.667+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:27:32.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:27:32.678+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:27:32.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:27:32.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-14T14:28:03.025+0000] {processor.py:157} INFO - Started process (PID=41378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:28:03.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:28:03.036+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:28:03.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:28:03.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:28:03.091+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:28:03.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:28:03.105+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:28:03.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:28:03.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-14T14:28:33.457+0000] {processor.py:157} INFO - Started process (PID=41389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:28:33.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:28:33.459+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:28:33.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:28:33.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:28:33.486+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:28:33.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:28:33.497+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:28:33.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:28:33.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-14T14:29:03.922+0000] {processor.py:157} INFO - Started process (PID=41399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:29:03.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:29:03.930+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:29:03.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:29:03.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:29:03.986+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:29:03.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:29:04.007+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:29:04.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:29:04.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-14T14:29:34.313+0000] {processor.py:157} INFO - Started process (PID=41409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:29:34.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:29:34.316+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:29:34.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:29:34.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:29:34.348+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:29:34.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:29:34.359+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:29:34.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:29:34.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-14T14:46:09.470+0000] {processor.py:157} INFO - Started process (PID=41419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:46:09.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:46:09.479+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:46:09.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:46:09.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:46:09.523+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:46:09.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:46:09.539+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:46:09.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:46:09.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-14T14:46:39.839+0000] {processor.py:157} INFO - Started process (PID=41429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:46:39.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:46:39.845+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:46:39.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:46:39.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:46:39.907+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:46:39.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:46:39.924+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:46:39.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:46:39.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-14T14:47:10.099+0000] {processor.py:157} INFO - Started process (PID=41441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:47:10.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:47:10.103+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:47:10.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:47:10.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:47:10.132+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:47:10.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:47:10.144+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:47:10.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:47:10.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T14:47:40.507+0000] {processor.py:157} INFO - Started process (PID=41451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:47:40.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:47:40.534+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:47:40.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:47:40.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:47:40.577+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:47:40.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:47:40.592+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:47:40.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:47:40.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-14T14:48:10.832+0000] {processor.py:157} INFO - Started process (PID=41461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:48:10.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:48:10.836+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:48:10.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:48:10.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:48:10.864+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:48:10.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:48:10.874+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:48:10.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:48:10.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T14:51:02.952+0000] {processor.py:157} INFO - Started process (PID=41473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:51:02.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:51:02.960+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:51:02.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:51:02.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:51:03.023+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:51:03.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:51:03.050+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:51:03.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:51:03.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-14T14:51:33.434+0000] {processor.py:157} INFO - Started process (PID=41483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:51:33.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:51:33.442+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:51:33.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:51:33.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:51:33.493+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:51:33.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:51:33.510+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:51:33.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:51:33.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-14T14:52:03.950+0000] {processor.py:157} INFO - Started process (PID=41492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:52:03.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T14:52:03.956+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:52:03.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:52:03.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T14:52:04.018+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:52:04.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T14:52:04.035+0000] {logging_mixin.py:151} INFO - [2024-08-14T14:52:04.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T14:52:04.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-14T15:24:03.483+0000] {processor.py:157} INFO - Started process (PID=41501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:24:03.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:24:03.489+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:24:03.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:24:03.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:24:03.548+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:24:03.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:24:03.564+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:24:03.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:24:03.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-14T15:24:33.805+0000] {processor.py:157} INFO - Started process (PID=41513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:24:33.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:24:33.828+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:24:33.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:24:33.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:24:33.884+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:24:33.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:24:33.901+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:24:33.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:24:33.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-14T15:26:20.826+0000] {processor.py:157} INFO - Started process (PID=41525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:26:20.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:26:20.835+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:26:20.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:26:20.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:26:20.909+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:26:20.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:26:20.936+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:26:20.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:26:20.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-14T15:40:13.297+0000] {processor.py:157} INFO - Started process (PID=41535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:40:13.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:40:13.308+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:40:13.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:40:13.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:40:13.368+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:40:13.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:40:13.385+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:40:13.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:40:13.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-14T15:40:43.611+0000] {processor.py:157} INFO - Started process (PID=41545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:40:43.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:40:43.619+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:40:43.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:40:43.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:40:43.674+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:40:43.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:40:43.691+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:40:43.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:40:43.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-14T15:41:16.216+0000] {processor.py:157} INFO - Started process (PID=41555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:41:16.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:41:16.220+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:41:16.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:41:16.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:41:16.247+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:41:16.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:41:16.260+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:41:16.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:41:16.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T15:41:46.589+0000] {processor.py:157} INFO - Started process (PID=41565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:41:46.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:41:46.597+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:41:46.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:41:46.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:41:46.636+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:41:46.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:41:46.649+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:41:46.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:41:46.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-14T15:42:16.903+0000] {processor.py:157} INFO - Started process (PID=41575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:42:16.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:42:16.906+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:42:16.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:42:16.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:42:16.937+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:42:16.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:42:16.948+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:42:16.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:42:16.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-14T15:42:47.222+0000] {processor.py:157} INFO - Started process (PID=41585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:42:47.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:42:47.224+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:42:47.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:42:47.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:42:47.248+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:42:47.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:42:47.259+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:42:47.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:42:47.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-14T15:43:17.556+0000] {processor.py:157} INFO - Started process (PID=41594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:43:17.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T15:43:17.563+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:43:17.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:43:17.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T15:43:17.619+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:43:17.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T15:43:17.635+0000] {logging_mixin.py:151} INFO - [2024-08-14T15:43:17.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T15:43:17.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-14T16:00:27.185+0000] {processor.py:157} INFO - Started process (PID=41606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:00:27.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:00:27.191+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:00:27.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:00:27.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:00:27.286+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:00:27.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:00:27.315+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:00:27.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:00:27.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-14T16:00:57.494+0000] {processor.py:157} INFO - Started process (PID=41617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:00:57.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:00:57.502+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:00:57.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:00:57.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:00:57.568+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:00:57.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:00:57.589+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:00:57.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:00:57.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-14T16:01:27.853+0000] {processor.py:157} INFO - Started process (PID=41627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:01:27.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:01:27.860+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:01:27.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:01:27.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:01:27.898+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:01:27.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:01:27.913+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:01:27.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:01:27.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-14T16:01:58.242+0000] {processor.py:157} INFO - Started process (PID=41637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:01:58.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:01:58.244+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:01:58.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:01:58.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:01:58.274+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:01:58.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:01:58.287+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:01:58.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:01:58.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-14T16:06:46.600+0000] {processor.py:157} INFO - Started process (PID=41649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:06:46.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:06:46.607+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:06:46.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:06:46.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:06:46.694+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:06:46.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:06:46.730+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:06:46.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:06:46.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-14T16:07:16.951+0000] {processor.py:157} INFO - Started process (PID=41658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:07:16.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:07:16.956+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:07:16.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:07:16.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:07:17.023+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:07:17.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:07:17.039+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:07:17.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:07:17.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-14T16:07:47.342+0000] {processor.py:157} INFO - Started process (PID=41669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:07:47.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:07:47.346+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:07:47.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:07:47.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:07:47.375+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:07:47.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:07:47.394+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:07:47.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:07:47.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-14T16:08:17.712+0000] {processor.py:157} INFO - Started process (PID=41679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:08:17.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:08:17.716+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:08:17.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:08:17.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:08:17.756+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:08:17.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:08:17.770+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:08:17.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:08:17.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-14T16:08:48.028+0000] {processor.py:157} INFO - Started process (PID=41689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:08:48.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:08:48.035+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:08:48.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:08:48.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:08:48.104+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:08:48.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:08:48.124+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:08:48.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:08:48.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-14T16:09:18.418+0000] {processor.py:157} INFO - Started process (PID=41699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:09:18.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:09:18.422+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:09:18.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:09:18.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:09:18.455+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:09:18.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:09:18.466+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:09:18.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:09:18.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-14T16:25:18.279+0000] {processor.py:157} INFO - Started process (PID=41709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:25:18.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:25:18.289+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:25:18.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:25:18.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:25:18.361+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:25:18.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:25:18.386+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:25:18.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:25:18.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-14T16:41:14.727+0000] {processor.py:157} INFO - Started process (PID=41720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:41:14.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:41:14.746+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:41:14.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:41:14.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:41:14.856+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:41:14.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:41:14.891+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:41:14.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:41:14.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-14T16:41:45.234+0000] {processor.py:157} INFO - Started process (PID=41730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:41:45.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:41:45.251+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:41:45.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:41:45.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:41:45.301+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:41:45.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:41:45.316+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:41:45.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:41:45.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-14T16:52:27.567+0000] {processor.py:157} INFO - Started process (PID=41739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:52:27.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:52:27.573+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:52:27.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:52:27.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:52:27.638+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:52:27.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:52:27.663+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:52:27.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:52:27.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-14T16:52:57.874+0000] {processor.py:157} INFO - Started process (PID=41750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:52:57.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:52:57.881+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:52:57.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:52:57.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:52:57.934+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:52:57.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:52:57.950+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:52:57.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:52:57.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-14T16:53:28.219+0000] {processor.py:157} INFO - Started process (PID=41760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:53:28.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T16:53:28.222+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:53:28.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:53:28.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T16:53:28.254+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:53:28.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T16:53:28.265+0000] {logging_mixin.py:151} INFO - [2024-08-14T16:53:28.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T16:53:28.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-14T17:30:03.181+0000] {processor.py:157} INFO - Started process (PID=41772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:30:03.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:30:03.195+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:30:03.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:30:03.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:30:03.266+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:30:03.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:30:03.291+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:30:03.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:30:03.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-14T17:30:33.512+0000] {processor.py:157} INFO - Started process (PID=41781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:30:33.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:30:33.523+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:30:33.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:30:33.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:30:33.584+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:30:33.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:30:33.602+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:30:33.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:30:33.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-14T17:32:13.045+0000] {processor.py:157} INFO - Started process (PID=41792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:32:13.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:32:13.054+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:32:13.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:32:13.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:32:13.139+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:32:13.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:32:13.157+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:32:13.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:32:13.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-14T17:32:43.363+0000] {processor.py:157} INFO - Started process (PID=41801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:32:43.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:32:43.372+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:32:43.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:32:43.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:32:43.432+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:32:43.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:32:43.448+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:32:43.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:32:43.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-14T17:33:41.267+0000] {processor.py:157} INFO - Started process (PID=41813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:33:41.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:33:41.270+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:33:41.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:33:41.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:33:41.297+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:33:41.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:33:41.311+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:33:41.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:33:41.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T17:34:11.638+0000] {processor.py:157} INFO - Started process (PID=41824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:34:11.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:34:11.642+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:34:11.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:34:11.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:34:11.670+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:34:11.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:34:11.682+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:34:11.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:34:11.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-14T17:34:41.945+0000] {processor.py:157} INFO - Started process (PID=41834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:34:41.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:34:41.949+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:34:41.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:34:41.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:34:41.988+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:34:41.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:34:42.001+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:34:42.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:34:42.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-14T17:36:59.009+0000] {processor.py:157} INFO - Started process (PID=41844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:36:59.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:36:59.012+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:36:59.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:36:59.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:36:59.035+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:36:59.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:36:59.044+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:36:59.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:36:59.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-14T17:37:29.360+0000] {processor.py:157} INFO - Started process (PID=41854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:37:29.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:37:29.364+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:37:29.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:37:29.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:37:29.404+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:37:29.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:37:29.417+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:37:29.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:37:29.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-14T17:37:59.663+0000] {processor.py:157} INFO - Started process (PID=41864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:37:59.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:37:59.665+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:37:59.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:37:59.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:37:59.699+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:37:59.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:37:59.709+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:37:59.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:37:59.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T17:38:30.064+0000] {processor.py:157} INFO - Started process (PID=41874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:38:30.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:38:30.068+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:38:30.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:38:30.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:38:30.095+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:38:30.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:38:30.105+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:38:30.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:38:30.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T17:39:00.376+0000] {processor.py:157} INFO - Started process (PID=41884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:39:00.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:39:00.384+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:39:00.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:39:00.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:39:00.407+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:39:00.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:39:00.420+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:39:00.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:39:00.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-14T17:39:30.755+0000] {processor.py:157} INFO - Started process (PID=41894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:39:30.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:39:30.758+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:39:30.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:39:30.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:39:30.785+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:39:30.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:39:30.796+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:39:30.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:39:30.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T17:48:36.530+0000] {processor.py:157} INFO - Started process (PID=41904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:48:36.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:48:36.539+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:48:36.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:48:36.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:48:36.583+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:48:36.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:48:36.608+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:48:36.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:48:36.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-14T17:49:06.892+0000] {processor.py:157} INFO - Started process (PID=41914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:49:06.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:49:06.899+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:49:06.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:49:06.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:49:06.939+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:49:06.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:49:06.952+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:49:06.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:49:06.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-14T17:49:37.285+0000] {processor.py:157} INFO - Started process (PID=41924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:49:37.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:49:37.289+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:49:37.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:49:37.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:49:37.315+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:49:37.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:49:37.326+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:49:37.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:49:37.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-14T17:50:07.645+0000] {processor.py:157} INFO - Started process (PID=41934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:50:07.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:50:07.653+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:50:07.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:50:07.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:50:07.691+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:50:07.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:50:07.704+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:50:07.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:50:07.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-14T17:50:37.992+0000] {processor.py:157} INFO - Started process (PID=41944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:50:37.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T17:50:37.996+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:50:37.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:50:38.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T17:50:38.030+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:50:38.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T17:50:38.041+0000] {logging_mixin.py:151} INFO - [2024-08-14T17:50:38.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T17:50:38.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-14T18:06:53.642+0000] {processor.py:157} INFO - Started process (PID=41954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:06:53.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:06:53.649+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:06:53.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:06:53.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:06:53.687+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:06:53.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:06:53.705+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:06:53.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:06:53.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-14T18:23:08.932+0000] {processor.py:157} INFO - Started process (PID=41965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:23:08.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:23:08.937+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:23:08.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:23:08.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:23:09.010+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:23:09.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:23:09.044+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:23:09.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:23:09.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-14T18:23:39.416+0000] {processor.py:157} INFO - Started process (PID=41976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:23:39.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:23:39.420+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:23:39.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:23:39.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:23:39.454+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:23:39.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:23:39.468+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:23:39.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:23:39.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-14T18:24:09.809+0000] {processor.py:157} INFO - Started process (PID=41986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:24:09.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:24:09.813+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:24:09.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:24:09.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:24:09.847+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:24:09.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:24:09.862+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:24:09.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:24:09.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-14T18:24:40.292+0000] {processor.py:157} INFO - Started process (PID=41996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:24:40.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:24:40.296+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:24:40.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:24:40.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:24:40.329+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:24:40.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:24:40.339+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:24:40.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:24:40.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-14T18:25:10.690+0000] {processor.py:157} INFO - Started process (PID=42006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:25:10.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:25:10.699+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:25:10.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:25:10.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:25:10.729+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:25:10.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:25:10.741+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:25:10.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:25:10.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-14T18:28:36.397+0000] {processor.py:157} INFO - Started process (PID=42017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:28:36.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:28:36.417+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:28:36.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:28:36.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:28:36.497+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:28:36.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:28:36.528+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:28:36.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:28:36.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-14T18:30:00.933+0000] {processor.py:157} INFO - Started process (PID=42028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:30:00.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:30:00.938+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:30:00.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:30:00.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:30:00.988+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:30:00.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:30:01.004+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:30:01.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:30:01.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-14T18:30:31.382+0000] {processor.py:157} INFO - Started process (PID=42038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:30:31.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:30:31.389+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:30:31.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:30:31.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:30:31.427+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:30:31.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:30:31.440+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:30:31.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:30:31.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-14T18:31:01.776+0000] {processor.py:157} INFO - Started process (PID=42048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:31:01.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:31:01.780+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:31:01.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:31:01.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:31:01.808+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:31:01.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:31:01.819+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:31:01.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:31:01.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-14T18:31:32.127+0000] {processor.py:157} INFO - Started process (PID=42058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:31:32.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:31:32.130+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:31:32.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:31:32.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:31:32.175+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:31:32.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:31:32.188+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:31:32.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:31:32.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-14T18:47:48.548+0000] {processor.py:157} INFO - Started process (PID=42068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:47:48.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:47:48.563+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:47:48.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:47:48.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:47:48.601+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:47:48.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:47:48.614+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:47:48.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:47:48.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-14T18:48:18.962+0000] {processor.py:157} INFO - Started process (PID=42080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:48:18.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T18:48:18.982+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:48:18.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:48:18.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T18:48:19.022+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:48:19.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T18:48:19.035+0000] {logging_mixin.py:151} INFO - [2024-08-14T18:48:19.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T18:48:19.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-14T19:03:57.646+0000] {processor.py:157} INFO - Started process (PID=42089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:03:57.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:03:57.657+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:03:57.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:03:57.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:03:57.713+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:03:57.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:03:57.733+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:03:57.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:03:57.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-14T19:04:28.010+0000] {processor.py:157} INFO - Started process (PID=42099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:04:28.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:04:28.037+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:04:28.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:04:28.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:04:28.108+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:04:28.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:04:28.127+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:04:28.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:04:28.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-14T19:04:58.466+0000] {processor.py:157} INFO - Started process (PID=42110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:04:58.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:04:58.474+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:04:58.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:04:58.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:04:58.527+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:04:58.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:04:58.542+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:04:58.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:04:58.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-14T19:05:28.835+0000] {processor.py:157} INFO - Started process (PID=42120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:05:28.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:05:28.840+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:05:28.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:05:28.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:05:28.864+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:05:28.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:05:28.873+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:05:28.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:05:28.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T19:05:59.249+0000] {processor.py:157} INFO - Started process (PID=42130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:05:59.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:05:59.252+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:05:59.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:05:59.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:05:59.278+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:05:59.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:05:59.288+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:05:59.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:05:59.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-14T19:06:29.688+0000] {processor.py:157} INFO - Started process (PID=42140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:06:29.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:06:29.693+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:06:29.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:06:29.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:06:29.736+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:06:29.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:06:29.752+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:06:29.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:06:29.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-14T19:23:15.258+0000] {processor.py:157} INFO - Started process (PID=42150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:23:15.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:23:15.264+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:23:15.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:23:15.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:23:15.284+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:23:15.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:23:15.294+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:23:15.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:23:15.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-14T19:23:45.721+0000] {processor.py:157} INFO - Started process (PID=42159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:23:45.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:23:45.725+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:23:45.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:23:45.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:23:45.768+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:23:45.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:23:45.786+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:23:45.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:23:45.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-14T19:24:16.123+0000] {processor.py:157} INFO - Started process (PID=42170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:24:16.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:24:16.130+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:24:16.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:24:16.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:24:16.149+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:24:16.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:24:16.158+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:24:16.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:24:16.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-14T19:24:46.565+0000] {processor.py:157} INFO - Started process (PID=42180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:24:46.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:24:46.569+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:24:46.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:24:46.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:24:46.601+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:24:46.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:24:46.613+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:24:46.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:24:46.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-14T19:25:17.036+0000] {processor.py:157} INFO - Started process (PID=42190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:25:17.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:25:17.039+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:25:17.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:25:17.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:25:17.071+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:25:17.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:25:17.082+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:25:17.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:25:17.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-14T19:33:13.653+0000] {processor.py:157} INFO - Started process (PID=42201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:33:13.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:33:13.659+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:33:13.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:33:13.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:33:13.697+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:33:13.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:33:13.711+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:33:13.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:33:13.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-14T19:33:44.069+0000] {processor.py:157} INFO - Started process (PID=42211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:33:44.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:33:44.076+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:33:44.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:33:44.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:33:44.131+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:33:44.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:33:44.156+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:33:44.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:33:44.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-14T19:34:14.431+0000] {processor.py:157} INFO - Started process (PID=42222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:34:14.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:34:14.433+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:34:14.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:34:14.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:34:14.457+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:34:14.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:34:14.471+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:34:14.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:34:14.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T19:34:44.790+0000] {processor.py:157} INFO - Started process (PID=42232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:34:44.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:34:44.792+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:34:44.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:34:44.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:34:44.829+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:34:44.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:34:44.842+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:34:44.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:34:44.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-14T19:35:15.143+0000] {processor.py:157} INFO - Started process (PID=42242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:35:15.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:35:15.151+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:35:15.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:35:15.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:35:15.176+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:35:15.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:35:15.185+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:35:15.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:35:15.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T19:42:53.233+0000] {processor.py:157} INFO - Started process (PID=42252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:42:53.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:42:53.239+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:42:53.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:42:53.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:42:53.293+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:42:53.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:42:53.307+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:42:53.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:42:53.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-14T19:43:23.615+0000] {processor.py:157} INFO - Started process (PID=42264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:43:23.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:43:23.622+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:43:23.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:43:23.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:43:23.662+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:43:23.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:43:23.675+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:43:23.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:43:23.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-14T19:43:53.960+0000] {processor.py:157} INFO - Started process (PID=42274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:43:53.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:43:53.964+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:43:53.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:43:53.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:43:53.992+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:43:53.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:43:54.005+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:43:54.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:43:54.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-14T19:44:24.277+0000] {processor.py:157} INFO - Started process (PID=42284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:44:24.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:44:24.280+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:44:24.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:44:24.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:44:24.306+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:44:24.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:44:24.320+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:44:24.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:44:24.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-14T19:44:54.625+0000] {processor.py:157} INFO - Started process (PID=42294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:44:54.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:44:54.628+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:44:54.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:44:54.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:44:54.652+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:44:54.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:44:54.662+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:44:54.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:44:54.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-14T19:45:24.978+0000] {processor.py:157} INFO - Started process (PID=42304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:45:24.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:45:24.983+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:45:24.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:45:24.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:45:25.017+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:45:25.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:45:25.027+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:45:25.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:45:25.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-14T19:45:55.311+0000] {processor.py:157} INFO - Started process (PID=42314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:45:55.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:45:55.315+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:45:55.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:45:55.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:45:55.351+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:45:55.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:45:55.366+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:45:55.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:45:55.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-14T19:46:25.602+0000] {processor.py:157} INFO - Started process (PID=42324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:46:25.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:46:25.605+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:46:25.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:46:25.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:46:25.636+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:46:25.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:46:25.647+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:46:25.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:46:25.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T19:47:22.407+0000] {processor.py:157} INFO - Started process (PID=42334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:47:22.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:47:22.409+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:47:22.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:47:22.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:47:22.432+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:47:22.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:47:22.440+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:47:22.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:47:22.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-14T19:47:52.724+0000] {processor.py:157} INFO - Started process (PID=42344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:47:52.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:47:52.726+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:47:52.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:47:52.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:47:52.750+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:47:52.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:47:52.761+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:47:52.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:47:52.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-14T19:48:23.069+0000] {processor.py:157} INFO - Started process (PID=42354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:48:23.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:48:23.070+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:48:23.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:48:23.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:48:23.093+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:48:23.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:48:23.102+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:48:23.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:48:23.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-14T19:48:53.442+0000] {processor.py:157} INFO - Started process (PID=42364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:48:53.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:48:53.448+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:48:53.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:48:53.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:48:53.486+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:48:53.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:48:53.498+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:48:53.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:48:53.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-14T19:49:23.811+0000] {processor.py:157} INFO - Started process (PID=42374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:49:23.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:49:23.814+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:49:23.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:49:23.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:49:23.845+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:49:23.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:49:23.858+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:49:23.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:49:23.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-14T19:59:06.361+0000] {processor.py:157} INFO - Started process (PID=42386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:59:06.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:59:06.366+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:59:06.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:59:06.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:59:06.410+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:59:06.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:59:06.430+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:59:06.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:59:06.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-14T19:59:36.740+0000] {processor.py:157} INFO - Started process (PID=42396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:59:36.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T19:59:36.743+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:59:36.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:59:36.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T19:59:36.781+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:59:36.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T19:59:36.794+0000] {logging_mixin.py:151} INFO - [2024-08-14T19:59:36.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T19:59:36.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-14T20:00:07.008+0000] {processor.py:157} INFO - Started process (PID=42406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:00:07.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:00:07.009+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:00:07.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:00:07.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:00:07.032+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:00:07.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:00:07.045+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:00:07.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:00:07.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-14T20:00:37.347+0000] {processor.py:157} INFO - Started process (PID=42416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:00:37.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:00:37.351+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:00:37.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:00:37.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:00:37.381+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:00:37.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:00:37.392+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:00:37.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:00:37.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-14T20:01:07.704+0000] {processor.py:157} INFO - Started process (PID=42426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:01:07.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:01:07.707+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:01:07.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:01:07.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:01:07.734+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:01:07.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:01:07.747+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:01:07.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:01:07.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T20:01:38.076+0000] {processor.py:157} INFO - Started process (PID=42436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:01:38.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:01:38.081+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:01:38.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:01:38.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:01:38.122+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:01:38.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:01:38.139+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:01:38.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:01:38.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-14T20:02:08.345+0000] {processor.py:157} INFO - Started process (PID=42446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:02:08.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:02:08.348+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:02:08.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:02:08.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:02:08.374+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:02:08.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:02:08.384+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:02:08.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:02:08.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-14T20:02:38.676+0000] {processor.py:157} INFO - Started process (PID=42456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:02:38.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:02:38.680+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:02:38.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:02:38.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:02:38.709+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:02:38.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:02:38.720+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:02:38.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:02:38.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-14T20:03:09.018+0000] {processor.py:157} INFO - Started process (PID=42466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:03:09.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:03:09.021+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:03:09.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:03:09.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:03:09.071+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:03:09.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:03:09.085+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:03:09.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:03:09.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-14T20:14:52.910+0000] {processor.py:157} INFO - Started process (PID=42476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:14:52.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:14:52.923+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:14:52.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:14:52.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:14:52.966+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:14:52.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:14:52.982+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:14:52.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:14:52.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-14T20:15:23.162+0000] {processor.py:157} INFO - Started process (PID=42486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:15:23.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:15:23.167+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:15:23.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:15:23.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:15:23.199+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:15:23.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:15:23.211+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:15:23.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:15:23.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-14T20:22:07.368+0000] {processor.py:157} INFO - Started process (PID=42498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:22:07.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:22:07.371+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:22:07.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:22:07.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:22:07.401+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:22:07.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:22:07.412+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:22:07.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:22:07.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-14T20:25:41.263+0000] {processor.py:157} INFO - Started process (PID=42507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:25:41.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:25:41.270+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:25:41.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:25:41.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:25:41.337+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:25:41.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:25:41.384+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:25:41.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:25:41.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-14T20:26:11.594+0000] {processor.py:157} INFO - Started process (PID=42518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:26:11.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:26:11.596+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:26:11.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:26:11.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:26:11.634+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:26:11.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:26:11.648+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:26:11.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:26:11.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-14T20:30:57.166+0000] {processor.py:157} INFO - Started process (PID=42528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:30:57.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:30:57.169+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:30:57.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:30:57.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:30:57.201+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:30:57.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:30:57.215+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:30:57.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:30:57.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-14T20:37:00.707+0000] {processor.py:157} INFO - Started process (PID=42539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:37:00.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:37:00.713+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:37:00.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:37:00.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:37:00.782+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:37:00.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:37:00.817+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:37:00.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:37:00.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-14T20:37:31.026+0000] {processor.py:157} INFO - Started process (PID=42550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:37:31.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T20:37:31.032+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:37:31.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:37:31.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T20:37:31.076+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:37:31.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T20:37:31.093+0000] {logging_mixin.py:151} INFO - [2024-08-14T20:37:31.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T20:37:31.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-14T21:43:46.548+0000] {processor.py:157} INFO - Started process (PID=42560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T21:43:46.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T21:43:46.553+0000] {logging_mixin.py:151} INFO - [2024-08-14T21:43:46.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T21:43:46.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T21:43:46.626+0000] {logging_mixin.py:151} INFO - [2024-08-14T21:43:46.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T21:43:46.658+0000] {logging_mixin.py:151} INFO - [2024-08-14T21:43:46.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T21:43:46.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-14T21:44:16.816+0000] {processor.py:157} INFO - Started process (PID=42570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T21:44:16.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T21:44:16.822+0000] {logging_mixin.py:151} INFO - [2024-08-14T21:44:16.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T21:44:16.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T21:44:16.864+0000] {logging_mixin.py:151} INFO - [2024-08-14T21:44:16.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T21:44:16.878+0000] {logging_mixin.py:151} INFO - [2024-08-14T21:44:16.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T21:44:16.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-14T22:19:39.424+0000] {processor.py:157} INFO - Started process (PID=42582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:19:39.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:19:39.438+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:19:39.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:19:39.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:19:39.510+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:19:39.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:19:39.539+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:19:39.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:19:39.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-14T22:20:09.760+0000] {processor.py:157} INFO - Started process (PID=42592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:20:09.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:20:09.765+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:20:09.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:20:09.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:20:09.808+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:20:09.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:20:09.822+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:20:09.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:20:09.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-14T22:20:39.898+0000] {processor.py:157} INFO - Started process (PID=42602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:20:39.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:20:39.901+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:20:39.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:20:39.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:20:39.942+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:20:39.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:20:39.955+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:20:39.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:20:39.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-14T22:21:10.264+0000] {processor.py:157} INFO - Started process (PID=42612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:21:10.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:21:10.269+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:21:10.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:21:10.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:21:10.307+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:21:10.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:21:10.320+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:21:10.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:21:10.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-14T22:21:40.596+0000] {processor.py:157} INFO - Started process (PID=42622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:21:40.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:21:40.599+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:21:40.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:21:40.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:21:40.634+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:21:40.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:21:40.647+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:21:40.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:21:40.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-14T22:22:10.948+0000] {processor.py:157} INFO - Started process (PID=42632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:22:10.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:22:10.953+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:22:10.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:22:10.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:22:10.994+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:22:10.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:22:11.009+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:22:11.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:22:11.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-14T22:22:41.296+0000] {processor.py:157} INFO - Started process (PID=42642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:22:41.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:22:41.303+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:22:41.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:22:41.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:22:41.365+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:22:41.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:22:41.391+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:22:41.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:22:41.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-14T22:23:11.644+0000] {processor.py:157} INFO - Started process (PID=42652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:23:11.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:23:11.656+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:23:11.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:23:11.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:23:11.740+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:23:11.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:23:11.763+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:23:11.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:23:11.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-14T22:23:41.861+0000] {processor.py:157} INFO - Started process (PID=42662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:23:41.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:23:41.863+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:23:41.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:23:41.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:23:41.885+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:23:41.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:23:41.895+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:23:41.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:23:41.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-14T22:24:12.156+0000] {processor.py:157} INFO - Started process (PID=42672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:24:12.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:24:12.158+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:24:12.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:24:12.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:24:12.179+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:24:12.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:24:12.188+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:24:12.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:24:12.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-08-14T22:24:42.532+0000] {processor.py:157} INFO - Started process (PID=42682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:24:42.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:24:42.536+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:24:42.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:24:42.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:24:42.573+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:24:42.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:24:42.587+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:24:42.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:24:42.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-14T22:25:12.871+0000] {processor.py:157} INFO - Started process (PID=42692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:25:12.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:25:12.873+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:25:12.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:25:12.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:25:12.896+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:25:12.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:25:12.907+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:25:12.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:25:12.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-14T22:25:43.223+0000] {processor.py:157} INFO - Started process (PID=42702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:25:43.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:25:43.226+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:25:43.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:25:43.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:25:43.271+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:25:43.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:25:43.286+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:25:43.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:25:43.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-14T22:26:13.627+0000] {processor.py:157} INFO - Started process (PID=42711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:26:13.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:26:13.630+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:26:13.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:26:13.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:26:13.656+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:26:13.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:26:13.667+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:26:13.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:26:13.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-14T22:26:43.957+0000] {processor.py:157} INFO - Started process (PID=42722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:26:43.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:26:43.959+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:26:43.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:26:43.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:26:43.980+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:26:43.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:26:43.989+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:26:43.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:26:43.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-08-14T22:27:14.297+0000] {processor.py:157} INFO - Started process (PID=42732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:27:14.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:27:14.298+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:27:14.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:27:14.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:27:14.321+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:27:14.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:27:14.330+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:27:14.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:27:14.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-14T22:27:44.641+0000] {processor.py:157} INFO - Started process (PID=42742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:27:44.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:27:44.643+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:27:44.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:27:44.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:27:44.667+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:27:44.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:27:44.676+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:27:44.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:27:44.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-14T22:28:15.002+0000] {processor.py:157} INFO - Started process (PID=42751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:28:15.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:28:15.006+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:28:15.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:28:15.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:28:15.047+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:28:15.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:28:15.062+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:28:15.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:28:15.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-14T22:28:45.339+0000] {processor.py:157} INFO - Started process (PID=42762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:28:45.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:28:45.341+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:28:45.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:28:45.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:28:45.364+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:28:45.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:28:45.376+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:28:45.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:28:45.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-14T22:29:15.668+0000] {processor.py:157} INFO - Started process (PID=42772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:29:15.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:29:15.671+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:29:15.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:29:15.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:29:15.698+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:29:15.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:29:15.709+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:29:15.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:29:15.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T22:29:46.007+0000] {processor.py:157} INFO - Started process (PID=42782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:29:46.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:29:46.010+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:29:46.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:29:46.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:29:46.043+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:29:46.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:29:46.059+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:29:46.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:29:46.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-14T22:30:16.323+0000] {processor.py:157} INFO - Started process (PID=42792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:30:16.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:30:16.325+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:30:16.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:30:16.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:30:16.347+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:30:16.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:30:16.356+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:30:16.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:30:16.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-14T22:30:46.633+0000] {processor.py:157} INFO - Started process (PID=42802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:30:46.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:30:46.636+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:30:46.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:30:46.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:30:46.657+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:30:46.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:30:46.667+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:30:46.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:30:46.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-14T22:31:16.993+0000] {processor.py:157} INFO - Started process (PID=42812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:31:16.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:31:16.999+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:31:16.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:31:17.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:31:17.055+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:31:17.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:31:17.076+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:31:17.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:31:17.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-14T22:31:47.241+0000] {processor.py:157} INFO - Started process (PID=42822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:31:47.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:31:47.244+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:31:47.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:31:47.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:31:47.268+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:31:47.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:31:47.278+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:31:47.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:31:47.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-14T22:32:17.571+0000] {processor.py:157} INFO - Started process (PID=42832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:32:17.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:32:17.575+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:32:17.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:32:17.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:32:17.607+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:32:17.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:32:17.619+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:32:17.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:32:17.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-14T22:32:47.936+0000] {processor.py:157} INFO - Started process (PID=42842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:32:47.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:32:47.942+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:32:47.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:32:47.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:32:47.997+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:32:47.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:32:48.013+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:32:48.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:32:48.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-14T22:33:18.326+0000] {processor.py:157} INFO - Started process (PID=42852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:33:18.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:33:18.330+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:33:18.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:33:18.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:33:18.388+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:33:18.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:33:18.408+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:33:18.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:33:18.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-14T22:33:48.737+0000] {processor.py:157} INFO - Started process (PID=42861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:33:48.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:33:48.739+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:33:48.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:33:48.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:33:48.760+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:33:48.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:33:48.769+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:33:48.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:33:48.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-14T22:34:19.095+0000] {processor.py:157} INFO - Started process (PID=42872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:34:19.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:34:19.100+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:34:19.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:34:19.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:34:19.138+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:34:19.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:34:19.152+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:34:19.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:34:19.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-14T22:34:49.374+0000] {processor.py:157} INFO - Started process (PID=42882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:34:49.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:34:49.376+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:34:49.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:34:49.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:34:49.401+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:34:49.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:34:49.412+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:34:49.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:34:49.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-14T22:35:19.709+0000] {processor.py:157} INFO - Started process (PID=42892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:35:19.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:35:19.710+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:35:19.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:35:19.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:35:19.734+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:35:19.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:35:19.743+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:35:19.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:35:19.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-14T22:52:18.260+0000] {processor.py:157} INFO - Started process (PID=42902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:52:18.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:52:18.267+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:52:18.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:52:18.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:52:18.338+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:52:18.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:52:18.360+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:52:18.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:52:18.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-14T22:52:48.701+0000] {processor.py:157} INFO - Started process (PID=42913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:52:48.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:52:48.705+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:52:48.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:52:48.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:52:48.734+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:52:48.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:52:48.744+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:52:48.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:52:48.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-14T22:53:19.040+0000] {processor.py:157} INFO - Started process (PID=42923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:53:19.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:53:19.043+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:53:19.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:53:19.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:53:19.068+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:53:19.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:53:19.078+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:53:19.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:53:19.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-14T22:53:49.469+0000] {processor.py:157} INFO - Started process (PID=42933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:53:49.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T22:53:49.472+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:53:49.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:53:49.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T22:53:49.505+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:53:49.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T22:53:49.517+0000] {logging_mixin.py:151} INFO - [2024-08-14T22:53:49.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T22:53:49.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-14T23:11:00.558+0000] {processor.py:157} INFO - Started process (PID=42943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:11:00.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:11:00.573+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:11:00.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:11:00.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:11:00.686+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:11:00.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:11:00.714+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:11:00.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:11:00.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-08-14T23:11:31.107+0000] {processor.py:157} INFO - Started process (PID=42954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:11:31.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:11:31.112+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:11:31.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:11:31.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:11:31.148+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:11:31.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:11:31.164+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:11:31.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:11:31.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-14T23:28:26.643+0000] {processor.py:157} INFO - Started process (PID=42967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:28:26.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:28:26.646+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:28:26.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:28:26.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:28:26.672+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:28:26.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:28:26.682+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:28:26.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:28:26.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-14T23:28:57.085+0000] {processor.py:157} INFO - Started process (PID=42976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:28:57.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:28:57.090+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:28:57.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:28:57.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:28:57.127+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:28:57.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:28:57.139+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:28:57.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:28:57.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-14T23:29:27.417+0000] {processor.py:157} INFO - Started process (PID=42987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:29:27.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:29:27.420+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:29:27.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:29:27.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:29:27.449+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:29:27.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:29:27.461+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:29:27.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:29:27.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-14T23:29:57.729+0000] {processor.py:157} INFO - Started process (PID=42997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:29:57.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:29:57.733+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:29:57.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:29:57.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:29:57.766+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:29:57.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:29:57.780+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:29:57.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:29:57.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-14T23:30:28.053+0000] {processor.py:157} INFO - Started process (PID=43007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:30:28.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:30:28.057+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:30:28.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:30:28.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:30:28.081+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:30:28.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:30:28.092+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:30:28.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:30:28.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-14T23:30:58.340+0000] {processor.py:157} INFO - Started process (PID=43017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:30:58.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:30:58.344+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:30:58.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:30:58.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:30:58.365+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:30:58.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:30:58.374+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:30:58.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:30:58.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-14T23:47:19.100+0000] {processor.py:157} INFO - Started process (PID=43026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:47:19.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-14T23:47:19.115+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:47:19.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:47:19.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-14T23:47:19.183+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:47:19.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-14T23:47:19.236+0000] {logging_mixin.py:151} INFO - [2024-08-14T23:47:19.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-14T23:47:19.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
