[2024-07-14T00:54:24.527+0000] {processor.py:157} INFO - Started process (PID=24987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T00:54:24.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T00:54:24.533+0000] {logging_mixin.py:151} INFO - [2024-07-14T00:54:24.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T00:54:24.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T00:54:24.574+0000] {logging_mixin.py:151} INFO - [2024-07-14T00:54:24.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T00:54:24.590+0000] {logging_mixin.py:151} INFO - [2024-07-14T00:54:24.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-14T00:54:24.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-14T01:05:46.536+0000] {processor.py:157} INFO - Started process (PID=25013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:05:46.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T01:05:46.546+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:05:46.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:05:46.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:05:46.597+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:05:46.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T01:05:46.628+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:05:46.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T01:05:46.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-14T01:27:58.067+0000] {processor.py:157} INFO - Started process (PID=25426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:27:58.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T01:27:58.073+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:27:58.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:27:58.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:27:58.120+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:27:58.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T01:27:58.137+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:27:58.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T01:27:58.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-14T01:28:28.525+0000] {processor.py:157} INFO - Started process (PID=25451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:28:28.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T01:28:28.529+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:28:28.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:28:28.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:28:28.555+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:28:28.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T01:28:28.565+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:28:28.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T01:28:28.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T01:29:00.759+0000] {processor.py:157} INFO - Started process (PID=25476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:29:00.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T01:29:00.764+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:29:00.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:29:00.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:29:00.800+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:29:00.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T01:29:00.814+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:29:00.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T01:29:00.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-14T01:43:32.322+0000] {processor.py:157} INFO - Started process (PID=25503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:43:32.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T01:43:32.327+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:43:32.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:43:32.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:43:32.382+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:43:32.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T01:43:32.401+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:43:32.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T01:43:32.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-14T01:44:02.785+0000] {processor.py:157} INFO - Started process (PID=25528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:44:02.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T01:44:02.789+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:44:02.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:44:02.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:44:02.819+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:44:02.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T01:44:02.830+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:44:02.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T01:44:02.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T01:59:48.376+0000] {processor.py:157} INFO - Started process (PID=25553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:59:48.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T01:59:48.383+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:59:48.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:59:48.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T01:59:48.436+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:59:48.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T01:59:48.459+0000] {logging_mixin.py:151} INFO - [2024-07-14T01:59:48.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T01:59:48.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-14T02:00:18.950+0000] {processor.py:157} INFO - Started process (PID=25578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:00:18.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T02:00:18.952+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:00:18.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:00:18.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:00:18.977+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:00:18.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T02:00:18.991+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:00:18.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T02:00:19.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T02:01:54.699+0000] {processor.py:157} INFO - Started process (PID=25605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:01:54.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T02:01:54.701+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:01:54.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:01:54.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:01:54.736+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:01:54.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T02:01:54.748+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:01:54.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T02:01:54.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-14T02:28:57.399+0000] {processor.py:157} INFO - Started process (PID=25630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:28:57.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T02:28:57.408+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:28:57.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:28:57.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:28:57.466+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:28:57.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T02:28:57.490+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:28:57.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T02:28:57.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-14T02:29:28.053+0000] {processor.py:157} INFO - Started process (PID=25655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:29:28.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T02:29:28.058+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:29:28.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:29:28.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:29:28.090+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:29:28.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T02:29:28.100+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:29:28.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T02:29:28.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-14T02:41:04.891+0000] {processor.py:157} INFO - Started process (PID=25680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:41:04.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T02:41:04.897+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:41:04.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:41:04.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:41:04.937+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:41:04.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T02:41:04.956+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:41:04.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T02:41:04.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-14T02:57:08.922+0000] {processor.py:157} INFO - Started process (PID=25705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:57:08.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T02:57:08.926+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:57:08.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:57:08.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T02:57:08.971+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:57:08.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T02:57:08.996+0000] {logging_mixin.py:151} INFO - [2024-07-14T02:57:08.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T02:57:09.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-14T03:06:42.148+0000] {processor.py:157} INFO - Started process (PID=25732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:06:42.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T03:06:42.155+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:06:42.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:06:42.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:06:42.229+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:06:42.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T03:06:42.243+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:06:42.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T03:06:42.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-14T03:07:36.578+0000] {processor.py:157} INFO - Started process (PID=25757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:07:36.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T03:07:36.584+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:07:36.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:07:36.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:07:36.625+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:07:36.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T03:07:36.639+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:07:36.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T03:07:36.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-14T03:08:07.019+0000] {processor.py:157} INFO - Started process (PID=25782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:08:07.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T03:08:07.021+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:08:07.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:08:07.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:08:07.049+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:08:07.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T03:08:07.060+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:08:07.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T03:08:07.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T03:30:09.198+0000] {processor.py:157} INFO - Started process (PID=25807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:30:09.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T03:30:09.205+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:30:09.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:30:09.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:30:09.259+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:30:09.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T03:30:09.284+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:30:09.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T03:30:09.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-14T03:30:39.692+0000] {processor.py:157} INFO - Started process (PID=25832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:30:39.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T03:30:39.694+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:30:39.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:30:39.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T03:30:39.720+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:30:39.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T03:30:39.731+0000] {logging_mixin.py:151} INFO - [2024-07-14T03:30:39.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T03:30:39.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T04:31:06.166+0000] {processor.py:157} INFO - Started process (PID=25858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:31:06.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T04:31:06.173+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:31:06.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:31:06.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:31:06.221+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:31:06.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T04:31:06.244+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:31:06.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T04:31:06.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-14T04:31:36.711+0000] {processor.py:157} INFO - Started process (PID=25883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:31:36.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T04:31:36.714+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:31:36.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:31:36.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:31:36.741+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:31:36.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T04:31:36.757+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:31:36.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T04:31:36.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T04:36:44.450+0000] {processor.py:157} INFO - Started process (PID=25908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:36:44.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T04:36:44.452+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:36:44.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:36:44.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T04:36:44.478+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:36:44.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T04:36:44.488+0000] {logging_mixin.py:151} INFO - [2024-07-14T04:36:44.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T04:36:44.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T05:11:24.293+0000] {processor.py:157} INFO - Started process (PID=25933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T05:11:24.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T05:11:24.298+0000] {logging_mixin.py:151} INFO - [2024-07-14T05:11:24.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T05:11:24.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T05:11:24.332+0000] {logging_mixin.py:151} INFO - [2024-07-14T05:11:24.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T05:11:24.343+0000] {logging_mixin.py:151} INFO - [2024-07-14T05:11:24.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T05:11:24.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-14T05:32:16.244+0000] {processor.py:157} INFO - Started process (PID=25960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T05:32:16.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T05:32:16.248+0000] {logging_mixin.py:151} INFO - [2024-07-14T05:32:16.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T05:32:16.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T05:32:16.282+0000] {logging_mixin.py:151} INFO - [2024-07-14T05:32:16.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T05:32:16.292+0000] {logging_mixin.py:151} INFO - [2024-07-14T05:32:16.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T05:32:16.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T06:05:17.362+0000] {processor.py:157} INFO - Started process (PID=25985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:05:17.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:05:17.366+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:05:17.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:05:17.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:05:17.404+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:05:17.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:05:17.419+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:05:17.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:05:17.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-14T06:10:45.336+0000] {processor.py:157} INFO - Started process (PID=26010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:10:45.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:10:45.345+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:10:45.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:10:45.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:10:45.388+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:10:45.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:10:45.403+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:10:45.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:10:45.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-14T06:20:36.926+0000] {processor.py:157} INFO - Started process (PID=26035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:20:36.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:20:36.931+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:20:36.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:20:36.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:20:36.968+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:20:36.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:20:36.985+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:20:36.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:20:37.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-14T06:21:07.331+0000] {processor.py:157} INFO - Started process (PID=26060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:21:07.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:21:07.335+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:21:07.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:21:07.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:21:07.369+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:21:07.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:21:07.381+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:21:07.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:21:07.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-14T06:27:34.378+0000] {processor.py:157} INFO - Started process (PID=26085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:27:34.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:27:34.380+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:27:34.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:27:34.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:27:34.406+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:27:34.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:27:34.418+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:27:34.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:27:34.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T06:32:57.389+0000] {processor.py:157} INFO - Started process (PID=26112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:32:57.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:32:57.394+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:32:57.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:32:57.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:32:57.435+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:32:57.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:32:57.456+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:32:57.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:32:57.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-14T06:33:27.807+0000] {processor.py:157} INFO - Started process (PID=26137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:33:27.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:33:27.809+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:33:27.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:33:27.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:33:27.836+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:33:27.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:33:27.848+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:33:27.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:33:27.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T06:43:22.449+0000] {processor.py:157} INFO - Started process (PID=26162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:43:22.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T06:43:22.453+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:43:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:43:22.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T06:43:22.475+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:43:22.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T06:43:22.488+0000] {logging_mixin.py:151} INFO - [2024-07-14T06:43:22.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T06:43:22.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T07:01:22.021+0000] {processor.py:157} INFO - Started process (PID=26187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:01:22.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:01:22.023+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:01:22.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:01:22.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:01:22.053+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:01:22.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:01:22.069+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:01:22.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:01:22.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T07:34:13.470+0000] {processor.py:157} INFO - Started process (PID=26214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:34:13.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:34:13.476+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:34:13.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:34:13.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:34:13.522+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:34:13.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:34:13.546+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:34:13.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:34:13.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-14T07:34:44.030+0000] {processor.py:157} INFO - Started process (PID=26239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:34:44.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:34:44.032+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:34:44.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:34:44.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:34:44.056+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:34:44.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:34:44.073+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:34:44.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:34:44.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T07:48:28.150+0000] {processor.py:157} INFO - Started process (PID=26264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:48:28.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:48:28.157+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:48:28.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:48:28.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:48:28.212+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:48:28.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:48:28.229+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:48:28.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:48:28.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-14T07:48:58.741+0000] {processor.py:157} INFO - Started process (PID=26289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:48:58.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:48:58.751+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:48:58.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:48:58.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:48:58.815+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:48:58.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:48:58.836+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:48:58.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:48:58.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-14T07:49:29.305+0000] {processor.py:157} INFO - Started process (PID=26314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:49:29.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:49:29.307+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:49:29.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:49:29.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:49:29.328+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:49:29.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:49:29.342+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:49:29.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:49:29.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T07:49:59.788+0000] {processor.py:157} INFO - Started process (PID=26339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:49:59.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:49:59.792+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:49:59.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:49:59.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:49:59.818+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:49:59.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:49:59.829+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:49:59.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:49:59.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T07:50:30.223+0000] {processor.py:157} INFO - Started process (PID=26364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:50:30.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:50:30.226+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:50:30.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:50:30.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:50:30.254+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:50:30.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:50:30.265+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:50:30.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:50:30.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T07:51:00.624+0000] {processor.py:157} INFO - Started process (PID=26389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:51:00.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:51:00.627+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:51:00.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:51:00.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:51:00.661+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:51:00.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:51:00.674+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:51:00.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:51:00.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-14T07:51:31.088+0000] {processor.py:157} INFO - Started process (PID=26414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:51:31.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:51:31.091+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:51:31.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:51:31.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:51:31.122+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:51:31.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:51:31.132+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:51:31.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:51:31.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T07:52:01.505+0000] {processor.py:157} INFO - Started process (PID=26439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:52:01.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:52:01.509+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:52:01.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:52:01.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:52:01.534+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:52:01.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:52:01.546+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:52:01.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:52:01.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T07:52:31.977+0000] {processor.py:157} INFO - Started process (PID=26464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:52:31.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:52:31.984+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:52:31.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:52:32.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:52:32.029+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:52:32.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:52:32.045+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:52:32.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:52:32.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-14T07:53:02.506+0000] {processor.py:157} INFO - Started process (PID=26489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:53:02.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:53:02.508+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:53:02.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:53:02.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:53:02.540+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:53:02.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:53:02.551+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:53:02.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:53:02.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T07:53:32.985+0000] {processor.py:157} INFO - Started process (PID=26514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:53:32.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:53:32.989+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:53:32.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:53:33.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:53:33.021+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:53:33.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:53:33.033+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:53:33.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:53:33.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-14T07:54:03.361+0000] {processor.py:157} INFO - Started process (PID=26539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:54:03.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:54:03.365+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:54:03.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:54:03.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:54:03.394+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:54:03.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:54:03.405+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:54:03.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:54:03.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T07:54:33.852+0000] {processor.py:157} INFO - Started process (PID=26564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:54:33.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:54:33.856+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:54:33.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:54:33.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:54:33.884+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:54:33.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:54:33.894+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:54:33.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:54:33.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T07:55:04.359+0000] {processor.py:157} INFO - Started process (PID=26589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:55:04.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:55:04.361+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:55:04.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:55:04.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:55:04.388+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:55:04.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:55:04.399+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:55:04.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:55:04.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T07:55:34.815+0000] {processor.py:157} INFO - Started process (PID=26614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:55:34.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:55:34.819+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:55:34.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:55:34.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:55:34.848+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:55:34.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:55:34.858+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:55:34.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:55:34.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T07:56:05.220+0000] {processor.py:157} INFO - Started process (PID=26639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:56:05.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:56:05.223+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:56:05.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:56:05.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:56:05.250+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:56:05.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:56:05.260+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:56:05.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:56:05.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T07:56:35.632+0000] {processor.py:157} INFO - Started process (PID=26664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:56:35.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:56:35.635+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:56:35.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:56:35.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:56:35.658+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:56:35.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:56:35.671+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:56:35.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:56:35.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T07:57:06.055+0000] {processor.py:157} INFO - Started process (PID=26689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:57:06.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:57:06.058+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:57:06.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:57:06.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:57:06.084+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:57:06.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:57:06.094+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:57:06.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:57:06.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T07:57:36.507+0000] {processor.py:157} INFO - Started process (PID=26714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:57:36.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:57:36.510+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:57:36.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:57:36.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:57:36.536+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:57:36.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:57:36.546+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:57:36.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:57:36.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T07:58:06.966+0000] {processor.py:157} INFO - Started process (PID=26739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:58:06.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:58:06.969+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:58:06.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:58:06.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:58:06.998+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:58:06.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:58:07.008+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:58:07.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:58:07.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T07:58:37.447+0000] {processor.py:157} INFO - Started process (PID=26764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:58:37.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:58:37.452+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:58:37.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:58:37.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:58:37.478+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:58:37.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:58:37.490+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:58:37.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:58:37.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T07:59:07.922+0000] {processor.py:157} INFO - Started process (PID=26789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:59:07.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:59:07.925+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:59:07.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:59:07.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:59:07.952+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:59:07.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:59:07.961+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:59:07.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:59:07.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T07:59:38.370+0000] {processor.py:157} INFO - Started process (PID=26814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:59:38.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T07:59:38.374+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:59:38.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:59:38.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T07:59:38.402+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:59:38.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T07:59:38.412+0000] {logging_mixin.py:151} INFO - [2024-07-14T07:59:38.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T07:59:38.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T08:00:08.882+0000] {processor.py:157} INFO - Started process (PID=26839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:00:08.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:00:08.887+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:00:08.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:00:08.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:00:08.926+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:00:08.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:00:08.939+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:00:08.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:00:08.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-14T08:00:39.422+0000] {processor.py:157} INFO - Started process (PID=26864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:00:39.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:00:39.425+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:00:39.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:00:39.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:00:39.454+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:00:39.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:00:39.467+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:00:39.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:00:39.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:01:09.862+0000] {processor.py:157} INFO - Started process (PID=26889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:01:09.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:01:09.868+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:01:09.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:01:09.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:01:09.899+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:01:09.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:01:09.909+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:01:09.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:01:09.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T08:01:40.361+0000] {processor.py:157} INFO - Started process (PID=26914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:01:40.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:01:40.364+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:01:40.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:01:40.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:01:40.391+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:01:40.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:01:40.402+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:01:40.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:01:40.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T08:02:10.771+0000] {processor.py:157} INFO - Started process (PID=26939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:02:10.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:02:10.773+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:02:10.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:02:10.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:02:10.802+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:02:10.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:02:10.812+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:02:10.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:02:10.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T08:02:41.220+0000] {processor.py:157} INFO - Started process (PID=26964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:02:41.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:02:41.225+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:02:41.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:02:41.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:02:41.249+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:02:41.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:02:41.259+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:02:41.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:02:41.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T08:03:11.638+0000] {processor.py:157} INFO - Started process (PID=26989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:03:11.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:03:11.640+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:03:11.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:03:11.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:03:11.666+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:03:11.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:03:11.685+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:03:11.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:03:11.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T08:03:42.068+0000] {processor.py:157} INFO - Started process (PID=27014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:03:42.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:03:42.071+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:03:42.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:03:42.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:03:42.100+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:03:42.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:03:42.111+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:03:42.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:03:42.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:04:12.476+0000] {processor.py:157} INFO - Started process (PID=27039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:04:12.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:04:12.480+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:04:12.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:04:12.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:04:12.509+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:04:12.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:04:12.519+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:04:12.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:04:12.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T08:04:42.899+0000] {processor.py:157} INFO - Started process (PID=27064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:04:42.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:04:42.904+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:04:42.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:04:42.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:04:42.929+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:04:42.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:04:42.939+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:04:42.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:04:42.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T08:05:13.314+0000] {processor.py:157} INFO - Started process (PID=27089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:05:13.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:05:13.319+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:05:13.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:05:13.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:05:13.348+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:05:13.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:05:13.358+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:05:13.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:05:13.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:05:43.712+0000] {processor.py:157} INFO - Started process (PID=27114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:05:43.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:05:43.715+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:05:43.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:05:43.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:05:43.741+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:05:43.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:05:43.752+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:05:43.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:05:43.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:06:14.115+0000] {processor.py:157} INFO - Started process (PID=27139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:06:14.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:06:14.119+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:06:14.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:06:14.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:06:14.142+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:06:14.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:06:14.153+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:06:14.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:06:14.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T08:06:44.518+0000] {processor.py:157} INFO - Started process (PID=27164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:06:44.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:06:44.521+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:06:44.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:06:44.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:06:44.548+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:06:44.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:06:44.558+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:06:44.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:06:44.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:07:15.040+0000] {processor.py:157} INFO - Started process (PID=27189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:07:15.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:07:15.043+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:07:15.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:07:15.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:07:15.067+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:07:15.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:07:15.080+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:07:15.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:07:15.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T08:07:45.467+0000] {processor.py:157} INFO - Started process (PID=27214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:07:45.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:07:45.472+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:07:45.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:07:45.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:07:45.497+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:07:45.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:07:45.509+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:07:45.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:07:45.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T08:08:15.951+0000] {processor.py:157} INFO - Started process (PID=27239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:08:15.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:08:15.954+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:08:15.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:08:15.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:08:15.980+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:08:15.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:08:15.990+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:08:15.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:08:16.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:08:46.443+0000] {processor.py:157} INFO - Started process (PID=27264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:08:46.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:08:46.447+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:08:46.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:08:46.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:08:46.475+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:08:46.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:08:46.491+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:08:46.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:08:46.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-14T08:09:16.977+0000] {processor.py:157} INFO - Started process (PID=27289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:09:16.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:09:16.981+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:09:16.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:09:16.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:09:17.004+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:09:17.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:09:17.015+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:09:17.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:09:17.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T08:09:47.406+0000] {processor.py:157} INFO - Started process (PID=27314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:09:47.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:09:47.408+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:09:47.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:09:47.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:09:47.436+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:09:47.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:09:47.447+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:09:47.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:09:47.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T08:10:17.891+0000] {processor.py:157} INFO - Started process (PID=27339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:10:17.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:10:17.895+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:10:17.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:10:17.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:10:17.925+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:10:17.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:10:17.937+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:10:17.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:10:17.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:10:48.318+0000] {processor.py:157} INFO - Started process (PID=27364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:10:48.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:10:48.320+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:10:48.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:10:48.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:10:48.342+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:10:48.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:10:48.354+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:10:48.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:10:48.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T08:11:18.782+0000] {processor.py:157} INFO - Started process (PID=27389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:11:18.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:11:18.784+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:11:18.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:11:18.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:11:18.810+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:11:18.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:11:18.825+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:11:18.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:11:18.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:11:49.247+0000] {processor.py:157} INFO - Started process (PID=27414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:11:49.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:11:49.251+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:11:49.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:11:49.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:11:49.275+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:11:49.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:11:49.286+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:11:49.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:11:49.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:12:19.788+0000] {processor.py:157} INFO - Started process (PID=27439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:12:19.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:12:19.792+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:12:19.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:12:19.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:12:19.821+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:12:19.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:12:19.831+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:12:19.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:12:19.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:12:50.304+0000] {processor.py:157} INFO - Started process (PID=27464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:12:50.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:12:50.308+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:12:50.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:12:50.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:12:50.332+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:12:50.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:12:50.345+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:12:50.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:12:50.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:13:20.777+0000] {processor.py:157} INFO - Started process (PID=27489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:13:20.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:13:20.780+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:13:20.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:13:20.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:13:20.802+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:13:20.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:13:20.814+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:13:20.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:13:20.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-14T08:13:51.198+0000] {processor.py:157} INFO - Started process (PID=27514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:13:51.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:13:51.202+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:13:51.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:13:51.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:13:51.232+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:13:51.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:13:51.245+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:13:51.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:13:51.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T08:14:21.629+0000] {processor.py:157} INFO - Started process (PID=27539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:14:21.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:14:21.633+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:14:21.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:14:21.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:14:21.661+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:14:21.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:14:21.672+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:14:21.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:14:21.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:14:52.175+0000] {processor.py:157} INFO - Started process (PID=27564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:14:52.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:14:52.178+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:14:52.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:14:52.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:14:52.207+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:14:52.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:14:52.217+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:14:52.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:14:52.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:15:22.614+0000] {processor.py:157} INFO - Started process (PID=27589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:15:22.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:15:22.619+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:15:22.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:15:22.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:15:22.650+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:15:22.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:15:22.660+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:15:22.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:15:22.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T08:15:53.130+0000] {processor.py:157} INFO - Started process (PID=27614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:15:53.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:15:53.134+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:15:53.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:15:53.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:15:53.166+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:15:53.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:15:53.175+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:15:53.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:15:53.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:16:23.530+0000] {processor.py:157} INFO - Started process (PID=27639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:16:23.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:16:23.537+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:16:23.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:16:23.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:16:23.571+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:16:23.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:16:23.583+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:16:23.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:16:23.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-14T08:16:54.017+0000] {processor.py:157} INFO - Started process (PID=27664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:16:54.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:16:54.019+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:16:54.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:16:54.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:16:54.047+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:16:54.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:16:54.057+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:16:54.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:16:54.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:17:24.526+0000] {processor.py:157} INFO - Started process (PID=27689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:17:24.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:17:24.531+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:17:24.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:17:24.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:17:24.558+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:17:24.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:17:24.568+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:17:24.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:17:24.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T08:17:55.016+0000] {processor.py:157} INFO - Started process (PID=27714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:17:55.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:17:55.020+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:17:55.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:17:55.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:17:55.048+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:17:55.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:17:55.059+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:17:55.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:17:55.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:18:25.493+0000] {processor.py:157} INFO - Started process (PID=27739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:18:25.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:18:25.497+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:18:25.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:18:25.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:18:25.527+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:18:25.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:18:25.537+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:18:25.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:18:25.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:18:55.931+0000] {processor.py:157} INFO - Started process (PID=27764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:18:55.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:18:55.935+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:18:55.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:18:55.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:18:55.968+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:18:55.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:18:55.984+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:18:55.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:18:55.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-14T08:19:26.498+0000] {processor.py:157} INFO - Started process (PID=27789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:19:26.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:19:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:19:26.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:19:26.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:19:26.526+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:19:26.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:19:26.536+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:19:26.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:19:26.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:19:56.902+0000] {processor.py:157} INFO - Started process (PID=27814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:19:56.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:19:56.906+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:19:56.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:19:56.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:19:56.932+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:19:56.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:19:56.942+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:19:56.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:19:56.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:20:27.361+0000] {processor.py:157} INFO - Started process (PID=27839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:20:27.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:20:27.364+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:20:27.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:20:27.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:20:27.394+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:20:27.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:20:27.406+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:20:27.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:20:27.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:20:57.750+0000] {processor.py:157} INFO - Started process (PID=27864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:20:57.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:20:57.753+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:20:57.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:20:57.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:20:57.777+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:20:57.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:20:57.790+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:20:57.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:20:57.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T08:21:28.218+0000] {processor.py:157} INFO - Started process (PID=27889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:21:28.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:21:28.222+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:21:28.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:21:28.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:21:28.250+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:21:28.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:21:28.260+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:21:28.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:21:28.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T08:21:58.755+0000] {processor.py:157} INFO - Started process (PID=27914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:21:58.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:21:58.758+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:21:58.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:21:58.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:21:58.784+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:21:58.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:21:58.794+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:21:58.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:21:58.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T08:22:29.213+0000] {processor.py:157} INFO - Started process (PID=27939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:22:29.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:22:29.219+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:22:29.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:22:29.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:22:29.259+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:22:29.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:22:29.271+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:22:29.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:22:29.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-14T08:22:59.698+0000] {processor.py:157} INFO - Started process (PID=27964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:22:59.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:22:59.702+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:22:59.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:22:59.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:22:59.729+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:22:59.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:22:59.744+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:22:59.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:22:59.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-14T08:23:30.182+0000] {processor.py:157} INFO - Started process (PID=27989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:23:30.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:23:30.186+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:23:30.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:23:30.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:23:30.209+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:23:30.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:23:30.222+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:23:30.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:23:30.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T08:24:00.629+0000] {processor.py:157} INFO - Started process (PID=28014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:24:00.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:24:00.634+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:24:00.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:24:00.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:24:00.665+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:24:00.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:24:00.681+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:24:00.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:24:00.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-14T08:24:31.072+0000] {processor.py:157} INFO - Started process (PID=28039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:24:31.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:24:31.075+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:24:31.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:24:31.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:24:31.102+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:24:31.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:24:31.116+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:24:31.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:24:31.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:25:01.556+0000] {processor.py:157} INFO - Started process (PID=28064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:25:01.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:25:01.559+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:25:01.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:25:01.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:25:01.586+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:25:01.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:25:01.603+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:25:01.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:25:01.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:25:31.988+0000] {processor.py:157} INFO - Started process (PID=28089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:25:31.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:25:31.990+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:25:31.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:25:31.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:25:32.014+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:25:32.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:25:32.027+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:25:32.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:25:32.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:26:02.426+0000] {processor.py:157} INFO - Started process (PID=28114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:26:02.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:26:02.429+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:26:02.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:26:02.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:26:02.453+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:26:02.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:26:02.467+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:26:02.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:26:02.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T08:26:32.881+0000] {processor.py:157} INFO - Started process (PID=28139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:26:32.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:26:32.884+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:26:32.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:26:32.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:26:32.910+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:26:32.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:26:32.922+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:26:32.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:26:32.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T08:27:03.318+0000] {processor.py:157} INFO - Started process (PID=28164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:27:03.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:27:03.320+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:27:03.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:27:03.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:27:03.343+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:27:03.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:27:03.353+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:27:03.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:27:03.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-14T08:27:33.736+0000] {processor.py:157} INFO - Started process (PID=28189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:27:33.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:27:33.738+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:27:33.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:27:33.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:27:33.766+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:27:33.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:27:33.776+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:27:33.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:27:33.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T08:28:04.173+0000] {processor.py:157} INFO - Started process (PID=28214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:28:04.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:28:04.176+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:28:04.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:28:04.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:28:04.202+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:28:04.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:28:04.216+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:28:04.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:28:04.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:28:34.633+0000] {processor.py:157} INFO - Started process (PID=28239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:28:34.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:28:34.637+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:28:34.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:28:34.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:28:34.669+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:28:34.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:28:34.682+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:28:34.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:28:34.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-14T08:29:05.177+0000] {processor.py:157} INFO - Started process (PID=28264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:29:05.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:29:05.183+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:29:05.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:29:05.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:29:05.232+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:29:05.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:29:05.247+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:29:05.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:29:05.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-14T08:29:35.679+0000] {processor.py:157} INFO - Started process (PID=28289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:29:35.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:29:35.684+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:29:35.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:29:35.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:29:35.717+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:29:35.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:29:35.732+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:29:35.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:29:35.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-14T08:30:06.091+0000] {processor.py:157} INFO - Started process (PID=28314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:30:06.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:30:06.095+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:30:06.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:30:06.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:30:06.125+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:30:06.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:30:06.137+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:30:06.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:30:06.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T08:30:36.557+0000] {processor.py:157} INFO - Started process (PID=28339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:30:36.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:30:36.560+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:30:36.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:30:36.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:30:36.589+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:30:36.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:30:36.602+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:30:36.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:30:36.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:31:07.011+0000] {processor.py:157} INFO - Started process (PID=28364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:31:07.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:31:07.016+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:31:07.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:31:07.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:31:07.039+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:31:07.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:31:07.048+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:31:07.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:31:07.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-14T08:31:37.411+0000] {processor.py:157} INFO - Started process (PID=28389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:31:37.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:31:37.415+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:31:37.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:31:37.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:31:37.448+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:31:37.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:31:37.461+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:31:37.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:31:37.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-14T08:32:07.811+0000] {processor.py:157} INFO - Started process (PID=28414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:32:07.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:32:07.815+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:32:07.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:32:07.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:32:07.850+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:32:07.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:32:07.862+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:32:07.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:32:07.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-14T08:32:38.315+0000] {processor.py:157} INFO - Started process (PID=28439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:32:38.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:32:38.317+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:32:38.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:32:38.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:32:38.342+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:32:38.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:32:38.352+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:32:38.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:32:38.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T08:33:08.776+0000] {processor.py:157} INFO - Started process (PID=28464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:33:08.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:33:08.779+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:33:08.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:33:08.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:33:08.806+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:33:08.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:33:08.819+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:33:08.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:33:08.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T08:33:39.219+0000] {processor.py:157} INFO - Started process (PID=28489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:33:39.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:33:39.224+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:33:39.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:33:39.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:33:39.256+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:33:39.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:33:39.266+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:33:39.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:33:39.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T08:34:09.720+0000] {processor.py:157} INFO - Started process (PID=28514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:34:09.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:34:09.723+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:34:09.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:34:09.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:34:09.755+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:34:09.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:34:09.768+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:34:09.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:34:09.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-14T08:34:40.198+0000] {processor.py:157} INFO - Started process (PID=28539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:34:40.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:34:40.200+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:34:40.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:34:40.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:34:40.223+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:34:40.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:34:40.235+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:34:40.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:34:40.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T08:35:10.581+0000] {processor.py:157} INFO - Started process (PID=28564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:35:10.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:35:10.585+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:35:10.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:35:10.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:35:10.619+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:35:10.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:35:10.632+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:35:10.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:35:10.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-14T08:35:41.080+0000] {processor.py:157} INFO - Started process (PID=28589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:35:41.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:35:41.083+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:35:41.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:35:41.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:35:41.114+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:35:41.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:35:41.124+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:35:41.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:35:41.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:36:11.560+0000] {processor.py:157} INFO - Started process (PID=28614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:36:11.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:36:11.564+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:36:11.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:36:11.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:36:11.596+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:36:11.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:36:11.609+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:36:11.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:36:11.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-14T08:36:42.062+0000] {processor.py:157} INFO - Started process (PID=28639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:36:42.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:36:42.064+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:36:42.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:36:42.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:36:42.088+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:36:42.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:36:42.101+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:36:42.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:36:42.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:37:12.539+0000] {processor.py:157} INFO - Started process (PID=28664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:37:12.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:37:12.543+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:37:12.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:37:12.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:37:12.569+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:37:12.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:37:12.582+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:37:12.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:37:12.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:37:43.060+0000] {processor.py:157} INFO - Started process (PID=28689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:37:43.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:37:43.064+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:37:43.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:37:43.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:37:43.089+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:37:43.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:37:43.099+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:37:43.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:37:43.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:38:13.525+0000] {processor.py:157} INFO - Started process (PID=28714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:38:13.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:38:13.529+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:38:13.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:38:13.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:38:13.557+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:38:13.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:38:13.569+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:38:13.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:38:13.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T08:38:44.009+0000] {processor.py:157} INFO - Started process (PID=28739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:38:44.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:38:44.012+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:38:44.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:38:44.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:38:44.037+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:38:44.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:38:44.047+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:38:44.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:38:44.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-14T08:39:14.465+0000] {processor.py:157} INFO - Started process (PID=28764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:39:14.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:39:14.468+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:39:14.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:39:14.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:39:14.498+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:39:14.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:39:14.512+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:39:14.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:39:14.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T08:39:44.960+0000] {processor.py:157} INFO - Started process (PID=28789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:39:44.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:39:44.963+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:39:44.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:39:44.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:39:44.989+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:39:44.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:39:45.002+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:39:45.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:39:45.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:40:15.434+0000] {processor.py:157} INFO - Started process (PID=28814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:40:15.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:40:15.439+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:40:15.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:40:15.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:40:15.474+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:40:15.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:40:15.485+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:40:15.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:40:15.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-14T08:40:45.908+0000] {processor.py:157} INFO - Started process (PID=28839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:40:45.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:40:45.912+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:40:45.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:40:45.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:40:45.946+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:40:45.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:40:45.962+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:40:45.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:40:45.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-14T08:41:16.394+0000] {processor.py:157} INFO - Started process (PID=28864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:41:16.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:41:16.398+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:41:16.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:41:16.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:41:16.428+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:41:16.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:41:16.439+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:41:16.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:41:16.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:41:46.930+0000] {processor.py:157} INFO - Started process (PID=28889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:41:46.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:41:46.933+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:41:46.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:41:46.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:41:46.965+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:41:46.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:41:46.981+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:41:46.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:41:46.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-14T08:42:17.358+0000] {processor.py:157} INFO - Started process (PID=28914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:42:17.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:42:17.361+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:42:17.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:42:17.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:42:17.385+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:42:17.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:42:17.400+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:42:17.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:42:17.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:42:47.770+0000] {processor.py:157} INFO - Started process (PID=28939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:42:47.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:42:47.773+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:42:47.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:42:47.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:42:47.798+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:42:47.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:42:47.809+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:42:47.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:42:47.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T08:43:18.199+0000] {processor.py:157} INFO - Started process (PID=28964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:43:18.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:43:18.202+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:43:18.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:43:18.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:43:18.229+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:43:18.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:43:18.243+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:43:18.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:43:18.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:43:48.611+0000] {processor.py:157} INFO - Started process (PID=28989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:43:48.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:43:48.614+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:43:48.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:43:48.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:43:48.638+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:43:48.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:43:48.651+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:43:48.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:43:48.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T08:44:19.093+0000] {processor.py:157} INFO - Started process (PID=29014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:44:19.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:44:19.097+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:44:19.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:44:19.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:44:19.124+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:44:19.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:44:19.134+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:44:19.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:44:19.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:44:49.537+0000] {processor.py:157} INFO - Started process (PID=29039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:44:49.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:44:49.543+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:44:49.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:44:49.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:44:49.571+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:44:49.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:44:49.581+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:44:49.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:44:49.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:45:19.949+0000] {processor.py:157} INFO - Started process (PID=29064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:45:19.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:45:19.952+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:45:19.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:45:19.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:45:19.981+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:45:19.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:45:19.992+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:45:19.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:45:20.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T08:45:50.382+0000] {processor.py:157} INFO - Started process (PID=29089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:45:50.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:45:50.387+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:45:50.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:45:50.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:45:50.421+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:45:50.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:45:50.433+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:45:50.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:45:50.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-14T08:46:20.876+0000] {processor.py:157} INFO - Started process (PID=29114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:46:20.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:46:20.879+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:46:20.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:46:20.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:46:20.910+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:46:20.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:46:20.920+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:46:20.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:46:20.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:46:51.347+0000] {processor.py:157} INFO - Started process (PID=29139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:46:51.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:46:51.349+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:46:51.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:46:51.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:46:51.380+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:46:51.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:46:51.393+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:46:51.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:46:51.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:47:21.737+0000] {processor.py:157} INFO - Started process (PID=29164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:47:21.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:47:21.741+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:47:21.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:47:21.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:47:21.771+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:47:21.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:47:21.781+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:47:21.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:47:21.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:47:52.155+0000] {processor.py:157} INFO - Started process (PID=29189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:47:52.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:47:52.161+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:47:52.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:47:52.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:47:52.187+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:47:52.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:47:52.199+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:47:52.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:47:52.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:48:22.633+0000] {processor.py:157} INFO - Started process (PID=29214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:48:22.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:48:22.636+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:48:22.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:48:22.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:48:22.665+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:48:22.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:48:22.677+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:48:22.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:48:22.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T08:48:53.014+0000] {processor.py:157} INFO - Started process (PID=29239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:48:53.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:48:53.017+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:48:53.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:48:53.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:48:53.040+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:48:53.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:48:53.053+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:48:53.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:48:53.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T08:49:23.433+0000] {processor.py:157} INFO - Started process (PID=29264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:49:23.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:49:23.436+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:49:23.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:49:23.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:49:23.462+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:49:23.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:49:23.473+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:49:23.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:49:23.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T08:49:53.864+0000] {processor.py:157} INFO - Started process (PID=29289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:49:53.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:49:53.868+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:49:53.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:49:53.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:49:53.897+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:49:53.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:49:53.911+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:49:53.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:49:53.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-14T08:50:24.367+0000] {processor.py:157} INFO - Started process (PID=29314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:50:24.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:50:24.370+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:50:24.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:50:24.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:50:24.403+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:50:24.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:50:24.416+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:50:24.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:50:24.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-14T08:50:54.837+0000] {processor.py:157} INFO - Started process (PID=29339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:50:54.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:50:54.841+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:50:54.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:50:54.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:50:54.869+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:50:54.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:50:54.883+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:50:54.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:50:54.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:51:25.254+0000] {processor.py:157} INFO - Started process (PID=29364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:51:25.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:51:25.256+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:51:25.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:51:25.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:51:25.280+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:51:25.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:51:25.295+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:51:25.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:51:25.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T08:51:55.677+0000] {processor.py:157} INFO - Started process (PID=29389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:51:55.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:51:55.679+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:51:55.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:51:55.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:51:55.700+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:51:55.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:51:55.710+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:51:55.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:51:55.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-14T08:52:26.130+0000] {processor.py:157} INFO - Started process (PID=29414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:52:26.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:52:26.136+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:52:26.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:52:26.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:52:26.165+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:52:26.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:52:26.175+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:52:26.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:52:26.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T08:52:56.542+0000] {processor.py:157} INFO - Started process (PID=29439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:52:56.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:52:56.546+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:52:56.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:52:56.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:52:56.573+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:52:56.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:52:56.587+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:52:56.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:52:56.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T08:53:27.015+0000] {processor.py:157} INFO - Started process (PID=29464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:53:27.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:53:27.020+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:53:27.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:53:27.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:53:27.052+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:53:27.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:53:27.064+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:53:27.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:53:27.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-14T08:53:57.493+0000] {processor.py:157} INFO - Started process (PID=29489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:53:57.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:53:57.498+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:53:57.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:53:57.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:53:57.528+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:53:57.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:53:57.544+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:53:57.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:53:57.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-14T08:54:27.988+0000] {processor.py:157} INFO - Started process (PID=29514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:54:27.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:54:27.991+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:54:27.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:54:28.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:54:28.016+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:54:28.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:54:28.034+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:54:28.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:54:28.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T08:54:58.436+0000] {processor.py:157} INFO - Started process (PID=29539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:54:58.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:54:58.440+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:54:58.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:54:58.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:54:58.467+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:54:58.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:54:58.479+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:54:58.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:54:58.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T08:55:28.844+0000] {processor.py:157} INFO - Started process (PID=29564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:55:28.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:55:28.846+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:55:28.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:55:28.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:55:28.871+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:55:28.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:55:28.880+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:55:28.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:55:28.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-14T08:55:59.295+0000] {processor.py:157} INFO - Started process (PID=29589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:55:59.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:55:59.298+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:55:59.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:55:59.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:55:59.333+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:55:59.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:55:59.346+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:55:59.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:55:59.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-14T08:56:29.790+0000] {processor.py:157} INFO - Started process (PID=29614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:56:29.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:56:29.798+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:56:29.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:56:29.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:56:29.845+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:56:29.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:56:29.858+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:56:29.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:56:29.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-14T08:57:00.206+0000] {processor.py:157} INFO - Started process (PID=29639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:57:00.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:57:00.209+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:57:00.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:57:00.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:57:00.245+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:57:00.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:57:00.262+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:57:00.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:57:00.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-14T08:57:30.761+0000] {processor.py:157} INFO - Started process (PID=29664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:57:30.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:57:30.769+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:57:30.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:57:30.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:57:30.831+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:57:30.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:57:30.897+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:57:30.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:57:30.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-07-14T08:58:01.409+0000] {processor.py:157} INFO - Started process (PID=29689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:58:01.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:58:01.416+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:58:01.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:58:01.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:58:01.461+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:58:01.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:58:01.475+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:58:01.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:58:01.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-14T08:58:31.827+0000] {processor.py:157} INFO - Started process (PID=29714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:58:31.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:58:31.833+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:58:31.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:58:31.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:58:31.908+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:58:31.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:58:31.927+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:58:31.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:58:31.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-14T08:59:02.320+0000] {processor.py:157} INFO - Started process (PID=29739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:59:02.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:59:02.327+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:59:02.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:59:02.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:59:02.358+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:59:02.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:59:02.370+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:59:02.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:59:02.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-14T08:59:32.788+0000] {processor.py:157} INFO - Started process (PID=29764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:59:32.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T08:59:32.793+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:59:32.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:59:32.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T08:59:32.872+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:59:32.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T08:59:32.891+0000] {logging_mixin.py:151} INFO - [2024-07-14T08:59:32.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T08:59:32.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-14T09:00:03.443+0000] {processor.py:157} INFO - Started process (PID=29789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:00:03.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:00:03.447+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:00:03.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:00:03.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:00:03.479+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:00:03.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:00:03.492+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:00:03.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:00:03.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-14T09:00:33.920+0000] {processor.py:157} INFO - Started process (PID=29814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:00:33.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:00:33.925+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:00:33.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:00:33.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:00:33.954+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:00:33.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:00:33.963+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:00:33.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:00:33.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T09:01:04.290+0000] {processor.py:157} INFO - Started process (PID=29839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:01:04.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:01:04.294+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:01:04.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:01:04.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:01:04.324+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:01:04.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:01:04.334+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:01:04.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:01:04.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T09:01:34.782+0000] {processor.py:157} INFO - Started process (PID=29864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:01:34.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:01:34.785+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:01:34.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:01:34.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:01:34.812+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:01:34.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:01:34.827+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:01:34.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:01:34.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T09:02:05.230+0000] {processor.py:157} INFO - Started process (PID=29889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:02:05.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:02:05.233+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:02:05.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:02:05.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:02:05.270+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:02:05.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:02:05.285+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:02:05.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:02:05.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-14T09:02:35.743+0000] {processor.py:157} INFO - Started process (PID=29914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:02:35.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:02:35.748+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:02:35.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:02:35.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:02:35.774+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:02:35.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:02:35.790+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:02:35.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:02:35.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T09:03:06.190+0000] {processor.py:157} INFO - Started process (PID=29939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:03:06.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:03:06.195+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:03:06.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:03:06.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:03:06.219+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:03:06.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:03:06.233+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:03:06.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:03:06.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T09:03:36.694+0000] {processor.py:157} INFO - Started process (PID=29964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:03:36.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:03:36.697+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:03:36.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:03:36.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:03:36.725+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:03:36.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:03:36.734+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:03:36.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:03:36.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T09:04:07.164+0000] {processor.py:157} INFO - Started process (PID=29989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:04:07.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:04:07.168+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:04:07.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:04:07.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:04:07.207+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:04:07.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:04:07.221+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:04:07.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:04:07.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-14T09:04:37.660+0000] {processor.py:157} INFO - Started process (PID=30014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:04:37.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:04:37.663+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:04:37.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:04:37.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:04:37.687+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:04:37.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:04:37.699+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:04:37.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:04:37.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T09:05:08.154+0000] {processor.py:157} INFO - Started process (PID=30039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:05:08.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:05:08.158+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:05:08.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:05:08.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:05:08.189+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:05:08.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:05:08.198+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:05:08.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:05:08.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T09:05:38.525+0000] {processor.py:157} INFO - Started process (PID=30064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:05:38.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:05:38.529+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:05:38.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:05:38.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:05:38.553+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:05:38.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:05:38.564+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:05:38.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:05:38.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T09:06:09.023+0000] {processor.py:157} INFO - Started process (PID=30089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:06:09.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:06:09.031+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:06:09.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:06:09.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:06:09.068+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:06:09.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:06:09.083+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:06:09.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:06:09.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-14T09:06:39.524+0000] {processor.py:157} INFO - Started process (PID=30114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:06:39.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:06:39.528+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:06:39.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:06:39.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:06:39.555+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:06:39.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:06:39.566+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:06:39.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:06:39.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T09:07:09.995+0000] {processor.py:157} INFO - Started process (PID=30139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:07:09.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:07:09.999+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:07:09.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:07:10.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:07:10.031+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:07:10.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:07:10.045+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:07:10.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:07:10.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-14T09:07:40.485+0000] {processor.py:157} INFO - Started process (PID=30164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:07:40.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:07:40.489+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:07:40.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:07:40.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:07:40.531+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:07:40.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:07:40.544+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:07:40.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:07:40.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-14T09:08:10.859+0000] {processor.py:157} INFO - Started process (PID=30189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:08:10.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:08:10.862+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:08:10.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:08:10.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:08:10.886+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:08:10.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:08:10.897+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:08:10.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:08:10.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T09:08:41.310+0000] {processor.py:157} INFO - Started process (PID=30214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:08:41.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:08:41.313+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:08:41.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:08:41.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:08:41.335+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:08:41.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:08:41.345+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:08:41.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:08:41.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-14T09:09:11.706+0000] {processor.py:157} INFO - Started process (PID=30239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:09:11.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:09:11.710+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:09:11.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:09:11.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:09:11.738+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:09:11.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:09:11.748+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:09:11.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:09:11.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T09:09:42.149+0000] {processor.py:157} INFO - Started process (PID=30264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:09:42.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:09:42.153+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:09:42.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:09:42.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:09:42.179+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:09:42.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:09:42.188+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:09:42.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:09:42.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T09:10:12.524+0000] {processor.py:157} INFO - Started process (PID=30289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:10:12.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:10:12.527+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:10:12.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:10:12.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:10:12.554+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:10:12.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:10:12.564+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:10:12.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:10:12.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T09:10:42.950+0000] {processor.py:157} INFO - Started process (PID=30314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:10:42.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:10:42.956+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:10:42.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:10:42.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:10:42.990+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:10:42.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:10:43.004+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:10:43.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:10:43.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-14T09:11:13.433+0000] {processor.py:157} INFO - Started process (PID=30339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:11:13.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:11:13.436+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:11:13.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:11:13.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:11:13.464+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:11:13.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:11:13.474+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:11:13.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:11:13.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T09:11:43.884+0000] {processor.py:157} INFO - Started process (PID=30364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:11:43.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:11:43.887+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:11:43.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:11:43.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:11:43.914+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:11:43.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:11:43.924+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:11:43.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:11:43.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T09:12:14.335+0000] {processor.py:157} INFO - Started process (PID=30389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:12:14.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:12:14.338+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:12:14.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:12:14.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:12:14.364+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:12:14.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:12:14.374+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:12:14.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:12:14.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T09:12:44.840+0000] {processor.py:157} INFO - Started process (PID=30414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:12:44.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:12:44.843+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:12:44.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:12:44.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:12:44.869+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:12:44.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:12:44.879+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:12:44.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:12:44.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T09:13:15.324+0000] {processor.py:157} INFO - Started process (PID=30439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:13:15.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:13:15.327+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:13:15.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:13:15.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:13:15.352+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:13:15.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:13:15.363+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:13:15.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:13:15.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T09:13:45.821+0000] {processor.py:157} INFO - Started process (PID=30464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:13:45.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:13:45.824+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:13:45.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:13:45.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:13:45.860+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:13:45.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:13:45.870+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:13:45.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:13:45.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-14T09:14:16.225+0000] {processor.py:157} INFO - Started process (PID=30489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:14:16.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:14:16.229+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:14:16.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:14:16.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:14:16.258+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:14:16.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:14:16.272+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:14:16.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:14:16.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T09:14:46.720+0000] {processor.py:157} INFO - Started process (PID=30514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:14:46.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:14:46.725+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:14:46.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:14:46.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:14:46.751+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:14:46.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:14:46.763+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:14:46.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:14:46.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T09:15:17.259+0000] {processor.py:157} INFO - Started process (PID=30539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:15:17.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:15:17.262+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:15:17.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:15:17.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:15:17.290+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:15:17.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:15:17.299+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:15:17.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:15:17.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T09:15:47.686+0000] {processor.py:157} INFO - Started process (PID=30564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:15:47.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:15:47.689+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:15:47.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:15:47.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:15:47.713+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:15:47.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:15:47.728+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:15:47.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:15:47.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-14T09:16:18.158+0000] {processor.py:157} INFO - Started process (PID=30589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:16:18.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:16:18.161+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:16:18.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:16:18.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:16:18.188+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:16:18.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:16:18.198+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:16:18.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:16:18.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T09:16:48.638+0000] {processor.py:157} INFO - Started process (PID=30614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:16:48.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:16:48.641+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:16:48.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:16:48.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:16:48.665+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:16:48.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:16:48.676+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:16:48.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:16:48.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T09:17:19.037+0000] {processor.py:157} INFO - Started process (PID=30639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:17:19.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:17:19.040+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:17:19.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:17:19.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:17:19.070+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:17:19.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:17:19.082+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:17:19.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:17:19.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T09:17:49.591+0000] {processor.py:157} INFO - Started process (PID=30664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:17:49.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:17:49.594+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:17:49.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:17:49.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:17:49.620+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:17:49.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:17:49.630+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:17:49.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:17:49.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T09:18:20.003+0000] {processor.py:157} INFO - Started process (PID=30689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:18:20.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:18:20.007+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:18:20.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:18:20.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:18:20.033+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:18:20.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:18:20.044+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:18:20.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:18:20.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T09:18:50.479+0000] {processor.py:157} INFO - Started process (PID=30714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:18:50.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:18:50.485+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:18:50.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:18:50.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:18:50.515+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:18:50.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:18:50.525+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:18:50.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:18:50.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T09:19:20.904+0000] {processor.py:157} INFO - Started process (PID=30739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:19:20.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:19:20.908+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:19:20.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:19:20.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:19:20.931+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:19:20.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:19:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:19:20.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:19:20.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T09:19:51.434+0000] {processor.py:157} INFO - Started process (PID=30764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:19:51.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:19:51.437+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:19:51.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:19:51.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:19:51.466+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:19:51.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:19:51.477+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:19:51.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:19:51.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T09:20:21.953+0000] {processor.py:157} INFO - Started process (PID=30789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:20:21.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:20:21.957+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:20:21.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:20:21.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:20:21.981+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:20:21.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:20:21.992+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:20:21.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:20:22.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T09:20:52.427+0000] {processor.py:157} INFO - Started process (PID=30814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:20:52.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:20:52.433+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:20:52.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:20:52.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:20:52.463+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:20:52.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:20:52.472+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:20:52.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:20:52.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-14T09:21:22.870+0000] {processor.py:157} INFO - Started process (PID=30839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:21:22.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:21:22.874+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:21:22.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:21:22.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:21:22.903+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:21:22.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:21:22.913+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:21:22.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:21:22.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-14T09:21:53.299+0000] {processor.py:157} INFO - Started process (PID=30864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:21:53.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:21:53.302+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:21:53.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:21:53.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:21:53.336+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:21:53.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:21:53.346+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:21:53.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:21:53.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T09:22:23.781+0000] {processor.py:157} INFO - Started process (PID=30889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:22:23.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:22:23.784+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:22:23.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:22:23.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:22:23.811+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:22:23.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:22:23.821+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:22:23.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:22:23.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-14T09:22:54.249+0000] {processor.py:157} INFO - Started process (PID=30914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:22:54.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:22:54.254+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:22:54.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:22:54.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:22:54.283+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:22:54.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:22:54.293+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:22:54.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:22:54.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-14T09:23:24.687+0000] {processor.py:157} INFO - Started process (PID=30939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:23:24.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:23:24.690+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:23:24.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:23:24.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:23:24.713+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:23:24.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:23:24.724+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:23:24.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:23:24.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-14T09:23:55.095+0000] {processor.py:157} INFO - Started process (PID=30964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:23:55.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:23:55.100+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:23:55.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:23:55.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:23:55.130+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:23:55.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:23:55.139+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:23:55.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:23:55.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-14T09:24:25.583+0000] {processor.py:157} INFO - Started process (PID=30989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:24:25.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:24:25.586+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:24:25.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:24:25.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:24:25.613+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:24:25.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:24:25.623+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:24:25.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:24:25.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T09:24:56.070+0000] {processor.py:157} INFO - Started process (PID=31014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:24:56.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:24:56.073+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:24:56.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:24:56.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:24:56.102+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:24:56.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:24:56.112+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:24:56.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:24:56.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-14T09:25:26.470+0000] {processor.py:157} INFO - Started process (PID=31039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:25:26.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:25:26.472+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:25:26.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:25:26.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:25:26.498+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:25:26.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:25:26.508+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:25:26.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:25:26.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-14T09:25:56.952+0000] {processor.py:157} INFO - Started process (PID=31064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:25:56.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:25:56.958+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:25:56.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:25:56.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:25:56.990+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:25:56.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:25:57.003+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:25:57.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:25:57.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-14T09:26:27.421+0000] {processor.py:157} INFO - Started process (PID=31089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:26:27.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:26:27.425+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:26:27.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:26:27.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:26:27.450+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:26:27.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:26:27.462+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:26:27.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:26:27.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-14T09:26:57.942+0000] {processor.py:157} INFO - Started process (PID=31114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:26:57.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:26:57.945+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:26:57.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:26:57.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:26:57.968+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:26:57.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:26:57.980+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:26:57.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:26:57.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T09:27:28.417+0000] {processor.py:157} INFO - Started process (PID=31139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:27:28.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:27:28.422+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:27:28.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:27:28.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:27:28.460+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:27:28.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:27:28.476+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:27:28.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:27:28.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-14T09:27:59.062+0000] {processor.py:157} INFO - Started process (PID=31164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:27:59.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:27:59.077+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:27:59.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:27:59.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:27:59.116+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:27:59.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:27:59.131+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:27:59.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:27:59.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-14T09:28:29.522+0000] {processor.py:157} INFO - Started process (PID=31189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:28:29.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:28:29.527+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:28:29.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:28:29.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:28:29.555+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:28:29.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:28:29.566+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:28:29.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:28:29.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T09:29:00.014+0000] {processor.py:157} INFO - Started process (PID=31214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:29:00.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:29:00.018+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:29:00.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:29:00.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:29:00.064+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:29:00.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:29:00.081+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:29:00.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:29:00.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-14T09:29:30.444+0000] {processor.py:157} INFO - Started process (PID=31239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:29:30.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:29:30.447+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:29:30.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:29:30.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:29:30.470+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:29:30.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:29:30.482+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:29:30.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:29:30.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-14T09:30:00.895+0000] {processor.py:157} INFO - Started process (PID=31264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:30:00.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:30:00.902+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:30:00.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:30:00.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:30:00.928+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:30:00.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:30:00.943+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:30:00.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:30:00.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-14T09:30:31.323+0000] {processor.py:157} INFO - Started process (PID=31289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:30:31.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:30:31.326+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:30:31.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:30:31.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:30:31.352+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:30:31.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:30:31.366+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:30:31.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:30:31.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-14T09:31:01.741+0000] {processor.py:157} INFO - Started process (PID=31314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:31:01.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:31:01.746+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:31:01.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:31:01.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:31:01.791+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:31:01.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:31:01.803+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:31:01.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:31:01.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-14T09:31:32.263+0000] {processor.py:157} INFO - Started process (PID=31339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:31:32.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:31:32.269+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:31:32.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:31:32.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:31:32.296+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:31:32.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:31:32.308+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:31:32.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:31:32.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-14T09:32:02.731+0000] {processor.py:157} INFO - Started process (PID=31364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:32:02.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-14T09:32:02.734+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:32:02.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:32:02.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-14T09:32:02.766+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:32:02.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-14T09:32:02.779+0000] {logging_mixin.py:151} INFO - [2024-07-14T09:32:02.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-14T01:00:00+00:00, run_after=2024-07-15T01:00:00+00:00
[2024-07-14T09:32:02.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
