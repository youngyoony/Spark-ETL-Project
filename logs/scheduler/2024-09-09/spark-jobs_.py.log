[2024-09-09T00:00:05.112+0000] {processor.py:157} INFO - Started process (PID=4424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:00:05.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:00:05.120+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:00:05.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:00:05.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:00:05.169+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:00:05.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:00:05.190+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:00:05.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:00:05.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-09T00:00:35.380+0000] {processor.py:157} INFO - Started process (PID=4434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:00:35.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:00:35.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:00:35.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:00:35.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:00:35.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:00:35.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:00:35.457+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:00:35.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:00:35.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-09T00:01:05.698+0000] {processor.py:157} INFO - Started process (PID=4443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:01:05.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:01:05.706+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:01:05.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:01:05.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:01:05.788+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:01:05.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:01:05.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:01:05.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:01:05.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-09T00:01:36.029+0000] {processor.py:157} INFO - Started process (PID=4454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:01:36.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:01:36.041+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:01:36.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:01:36.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:01:36.156+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:01:36.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:01:36.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:01:36.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:01:36.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-09-09T00:02:06.334+0000] {processor.py:157} INFO - Started process (PID=4464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:02:06.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:02:06.346+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:02:06.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:02:06.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:02:06.408+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:02:06.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:02:06.426+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:02:06.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:02:06.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-09T00:02:36.656+0000] {processor.py:157} INFO - Started process (PID=4474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:02:36.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:02:36.667+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:02:36.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:02:36.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:02:36.749+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:02:36.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:02:36.788+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:02:36.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:02:36.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-09T00:03:06.972+0000] {processor.py:157} INFO - Started process (PID=4484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:03:06.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:03:06.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:03:06.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:03:07.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:03:07.045+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:03:07.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:03:07.087+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:03:07.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:03:07.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-09T00:03:37.344+0000] {processor.py:157} INFO - Started process (PID=4494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:03:37.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:03:37.354+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:03:37.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:03:37.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:03:37.445+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:03:37.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:03:37.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:03:37.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:03:37.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-09T00:04:07.638+0000] {processor.py:157} INFO - Started process (PID=4504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:04:07.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:04:07.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:04:07.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:04:07.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:04:07.734+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:04:07.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:04:07.760+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:04:07.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:04:07.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-09T00:04:37.955+0000] {processor.py:157} INFO - Started process (PID=4514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:04:37.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:04:37.968+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:04:37.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:04:38.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:04:38.062+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:04:38.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:04:38.087+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:04:38.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:04:38.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-09T00:05:08.261+0000] {processor.py:157} INFO - Started process (PID=4524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:05:08.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:05:08.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:05:08.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:05:08.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:05:08.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:05:08.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:05:08.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:05:08.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:05:08.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-09T00:05:38.617+0000] {processor.py:157} INFO - Started process (PID=4534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:05:38.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:05:38.623+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:05:38.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:05:38.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:05:38.709+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:05:38.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:05:38.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:05:38.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:05:38.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-09T00:06:08.917+0000] {processor.py:157} INFO - Started process (PID=4544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:06:08.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:06:08.926+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:06:08.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:06:08.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:06:09.022+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:06:09.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:06:09.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:06:09.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:06:09.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-09T00:06:39.415+0000] {processor.py:157} INFO - Started process (PID=4554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:06:39.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:06:39.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:06:39.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:06:39.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:06:39.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:06:39.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:06:39.525+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:06:39.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:06:39.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-09T00:07:09.740+0000] {processor.py:157} INFO - Started process (PID=4564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:07:09.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:07:09.754+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:07:09.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:07:09.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:07:09.811+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:07:09.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:07:09.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:07:09.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:07:09.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-09T00:07:39.967+0000] {processor.py:157} INFO - Started process (PID=4574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:07:39.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:07:39.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:07:39.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:07:39.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:07:40.012+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:07:40.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:07:40.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:07:40.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:07:40.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T00:08:10.406+0000] {processor.py:157} INFO - Started process (PID=4584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:08:10.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:08:10.412+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:08:10.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:08:10.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:08:10.494+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:08:10.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:08:10.523+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:08:10.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:08:10.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-09T00:08:40.687+0000] {processor.py:157} INFO - Started process (PID=4594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:08:40.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:08:40.695+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:08:40.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:08:40.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:08:40.769+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:08:40.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:08:40.792+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:08:40.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:08:40.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-09T00:09:11.028+0000] {processor.py:157} INFO - Started process (PID=4604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:09:11.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:09:11.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:09:11.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:09:11.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:09:11.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:09:11.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:09:11.124+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:09:11.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:09:11.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-09T00:09:41.365+0000] {processor.py:157} INFO - Started process (PID=4614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:09:41.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:09:41.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:09:41.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:09:41.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:09:41.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:09:41.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:09:41.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:09:41.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:09:41.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-09T00:10:11.683+0000] {processor.py:157} INFO - Started process (PID=4624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:10:11.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:10:11.690+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:10:11.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:10:11.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:10:11.776+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:10:11.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:10:11.798+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:10:11.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:10:11.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-09T00:10:42.009+0000] {processor.py:157} INFO - Started process (PID=4634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:10:42.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:10:42.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:10:42.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:10:42.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:10:42.071+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:10:42.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:10:42.087+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:10:42.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:10:42.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T00:11:12.512+0000] {processor.py:157} INFO - Started process (PID=4644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:11:12.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:11:12.518+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:11:12.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:11:12.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:11:12.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:11:12.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:11:12.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:11:12.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:11:12.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-09T00:11:43.096+0000] {processor.py:157} INFO - Started process (PID=4654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:11:43.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:11:43.102+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:11:43.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:11:43.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:11:43.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:11:43.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:11:43.203+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:11:43.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:11:43.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T00:12:13.413+0000] {processor.py:157} INFO - Started process (PID=4664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:12:13.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:12:13.418+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:12:13.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:12:13.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:12:13.496+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:12:13.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:12:13.517+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:12:13.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:12:13.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-09T00:12:43.768+0000] {processor.py:157} INFO - Started process (PID=4674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:12:43.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:12:43.776+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:12:43.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:12:43.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:12:43.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:12:43.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:12:43.869+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:12:43.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:12:43.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-09T00:13:14.271+0000] {processor.py:157} INFO - Started process (PID=4684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:13:14.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:13:14.278+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:13:14.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:13:14.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:13:14.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:13:14.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:13:14.411+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:13:14.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:13:14.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-09T00:13:44.557+0000] {processor.py:157} INFO - Started process (PID=4694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:13:44.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:13:44.564+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:13:44.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:13:44.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:13:44.637+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:13:44.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:13:44.658+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:13:44.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:13:44.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-09T00:14:14.944+0000] {processor.py:157} INFO - Started process (PID=4704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:14:14.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:14:14.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:14:14.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:14:14.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:14:15.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:14:15.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:14:15.049+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:14:15.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:14:15.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-09T00:14:45.318+0000] {processor.py:157} INFO - Started process (PID=4714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:14:45.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:14:45.327+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:14:45.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:14:45.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:14:45.408+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:14:45.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:14:45.429+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:14:45.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:14:45.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-09T00:15:15.674+0000] {processor.py:157} INFO - Started process (PID=4724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:15:15.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:15:15.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:15:15.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:15:15.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:15:15.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:15:15.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:15:15.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:15:15.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:15:15.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-09T00:15:45.949+0000] {processor.py:157} INFO - Started process (PID=4734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:15:45.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:15:45.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:15:45.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:15:45.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:15:46.013+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:15:46.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:15:46.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:15:46.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:15:46.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-09T00:16:16.417+0000] {processor.py:157} INFO - Started process (PID=4744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:16:16.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:16:16.426+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:16:16.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:16:16.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:16:16.494+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:16:16.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:16:16.512+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:16:16.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:16:16.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T00:16:46.734+0000] {processor.py:157} INFO - Started process (PID=4754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:16:46.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:16:46.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:16:46.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:16:46.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:16:46.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:16:46.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:16:46.830+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:16:46.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:16:46.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T00:17:17.436+0000] {processor.py:157} INFO - Started process (PID=4764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:17:17.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:17:17.443+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:17:17.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:17:17.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:17:17.521+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:17:17.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:17:17.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:17:17.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:17:17.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-09T00:17:47.817+0000] {processor.py:157} INFO - Started process (PID=4774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:17:47.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:17:47.821+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:17:47.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:17:47.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:17:47.865+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:17:47.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:17:47.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:17:47.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:17:47.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-09T00:18:18.278+0000] {processor.py:157} INFO - Started process (PID=4784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:18:18.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:18:18.288+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:18:18.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:18:18.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:18:18.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:18:18.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:18:18.390+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:18:18.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:18:18.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-09T00:18:48.953+0000] {processor.py:157} INFO - Started process (PID=4794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:18:48.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:18:48.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:18:48.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:18:48.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:18:49.024+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:18:49.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:18:49.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:18:49.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:18:49.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-09T00:19:19.379+0000] {processor.py:157} INFO - Started process (PID=4804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:19:19.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:19:19.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:19:19.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:19:19.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:19:19.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:19:19.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:19:19.490+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:19:19.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:19:19.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-09T00:19:49.703+0000] {processor.py:157} INFO - Started process (PID=4813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:19:49.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:19:49.710+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:19:49.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:19:49.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:19:49.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:19:49.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:19:49.800+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:19:49.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:19:49.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-09T00:20:20.055+0000] {processor.py:157} INFO - Started process (PID=4824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:20:20.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:20:20.059+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:20:20.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:20:20.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:20:20.148+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:20:20.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:20:20.168+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:20:20.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:20:20.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-09T00:20:50.394+0000] {processor.py:157} INFO - Started process (PID=4834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:20:50.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:20:50.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:20:50.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:20:50.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:20:50.481+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:20:50.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:20:50.503+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:20:50.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:20:50.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-09T00:21:20.690+0000] {processor.py:157} INFO - Started process (PID=4844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:21:20.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:21:20.698+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:21:20.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:21:20.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:21:20.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:21:20.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:21:20.765+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:21:20.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:21:20.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-09T00:21:50.973+0000] {processor.py:157} INFO - Started process (PID=4854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:21:50.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:21:50.976+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:21:50.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:21:50.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:21:51.010+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:21:51.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:21:51.028+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:21:51.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:21:51.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T00:22:21.488+0000] {processor.py:157} INFO - Started process (PID=4864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:22:21.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:22:21.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:22:21.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:22:21.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:22:21.559+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:22:21.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:22:21.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:22:21.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:22:21.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-09T00:22:51.821+0000] {processor.py:157} INFO - Started process (PID=4874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:22:51.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:22:51.833+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:22:51.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:22:51.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:22:51.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:22:51.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:22:51.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:22:51.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:22:51.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-09T00:23:22.141+0000] {processor.py:157} INFO - Started process (PID=4884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:23:22.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:23:22.147+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:23:22.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:23:22.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:23:22.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:23:22.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:23:22.221+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:23:22.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:23:22.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-09T00:23:52.471+0000] {processor.py:157} INFO - Started process (PID=4894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:23:52.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:23:52.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:23:52.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:23:52.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:23:52.549+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:23:52.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:23:52.566+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:23:52.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:23:52.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-09T00:24:22.784+0000] {processor.py:157} INFO - Started process (PID=4904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:24:22.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:24:22.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:24:22.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:24:22.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:24:22.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:24:22.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:24:22.914+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:24:22.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:24:22.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-09T00:24:53.129+0000] {processor.py:157} INFO - Started process (PID=4914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:24:53.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:24:53.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:24:53.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:24:53.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:24:53.465+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:24:53.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:24:53.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:24:53.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:24:53.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.387 seconds
[2024-09-09T00:25:23.905+0000] {processor.py:157} INFO - Started process (PID=4924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:25:23.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:25:23.918+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:25:23.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:25:23.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:25:23.992+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:25:23.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:25:24.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:25:24.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:25:24.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-09T00:25:54.350+0000] {processor.py:157} INFO - Started process (PID=4934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:25:54.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:25:54.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:25:54.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:25:54.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:25:54.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:25:54.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:25:54.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:25:54.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:25:54.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-09T00:26:24.730+0000] {processor.py:157} INFO - Started process (PID=4944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:26:24.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:26:24.738+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:26:24.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:26:24.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:26:24.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:26:24.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:26:24.826+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:26:24.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:26:24.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-09T00:26:55.038+0000] {processor.py:157} INFO - Started process (PID=4954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:26:55.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:26:55.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:26:55.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:26:55.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:26:55.095+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:26:55.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:26:55.119+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:26:55.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:26:55.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-09T00:27:25.498+0000] {processor.py:157} INFO - Started process (PID=4964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:27:25.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:27:25.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:27:25.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:27:25.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:27:25.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:27:25.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:27:25.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:27:25.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:27:25.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T00:27:55.849+0000] {processor.py:157} INFO - Started process (PID=4974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:27:55.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:27:55.870+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:27:55.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:27:55.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:27:55.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:27:55.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:27:55.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:27:55.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:27:55.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-09T00:28:26.292+0000] {processor.py:157} INFO - Started process (PID=4984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:28:26.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:28:26.296+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:28:26.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:28:26.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:28:26.343+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:28:26.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:28:26.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:28:26.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:28:26.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T00:28:56.577+0000] {processor.py:157} INFO - Started process (PID=4994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:28:56.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:28:56.582+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:28:56.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:28:56.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:28:56.616+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:28:56.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:28:56.627+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:28:56.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:28:56.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T00:29:26.917+0000] {processor.py:157} INFO - Started process (PID=5004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:29:26.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:29:26.922+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:29:26.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:29:26.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:29:26.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:29:26.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:29:26.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:29:26.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:29:26.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T00:29:57.251+0000] {processor.py:157} INFO - Started process (PID=5014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:29:57.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:29:57.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:29:57.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:29:57.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:29:57.281+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:29:57.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:29:57.292+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:29:57.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:29:57.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T00:30:27.577+0000] {processor.py:157} INFO - Started process (PID=5626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:30:27.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:30:27.583+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:30:27.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:30:27.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:30:27.637+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:30:27.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:30:27.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:30:27.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:30:27.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T00:30:57.917+0000] {processor.py:157} INFO - Started process (PID=5636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:30:57.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:30:57.922+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:30:57.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:30:57.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:30:57.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:30:57.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:30:57.983+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:30:57.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:30:57.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-09T00:31:28.337+0000] {processor.py:157} INFO - Started process (PID=5645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:31:28.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:31:28.345+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:31:28.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:31:28.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:31:28.421+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:31:28.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:31:28.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:31:28.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:31:28.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-09T00:31:58.609+0000] {processor.py:157} INFO - Started process (PID=5656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:31:58.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:31:58.612+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:31:58.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:31:58.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:31:58.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:31:58.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:31:58.651+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:31:58.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:31:58.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T00:32:29.081+0000] {processor.py:157} INFO - Started process (PID=5833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:32:29.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:32:29.086+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:32:29.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:32:29.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:32:29.131+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:32:29.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:32:29.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:32:29.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:32:29.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-09T00:32:59.369+0000] {processor.py:157} INFO - Started process (PID=5843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:32:59.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:32:59.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:32:59.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:32:59.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:32:59.410+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:32:59.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:32:59.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:32:59.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:32:59.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T00:33:29.738+0000] {processor.py:157} INFO - Started process (PID=5853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:33:29.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:33:29.743+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:33:29.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:33:29.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:33:29.779+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:33:29.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:33:29.794+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:33:29.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:33:29.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T00:34:00.134+0000] {processor.py:157} INFO - Started process (PID=5863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:34:00.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:34:00.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:34:00.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:34:00.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:34:00.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:34:00.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:34:00.182+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:34:00.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:34:00.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T00:34:30.527+0000] {processor.py:157} INFO - Started process (PID=5873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:34:30.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:34:30.532+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:34:30.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:34:30.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:34:30.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:34:30.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:34:30.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:34:30.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:34:30.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T00:35:00.922+0000] {processor.py:157} INFO - Started process (PID=5883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:35:00.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:35:00.928+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:35:00.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:35:00.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:35:00.984+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:35:00.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:35:01.007+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:35:01.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:35:01.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-09T00:35:31.309+0000] {processor.py:157} INFO - Started process (PID=5893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:35:31.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:35:31.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:35:31.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:35:31.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:35:31.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:35:31.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:35:31.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:35:31.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:35:31.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T00:36:01.591+0000] {processor.py:157} INFO - Started process (PID=5903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:36:01.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:36:01.594+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:36:01.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:36:01.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:36:01.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:36:01.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:36:01.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:36:01.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:36:01.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T00:36:31.956+0000] {processor.py:157} INFO - Started process (PID=5913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:36:31.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:36:31.960+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:36:31.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:36:31.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:36:32.002+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:36:32.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:36:32.015+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:36:32.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:36:32.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T00:37:02.309+0000] {processor.py:157} INFO - Started process (PID=5923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:37:02.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:37:02.312+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:37:02.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:37:02.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:37:02.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:37:02.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:37:02.360+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:37:02.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:37:02.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T00:37:32.685+0000] {processor.py:157} INFO - Started process (PID=5933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:37:32.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:37:32.688+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:37:32.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:37:32.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:37:32.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:37:32.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:37:32.727+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:37:32.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:37:32.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T00:38:03.070+0000] {processor.py:157} INFO - Started process (PID=5943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:38:03.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:38:03.080+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:38:03.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:38:03.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:38:03.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:38:03.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:38:03.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:38:03.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:38:03.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T00:38:33.459+0000] {processor.py:157} INFO - Started process (PID=5953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:38:33.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:38:33.462+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:38:33.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:38:33.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:38:33.495+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:38:33.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:38:33.508+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:38:33.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:38:33.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T00:39:03.838+0000] {processor.py:157} INFO - Started process (PID=5963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:39:03.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:39:03.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:39:03.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:39:03.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:39:03.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:39:03.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:39:03.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:39:03.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:39:03.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T00:39:34.253+0000] {processor.py:157} INFO - Started process (PID=5973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:39:34.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:39:34.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:39:34.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:39:34.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:39:34.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:39:34.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:39:34.305+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:39:34.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:39:34.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T00:40:04.680+0000] {processor.py:157} INFO - Started process (PID=5983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:40:04.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:40:04.689+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:40:04.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:40:04.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:40:04.727+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:40:04.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:40:04.739+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:40:04.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:40:04.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T00:40:35.021+0000] {processor.py:157} INFO - Started process (PID=5993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:40:35.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:40:35.024+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:40:35.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:40:35.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:40:35.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:40:35.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:40:35.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:40:35.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:40:35.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T00:41:05.400+0000] {processor.py:157} INFO - Started process (PID=6003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:41:05.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:41:05.406+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:41:05.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:41:05.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:41:05.440+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:41:05.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:41:05.451+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:41:05.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:41:05.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T00:41:35.703+0000] {processor.py:157} INFO - Started process (PID=6013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:41:35.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:41:35.705+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:41:35.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:41:35.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:41:35.735+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:41:35.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:41:35.751+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:41:35.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:41:35.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T00:42:06.046+0000] {processor.py:157} INFO - Started process (PID=6022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:42:06.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:42:06.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:42:06.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:42:06.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:42:06.092+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:42:06.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:42:06.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:42:06.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:42:06.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T00:42:36.402+0000] {processor.py:157} INFO - Started process (PID=6033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:42:36.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:42:36.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:42:36.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:42:36.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:42:36.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:42:36.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:42:36.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:42:36.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:42:36.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T00:43:06.832+0000] {processor.py:157} INFO - Started process (PID=6042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:43:06.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:43:06.837+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:43:06.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:43:06.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:43:06.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:43:06.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:43:06.907+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:43:06.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:43:06.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T00:43:37.277+0000] {processor.py:157} INFO - Started process (PID=6052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:43:37.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:43:37.283+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:43:37.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:43:37.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:43:37.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:43:37.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:43:37.334+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:43:37.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:43:37.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T00:44:07.610+0000] {processor.py:157} INFO - Started process (PID=6063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:44:07.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:44:07.612+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:44:07.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:44:07.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:44:07.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:44:07.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:44:07.648+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:44:07.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:44:07.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T00:44:38.015+0000] {processor.py:157} INFO - Started process (PID=6073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:44:38.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:44:38.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:44:38.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:44:38.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:44:38.045+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:44:38.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:44:38.060+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:44:38.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:44:38.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T00:45:08.436+0000] {processor.py:157} INFO - Started process (PID=6083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:45:08.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:45:08.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:45:08.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:45:08.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:45:08.483+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:45:08.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:45:08.496+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:45:08.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:45:08.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-09T00:45:38.744+0000] {processor.py:157} INFO - Started process (PID=6093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:45:38.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:45:38.758+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:45:38.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:45:38.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:45:38.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:45:38.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:45:38.831+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:45:38.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:45:38.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-09T00:46:09.008+0000] {processor.py:157} INFO - Started process (PID=6103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:46:09.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:46:09.011+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:46:09.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:46:09.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:46:09.035+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:46:09.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:46:09.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:46:09.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:46:09.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T00:46:39.339+0000] {processor.py:157} INFO - Started process (PID=6113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:46:39.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:46:39.341+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:46:39.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:46:39.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:46:39.368+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:46:39.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:46:39.380+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:46:39.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:46:39.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T00:47:09.740+0000] {processor.py:157} INFO - Started process (PID=6122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:47:09.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:47:09.744+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:47:09.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:47:09.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:47:09.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:47:09.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:47:09.820+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:47:09.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:47:09.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T00:47:40.067+0000] {processor.py:157} INFO - Started process (PID=6133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:47:40.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:47:40.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:47:40.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:47:40.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:47:40.099+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:47:40.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:47:40.116+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:47:40.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:47:40.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T00:48:10.436+0000] {processor.py:157} INFO - Started process (PID=6143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:48:10.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:48:10.439+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:48:10.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:48:10.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:48:10.466+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:48:10.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:48:10.475+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:48:10.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:48:10.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T00:48:40.858+0000] {processor.py:157} INFO - Started process (PID=6153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:48:40.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:48:40.865+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:48:40.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:48:40.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:48:40.900+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:48:40.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:48:40.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:48:40.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:48:40.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T00:49:11.262+0000] {processor.py:157} INFO - Started process (PID=6163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:49:11.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:49:11.264+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:49:11.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:49:11.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:49:11.292+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:49:11.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:49:11.305+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:49:11.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:49:11.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T00:49:41.592+0000] {processor.py:157} INFO - Started process (PID=6173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:49:41.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:49:41.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:49:41.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:49:41.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:49:41.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:49:41.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:49:41.644+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:49:41.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:49:41.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T00:50:11.970+0000] {processor.py:157} INFO - Started process (PID=6183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:50:11.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:50:11.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:50:11.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:50:11.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:50:12.001+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:50:12.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:50:12.015+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:50:12.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:50:12.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T00:50:42.386+0000] {processor.py:157} INFO - Started process (PID=6193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:50:42.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:50:42.390+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:50:42.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:50:42.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:50:42.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:50:42.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:50:42.432+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:50:42.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:50:42.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T00:51:12.762+0000] {processor.py:157} INFO - Started process (PID=6203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:51:12.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:51:12.767+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:51:12.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:51:12.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:51:12.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:51:12.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:51:12.830+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:51:12.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:51:12.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T00:51:43.190+0000] {processor.py:157} INFO - Started process (PID=6213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:51:43.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:51:43.192+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:51:43.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:51:43.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:51:43.218+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:51:43.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:51:43.229+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:51:43.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:51:43.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T00:52:13.584+0000] {processor.py:157} INFO - Started process (PID=6223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:52:13.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:52:13.591+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:52:13.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:52:13.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:52:13.626+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:52:13.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:52:13.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:52:13.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:52:13.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T00:52:43.915+0000] {processor.py:157} INFO - Started process (PID=6233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:52:43.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:52:43.920+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:52:43.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:52:43.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:52:43.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:52:43.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:52:43.955+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:52:43.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:52:43.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T00:53:14.239+0000] {processor.py:157} INFO - Started process (PID=6243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:53:14.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:53:14.242+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:53:14.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:53:14.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:53:14.270+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:53:14.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:53:14.283+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:53:14.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:53:14.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T00:53:44.630+0000] {processor.py:157} INFO - Started process (PID=6253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:53:44.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:53:44.646+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:53:44.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:53:44.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:53:44.695+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:53:44.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:53:44.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:53:44.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:53:44.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-09T00:54:14.962+0000] {processor.py:157} INFO - Started process (PID=6263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:54:14.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:54:14.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:54:14.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:54:14.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:54:14.994+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:54:14.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:54:15.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:54:15.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:54:15.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T00:54:45.472+0000] {processor.py:157} INFO - Started process (PID=6273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:54:45.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:54:45.484+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:54:45.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:54:45.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:54:45.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:54:45.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:54:45.564+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:54:45.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:54:45.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-09T00:55:16.050+0000] {processor.py:157} INFO - Started process (PID=6281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:55:16.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:55:16.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:55:16.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:55:16.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:55:16.108+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:55:16.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:55:16.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:55:16.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:55:16.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T00:55:46.352+0000] {processor.py:157} INFO - Started process (PID=6292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:55:46.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:55:46.358+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:55:46.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:55:46.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:55:46.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:55:46.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:55:46.437+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:55:46.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:55:46.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-09T00:56:16.619+0000] {processor.py:157} INFO - Started process (PID=6303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:56:16.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:56:16.622+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:56:16.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:56:16.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:56:16.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:56:16.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:56:16.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:56:16.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:56:16.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-09T00:56:46.941+0000] {processor.py:157} INFO - Started process (PID=6313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:56:46.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:56:46.946+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:56:46.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:56:46.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:56:46.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:56:46.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:56:47.000+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:56:47.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:56:47.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T00:57:17.306+0000] {processor.py:157} INFO - Started process (PID=6323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:57:17.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:57:17.310+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:57:17.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:57:17.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:57:17.338+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:57:17.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:57:17.352+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:57:17.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:57:17.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T00:57:47.673+0000] {processor.py:157} INFO - Started process (PID=6333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:57:47.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:57:47.678+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:57:47.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:57:47.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:57:47.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:57:47.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:57:47.726+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:57:47.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:57:47.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T00:58:18.040+0000] {processor.py:157} INFO - Started process (PID=6343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:58:18.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:58:18.049+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:58:18.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:58:18.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:58:18.081+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:58:18.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:58:18.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:58:18.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:58:18.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T00:58:48.454+0000] {processor.py:157} INFO - Started process (PID=6352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:58:48.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:58:48.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:58:48.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:58:48.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:58:48.521+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:58:48.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:58:48.534+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:58:48.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:58:48.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T00:59:18.844+0000] {processor.py:157} INFO - Started process (PID=6363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:59:18.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:59:18.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:59:18.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:59:18.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:59:18.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:59:18.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:59:18.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:59:18.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:59:18.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T00:59:49.217+0000] {processor.py:157} INFO - Started process (PID=6373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:59:49.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T00:59:49.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:59:49.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:59:49.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T00:59:49.283+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:59:49.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T00:59:49.298+0000] {logging_mixin.py:151} INFO - [2024-09-09T00:59:49.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-09T00:59:49.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-09T01:00:19.549+0000] {processor.py:157} INFO - Started process (PID=6383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:00:19.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:00:19.559+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:00:19.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:00:19.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:00:19.607+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:00:19.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:00:19.619+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:00:19.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:00:19.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-09T01:00:49.930+0000] {processor.py:157} INFO - Started process (PID=6393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:00:49.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:00:49.936+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:00:49.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:00:49.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:00:49.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:00:49.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:00:50.000+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:00:50.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:00:50.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T01:01:20.256+0000] {processor.py:157} INFO - Started process (PID=6403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:01:20.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:01:20.262+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:01:20.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:01:20.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:01:20.302+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:01:20.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:01:20.314+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:01:20.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:01:20.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T01:01:50.516+0000] {processor.py:157} INFO - Started process (PID=6413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:01:50.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:01:50.519+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:01:50.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:01:50.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:01:50.545+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:01:50.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:01:50.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:01:50.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:01:50.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T01:02:20.903+0000] {processor.py:157} INFO - Started process (PID=6422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:02:20.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:02:20.909+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:02:20.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:02:20.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:02:20.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:02:20.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:02:20.964+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:02:20.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:02:20.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T01:02:51.196+0000] {processor.py:157} INFO - Started process (PID=6433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:02:51.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:02:51.200+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:02:51.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:02:51.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:02:51.231+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:02:51.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:02:51.241+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:02:51.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:02:51.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:03:21.582+0000] {processor.py:157} INFO - Started process (PID=6443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:03:21.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:03:21.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:03:21.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:03:21.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:03:21.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:03:21.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:03:21.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:03:21.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:03:21.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T01:03:52.222+0000] {processor.py:157} INFO - Started process (PID=6453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:03:52.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:03:52.235+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:03:52.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:03:52.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:03:52.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:03:52.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:03:52.306+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:03:52.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:03:52.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-09T01:04:22.628+0000] {processor.py:157} INFO - Started process (PID=6463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:04:22.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:04:22.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:04:22.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:04:22.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:04:22.676+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:04:22.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:04:22.692+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:04:22.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:04:22.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T01:04:53.025+0000] {processor.py:157} INFO - Started process (PID=6473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:04:53.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:04:53.030+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:04:53.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:04:53.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:04:53.084+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:04:53.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:04:53.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:04:53.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:04:53.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T01:05:23.487+0000] {processor.py:157} INFO - Started process (PID=6483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:05:23.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:05:23.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:05:23.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:05:23.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:05:23.580+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:05:23.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:05:23.599+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:05:23.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:05:23.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-09T01:05:54.009+0000] {processor.py:157} INFO - Started process (PID=6493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:05:54.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:05:54.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:05:54.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:05:54.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:05:54.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:05:54.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:05:54.092+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:05:54.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:05:54.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-09T01:06:24.514+0000] {processor.py:157} INFO - Started process (PID=6501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:06:24.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:06:24.521+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:06:24.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:06:24.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:06:24.589+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:06:24.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:06:24.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:06:24.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:06:24.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-09T01:06:54.816+0000] {processor.py:157} INFO - Started process (PID=6513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:06:54.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:06:54.823+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:06:54.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:06:54.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:06:54.872+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:06:54.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:06:54.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:06:54.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:06:54.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-09T01:07:25.175+0000] {processor.py:157} INFO - Started process (PID=6523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:07:25.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:07:25.178+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:07:25.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:07:25.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:07:25.216+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:07:25.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:07:25.232+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:07:25.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:07:25.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T01:07:55.554+0000] {processor.py:157} INFO - Started process (PID=6533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:07:55.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:07:55.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:07:55.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:07:55.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:07:55.611+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:07:55.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:07:55.630+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:07:55.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:07:55.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T01:08:25.999+0000] {processor.py:157} INFO - Started process (PID=6543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:08:26.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:08:26.009+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:08:26.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:08:26.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:08:26.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:08:26.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:08:26.071+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:08:26.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:08:26.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T01:08:56.284+0000] {processor.py:157} INFO - Started process (PID=6553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:08:56.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:08:56.287+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:08:56.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:08:56.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:08:56.315+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:08:56.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:08:56.327+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:08:56.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:08:56.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T01:09:26.688+0000] {processor.py:157} INFO - Started process (PID=6562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:09:26.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:09:26.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:09:26.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:09:26.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:09:26.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:09:26.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:09:26.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:09:26.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:09:26.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-09T01:09:57.108+0000] {processor.py:157} INFO - Started process (PID=6573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:09:57.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:09:57.112+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:09:57.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:09:57.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:09:57.140+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:09:57.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:09:57.153+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:09:57.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:09:57.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T01:10:27.498+0000] {processor.py:157} INFO - Started process (PID=6582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:10:27.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:10:27.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:10:27.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:10:27.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:10:27.539+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:10:27.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:10:27.552+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:10:27.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:10:27.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T01:10:57.877+0000] {processor.py:157} INFO - Started process (PID=6593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:10:57.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:10:57.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:10:57.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:10:57.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:10:57.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:10:57.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:10:57.921+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:10:57.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:10:57.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:11:28.198+0000] {processor.py:157} INFO - Started process (PID=6603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:11:28.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:11:28.202+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:11:28.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:11:28.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:11:28.236+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:11:28.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:11:28.249+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:11:28.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:11:28.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T01:11:58.701+0000] {processor.py:157} INFO - Started process (PID=6613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:11:58.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:11:58.713+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:11:58.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:11:58.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:11:58.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:11:58.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:11:58.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:11:58.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:11:58.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T01:12:29.034+0000] {processor.py:157} INFO - Started process (PID=6623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:12:29.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:12:29.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:12:29.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:12:29.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:12:29.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:12:29.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:12:29.157+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:12:29.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:12:29.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-09T01:12:59.387+0000] {processor.py:157} INFO - Started process (PID=6633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:12:59.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:12:59.393+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:12:59.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:12:59.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:12:59.450+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:12:59.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:12:59.463+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:12:59.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:12:59.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T01:13:29.827+0000] {processor.py:157} INFO - Started process (PID=6643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:13:29.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:13:29.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:13:29.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:13:29.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:13:29.913+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:13:29.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:13:29.927+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:13:29.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:13:29.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T01:14:00.210+0000] {processor.py:157} INFO - Started process (PID=6653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:14:00.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:14:00.224+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:14:00.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:14:00.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:14:00.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:14:00.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:14:00.331+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:14:00.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:14:00.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-09T01:14:30.721+0000] {processor.py:157} INFO - Started process (PID=6662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:14:30.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:14:30.743+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:14:30.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:14:30.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:14:30.878+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:14:30.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:14:30.897+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:14:30.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:14:30.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-09-09T01:15:01.033+0000] {processor.py:157} INFO - Started process (PID=6673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:15:01.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:15:01.039+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:15:01.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:15:01.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:15:01.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:15:01.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:15:01.115+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:15:01.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:15:01.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-09T01:15:31.439+0000] {processor.py:157} INFO - Started process (PID=6682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:15:31.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:15:31.445+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:15:31.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:15:31.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:15:31.492+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:15:31.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:15:31.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:15:31.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:15:31.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T01:16:01.768+0000] {processor.py:157} INFO - Started process (PID=6692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:16:01.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:16:01.772+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:16:01.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:16:01.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:16:01.798+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:16:01.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:16:01.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:16:01.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:16:01.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T01:16:32.158+0000] {processor.py:157} INFO - Started process (PID=6703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:16:32.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:16:32.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:16:32.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:16:32.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:16:32.202+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:16:32.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:16:32.214+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:16:32.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:16:32.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T01:17:02.435+0000] {processor.py:157} INFO - Started process (PID=6713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:17:02.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:17:02.439+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:17:02.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:17:02.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:17:02.464+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:17:02.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:17:02.475+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:17:02.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:17:02.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T01:17:32.810+0000] {processor.py:157} INFO - Started process (PID=6723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:17:32.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:17:32.811+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:17:32.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:17:32.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:17:32.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:17:32.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:17:32.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:17:32.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:17:32.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T01:18:03.121+0000] {processor.py:157} INFO - Started process (PID=6733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:18:03.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:18:03.125+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:18:03.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:18:03.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:18:03.153+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:18:03.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:18:03.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:18:03.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:18:03.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T01:18:33.429+0000] {processor.py:157} INFO - Started process (PID=6743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:18:33.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:18:33.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:18:33.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:18:33.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:18:33.458+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:18:33.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:18:33.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:18:33.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:18:33.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T01:19:03.777+0000] {processor.py:157} INFO - Started process (PID=6753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:19:03.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:19:03.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:19:03.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:19:03.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:19:03.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:19:03.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:19:03.819+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:19:03.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:19:03.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T01:19:34.131+0000] {processor.py:157} INFO - Started process (PID=6763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:19:34.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:19:34.134+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:19:34.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:19:34.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:19:34.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:19:34.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:19:34.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:19:34.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:19:34.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T01:20:04.473+0000] {processor.py:157} INFO - Started process (PID=6773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:20:04.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:20:04.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:20:04.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:20:04.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:20:04.514+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:20:04.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:20:04.527+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:20:04.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:20:04.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T01:20:34.881+0000] {processor.py:157} INFO - Started process (PID=6783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:20:34.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:20:34.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:20:34.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:20:34.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:20:34.911+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:20:34.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:20:34.922+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:20:34.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:20:34.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T01:21:05.228+0000] {processor.py:157} INFO - Started process (PID=6793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:21:05.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:21:05.231+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:21:05.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:21:05.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:21:05.258+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:21:05.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:21:05.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:21:05.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:21:05.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T01:21:35.557+0000] {processor.py:157} INFO - Started process (PID=6803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:21:35.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:21:35.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:21:35.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:21:35.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:21:35.586+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:21:35.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:21:35.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:21:35.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:21:35.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T01:22:05.937+0000] {processor.py:157} INFO - Started process (PID=6813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:22:05.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:22:05.942+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:22:05.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:22:05.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:22:05.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:22:05.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:22:05.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:22:05.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:22:06.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T01:22:36.268+0000] {processor.py:157} INFO - Started process (PID=6823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:22:36.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:22:36.272+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:22:36.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:22:36.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:22:36.302+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:22:36.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:22:36.313+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:22:36.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:22:36.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:23:06.648+0000] {processor.py:157} INFO - Started process (PID=6833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:23:06.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:23:06.653+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:23:06.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:23:06.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:23:06.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:23:06.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:23:06.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:23:06.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:23:06.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T01:23:37.022+0000] {processor.py:157} INFO - Started process (PID=6843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:23:37.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:23:37.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:23:37.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:23:37.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:23:37.054+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:23:37.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:23:37.064+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:23:37.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:23:37.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T01:24:07.433+0000] {processor.py:157} INFO - Started process (PID=6853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:24:07.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:24:07.438+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:24:07.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:24:07.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:24:07.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:24:07.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:24:07.490+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:24:07.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:24:07.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T01:24:37.855+0000] {processor.py:157} INFO - Started process (PID=6863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:24:37.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:24:37.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:24:37.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:24:37.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:24:37.889+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:24:37.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:24:37.901+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:24:37.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:24:37.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T01:25:08.170+0000] {processor.py:157} INFO - Started process (PID=6873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:25:08.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:25:08.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:25:08.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:25:08.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:25:08.199+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:25:08.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:25:08.208+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:25:08.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:25:08.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T01:25:38.567+0000] {processor.py:157} INFO - Started process (PID=6883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:25:38.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:25:38.572+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:25:38.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:25:38.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:25:38.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:25:38.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:25:38.622+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:25:38.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:25:38.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T01:26:08.866+0000] {processor.py:157} INFO - Started process (PID=6893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:26:08.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:26:08.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:26:08.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:26:08.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:26:08.935+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:26:08.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:26:08.949+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:26:08.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:26:08.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-09T01:26:39.205+0000] {processor.py:157} INFO - Started process (PID=6903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:26:39.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:26:39.208+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:26:39.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:26:39.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:26:39.239+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:26:39.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:26:39.249+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:26:39.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:26:39.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T01:27:09.542+0000] {processor.py:157} INFO - Started process (PID=6913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:27:09.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:27:09.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:27:09.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:27:09.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:27:09.574+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:27:09.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:27:09.585+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:27:09.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:27:09.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T01:27:39.875+0000] {processor.py:157} INFO - Started process (PID=6923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:27:39.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:27:39.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:27:39.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:27:39.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:27:39.907+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:27:39.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:27:39.916+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:27:39.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:27:39.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T01:28:10.261+0000] {processor.py:157} INFO - Started process (PID=6933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:28:10.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:28:10.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:28:10.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:28:10.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:28:10.304+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:28:10.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:28:10.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:28:10.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:28:10.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T01:28:40.587+0000] {processor.py:157} INFO - Started process (PID=6943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:28:40.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:28:40.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:28:40.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:28:40.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:28:40.620+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:28:40.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:28:40.630+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:28:40.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:28:40.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T01:29:10.957+0000] {processor.py:157} INFO - Started process (PID=6953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:29:10.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:29:10.961+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:29:10.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:29:10.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:29:10.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:29:10.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:29:10.997+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:29:10.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:29:11.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T01:29:41.350+0000] {processor.py:157} INFO - Started process (PID=6963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:29:41.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:29:41.354+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:29:41.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:29:41.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:29:41.383+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:29:41.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:29:41.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:29:41.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:29:41.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:30:11.730+0000] {processor.py:157} INFO - Started process (PID=6972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:30:11.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:30:11.736+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:30:11.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:30:11.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:30:11.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:30:11.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:30:11.788+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:30:11.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:30:11.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T01:30:42.141+0000] {processor.py:157} INFO - Started process (PID=6983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:30:42.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:30:42.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:30:42.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:30:42.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:30:42.205+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:30:42.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:30:42.220+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:30:42.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:30:42.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T01:31:12.582+0000] {processor.py:157} INFO - Started process (PID=6993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:31:12.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:31:12.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:31:12.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:31:12.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:31:12.615+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:31:12.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:31:12.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:31:12.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:31:12.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T01:31:42.922+0000] {processor.py:157} INFO - Started process (PID=7003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:31:42.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:31:42.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:31:42.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:31:42.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:31:42.958+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:31:42.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:31:42.968+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:31:42.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:31:42.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T01:32:13.257+0000] {processor.py:157} INFO - Started process (PID=7013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:32:13.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:32:13.261+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:32:13.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:32:13.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:32:13.300+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:32:13.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:32:13.313+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:32:13.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:32:13.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T01:32:43.659+0000] {processor.py:157} INFO - Started process (PID=7023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:32:43.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:32:43.662+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:32:43.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:32:43.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:32:43.692+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:32:43.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:32:43.705+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:32:43.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:32:43.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:33:14.036+0000] {processor.py:157} INFO - Started process (PID=7033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:33:14.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:33:14.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:33:14.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:33:14.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:33:14.066+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:33:14.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:33:14.076+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:33:14.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:33:14.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:33:44.441+0000] {processor.py:157} INFO - Started process (PID=7043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:33:44.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:33:44.447+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:33:44.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:33:44.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:33:44.486+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:33:44.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:33:44.497+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:33:44.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:33:44.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T01:34:14.803+0000] {processor.py:157} INFO - Started process (PID=7053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:34:14.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:34:14.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:34:14.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:34:14.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:34:14.837+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:34:14.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:34:14.850+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:34:14.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:34:14.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T01:34:45.141+0000] {processor.py:157} INFO - Started process (PID=7063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:34:45.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:34:45.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:34:45.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:34:45.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:34:45.174+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:34:45.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:34:45.185+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:34:45.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:34:45.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T01:35:15.448+0000] {processor.py:157} INFO - Started process (PID=7073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:35:15.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:35:15.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:35:15.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:35:15.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:35:15.499+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:35:15.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:35:15.514+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:35:15.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:35:15.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T01:35:45.819+0000] {processor.py:157} INFO - Started process (PID=7083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:35:45.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:35:45.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:35:45.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:35:45.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:35:45.864+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:35:45.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:35:45.877+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:35:45.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:35:45.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T01:36:16.223+0000] {processor.py:157} INFO - Started process (PID=7093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:36:16.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:36:16.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:36:16.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:36:16.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:36:16.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:36:16.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:36:16.276+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:36:16.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:36:16.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T01:36:46.567+0000] {processor.py:157} INFO - Started process (PID=7103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:36:46.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:36:46.573+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:36:46.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:36:46.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:36:46.609+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:36:46.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:36:46.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:36:46.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:36:46.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T01:37:16.965+0000] {processor.py:157} INFO - Started process (PID=7113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:37:16.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:37:16.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:37:16.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:37:16.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:37:17.019+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:37:17.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:37:17.029+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:37:17.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:37:17.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-09T01:37:47.234+0000] {processor.py:157} INFO - Started process (PID=7123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:37:47.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:37:47.237+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:37:47.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:37:47.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:37:47.261+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:37:47.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:37:47.273+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:37:47.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:37:47.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T01:38:17.532+0000] {processor.py:157} INFO - Started process (PID=7132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:38:17.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:38:17.536+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:38:17.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:38:17.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:38:17.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:38:17.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:38:17.581+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:38:17.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:38:17.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T01:38:47.841+0000] {processor.py:157} INFO - Started process (PID=7143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:38:47.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:38:47.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:38:47.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:38:47.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:38:47.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:38:47.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:38:47.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:38:47.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:38:47.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T01:39:18.148+0000] {processor.py:157} INFO - Started process (PID=7153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:39:18.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:39:18.151+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:39:18.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:39:18.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:39:18.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:39:18.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:39:18.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:39:18.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:39:18.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T01:39:48.481+0000] {processor.py:157} INFO - Started process (PID=7163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:39:48.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:39:48.486+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:39:48.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:39:48.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:39:48.517+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:39:48.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:39:48.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:39:48.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:39:48.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T01:40:18.859+0000] {processor.py:157} INFO - Started process (PID=7173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:40:18.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:40:18.862+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:40:18.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:40:18.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:40:18.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:40:18.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:40:18.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:40:18.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:40:18.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T01:40:49.256+0000] {processor.py:157} INFO - Started process (PID=7183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:40:49.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:40:49.260+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:40:49.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:40:49.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:40:49.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:40:49.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:40:49.305+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:40:49.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:40:49.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T01:41:19.635+0000] {processor.py:157} INFO - Started process (PID=7193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:41:19.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:41:19.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:41:19.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:41:19.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:41:19.678+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:41:19.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:41:19.688+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:41:19.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:41:19.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T01:41:50.021+0000] {processor.py:157} INFO - Started process (PID=7203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:41:50.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:41:50.025+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:41:50.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:41:50.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:41:50.051+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:41:50.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:41:50.061+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:41:50.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:41:50.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T01:42:20.388+0000] {processor.py:157} INFO - Started process (PID=7213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:42:20.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:42:20.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:42:20.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:42:20.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:42:20.418+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:42:20.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:42:20.428+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:42:20.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:42:20.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:42:50.689+0000] {processor.py:157} INFO - Started process (PID=7223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:42:50.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:42:50.692+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:42:50.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:42:50.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:42:50.724+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:42:50.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:42:50.735+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:42:50.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:42:50.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:43:21.073+0000] {processor.py:157} INFO - Started process (PID=7233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:43:21.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:43:21.078+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:43:21.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:43:21.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:43:21.114+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:43:21.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:43:21.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:43:21.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:43:21.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T01:43:51.508+0000] {processor.py:157} INFO - Started process (PID=7243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:43:51.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:43:51.512+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:43:51.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:43:51.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:43:51.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:43:51.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:43:51.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:43:51.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:43:51.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:44:21.882+0000] {processor.py:157} INFO - Started process (PID=7253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:44:21.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:44:21.885+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:44:21.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:44:21.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:44:21.915+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:44:21.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:44:21.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:44:21.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:44:21.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T01:44:52.238+0000] {processor.py:157} INFO - Started process (PID=7263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:44:52.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:44:52.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:44:52.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:44:52.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:44:52.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:44:52.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:44:52.278+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:44:52.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:44:52.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T01:45:22.619+0000] {processor.py:157} INFO - Started process (PID=7273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:45:22.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:45:22.626+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:45:22.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:45:22.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:45:22.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:45:22.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:45:22.672+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:45:22.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:45:22.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T01:45:53.048+0000] {processor.py:157} INFO - Started process (PID=7283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:45:53.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:45:53.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:45:53.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:45:53.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:45:53.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:45:53.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:45:53.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:45:53.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:45:53.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T01:46:23.405+0000] {processor.py:157} INFO - Started process (PID=7293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:46:23.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:46:23.410+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:46:23.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:46:23.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:46:23.439+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:46:23.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:46:23.451+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:46:23.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:46:23.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T01:46:53.724+0000] {processor.py:157} INFO - Started process (PID=7303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:46:53.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:46:53.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:46:53.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:46:53.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:46:53.760+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:46:53.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:46:53.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:46:53.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:46:53.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T01:47:24.022+0000] {processor.py:157} INFO - Started process (PID=7313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:47:24.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:47:24.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:47:24.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:47:24.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:47:24.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:47:24.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:47:24.068+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:47:24.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:47:24.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T01:47:54.345+0000] {processor.py:157} INFO - Started process (PID=7323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:47:54.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:47:54.349+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:47:54.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:47:54.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:47:54.378+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:47:54.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:47:54.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:47:54.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:47:54.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:48:24.727+0000] {processor.py:157} INFO - Started process (PID=7333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:48:24.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:48:24.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:48:24.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:48:24.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:48:24.759+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:48:24.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:48:24.770+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:48:24.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:48:24.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T01:48:55.064+0000] {processor.py:157} INFO - Started process (PID=7343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:48:55.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:48:55.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:48:55.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:48:55.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:48:55.105+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:48:55.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:48:55.117+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:48:55.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:48:55.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T01:49:25.455+0000] {processor.py:157} INFO - Started process (PID=7353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:49:25.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:49:25.458+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:49:25.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:49:25.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:49:25.487+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:49:25.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:49:25.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:49:25.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:49:25.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:49:55.862+0000] {processor.py:157} INFO - Started process (PID=7363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:49:55.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:49:55.865+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:49:55.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:49:55.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:49:55.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:49:55.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:49:55.905+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:49:55.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:49:55.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:50:26.201+0000] {processor.py:157} INFO - Started process (PID=7373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:50:26.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:50:26.204+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:50:26.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:50:26.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:50:26.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:50:26.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:50:26.244+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:50:26.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:50:26.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T01:50:56.640+0000] {processor.py:157} INFO - Started process (PID=7383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:50:56.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:50:56.647+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:50:56.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:50:56.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:50:56.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:50:56.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:50:56.691+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:50:56.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:50:56.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T01:51:26.955+0000] {processor.py:157} INFO - Started process (PID=7393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:51:26.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:51:26.958+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:51:26.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:51:26.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:51:26.989+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:51:26.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:51:26.999+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:51:26.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:51:27.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:51:57.328+0000] {processor.py:157} INFO - Started process (PID=7403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:51:57.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:51:57.333+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:51:57.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:51:57.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:51:57.360+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:51:57.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:51:57.372+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:51:57.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:51:57.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T01:52:27.711+0000] {processor.py:157} INFO - Started process (PID=7413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:52:27.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:52:27.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:52:27.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:52:27.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:52:27.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:52:27.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:52:27.752+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:52:27.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:52:27.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T01:52:58.013+0000] {processor.py:157} INFO - Started process (PID=7423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:52:58.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:52:58.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:52:58.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:52:58.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:52:58.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:52:58.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:52:58.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:52:58.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:52:58.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T01:53:28.446+0000] {processor.py:157} INFO - Started process (PID=7433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:53:28.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:53:28.463+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:53:28.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:53:28.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:53:28.506+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:53:28.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:53:28.520+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:53:28.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:53:28.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-09T01:53:58.838+0000] {processor.py:157} INFO - Started process (PID=7443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:53:58.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:53:58.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:53:58.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:53:58.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:53:58.873+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:53:58.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:53:58.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:53:58.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:53:58.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T01:54:29.239+0000] {processor.py:157} INFO - Started process (PID=7453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:54:29.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:54:29.244+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:54:29.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:54:29.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:54:29.271+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:54:29.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:54:29.281+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:54:29.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:54:29.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:54:59.695+0000] {processor.py:157} INFO - Started process (PID=7463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:54:59.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:54:59.701+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:54:59.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:54:59.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:54:59.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:54:59.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:54:59.768+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:54:59.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:54:59.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T01:55:29.999+0000] {processor.py:157} INFO - Started process (PID=7473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:55:30.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:55:30.003+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:55:30.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:55:30.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:55:30.028+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:55:30.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:55:30.037+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:55:30.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:55:30.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T01:56:00.320+0000] {processor.py:157} INFO - Started process (PID=7483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:56:00.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:56:00.324+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:56:00.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:56:00.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:56:00.359+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:56:00.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:56:00.368+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:56:00.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:56:00.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T01:56:30.629+0000] {processor.py:157} INFO - Started process (PID=7493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:56:30.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:56:30.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:56:30.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:56:30.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:56:30.694+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:56:30.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:56:30.706+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:56:30.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:56:30.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T01:57:01.045+0000] {processor.py:157} INFO - Started process (PID=7502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:57:01.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:57:01.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:57:01.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:57:01.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:57:01.078+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:57:01.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:57:01.088+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:57:01.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:57:01.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T01:57:31.381+0000] {processor.py:157} INFO - Started process (PID=7513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:57:31.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:57:31.384+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:57:31.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:57:31.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:57:31.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:57:31.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:57:31.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:57:31.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:57:31.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T01:58:01.760+0000] {processor.py:157} INFO - Started process (PID=7523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:58:01.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:58:01.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:58:01.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:58:01.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:58:01.791+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:58:01.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:58:01.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:58:01.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:58:01.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T01:58:32.132+0000] {processor.py:157} INFO - Started process (PID=7533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:58:32.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:58:32.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:58:32.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:58:32.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:58:32.162+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:58:32.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:58:32.175+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:58:32.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:58:32.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T01:59:02.490+0000] {processor.py:157} INFO - Started process (PID=7543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:59:02.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:59:02.497+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:59:02.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:59:02.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:59:02.552+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:59:02.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:59:02.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:59:02.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:59:02.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T01:59:32.776+0000] {processor.py:157} INFO - Started process (PID=7553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:59:32.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T01:59:32.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:59:32.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:59:32.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T01:59:32.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:59:32.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T01:59:32.821+0000] {logging_mixin.py:151} INFO - [2024-09-09T01:59:32.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T01:59:32.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T02:00:03.162+0000] {processor.py:157} INFO - Started process (PID=7563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:00:03.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:00:03.166+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:00:03.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:00:03.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:00:03.210+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:00:03.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:00:03.223+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:00:03.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:00:03.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T02:00:33.615+0000] {processor.py:157} INFO - Started process (PID=7572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:00:33.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:00:33.646+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:00:33.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:00:33.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:00:33.874+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:00:33.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:00:34.111+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:00:34.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:00:34.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.552 seconds
[2024-09-09T02:01:04.530+0000] {processor.py:157} INFO - Started process (PID=7583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:01:04.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:01:04.540+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:01:04.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:01:04.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:01:04.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:01:04.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:01:04.659+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:01:04.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:01:04.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-09T02:01:34.827+0000] {processor.py:157} INFO - Started process (PID=7593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:01:34.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:01:34.837+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:01:34.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:01:34.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:01:34.920+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:01:34.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:01:34.942+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:01:34.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:01:34.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-09T02:02:05.218+0000] {processor.py:157} INFO - Started process (PID=7603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:02:05.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:02:05.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:02:05.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:02:05.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:02:05.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:02:05.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:02:05.352+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:02:05.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:02:05.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-09T02:02:35.468+0000] {processor.py:157} INFO - Started process (PID=7613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:02:35.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:02:35.476+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:02:35.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:02:35.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:02:35.528+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:02:35.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:02:35.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:02:35.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:02:35.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-09T02:03:05.835+0000] {processor.py:157} INFO - Started process (PID=7623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:03:05.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:03:05.847+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:03:05.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:03:05.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:03:05.924+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:03:05.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:03:05.941+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:03:05.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:03:05.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-09T02:03:36.170+0000] {processor.py:157} INFO - Started process (PID=7633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:03:36.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:03:36.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:03:36.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:03:36.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:03:36.247+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:03:36.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:03:36.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:03:36.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:03:36.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T02:04:06.467+0000] {processor.py:157} INFO - Started process (PID=7643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:04:06.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:04:06.476+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:04:06.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:04:06.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:04:06.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:04:06.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:04:06.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:04:06.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:04:06.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-09T02:04:36.758+0000] {processor.py:157} INFO - Started process (PID=7653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:04:36.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:04:36.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:04:36.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:04:36.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:04:36.844+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:04:36.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:04:36.865+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:04:36.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:04:36.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-09T02:05:07.220+0000] {processor.py:157} INFO - Started process (PID=7663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:05:07.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:05:07.242+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:05:07.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:05:07.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:05:07.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:05:07.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:05:07.343+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:05:07.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:05:07.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-09T02:05:37.681+0000] {processor.py:157} INFO - Started process (PID=7673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:05:37.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:05:37.692+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:05:37.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:05:37.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:05:37.771+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:05:37.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:05:37.792+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:05:37.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:05:37.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-09T02:06:07.995+0000] {processor.py:157} INFO - Started process (PID=7683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:06:08.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:06:08.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:06:08.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:06:08.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:06:08.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:06:08.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:06:08.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:06:08.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:06:08.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-09T02:06:38.364+0000] {processor.py:157} INFO - Started process (PID=7692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:06:38.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:06:38.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:06:38.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:06:38.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:06:38.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:06:38.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:06:38.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:06:38.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:06:38.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-09T02:07:08.699+0000] {processor.py:157} INFO - Started process (PID=7703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:07:08.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:07:08.707+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:07:08.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:07:08.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:07:08.778+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:07:08.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:07:08.800+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:07:08.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:07:08.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T02:07:39.253+0000] {processor.py:157} INFO - Started process (PID=7713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:07:39.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:07:39.259+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:07:39.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:07:39.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:07:39.336+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:07:39.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:07:39.358+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:07:39.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:07:39.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-09T02:08:09.500+0000] {processor.py:157} INFO - Started process (PID=7723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:08:09.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:08:09.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:08:09.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:08:09.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:08:09.539+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:08:09.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:08:09.553+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:08:09.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:08:09.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T02:08:40.094+0000] {processor.py:157} INFO - Started process (PID=7733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:08:40.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:08:40.105+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:08:40.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:08:40.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:08:40.215+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:08:40.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:08:40.238+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:08:40.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:08:40.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-09T02:09:10.370+0000] {processor.py:157} INFO - Started process (PID=7743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:09:10.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:09:10.373+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:09:10.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:09:10.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:09:10.417+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:09:10.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:09:10.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:09:10.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:09:10.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T02:09:40.784+0000] {processor.py:157} INFO - Started process (PID=7753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:09:40.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:09:40.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:09:40.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:09:40.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:09:40.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:09:40.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:09:40.904+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:09:40.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:09:40.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-09T02:10:11.173+0000] {processor.py:157} INFO - Started process (PID=7763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:10:11.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:10:11.182+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:10:11.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:10:11.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:10:11.245+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:10:11.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:10:11.265+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:10:11.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:10:11.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-09T02:10:41.639+0000] {processor.py:157} INFO - Started process (PID=7773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:10:41.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:10:41.646+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:10:41.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:10:41.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:10:41.709+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:10:41.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:10:41.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:10:41.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:10:41.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-09T02:11:12.158+0000] {processor.py:157} INFO - Started process (PID=7783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:11:12.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:11:12.167+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:11:12.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:11:12.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:11:12.242+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:11:12.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:11:12.264+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:11:12.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:11:12.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-09T02:11:42.416+0000] {processor.py:157} INFO - Started process (PID=7793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:11:42.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:11:42.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:11:42.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:11:42.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:11:42.463+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:11:42.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:11:42.475+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:11:42.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:11:42.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T02:12:12.876+0000] {processor.py:157} INFO - Started process (PID=7803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:12:12.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:12:12.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:12:12.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:12:12.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:12:12.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:12:12.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:12:12.985+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:12:12.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:12:12.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-09T02:12:43.299+0000] {processor.py:157} INFO - Started process (PID=7813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:12:43.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:12:43.304+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:12:43.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:12:43.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:12:43.351+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:12:43.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:12:43.369+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:12:43.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:12:43.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-09T02:13:13.566+0000] {processor.py:157} INFO - Started process (PID=7823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:13:13.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:13:13.572+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:13:13.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:13:13.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:13:13.626+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:13:13.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:13:13.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:13:13.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:13:13.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T02:13:43.960+0000] {processor.py:157} INFO - Started process (PID=7833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:13:43.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:13:43.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:13:43.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:13:43.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:13:44.052+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:13:44.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:13:44.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:13:44.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:13:44.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-09T02:14:14.221+0000] {processor.py:157} INFO - Started process (PID=7843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:14:14.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:14:14.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:14:14.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:14:14.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:14:14.265+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:14:14.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:14:14.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:14:14.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:14:14.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T02:14:44.590+0000] {processor.py:157} INFO - Started process (PID=7852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:14:44.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:14:44.604+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:14:44.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:14:44.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:14:44.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:14:44.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:14:44.717+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:14:44.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:14:44.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-09T02:15:14.897+0000] {processor.py:157} INFO - Started process (PID=7863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:15:14.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:15:14.907+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:15:14.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:15:14.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:15:14.955+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:15:14.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:15:14.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:15:14.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:15:14.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T02:15:45.195+0000] {processor.py:157} INFO - Started process (PID=7873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:15:45.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:15:45.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:15:45.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:15:45.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:15:45.253+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:15:45.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:15:45.273+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:15:45.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:15:45.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T02:16:15.482+0000] {processor.py:157} INFO - Started process (PID=7883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:16:15.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:16:15.495+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:16:15.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:16:15.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:16:15.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:16:15.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:16:15.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:16:15.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:16:15.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-09T02:16:45.759+0000] {processor.py:157} INFO - Started process (PID=7893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:16:45.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:16:45.768+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:16:45.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:16:45.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:16:45.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:16:45.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:16:45.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:16:45.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:16:45.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T02:17:16.077+0000] {processor.py:157} INFO - Started process (PID=7903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:17:16.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:17:16.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:17:16.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:17:16.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:17:16.132+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:17:16.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:17:16.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:17:16.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:17:16.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T02:17:46.395+0000] {processor.py:157} INFO - Started process (PID=7913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:17:46.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:17:46.408+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:17:46.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:17:46.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:17:46.465+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:17:46.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:17:46.485+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:17:46.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:17:46.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-09T02:18:16.697+0000] {processor.py:157} INFO - Started process (PID=7922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:18:16.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:18:16.706+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:18:16.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:18:16.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:18:16.774+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:18:16.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:18:16.810+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:18:16.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:18:16.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-09T02:18:47.117+0000] {processor.py:157} INFO - Started process (PID=7933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:18:47.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:18:47.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:18:47.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:18:47.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:18:47.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:18:47.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:18:47.182+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:18:47.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:18:47.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T02:19:17.470+0000] {processor.py:157} INFO - Started process (PID=7943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:19:17.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:19:17.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:19:17.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:19:17.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:19:17.527+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:19:17.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:19:17.545+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:19:17.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:19:17.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T02:19:47.844+0000] {processor.py:157} INFO - Started process (PID=7953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:19:47.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:19:47.850+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:19:47.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:19:47.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:19:47.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:19:47.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:19:47.912+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:19:47.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:19:47.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T02:20:18.193+0000] {processor.py:157} INFO - Started process (PID=7963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:20:18.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:20:18.200+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:20:18.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:20:18.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:20:18.270+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:20:18.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:20:18.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:20:18.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:20:18.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T02:20:48.512+0000] {processor.py:157} INFO - Started process (PID=7973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:20:48.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:20:48.517+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:20:48.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:20:48.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:20:48.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:20:48.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:20:48.588+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:20:48.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:20:48.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-09T02:21:18.867+0000] {processor.py:157} INFO - Started process (PID=7983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:21:18.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:21:18.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:21:18.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:21:18.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:21:18.904+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:21:18.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:21:18.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:21:18.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:21:18.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T02:21:49.189+0000] {processor.py:157} INFO - Started process (PID=7993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:21:49.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:21:49.192+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:21:49.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:21:49.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:21:49.225+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:21:49.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:21:49.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:21:49.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:21:49.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T02:22:19.526+0000] {processor.py:157} INFO - Started process (PID=8002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:22:19.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:22:19.532+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:22:19.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:22:19.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:22:19.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:22:19.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:22:19.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:22:19.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:22:19.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-09T02:22:49.775+0000] {processor.py:157} INFO - Started process (PID=8013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:22:49.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:22:49.787+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:22:49.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:22:49.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:22:49.851+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:22:49.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:22:49.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:22:49.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:22:49.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T02:23:20.139+0000] {processor.py:157} INFO - Started process (PID=8023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:23:20.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:23:20.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:23:20.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:23:20.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:23:20.184+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:23:20.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:23:20.198+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:23:20.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:23:20.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T02:23:50.518+0000] {processor.py:157} INFO - Started process (PID=8032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:23:50.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:23:50.526+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:23:50.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:23:50.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:23:50.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:23:50.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:23:50.628+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:23:50.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:23:50.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-09T02:24:20.834+0000] {processor.py:157} INFO - Started process (PID=8043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:24:20.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:24:20.842+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:24:20.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:24:20.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:24:20.898+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:24:20.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:24:20.916+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:24:20.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:24:20.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-09T02:24:51.138+0000] {processor.py:157} INFO - Started process (PID=8053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:24:51.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:24:51.143+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:24:51.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:24:51.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:24:51.202+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:24:51.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:24:51.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:24:51.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:24:51.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-09T02:25:21.490+0000] {processor.py:157} INFO - Started process (PID=8063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:25:21.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:25:21.508+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:25:21.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:25:21.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:25:21.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:25:21.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:25:21.586+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:25:21.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:25:21.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-09T02:25:51.854+0000] {processor.py:157} INFO - Started process (PID=8073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:25:51.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:25:51.863+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:25:51.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:25:51.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:25:51.912+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:25:51.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:25:51.928+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:25:51.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:25:51.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T02:26:22.287+0000] {processor.py:157} INFO - Started process (PID=8083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:26:22.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:26:22.300+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:26:22.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:26:22.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:26:22.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:26:22.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:26:22.414+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:26:22.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:26:22.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-09T02:26:52.618+0000] {processor.py:157} INFO - Started process (PID=8093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:26:52.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:26:52.626+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:26:52.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:26:52.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:26:52.735+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:26:52.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:26:52.757+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:26:52.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:26:52.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-09T02:27:22.969+0000] {processor.py:157} INFO - Started process (PID=8102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:27:22.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:27:22.995+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:27:22.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:27:23.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:27:23.074+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:27:23.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:27:23.118+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:27:23.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:27:23.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-09-09T02:27:53.341+0000] {processor.py:157} INFO - Started process (PID=8112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:27:53.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:27:53.353+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:27:53.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:27:53.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:27:53.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:27:53.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:27:53.440+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:27:53.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:27:53.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-09T02:28:23.611+0000] {processor.py:157} INFO - Started process (PID=8123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:28:23.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:28:23.617+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:28:23.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:28:23.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:28:23.665+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:28:23.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:28:23.684+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:28:23.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:28:23.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T02:28:53.891+0000] {processor.py:157} INFO - Started process (PID=8133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:28:53.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:28:53.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:28:53.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:28:53.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:28:53.944+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:28:53.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:28:53.962+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:28:53.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:28:53.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-09T02:29:24.290+0000] {processor.py:157} INFO - Started process (PID=8143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:29:24.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:29:24.300+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:29:24.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:29:24.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:29:24.367+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:29:24.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:29:24.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:29:24.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:29:24.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-09T02:29:54.670+0000] {processor.py:157} INFO - Started process (PID=8152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:29:54.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:29:54.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:29:54.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:29:54.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:29:54.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:29:54.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:29:54.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:29:54.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:29:54.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T02:30:25.060+0000] {processor.py:157} INFO - Started process (PID=8163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:30:25.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:30:25.069+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:30:25.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:30:25.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:30:25.138+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:30:25.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:30:25.156+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:30:25.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:30:25.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T02:30:55.382+0000] {processor.py:157} INFO - Started process (PID=8173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:30:55.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:30:55.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:30:55.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:30:55.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:30:55.426+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:30:55.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:30:55.446+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:30:55.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:30:55.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T02:31:25.735+0000] {processor.py:157} INFO - Started process (PID=8183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:31:25.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:31:25.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:31:25.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:31:25.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:31:25.812+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:31:25.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:31:25.837+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:31:25.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:31:25.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-09T02:31:56.111+0000] {processor.py:157} INFO - Started process (PID=8193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:31:56.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:31:56.115+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:31:56.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:31:56.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:31:56.148+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:31:56.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:31:56.165+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:31:56.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:31:56.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T02:32:26.397+0000] {processor.py:157} INFO - Started process (PID=8203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:32:26.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:32:26.402+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:32:26.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:32:26.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:32:26.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:32:26.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:32:26.465+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:32:26.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:32:26.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T02:32:56.735+0000] {processor.py:157} INFO - Started process (PID=8212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:32:56.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:32:56.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:32:56.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:32:56.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:32:56.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:32:56.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:32:56.864+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:32:56.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:32:56.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-09T02:33:26.976+0000] {processor.py:157} INFO - Started process (PID=8223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:33:26.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:33:26.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:33:26.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:33:26.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:33:27.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:33:27.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:33:27.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:33:27.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:33:27.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T02:33:57.282+0000] {processor.py:157} INFO - Started process (PID=8233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:33:57.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:33:57.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:33:57.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:33:57.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:33:57.378+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:33:57.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:33:57.413+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:33:57.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:33:57.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-09T02:34:27.527+0000] {processor.py:157} INFO - Started process (PID=8243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:34:27.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:34:27.531+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:34:27.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:34:27.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:34:27.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:34:27.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:34:27.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:34:27.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:34:27.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T02:34:57.837+0000] {processor.py:157} INFO - Started process (PID=8252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:34:57.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:34:57.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:34:57.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:34:57.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:34:57.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:34:57.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:34:57.948+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:34:57.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:34:57.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-09T02:35:28.095+0000] {processor.py:157} INFO - Started process (PID=8263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:35:28.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:35:28.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:35:28.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:35:28.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:35:28.148+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:35:28.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:35:28.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:35:28.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:35:28.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T02:35:58.539+0000] {processor.py:157} INFO - Started process (PID=8273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:35:58.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:35:58.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:35:58.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:35:58.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:35:58.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:35:58.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:35:58.651+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:35:58.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:35:58.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-09T02:36:28.833+0000] {processor.py:157} INFO - Started process (PID=8282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:36:28.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:36:28.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:36:28.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:36:28.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:36:28.920+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:36:28.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:36:28.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:36:28.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:36:28.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-09T02:36:59.130+0000] {processor.py:157} INFO - Started process (PID=8293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:36:59.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:36:59.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:36:59.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:36:59.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:36:59.208+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:36:59.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:36:59.231+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:36:59.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:36:59.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T02:37:29.407+0000] {processor.py:157} INFO - Started process (PID=8303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:37:29.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:37:29.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:37:29.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:37:29.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:37:29.465+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:37:29.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:37:29.496+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:37:29.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:37:29.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-09T02:37:59.713+0000] {processor.py:157} INFO - Started process (PID=8313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:37:59.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:37:59.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:37:59.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:37:59.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:37:59.788+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:37:59.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:37:59.805+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:37:59.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:37:59.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-09T02:38:30.038+0000] {processor.py:157} INFO - Started process (PID=8322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:38:30.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:38:30.047+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:38:30.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:38:30.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:38:30.107+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:38:30.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:38:30.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:38:30.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:38:30.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-09T02:39:00.310+0000] {processor.py:157} INFO - Started process (PID=8333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:39:00.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:39:00.320+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:39:00.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:39:00.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:39:00.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:39:00.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:39:00.370+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:39:00.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:39:00.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T02:39:30.698+0000] {processor.py:157} INFO - Started process (PID=8343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:39:30.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:39:30.722+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:39:30.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:39:30.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:39:30.793+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:39:30.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:39:30.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:39:30.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:39:30.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-09T02:40:00.953+0000] {processor.py:157} INFO - Started process (PID=8353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:40:00.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:40:00.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:40:00.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:40:00.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:40:00.998+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:40:00.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:40:01.015+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:40:01.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:40:01.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T02:40:31.333+0000] {processor.py:157} INFO - Started process (PID=8362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:40:31.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:40:31.341+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:40:31.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:40:31.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:40:31.411+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:40:31.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:40:31.430+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:40:31.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:40:31.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-09T02:41:01.630+0000] {processor.py:157} INFO - Started process (PID=8372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:41:01.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:41:01.638+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:41:01.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:41:01.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:41:01.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:41:01.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:41:01.738+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:41:01.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:41:01.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-09T02:41:31.876+0000] {processor.py:157} INFO - Started process (PID=8383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:41:31.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:41:31.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:41:31.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:41:31.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:41:31.921+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:41:31.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:41:31.937+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:41:31.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:41:31.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T02:42:02.215+0000] {processor.py:157} INFO - Started process (PID=8393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:42:02.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:42:02.224+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:42:02.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:42:02.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:42:02.273+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:42:02.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:42:02.292+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:42:02.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:42:02.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-09T02:42:32.431+0000] {processor.py:157} INFO - Started process (PID=8403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:42:32.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:42:32.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:42:32.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:42:32.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:42:32.466+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:42:32.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:42:32.483+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:42:32.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:42:32.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T02:43:02.810+0000] {processor.py:157} INFO - Started process (PID=8413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:43:02.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:43:02.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:43:02.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:43:02.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:43:02.882+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:43:02.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:43:02.907+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:43:02.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:43:02.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-09T02:43:33.149+0000] {processor.py:157} INFO - Started process (PID=8423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:43:33.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:43:33.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:43:33.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:43:33.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:43:33.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:43:33.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:43:33.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:43:33.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:43:33.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-09T02:44:03.417+0000] {processor.py:157} INFO - Started process (PID=8433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:44:03.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:44:03.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:44:03.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:44:03.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:44:03.457+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:44:03.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:44:03.473+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:44:03.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:44:03.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T02:44:33.744+0000] {processor.py:157} INFO - Started process (PID=8443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:44:33.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:44:33.751+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:44:33.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:44:33.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:44:33.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:44:33.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:44:33.847+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:44:33.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:44:33.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-09T02:45:04.013+0000] {processor.py:157} INFO - Started process (PID=8453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:45:04.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:45:04.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:45:04.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:45:04.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:45:04.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:45:04.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:45:04.074+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:45:04.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:45:04.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T02:45:34.342+0000] {processor.py:157} INFO - Started process (PID=8463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:45:34.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:45:34.347+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:45:34.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:45:34.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:45:34.383+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:45:34.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:45:34.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:45:34.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:45:34.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T02:46:04.710+0000] {processor.py:157} INFO - Started process (PID=8473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:46:04.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:46:04.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:46:04.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:46:04.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:46:04.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:46:04.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:46:04.819+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:46:04.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:46:04.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-09T02:46:35.017+0000] {processor.py:157} INFO - Started process (PID=8482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:46:35.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:46:35.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:46:35.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:46:35.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:46:35.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:46:35.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:46:35.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:46:35.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:46:35.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-09T02:47:05.470+0000] {processor.py:157} INFO - Started process (PID=8492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:47:05.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:47:05.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:47:05.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:47:05.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:47:05.543+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:47:05.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:47:05.566+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:47:05.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:47:05.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-09T02:47:35.732+0000] {processor.py:157} INFO - Started process (PID=8503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:47:35.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:47:35.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:47:35.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:47:35.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:47:35.835+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:47:35.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:47:35.857+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:47:35.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:47:35.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-09T02:48:06.045+0000] {processor.py:157} INFO - Started process (PID=8513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:48:06.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:48:06.051+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:48:06.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:48:06.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:48:06.084+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:48:06.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:48:06.098+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:48:06.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:48:06.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T02:48:36.380+0000] {processor.py:157} INFO - Started process (PID=8523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:48:36.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:48:36.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:48:36.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:48:36.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:48:36.429+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:48:36.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:48:36.446+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:48:36.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:48:36.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T02:49:06.709+0000] {processor.py:157} INFO - Started process (PID=8533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:49:06.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:49:06.717+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:49:06.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:49:06.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:49:06.789+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:49:06.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:49:06.821+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:49:06.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:49:06.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-09T02:49:37.023+0000] {processor.py:157} INFO - Started process (PID=8543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:49:37.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:49:37.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:49:37.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:49:37.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:49:37.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:49:37.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:49:37.122+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:49:37.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:49:37.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-09T02:50:07.659+0000] {processor.py:157} INFO - Started process (PID=8553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:50:07.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:50:07.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:50:07.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:50:07.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:50:07.724+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:50:07.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:50:07.740+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:50:07.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:50:07.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-09T02:50:38.091+0000] {processor.py:157} INFO - Started process (PID=8563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:50:38.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:50:38.097+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:50:38.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:50:38.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:50:38.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:50:38.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:50:38.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:50:38.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:50:38.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T02:51:08.386+0000] {processor.py:157} INFO - Started process (PID=8573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:51:08.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:51:08.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:51:08.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:51:08.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:51:08.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:51:08.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:51:08.432+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:51:08.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:51:08.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T02:51:38.773+0000] {processor.py:157} INFO - Started process (PID=8583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:51:38.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:51:38.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:51:38.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:51:38.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:51:38.828+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:51:38.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:51:38.847+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:51:38.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:51:38.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T02:52:09.069+0000] {processor.py:157} INFO - Started process (PID=8593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:52:09.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:52:09.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:52:09.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:52:09.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:52:09.102+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:52:09.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:52:09.115+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:52:09.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:52:09.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T02:52:39.448+0000] {processor.py:157} INFO - Started process (PID=8603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:52:39.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:52:39.473+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:52:39.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:52:39.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:52:39.522+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:52:39.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:52:39.538+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:52:39.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:52:39.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-09T02:53:09.722+0000] {processor.py:157} INFO - Started process (PID=8613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:53:09.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:53:09.725+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:53:09.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:53:09.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:53:09.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:53:09.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:53:09.766+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:53:09.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:53:09.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T02:53:40.100+0000] {processor.py:157} INFO - Started process (PID=8623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:53:40.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:53:40.106+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:53:40.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:53:40.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:53:40.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:53:40.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:53:40.157+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:53:40.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:53:40.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T02:54:10.412+0000] {processor.py:157} INFO - Started process (PID=8633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:54:10.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:54:10.417+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:54:10.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:54:10.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:54:10.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:54:10.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:54:10.466+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:54:10.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:54:10.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T02:54:40.712+0000] {processor.py:157} INFO - Started process (PID=8643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:54:40.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:54:40.716+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:54:40.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:54:40.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:54:40.743+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:54:40.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:54:40.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:54:40.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:54:40.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T02:55:11.014+0000] {processor.py:157} INFO - Started process (PID=8653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:55:11.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:55:11.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:55:11.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:55:11.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:55:11.045+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:55:11.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:55:11.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:55:11.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:55:11.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T02:55:41.400+0000] {processor.py:157} INFO - Started process (PID=8663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:55:41.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:55:41.404+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:55:41.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:55:41.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:55:41.440+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:55:41.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:55:41.451+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:55:41.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:55:41.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T02:56:11.686+0000] {processor.py:157} INFO - Started process (PID=8673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:56:11.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:56:11.688+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:56:11.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:56:11.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:56:11.718+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:56:11.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:56:11.730+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:56:11.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:56:11.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T02:56:42.007+0000] {processor.py:157} INFO - Started process (PID=8683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:56:42.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:56:42.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:56:42.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:56:42.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:56:42.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:56:42.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:56:42.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:56:42.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:56:42.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T02:57:12.377+0000] {processor.py:157} INFO - Started process (PID=8693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:57:12.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:57:12.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:57:12.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:57:12.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:57:12.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:57:12.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:57:12.428+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:57:12.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:57:12.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T02:57:42.733+0000] {processor.py:157} INFO - Started process (PID=8703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:57:42.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:57:42.736+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:57:42.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:57:42.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:57:42.767+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:57:42.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:57:42.778+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:57:42.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:57:42.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T02:58:13.080+0000] {processor.py:157} INFO - Started process (PID=8713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:58:13.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:58:13.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:58:13.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:58:13.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:58:13.109+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:58:13.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:58:13.119+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:58:13.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:58:13.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T02:58:43.442+0000] {processor.py:157} INFO - Started process (PID=8723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:58:43.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:58:43.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:58:43.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:58:43.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:58:43.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:58:43.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:58:43.489+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:58:43.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:58:43.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T02:59:13.798+0000] {processor.py:157} INFO - Started process (PID=8733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:59:13.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:59:13.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:59:13.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:59:13.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:59:13.835+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:59:13.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:59:13.844+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:59:13.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:59:13.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T02:59:44.133+0000] {processor.py:157} INFO - Started process (PID=8743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:59:44.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T02:59:44.136+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:59:44.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:59:44.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T02:59:44.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:59:44.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T02:59:44.176+0000] {logging_mixin.py:151} INFO - [2024-09-09T02:59:44.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T02:59:44.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T03:00:14.478+0000] {processor.py:157} INFO - Started process (PID=8752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:00:14.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:00:14.484+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:00:14.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:00:14.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:00:14.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:00:14.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:00:14.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:00:14.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:00:14.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T03:00:44.745+0000] {processor.py:157} INFO - Started process (PID=8763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:00:44.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:00:44.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:00:44.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:00:44.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:00:44.785+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:00:44.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:00:44.795+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:00:44.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:00:44.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T03:01:15.067+0000] {processor.py:157} INFO - Started process (PID=8773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:01:15.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:01:15.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:01:15.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:01:15.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:01:15.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:01:15.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:01:15.111+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:01:15.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:01:15.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T03:01:45.398+0000] {processor.py:157} INFO - Started process (PID=8783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:01:45.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:01:45.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:01:45.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:01:45.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:01:45.443+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:01:45.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:01:45.456+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:01:45.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:01:45.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T03:02:15.711+0000] {processor.py:157} INFO - Started process (PID=8793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:02:15.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:02:15.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:02:15.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:02:15.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:02:15.741+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:02:15.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:02:15.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:02:15.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:02:15.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:02:46.091+0000] {processor.py:157} INFO - Started process (PID=8803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:02:46.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:02:46.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:02:46.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:02:46.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:02:46.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:02:46.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:02:46.147+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:02:46.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:02:46.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T03:03:16.471+0000] {processor.py:157} INFO - Started process (PID=8813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:03:16.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:03:16.476+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:03:16.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:03:16.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:03:16.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:03:16.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:03:16.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:03:16.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:03:16.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T03:03:46.821+0000] {processor.py:157} INFO - Started process (PID=8823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:03:46.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:03:46.824+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:03:46.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:03:46.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:03:46.849+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:03:46.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:03:46.860+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:03:46.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:03:46.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:04:17.098+0000] {processor.py:157} INFO - Started process (PID=8833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:04:17.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:04:17.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:04:17.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:04:17.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:04:17.130+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:04:17.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:04:17.139+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:04:17.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:04:17.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:04:47.391+0000] {processor.py:157} INFO - Started process (PID=8843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:04:47.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:04:47.394+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:04:47.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:04:47.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:04:47.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:04:47.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:04:47.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:04:47.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:04:47.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T03:05:17.770+0000] {processor.py:157} INFO - Started process (PID=8853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:05:17.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:05:17.772+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:05:17.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:05:17.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:05:17.800+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:05:17.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:05:17.810+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:05:17.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:05:17.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:05:48.133+0000] {processor.py:157} INFO - Started process (PID=8863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:05:48.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:05:48.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:05:48.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:05:48.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:05:48.169+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:05:48.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:05:48.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:05:48.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:05:48.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T03:06:18.402+0000] {processor.py:157} INFO - Started process (PID=8873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:06:18.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:06:18.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:06:18.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:06:18.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:06:18.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:06:18.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:06:18.446+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:06:18.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:06:18.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:06:48.696+0000] {processor.py:157} INFO - Started process (PID=8883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:06:48.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:06:48.700+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:06:48.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:06:48.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:06:48.726+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:06:48.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:06:48.739+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:06:48.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:06:48.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:07:19.018+0000] {processor.py:157} INFO - Started process (PID=8893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:07:19.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:07:19.021+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:07:19.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:07:19.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:07:19.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:07:19.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:07:19.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:07:19.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:07:19.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T03:07:49.324+0000] {processor.py:157} INFO - Started process (PID=8903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:07:49.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:07:49.328+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:07:49.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:07:49.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:07:49.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:07:49.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:07:49.364+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:07:49.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:07:49.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:08:19.651+0000] {processor.py:157} INFO - Started process (PID=8913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:08:19.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:08:19.654+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:08:19.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:08:19.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:08:19.676+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:08:19.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:08:19.685+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:08:19.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:08:19.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T03:08:49.911+0000] {processor.py:157} INFO - Started process (PID=8923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:08:49.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:08:49.915+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:08:49.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:08:49.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:08:49.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:08:49.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:08:49.949+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:08:49.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:08:49.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:09:20.250+0000] {processor.py:157} INFO - Started process (PID=8933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:09:20.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:09:20.253+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:09:20.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:09:20.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:09:20.278+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:09:20.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:09:20.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:09:20.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:09:20.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:09:50.625+0000] {processor.py:157} INFO - Started process (PID=8943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:09:50.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:09:50.632+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:09:50.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:09:50.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:09:50.666+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:09:50.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:09:50.678+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:09:50.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:09:50.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T03:10:20.922+0000] {processor.py:157} INFO - Started process (PID=8953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:10:20.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:10:20.927+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:10:20.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:10:20.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:10:20.953+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:10:20.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:10:20.963+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:10:20.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:10:20.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:10:51.260+0000] {processor.py:157} INFO - Started process (PID=8963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:10:51.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:10:51.261+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:10:51.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:10:51.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:10:51.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:10:51.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:10:51.297+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:10:51.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:10:51.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T03:11:21.609+0000] {processor.py:157} INFO - Started process (PID=8973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:11:21.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:11:21.612+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:11:21.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:11:21.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:11:21.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:11:21.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:11:21.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:11:21.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:11:21.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T03:11:51.918+0000] {processor.py:157} INFO - Started process (PID=8983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:11:51.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:11:51.921+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:11:51.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:11:51.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:11:51.949+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:11:51.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:11:51.962+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:11:51.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:11:51.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T03:12:22.252+0000] {processor.py:157} INFO - Started process (PID=8993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:12:22.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:12:22.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:12:22.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:12:22.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:12:22.283+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:12:22.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:12:22.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:12:22.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:12:22.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:12:52.587+0000] {processor.py:157} INFO - Started process (PID=9003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:12:52.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:12:52.590+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:12:52.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:12:52.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:12:52.616+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:12:52.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:12:52.628+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:12:52.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:12:52.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:13:22.885+0000] {processor.py:157} INFO - Started process (PID=9013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:13:22.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:13:22.887+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:13:22.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:13:22.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:13:22.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:13:22.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:13:22.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:13:22.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:13:22.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T03:13:53.206+0000] {processor.py:157} INFO - Started process (PID=9023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:13:53.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:13:53.209+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:13:53.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:13:53.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:13:53.235+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:13:53.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:13:53.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:13:53.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:13:53.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:14:23.522+0000] {processor.py:157} INFO - Started process (PID=9033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:14:23.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:14:23.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:14:23.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:14:23.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:14:23.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:14:23.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:14:23.559+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:14:23.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:14:23.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T03:14:53.870+0000] {processor.py:157} INFO - Started process (PID=9043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:14:53.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:14:53.872+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:14:53.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:14:53.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:14:53.896+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:14:53.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:14:53.909+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:14:53.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:14:53.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:15:24.209+0000] {processor.py:157} INFO - Started process (PID=9053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:15:24.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:15:24.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:15:24.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:15:24.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:15:24.239+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:15:24.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:15:24.249+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:15:24.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:15:24.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:15:54.555+0000] {processor.py:157} INFO - Started process (PID=9063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:15:54.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:15:54.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:15:54.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:15:54.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:15:54.584+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:15:54.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:15:54.594+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:15:54.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:15:54.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:16:24.952+0000] {processor.py:157} INFO - Started process (PID=9073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:16:24.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:16:24.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:16:24.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:16:24.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:16:24.983+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:16:24.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:16:24.993+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:16:24.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:16:25.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:16:55.339+0000] {processor.py:157} INFO - Started process (PID=9083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:16:55.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:16:55.344+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:16:55.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:16:55.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:16:55.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:16:55.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:16:55.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:16:55.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:16:55.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T03:17:25.742+0000] {processor.py:157} INFO - Started process (PID=9093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:17:25.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:17:25.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:17:25.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:17:25.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:17:25.775+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:17:25.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:17:25.784+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:17:25.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:17:25.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:17:56.112+0000] {processor.py:157} INFO - Started process (PID=9103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:17:56.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:17:56.115+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:17:56.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:17:56.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:17:56.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:17:56.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:17:56.155+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:17:56.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:17:56.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:18:26.508+0000] {processor.py:157} INFO - Started process (PID=9113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:18:26.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:18:26.510+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:18:26.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:18:26.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:18:26.535+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:18:26.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:18:26.548+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:18:26.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:18:26.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:18:56.826+0000] {processor.py:157} INFO - Started process (PID=9123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:18:56.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:18:56.830+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:18:56.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:18:56.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:18:56.857+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:18:56.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:18:56.866+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:18:56.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:18:56.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:19:27.159+0000] {processor.py:157} INFO - Started process (PID=9133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:19:27.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:19:27.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:19:27.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:19:27.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:19:27.190+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:19:27.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:19:27.203+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:19:27.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:19:27.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:19:57.511+0000] {processor.py:157} INFO - Started process (PID=9143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:19:57.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:19:57.515+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:19:57.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:19:57.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:19:57.543+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:19:57.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:19:57.552+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:19:57.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:19:57.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:20:27.831+0000] {processor.py:157} INFO - Started process (PID=9153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:20:27.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:20:27.833+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:20:27.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:20:27.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:20:27.859+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:20:27.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:20:27.870+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:20:27.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:20:27.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:20:58.228+0000] {processor.py:157} INFO - Started process (PID=9163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:20:58.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:20:58.232+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:20:58.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:20:58.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:20:58.258+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:20:58.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:20:58.269+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:20:58.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:20:58.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:21:28.557+0000] {processor.py:157} INFO - Started process (PID=9173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:21:28.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:21:28.561+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:21:28.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:21:28.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:21:28.595+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:21:28.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:21:28.607+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:21:28.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:21:28.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T03:21:58.906+0000] {processor.py:157} INFO - Started process (PID=9183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:21:58.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:21:58.909+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:21:58.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:21:58.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:21:58.936+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:21:58.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:21:58.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:21:58.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:21:58.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:22:29.253+0000] {processor.py:157} INFO - Started process (PID=9193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:22:29.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:22:29.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:22:29.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:22:29.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:22:29.285+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:22:29.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:22:29.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:22:29.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:22:29.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:22:59.629+0000] {processor.py:157} INFO - Started process (PID=9203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:22:59.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:22:59.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:22:59.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:22:59.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:22:59.660+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:22:59.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:22:59.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:22:59.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:22:59.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:23:30.007+0000] {processor.py:157} INFO - Started process (PID=9212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:23:30.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:23:30.010+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:23:30.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:23:30.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:23:30.037+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:23:30.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:23:30.047+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:23:30.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:23:30.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T03:24:00.384+0000] {processor.py:157} INFO - Started process (PID=9223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:24:00.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:24:00.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:24:00.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:24:00.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:24:00.413+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:24:00.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:24:00.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:24:00.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:24:00.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:24:30.715+0000] {processor.py:157} INFO - Started process (PID=9233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:24:30.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:24:30.718+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:24:30.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:24:30.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:24:30.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:24:30.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:24:30.757+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:24:30.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:24:30.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:25:01.078+0000] {processor.py:157} INFO - Started process (PID=9243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:25:01.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:25:01.084+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:25:01.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:25:01.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:25:01.111+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:25:01.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:25:01.121+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:25:01.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:25:01.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T03:25:31.449+0000] {processor.py:157} INFO - Started process (PID=9253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:25:31.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:25:31.452+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:25:31.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:25:31.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:25:31.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:25:31.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:25:31.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:25:31.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:25:31.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T03:26:01.849+0000] {processor.py:157} INFO - Started process (PID=9263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:26:01.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:26:01.853+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:26:01.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:26:01.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:26:01.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:26:01.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:26:01.893+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:26:01.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:26:01.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T03:26:32.201+0000] {processor.py:157} INFO - Started process (PID=9273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:26:32.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:26:32.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:26:32.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:26:32.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:26:32.242+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:26:32.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:26:32.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:26:32.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:26:32.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T03:27:02.587+0000] {processor.py:157} INFO - Started process (PID=9283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:27:02.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:27:02.589+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:27:02.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:27:02.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:27:02.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:27:02.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:27:02.629+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:27:02.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:27:02.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:27:32.992+0000] {processor.py:157} INFO - Started process (PID=9293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:27:32.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:27:32.995+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:27:32.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:27:33.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:27:33.020+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:27:33.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:27:33.030+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:27:33.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:27:33.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:28:03.356+0000] {processor.py:157} INFO - Started process (PID=9303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:28:03.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:28:03.360+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:28:03.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:28:03.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:28:03.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:28:03.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:28:03.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:28:03.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:28:03.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:28:33.718+0000] {processor.py:157} INFO - Started process (PID=9313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:28:33.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:28:33.721+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:28:33.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:28:33.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:28:33.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:28:33.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:28:33.759+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:28:33.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:28:33.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T03:29:04.048+0000] {processor.py:157} INFO - Started process (PID=9323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:29:04.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:29:04.051+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:29:04.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:29:04.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:29:04.079+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:29:04.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:29:04.089+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:29:04.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:29:04.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:29:34.342+0000] {processor.py:157} INFO - Started process (PID=9333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:29:34.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:29:34.346+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:29:34.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:29:34.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:29:34.377+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:29:34.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:29:34.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:29:34.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:29:34.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T03:30:04.749+0000] {processor.py:157} INFO - Started process (PID=9343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:30:04.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:30:04.752+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:30:04.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:30:04.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:30:04.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:30:04.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:30:04.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:30:04.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:30:04.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:30:35.059+0000] {processor.py:157} INFO - Started process (PID=9353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:30:35.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:30:35.062+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:30:35.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:30:35.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:30:35.086+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:30:35.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:30:35.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:30:35.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:30:35.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T03:31:05.412+0000] {processor.py:157} INFO - Started process (PID=9363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:31:05.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:31:05.418+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:31:05.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:31:05.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:31:05.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:31:05.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:31:05.466+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:31:05.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:31:05.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T03:31:35.807+0000] {processor.py:157} INFO - Started process (PID=9373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:31:35.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:31:35.812+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:31:35.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:31:35.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:31:35.838+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:31:35.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:31:35.848+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:31:35.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:31:35.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:32:06.206+0000] {processor.py:157} INFO - Started process (PID=9383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:32:06.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:32:06.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:32:06.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:32:06.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:32:06.236+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:32:06.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:32:06.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:32:06.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:32:06.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:32:36.552+0000] {processor.py:157} INFO - Started process (PID=9393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:32:36.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:32:36.555+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:32:36.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:32:36.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:32:36.584+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:32:36.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:32:36.597+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:32:36.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:32:36.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T03:33:06.929+0000] {processor.py:157} INFO - Started process (PID=9403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:33:06.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:33:06.933+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:33:06.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:33:06.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:33:06.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:33:06.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:33:06.967+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:33:06.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:33:06.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:33:37.317+0000] {processor.py:157} INFO - Started process (PID=9413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:33:37.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:33:37.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:33:37.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:33:37.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:33:37.347+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:33:37.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:33:37.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:33:37.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:33:37.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:34:07.727+0000] {processor.py:157} INFO - Started process (PID=9423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:34:07.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:34:07.733+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:34:07.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:34:07.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:34:07.767+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:34:07.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:34:07.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:34:07.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:34:07.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T03:34:38.108+0000] {processor.py:157} INFO - Started process (PID=9433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:34:38.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:34:38.112+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:34:38.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:34:38.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:34:38.140+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:34:38.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:34:38.150+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:34:38.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:34:38.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:35:08.477+0000] {processor.py:157} INFO - Started process (PID=9443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:35:08.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:35:08.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:35:08.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:35:08.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:35:08.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:35:08.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:35:08.520+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:35:08.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:35:08.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:35:38.815+0000] {processor.py:157} INFO - Started process (PID=9453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:35:38.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:35:38.817+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:35:38.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:35:38.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:35:38.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:35:38.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:35:38.854+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:35:38.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:35:38.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:36:09.158+0000] {processor.py:157} INFO - Started process (PID=9463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:36:09.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:36:09.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:36:09.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:36:09.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:36:09.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:36:09.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:36:09.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:36:09.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:36:09.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:36:39.512+0000] {processor.py:157} INFO - Started process (PID=9473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:36:39.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:36:39.515+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:36:39.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:36:39.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:36:39.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:36:39.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:36:39.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:36:39.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:36:39.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:37:09.865+0000] {processor.py:157} INFO - Started process (PID=9483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:37:09.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:37:09.867+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:37:09.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:37:09.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:37:09.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:37:09.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:37:09.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:37:09.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:37:09.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:37:40.227+0000] {processor.py:157} INFO - Started process (PID=9493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:37:40.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:37:40.232+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:37:40.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:37:40.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:37:40.257+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:37:40.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:37:40.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:37:40.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:37:40.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:38:10.576+0000] {processor.py:157} INFO - Started process (PID=9503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:38:10.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:38:10.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:38:10.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:38:10.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:38:10.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:38:10.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:38:10.621+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:38:10.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:38:10.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T03:38:40.895+0000] {processor.py:157} INFO - Started process (PID=9513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:38:40.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:38:40.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:38:40.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:38:40.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:38:40.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:38:40.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:38:40.936+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:38:40.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:38:40.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:39:11.252+0000] {processor.py:157} INFO - Started process (PID=9523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:39:11.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:39:11.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:39:11.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:39:11.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:39:11.281+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:39:11.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:39:11.295+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:39:11.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:39:11.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:39:41.617+0000] {processor.py:157} INFO - Started process (PID=9533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:39:41.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:39:41.620+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:39:41.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:39:41.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:39:41.647+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:39:41.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:39:41.658+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:39:41.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:39:41.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:40:11.950+0000] {processor.py:157} INFO - Started process (PID=9543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:40:11.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:40:11.958+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:40:11.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:40:11.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:40:11.982+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:40:11.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:40:11.993+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:40:11.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:40:12.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:40:42.352+0000] {processor.py:157} INFO - Started process (PID=9553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:40:42.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:40:42.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:40:42.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:40:42.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:40:42.383+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:40:42.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:40:42.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:40:42.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:40:42.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:41:12.714+0000] {processor.py:157} INFO - Started process (PID=9563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:41:12.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:41:12.718+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:41:12.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:41:12.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:41:12.743+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:41:12.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:41:12.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:41:12.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:41:12.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:41:43.038+0000] {processor.py:157} INFO - Started process (PID=9573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:41:43.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:41:43.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:41:43.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:41:43.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:41:43.066+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:41:43.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:41:43.078+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:41:43.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:41:43.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:42:13.345+0000] {processor.py:157} INFO - Started process (PID=9583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:42:13.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:42:13.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:42:13.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:42:13.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:42:13.383+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:42:13.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:42:13.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:42:13.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:42:13.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T03:42:43.658+0000] {processor.py:157} INFO - Started process (PID=9593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:42:43.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:42:43.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:42:43.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:42:43.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:42:43.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:42:43.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:42:43.698+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:42:43.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:42:43.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:43:14.008+0000] {processor.py:157} INFO - Started process (PID=9603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:43:14.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:43:14.011+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:43:14.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:43:14.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:43:14.041+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:43:14.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:43:14.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:43:14.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:43:14.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:43:44.391+0000] {processor.py:157} INFO - Started process (PID=9613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:43:44.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:43:44.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:43:44.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:43:44.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:43:44.425+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:43:44.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:43:44.438+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:43:44.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:43:44.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T03:44:14.745+0000] {processor.py:157} INFO - Started process (PID=9623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:44:14.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:44:14.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:44:14.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:44:14.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:44:14.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:44:14.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:44:14.782+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:44:14.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:44:14.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:44:45.089+0000] {processor.py:157} INFO - Started process (PID=9633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:44:45.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:44:45.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:44:45.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:44:45.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:44:45.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:44:45.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:44:45.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:44:45.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:44:45.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T03:45:15.525+0000] {processor.py:157} INFO - Started process (PID=9643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:45:15.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:45:15.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:45:15.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:45:15.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:45:15.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:45:15.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:45:15.574+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:45:15.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:45:15.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T03:45:45.877+0000] {processor.py:157} INFO - Started process (PID=9653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:45:45.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:45:45.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:45:45.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:45:45.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:45:45.907+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:45:45.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:45:45.916+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:45:45.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:45:45.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T03:46:16.171+0000] {processor.py:157} INFO - Started process (PID=9663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:46:16.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:46:16.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:46:16.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:46:16.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:46:16.204+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:46:16.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:46:16.214+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:46:16.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:46:16.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:46:46.533+0000] {processor.py:157} INFO - Started process (PID=9673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:46:46.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:46:46.537+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:46:46.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:46:46.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:46:46.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:46:46.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:46:46.578+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:46:46.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:46:46.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:47:16.922+0000] {processor.py:157} INFO - Started process (PID=9683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:47:16.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:47:16.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:47:16.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:47:16.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:47:16.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:47:16.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:47:16.960+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:47:16.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:47:16.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T03:47:47.227+0000] {processor.py:157} INFO - Started process (PID=9693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:47:47.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:47:47.229+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:47:47.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:47:47.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:47:47.258+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:47:47.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:47:47.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:47:47.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:47:47.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:48:17.576+0000] {processor.py:157} INFO - Started process (PID=9703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:48:17.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:48:17.580+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:48:17.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:48:17.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:48:17.607+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:48:17.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:48:17.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:48:17.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:48:17.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:48:47.884+0000] {processor.py:157} INFO - Started process (PID=9713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:48:47.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:48:47.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:48:47.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:48:47.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:48:47.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:48:47.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:48:47.937+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:48:47.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:48:47.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T03:49:18.139+0000] {processor.py:157} INFO - Started process (PID=9723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:49:18.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:49:18.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:49:18.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:49:18.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:49:18.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:49:18.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:49:18.182+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:49:18.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:49:18.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:49:48.503+0000] {processor.py:157} INFO - Started process (PID=9733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:49:48.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:49:48.506+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:49:48.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:49:48.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:49:48.531+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:49:48.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:49:48.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:49:48.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:49:48.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T03:50:18.847+0000] {processor.py:157} INFO - Started process (PID=9743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:50:18.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:50:18.857+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:50:18.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:50:18.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:50:18.904+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:50:18.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:50:18.918+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:50:18.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:50:18.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T03:50:49.194+0000] {processor.py:157} INFO - Started process (PID=9753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:50:49.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:50:49.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:50:49.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:50:49.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:50:49.230+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:50:49.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:50:49.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:50:49.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:50:49.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T03:51:19.513+0000] {processor.py:157} INFO - Started process (PID=9763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:51:19.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:51:19.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:51:19.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:51:19.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:51:19.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:51:19.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:51:19.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:51:19.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:51:19.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T03:51:49.893+0000] {processor.py:157} INFO - Started process (PID=9773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:51:49.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:51:49.896+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:51:49.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:51:49.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:51:49.927+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:51:49.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:51:49.937+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:51:49.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:51:49.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T03:52:20.245+0000] {processor.py:157} INFO - Started process (PID=9783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:52:20.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:52:20.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:52:20.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:52:20.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:52:20.281+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:52:20.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:52:20.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:52:20.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:52:20.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T03:52:50.679+0000] {processor.py:157} INFO - Started process (PID=9793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:52:50.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:52:50.684+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:52:50.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:52:50.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:52:50.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:52:50.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:52:50.731+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:52:50.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:52:50.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T03:53:21.101+0000] {processor.py:157} INFO - Started process (PID=9803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:53:21.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:53:21.105+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:53:21.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:53:21.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:53:21.132+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:53:21.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:53:21.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:53:21.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:53:21.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:53:51.441+0000] {processor.py:157} INFO - Started process (PID=9813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:53:51.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:53:51.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:53:51.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:53:51.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:53:51.471+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:53:51.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:53:51.482+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:53:51.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:53:51.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T03:54:21.816+0000] {processor.py:157} INFO - Started process (PID=9823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:54:21.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:54:21.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:54:21.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:54:21.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:54:21.847+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:54:21.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:54:21.859+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:54:21.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:54:21.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:54:52.161+0000] {processor.py:157} INFO - Started process (PID=9833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:54:52.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:54:52.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:54:52.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:54:52.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:54:52.194+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:54:52.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:54:52.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:54:52.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:54:52.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T03:55:22.534+0000] {processor.py:157} INFO - Started process (PID=9843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:55:22.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:55:22.538+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:55:22.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:55:22.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:55:22.573+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:55:22.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:55:22.585+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:55:22.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:55:22.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T03:55:52.858+0000] {processor.py:157} INFO - Started process (PID=9853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:55:52.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:55:52.862+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:55:52.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:55:52.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:55:52.889+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:55:52.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:55:52.901+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:55:52.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:55:52.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:56:23.163+0000] {processor.py:157} INFO - Started process (PID=9863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:56:23.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:56:23.167+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:56:23.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:56:23.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:56:23.195+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:56:23.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:56:23.209+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:56:23.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:56:23.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T03:56:53.536+0000] {processor.py:157} INFO - Started process (PID=9873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:56:53.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:56:53.538+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:56:53.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:56:53.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:56:53.565+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:56:53.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:56:53.575+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:56:53.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:56:53.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T03:57:23.933+0000] {processor.py:157} INFO - Started process (PID=9883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:57:23.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:57:23.939+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:57:23.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:57:23.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:57:23.963+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:57:23.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:57:23.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:57:23.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:57:23.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T03:57:54.339+0000] {processor.py:157} INFO - Started process (PID=9893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:57:54.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:57:54.343+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:57:54.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:57:54.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:57:54.373+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:57:54.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:57:54.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:57:54.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:57:54.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T03:58:24.729+0000] {processor.py:157} INFO - Started process (PID=9903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:58:24.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:58:24.734+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:58:24.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:58:24.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:58:24.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:58:24.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:58:24.772+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:58:24.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:58:24.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T03:58:55.132+0000] {processor.py:157} INFO - Started process (PID=9913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:58:55.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:58:55.136+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:58:55.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:58:55.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:58:55.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:58:55.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:58:55.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:58:55.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:58:55.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T03:59:25.456+0000] {processor.py:157} INFO - Started process (PID=9923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:59:25.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:59:25.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:59:25.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:59:25.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:59:25.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:59:25.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:59:25.499+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:59:25.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:59:25.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T03:59:55.803+0000] {processor.py:157} INFO - Started process (PID=9933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:59:55.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T03:59:55.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:59:55.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:59:55.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T03:59:55.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:59:55.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T03:59:55.849+0000] {logging_mixin.py:151} INFO - [2024-09-09T03:59:55.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T03:59:55.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T04:00:26.161+0000] {processor.py:157} INFO - Started process (PID=9943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:00:26.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:00:26.165+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:00:26.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:00:26.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:00:26.191+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:00:26.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:00:26.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:00:26.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:00:26.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:00:56.549+0000] {processor.py:157} INFO - Started process (PID=9953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:00:56.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:00:56.553+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:00:56.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:00:56.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:00:56.589+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:00:56.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:00:56.601+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:00:56.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:00:56.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T04:01:26.823+0000] {processor.py:157} INFO - Started process (PID=9963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:01:26.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:01:26.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:01:26.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:01:26.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:01:26.857+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:01:26.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:01:26.869+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:01:26.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:01:26.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:01:57.204+0000] {processor.py:157} INFO - Started process (PID=9973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:01:57.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:01:57.211+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:01:57.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:01:57.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:01:57.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:01:57.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:01:57.274+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:01:57.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:01:57.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T04:02:27.512+0000] {processor.py:157} INFO - Started process (PID=9983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:02:27.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:02:27.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:02:27.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:02:27.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:02:27.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:02:27.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:02:27.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:02:27.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:02:27.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T04:02:57.895+0000] {processor.py:157} INFO - Started process (PID=9993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:02:57.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:02:57.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:02:57.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:02:57.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:02:57.924+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:02:57.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:02:57.934+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:02:57.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:02:57.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:03:28.251+0000] {processor.py:157} INFO - Started process (PID=10003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:03:28.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:03:28.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:03:28.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:03:28.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:03:28.282+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:03:28.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:03:28.292+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:03:28.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:03:28.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:03:58.608+0000] {processor.py:157} INFO - Started process (PID=10013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:03:58.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:03:58.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:03:58.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:03:58.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:03:58.639+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:03:58.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:03:58.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:03:58.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:03:58.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:04:28.899+0000] {processor.py:157} INFO - Started process (PID=10023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:04:28.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:04:28.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:04:28.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:04:28.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:04:28.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:04:28.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:04:28.953+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:04:28.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:04:28.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T04:04:59.283+0000] {processor.py:157} INFO - Started process (PID=10033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:04:59.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:04:59.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:04:59.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:04:59.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:04:59.313+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:04:59.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:04:59.324+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:04:59.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:04:59.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:05:29.598+0000] {processor.py:157} INFO - Started process (PID=10043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:05:29.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:05:29.600+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:05:29.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:05:29.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:05:29.627+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:05:29.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:05:29.638+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:05:29.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:05:29.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:05:59.912+0000] {processor.py:157} INFO - Started process (PID=10053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:05:59.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:05:59.915+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:05:59.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:05:59.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:05:59.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:05:59.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:05:59.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:05:59.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:05:59.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T04:06:30.268+0000] {processor.py:157} INFO - Started process (PID=10063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:06:30.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:06:30.271+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:06:30.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:06:30.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:06:30.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:06:30.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:06:30.309+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:06:30.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:06:30.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:07:00.635+0000] {processor.py:157} INFO - Started process (PID=10073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:07:00.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:07:00.639+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:07:00.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:07:00.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:07:00.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:07:00.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:07:00.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:07:00.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:07:00.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T04:07:30.934+0000] {processor.py:157} INFO - Started process (PID=10083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:07:30.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:07:30.938+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:07:30.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:07:30.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:07:30.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:07:30.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:07:30.977+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:07:30.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:07:30.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:08:01.226+0000] {processor.py:157} INFO - Started process (PID=10093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:08:01.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:08:01.228+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:08:01.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:08:01.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:08:01.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:08:01.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:08:01.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:08:01.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:08:01.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:08:31.595+0000] {processor.py:157} INFO - Started process (PID=10103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:08:31.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:08:31.599+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:08:31.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:08:31.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:08:31.623+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:08:31.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:08:31.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:08:31.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:08:31.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:09:01.987+0000] {processor.py:157} INFO - Started process (PID=10113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:09:01.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:09:01.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:09:01.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:09:02.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:09:02.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:09:02.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:09:02.037+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:09:02.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:09:02.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T04:09:32.408+0000] {processor.py:157} INFO - Started process (PID=10123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:09:32.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:09:32.411+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:09:32.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:09:32.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:09:32.439+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:09:32.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:09:32.450+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:09:32.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:09:32.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:10:02.710+0000] {processor.py:157} INFO - Started process (PID=10133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:10:02.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:10:02.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:10:02.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:10:02.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:10:02.758+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:10:02.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:10:02.771+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:10:02.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:10:02.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T04:10:33.050+0000] {processor.py:157} INFO - Started process (PID=10141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:10:33.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:10:33.054+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:10:33.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:10:33.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:10:33.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:10:33.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:10:33.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:10:33.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:10:33.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:11:03.392+0000] {processor.py:157} INFO - Started process (PID=10153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:11:03.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:11:03.394+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:11:03.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:11:03.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:11:03.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:11:03.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:11:03.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:11:03.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:11:03.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:11:33.744+0000] {processor.py:157} INFO - Started process (PID=10163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:11:33.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:11:33.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:11:33.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:11:33.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:11:33.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:11:33.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:11:33.786+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:11:33.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:11:33.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:12:04.093+0000] {processor.py:157} INFO - Started process (PID=10173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:12:04.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:12:04.097+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:12:04.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:12:04.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:12:04.125+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:12:04.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:12:04.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:12:04.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:12:04.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:12:34.458+0000] {processor.py:157} INFO - Started process (PID=10183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:12:34.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:12:34.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:12:34.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:12:34.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:12:34.483+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:12:34.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:12:34.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:12:34.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:12:34.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T04:13:04.795+0000] {processor.py:157} INFO - Started process (PID=10193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:13:04.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:13:04.799+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:13:04.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:13:04.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:13:04.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:13:04.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:13:04.835+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:13:04.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:13:04.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:13:35.184+0000] {processor.py:157} INFO - Started process (PID=10203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:13:35.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:13:35.188+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:13:35.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:13:35.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:13:35.221+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:13:35.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:13:35.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:13:35.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:13:35.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T04:14:05.591+0000] {processor.py:157} INFO - Started process (PID=10213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:14:05.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:14:05.594+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:14:05.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:14:05.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:14:05.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:14:05.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:14:05.628+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:14:05.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:14:05.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:14:35.959+0000] {processor.py:157} INFO - Started process (PID=10223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:14:35.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:14:35.963+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:14:35.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:14:35.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:14:35.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:14:35.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:14:36.002+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:14:36.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:14:36.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T04:15:06.306+0000] {processor.py:157} INFO - Started process (PID=10233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:15:06.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:15:06.308+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:15:06.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:15:06.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:15:06.334+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:15:06.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:15:06.345+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:15:06.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:15:06.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:15:36.735+0000] {processor.py:157} INFO - Started process (PID=10243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:15:36.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:15:36.741+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:15:36.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:15:36.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:15:36.775+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:15:36.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:15:36.788+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:15:36.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:15:36.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T04:16:07.088+0000] {processor.py:157} INFO - Started process (PID=10253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:16:07.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:16:07.091+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:16:07.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:16:07.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:16:07.118+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:16:07.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:16:07.128+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:16:07.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:16:07.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:16:37.400+0000] {processor.py:157} INFO - Started process (PID=10263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:16:37.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:16:37.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:16:37.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:16:37.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:16:37.432+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:16:37.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:16:37.445+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:16:37.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:16:37.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:17:07.751+0000] {processor.py:157} INFO - Started process (PID=10273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:17:07.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:17:07.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:17:07.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:17:07.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:17:07.784+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:17:07.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:17:07.797+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:17:07.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:17:07.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:17:38.167+0000] {processor.py:157} INFO - Started process (PID=10283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:17:38.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:17:38.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:17:38.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:17:38.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:17:38.203+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:17:38.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:17:38.215+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:17:38.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:17:38.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T04:18:08.469+0000] {processor.py:157} INFO - Started process (PID=10293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:18:08.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:18:08.474+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:18:08.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:18:08.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:18:08.502+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:18:08.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:18:08.512+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:18:08.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:18:08.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T04:18:38.850+0000] {processor.py:157} INFO - Started process (PID=10303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:18:38.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:18:38.853+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:18:38.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:18:38.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:18:38.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:18:38.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:18:38.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:18:38.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:18:38.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:19:09.228+0000] {processor.py:157} INFO - Started process (PID=10313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:19:09.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:19:09.230+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:19:09.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:19:09.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:19:09.258+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:19:09.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:19:09.267+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:19:09.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:19:09.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:19:39.512+0000] {processor.py:157} INFO - Started process (PID=10323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:19:39.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:19:39.515+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:19:39.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:19:39.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:19:39.538+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:19:39.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:19:39.548+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:19:39.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:19:39.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T04:20:09.917+0000] {processor.py:157} INFO - Started process (PID=10333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:20:09.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:20:09.922+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:20:09.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:20:09.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:20:09.961+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:20:09.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:20:09.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:20:09.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:20:09.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T04:20:40.316+0000] {processor.py:157} INFO - Started process (PID=10343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:20:40.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:20:40.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:20:40.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:20:40.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:20:40.347+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:20:40.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:20:40.358+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:20:40.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:20:40.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:21:10.707+0000] {processor.py:157} INFO - Started process (PID=10353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:21:10.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:21:10.710+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:21:10.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:21:10.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:21:10.737+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:21:10.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:21:10.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:21:10.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:21:10.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:21:41.055+0000] {processor.py:157} INFO - Started process (PID=10363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:21:41.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:21:41.060+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:21:41.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:21:41.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:21:41.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:21:41.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:21:41.107+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:21:41.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:21:41.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T04:22:11.441+0000] {processor.py:157} INFO - Started process (PID=10373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:22:11.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:22:11.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:22:11.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:22:11.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:22:11.472+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:22:11.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:22:11.482+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:22:11.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:22:11.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:22:41.821+0000] {processor.py:157} INFO - Started process (PID=10383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:22:41.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:22:41.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:22:41.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:22:41.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:22:41.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:22:41.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:22:41.864+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:22:41.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:22:41.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:23:12.228+0000] {processor.py:157} INFO - Started process (PID=10393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:23:12.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:23:12.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:23:12.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:23:12.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:23:12.260+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:23:12.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:23:12.274+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:23:12.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:23:12.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T04:23:42.595+0000] {processor.py:157} INFO - Started process (PID=10403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:23:42.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:23:42.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:23:42.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:23:42.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:23:42.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:23:42.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:23:42.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:23:42.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:23:42.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:24:12.963+0000] {processor.py:157} INFO - Started process (PID=10413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:24:12.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:24:12.968+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:24:12.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:24:12.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:24:12.995+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:24:12.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:24:13.004+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:24:13.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:24:13.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:24:43.380+0000] {processor.py:157} INFO - Started process (PID=10423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:24:43.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:24:43.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:24:43.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:24:43.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:24:43.419+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:24:43.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:24:43.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:24:43.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:24:43.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T04:25:13.772+0000] {processor.py:157} INFO - Started process (PID=10433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:25:13.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:25:13.775+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:25:13.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:25:13.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:25:13.803+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:25:13.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:25:13.813+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:25:13.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:25:13.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:25:44.099+0000] {processor.py:157} INFO - Started process (PID=10443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:25:44.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:25:44.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:25:44.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:25:44.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:25:44.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:25:44.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:25:44.138+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:25:44.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:25:44.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:26:14.441+0000] {processor.py:157} INFO - Started process (PID=10453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:26:14.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:26:14.443+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:26:14.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:26:14.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:26:14.472+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:26:14.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:26:14.485+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:26:14.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:26:14.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:26:44.802+0000] {processor.py:157} INFO - Started process (PID=10463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:26:44.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:26:44.805+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:26:44.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:26:44.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:26:44.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:26:44.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:26:44.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:26:44.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:26:44.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:27:15.135+0000] {processor.py:157} INFO - Started process (PID=10473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:27:15.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:27:15.138+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:27:15.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:27:15.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:27:15.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:27:15.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:27:15.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:27:15.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:27:15.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:27:45.521+0000] {processor.py:157} INFO - Started process (PID=10483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:27:45.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:27:45.523+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:27:45.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:27:45.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:27:45.553+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:27:45.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:27:45.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:27:45.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:27:45.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:28:15.894+0000] {processor.py:157} INFO - Started process (PID=10493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:28:15.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:28:15.897+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:28:15.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:28:15.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:28:15.926+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:28:15.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:28:15.938+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:28:15.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:28:15.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:28:46.281+0000] {processor.py:157} INFO - Started process (PID=10503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:28:46.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:28:46.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:28:46.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:28:46.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:28:46.313+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:28:46.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:28:46.325+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:28:46.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:28:46.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T04:29:16.684+0000] {processor.py:157} INFO - Started process (PID=10513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:29:16.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:29:16.689+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:29:16.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:29:16.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:29:16.724+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:29:16.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:29:16.736+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:29:16.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:29:16.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T04:29:46.976+0000] {processor.py:157} INFO - Started process (PID=10523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:29:46.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:29:46.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:29:46.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:29:46.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:29:47.011+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:29:47.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:29:47.023+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:29:47.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:29:47.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T04:30:17.265+0000] {processor.py:157} INFO - Started process (PID=10533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:30:17.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:30:17.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:30:17.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:30:17.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:30:17.298+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:30:17.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:30:17.309+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:30:17.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:30:17.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:30:47.649+0000] {processor.py:157} INFO - Started process (PID=10543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:30:47.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:30:47.653+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:30:47.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:30:47.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:30:47.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:30:47.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:30:47.698+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:30:47.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:30:47.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T04:31:18.037+0000] {processor.py:157} INFO - Started process (PID=10553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:31:18.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:31:18.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:31:18.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:31:18.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:31:18.067+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:31:18.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:31:18.079+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:31:18.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:31:18.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:31:48.319+0000] {processor.py:157} INFO - Started process (PID=10563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:31:48.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:31:48.322+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:31:48.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:31:48.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:31:48.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:31:48.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:31:48.358+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:31:48.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:31:48.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T04:32:18.657+0000] {processor.py:157} INFO - Started process (PID=10573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:32:18.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:32:18.660+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:32:18.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:32:18.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:32:18.689+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:32:18.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:32:18.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:32:18.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:32:18.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:32:49.019+0000] {processor.py:157} INFO - Started process (PID=10583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:32:49.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:32:49.023+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:32:49.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:32:49.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:32:49.052+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:32:49.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:32:49.064+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:32:49.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:32:49.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T04:33:19.412+0000] {processor.py:157} INFO - Started process (PID=10593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:33:19.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:33:19.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:33:19.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:33:19.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:33:19.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:33:19.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:33:19.459+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:33:19.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:33:19.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T04:33:49.806+0000] {processor.py:157} INFO - Started process (PID=10603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:33:49.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:33:49.811+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:33:49.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:33:49.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:33:49.842+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:33:49.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:33:49.853+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:33:49.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:33:49.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T04:34:20.172+0000] {processor.py:157} INFO - Started process (PID=10613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:34:20.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:34:20.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:34:20.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:34:20.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:34:20.207+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:34:20.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:34:20.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:34:20.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:34:20.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T04:34:50.538+0000] {processor.py:157} INFO - Started process (PID=10623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:34:50.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:34:50.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:34:50.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:34:50.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:34:50.572+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:34:50.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:34:50.585+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:34:50.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:34:50.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T04:35:20.917+0000] {processor.py:157} INFO - Started process (PID=10633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:35:20.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:35:20.920+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:35:20.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:35:20.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:35:20.948+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:35:20.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:35:20.961+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:35:20.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:35:20.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T04:35:51.318+0000] {processor.py:157} INFO - Started process (PID=10643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:35:51.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:35:51.323+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:35:51.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:35:51.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:35:51.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:35:51.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:35:51.367+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:35:51.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:35:51.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T04:36:21.668+0000] {processor.py:157} INFO - Started process (PID=10653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:36:21.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:36:21.673+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:36:21.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:36:21.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:36:21.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:36:21.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:36:21.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:36:21.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:36:21.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T04:36:52.014+0000] {processor.py:157} INFO - Started process (PID=10663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:36:52.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:36:52.019+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:36:52.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:36:52.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:36:52.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:36:52.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:36:52.058+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:36:52.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:36:52.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:37:22.383+0000] {processor.py:157} INFO - Started process (PID=10673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:37:22.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:37:22.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:37:22.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:37:22.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:37:22.412+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:37:22.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:37:22.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:37:22.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:37:22.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:37:52.674+0000] {processor.py:157} INFO - Started process (PID=10683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:37:52.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:37:52.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:37:52.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:37:52.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:37:52.703+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:37:52.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:37:52.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:37:52.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:37:52.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:38:23.035+0000] {processor.py:157} INFO - Started process (PID=10693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:38:23.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:38:23.038+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:38:23.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:38:23.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:38:23.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:38:23.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:38:23.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:38:23.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:38:23.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:38:53.408+0000] {processor.py:157} INFO - Started process (PID=10703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:38:53.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:38:53.413+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:38:53.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:38:53.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:38:53.441+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:38:53.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:38:53.451+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:38:53.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:38:53.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:39:23.753+0000] {processor.py:157} INFO - Started process (PID=10713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:39:23.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:39:23.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:39:23.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:39:23.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:39:23.782+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:39:23.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:39:23.794+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:39:23.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:39:23.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:39:54.139+0000] {processor.py:157} INFO - Started process (PID=10723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:39:54.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:39:54.143+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:39:54.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:39:54.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:39:54.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:39:54.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:39:54.191+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:39:54.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:39:54.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T04:40:24.484+0000] {processor.py:157} INFO - Started process (PID=10733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:40:24.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:40:24.487+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:40:24.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:40:24.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:40:24.518+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:40:24.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:40:24.531+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:40:24.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:40:24.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T04:40:54.875+0000] {processor.py:157} INFO - Started process (PID=10743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:40:54.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:40:54.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:40:54.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:40:54.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:40:54.904+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:40:54.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:40:54.916+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:40:54.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:40:54.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:41:25.154+0000] {processor.py:157} INFO - Started process (PID=10753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:41:25.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:41:25.157+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:41:25.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:41:25.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:41:25.184+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:41:25.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:41:25.197+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:41:25.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:41:25.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:41:55.522+0000] {processor.py:157} INFO - Started process (PID=10763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:41:55.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:41:55.525+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:41:55.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:41:55.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:41:55.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:41:55.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:41:55.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:41:55.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:41:55.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:42:25.888+0000] {processor.py:157} INFO - Started process (PID=10773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:42:25.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:42:25.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:42:25.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:42:25.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:42:25.918+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:42:25.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:42:25.928+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:42:25.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:42:25.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:42:56.191+0000] {processor.py:157} INFO - Started process (PID=10783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:42:56.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:42:56.194+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:42:56.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:42:56.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:42:56.221+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:42:56.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:42:56.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:42:56.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:42:56.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:43:26.560+0000] {processor.py:157} INFO - Started process (PID=10793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:43:26.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:43:26.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:43:26.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:43:26.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:43:26.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:43:26.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:43:26.597+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:43:26.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:43:26.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T04:43:56.913+0000] {processor.py:157} INFO - Started process (PID=10803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:43:56.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:43:56.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:43:56.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:43:56.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:43:56.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:43:56.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:43:56.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:43:56.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:43:56.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T04:44:27.247+0000] {processor.py:157} INFO - Started process (PID=10813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:44:27.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:44:27.252+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:44:27.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:44:27.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:44:27.279+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:44:27.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:44:27.291+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:44:27.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:44:27.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T04:44:57.634+0000] {processor.py:157} INFO - Started process (PID=10823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:44:57.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:44:57.638+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:44:57.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:44:57.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:44:57.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:44:57.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:44:57.673+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:44:57.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:44:57.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:45:28.010+0000] {processor.py:157} INFO - Started process (PID=10833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:45:28.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:45:28.013+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:45:28.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:45:28.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:45:28.044+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:45:28.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:45:28.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:45:28.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:45:28.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T04:45:58.378+0000] {processor.py:157} INFO - Started process (PID=10843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:45:58.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:45:58.382+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:45:58.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:45:58.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:45:58.407+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:45:58.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:45:58.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:45:58.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:45:58.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:46:28.716+0000] {processor.py:157} INFO - Started process (PID=10853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:46:28.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:46:28.722+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:46:28.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:46:28.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:46:28.757+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:46:28.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:46:28.769+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:46:28.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:46:28.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T04:46:58.960+0000] {processor.py:157} INFO - Started process (PID=10863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:46:58.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:46:58.967+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:46:58.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:46:58.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:46:58.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:46:58.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:46:58.998+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:46:58.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:46:59.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:47:29.289+0000] {processor.py:157} INFO - Started process (PID=10873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:47:29.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:47:29.291+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:47:29.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:47:29.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:47:29.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:47:29.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:47:29.329+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:47:29.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:47:29.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T04:47:59.667+0000] {processor.py:157} INFO - Started process (PID=10883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:47:59.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:47:59.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:47:59.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:47:59.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:47:59.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:47:59.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:47:59.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:47:59.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:47:59.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T04:48:30.030+0000] {processor.py:157} INFO - Started process (PID=10893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:48:30.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:48:30.032+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:48:30.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:48:30.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:48:30.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:48:30.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:48:30.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:48:30.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:48:30.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:49:00.395+0000] {processor.py:157} INFO - Started process (PID=10903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:49:00.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:49:00.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:49:00.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:49:00.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:49:00.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:49:00.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:49:00.445+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:49:00.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:49:00.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T04:49:30.781+0000] {processor.py:157} INFO - Started process (PID=10912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:49:30.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:49:30.787+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:49:30.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:49:30.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:49:30.815+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:49:30.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:49:30.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:49:30.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:49:30.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T04:50:01.145+0000] {processor.py:157} INFO - Started process (PID=10923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:50:01.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:50:01.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:50:01.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:50:01.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:50:01.176+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:50:01.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:50:01.188+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:50:01.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:50:01.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T04:50:31.492+0000] {processor.py:157} INFO - Started process (PID=10933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:50:31.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:50:31.496+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:50:31.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:50:31.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:50:31.527+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:50:31.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:50:31.540+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:50:31.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:50:31.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T04:51:01.887+0000] {processor.py:157} INFO - Started process (PID=10943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:51:01.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:51:01.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:51:01.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:51:01.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:51:01.958+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:51:01.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:51:01.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:51:01.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:51:01.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-09T04:51:32.131+0000] {processor.py:157} INFO - Started process (PID=10953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:51:32.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:51:32.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:51:32.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:51:32.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:51:32.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:51:32.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:51:32.172+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:51:32.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:51:32.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:52:02.388+0000] {processor.py:157} INFO - Started process (PID=10963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:52:02.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:52:02.393+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:52:02.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:52:02.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:52:02.427+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:52:02.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:52:02.441+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:52:02.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:52:02.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T04:52:32.760+0000] {processor.py:157} INFO - Started process (PID=10973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:52:32.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:52:32.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:52:32.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:52:32.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:52:32.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:52:32.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:52:32.803+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:52:32.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:52:32.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T04:53:03.125+0000] {processor.py:157} INFO - Started process (PID=10983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:53:03.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:53:03.129+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:53:03.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:53:03.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:53:03.155+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:53:03.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:53:03.165+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:53:03.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:53:03.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T04:53:33.512+0000] {processor.py:157} INFO - Started process (PID=10993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:53:33.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:53:33.515+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:53:33.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:53:33.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:53:33.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:53:33.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:53:33.552+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:53:33.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:53:33.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T04:54:03.920+0000] {processor.py:157} INFO - Started process (PID=11003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:54:03.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:54:03.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:54:03.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:54:03.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:54:03.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:54:03.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:54:03.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:54:03.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:54:03.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T04:54:34.261+0000] {processor.py:157} INFO - Started process (PID=11013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:54:34.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:54:34.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:54:34.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:54:34.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:54:34.291+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:54:34.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:54:34.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:54:34.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:54:34.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T04:55:04.612+0000] {processor.py:157} INFO - Started process (PID=11023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:55:04.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:55:04.615+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:55:04.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:55:04.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:55:04.648+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:55:04.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:55:04.658+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:55:04.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:55:04.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T04:55:35.257+0000] {processor.py:157} INFO - Started process (PID=11033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:55:35.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:55:35.263+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:55:35.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:55:35.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:55:35.335+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:55:35.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:55:35.350+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:55:35.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:55:35.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-09T04:56:10.853+0000] {processor.py:157} INFO - Started process (PID=11043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:56:10.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:56:10.861+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:56:10.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:56:10.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:56:10.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:56:10.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:56:10.901+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:56:10.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:56:10.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T04:56:41.313+0000] {processor.py:157} INFO - Started process (PID=11054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:56:41.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T04:56:41.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:56:41.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:56:41.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T04:56:41.345+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:56:41.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T04:56:41.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T04:56:41.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T04:56:41.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T05:13:41.745+0000] {processor.py:157} INFO - Started process (PID=11066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:13:41.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:13:41.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:13:41.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:13:41.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:13:41.893+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:13:41.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:13:41.929+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:13:41.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:13:41.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-09-09T05:14:12.053+0000] {processor.py:157} INFO - Started process (PID=11075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:14:12.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:14:12.061+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:14:12.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:14:12.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:14:12.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:14:12.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:14:12.125+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:14:12.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:14:12.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-09T05:14:42.420+0000] {processor.py:157} INFO - Started process (PID=11087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:14:42.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:14:42.426+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:14:42.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:14:42.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:14:42.469+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:14:42.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:14:42.482+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:14:42.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:14:42.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T05:15:40.245+0000] {processor.py:157} INFO - Started process (PID=11099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:15:40.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:15:40.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:15:40.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:15:40.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:15:40.274+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:15:40.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:15:40.288+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:15:40.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:15:40.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T05:16:10.585+0000] {processor.py:157} INFO - Started process (PID=11109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:16:10.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:16:10.590+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:16:10.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:16:10.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:16:10.631+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:16:10.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:16:10.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:16:10.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:16:10.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T05:32:47.460+0000] {processor.py:157} INFO - Started process (PID=11119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:32:47.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:32:47.463+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:32:47.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:32:47.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:32:47.522+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:32:47.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:32:47.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:32:47.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:32:47.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T05:49:23.636+0000] {processor.py:157} INFO - Started process (PID=11129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:49:23.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:49:23.644+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:49:23.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:49:23.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:49:23.703+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:49:23.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:49:23.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:49:23.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:49:23.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-09T05:49:54.049+0000] {processor.py:157} INFO - Started process (PID=11139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:49:54.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T05:49:54.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:49:54.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:49:54.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T05:49:54.088+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:49:54.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T05:49:54.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T05:49:54.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T05:49:54.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T06:05:35.052+0000] {processor.py:157} INFO - Started process (PID=11148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:05:35.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:05:35.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:05:35.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:05:35.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:05:35.115+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:05:35.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:05:35.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:05:35.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:05:35.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-09T06:06:05.347+0000] {processor.py:157} INFO - Started process (PID=11159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:06:05.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:06:05.352+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:06:05.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:06:05.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:06:05.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:06:05.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:06:05.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:06:05.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:06:05.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T06:06:35.752+0000] {processor.py:157} INFO - Started process (PID=11169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:06:35.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:06:35.756+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:06:35.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:06:35.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:06:35.787+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:06:35.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:06:35.798+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:06:35.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:06:35.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T06:07:06.155+0000] {processor.py:157} INFO - Started process (PID=11179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:07:06.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:07:06.158+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:07:06.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:07:06.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:07:06.183+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:07:06.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:07:06.193+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:07:06.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:07:06.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T06:07:36.484+0000] {processor.py:157} INFO - Started process (PID=11189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:07:36.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:07:36.487+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:07:36.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:07:36.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:07:36.514+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:07:36.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:07:36.524+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:07:36.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:07:36.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T06:24:46.185+0000] {processor.py:157} INFO - Started process (PID=11200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:24:46.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:24:46.195+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:24:46.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:24:46.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:24:46.239+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:24:46.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:24:46.251+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:24:46.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:24:46.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T06:25:16.432+0000] {processor.py:157} INFO - Started process (PID=11211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:25:16.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:25:16.435+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:25:16.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:25:16.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:25:16.474+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:25:16.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:25:16.487+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:25:16.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:25:16.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T06:25:46.806+0000] {processor.py:157} INFO - Started process (PID=11221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:25:46.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:25:46.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:25:46.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:25:46.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:25:46.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:25:46.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:25:46.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:25:46.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:25:46.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T06:26:17.178+0000] {processor.py:157} INFO - Started process (PID=11231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:26:17.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:26:17.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:26:17.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:26:17.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:26:17.209+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:26:17.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:26:17.219+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:26:17.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:26:17.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:26:47.566+0000] {processor.py:157} INFO - Started process (PID=11241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:26:47.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:26:47.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:26:47.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:26:47.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:26:47.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:26:47.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:26:47.608+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:26:47.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:26:47.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:27:17.925+0000] {processor.py:157} INFO - Started process (PID=11251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:27:17.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:27:17.928+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:27:17.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:27:17.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:27:17.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:27:17.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:27:17.963+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:27:17.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:27:17.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T06:27:48.267+0000] {processor.py:157} INFO - Started process (PID=11261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:27:48.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:27:48.271+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:27:48.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:27:48.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:27:48.305+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:27:48.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:27:48.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:27:48.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:27:48.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T06:28:18.670+0000] {processor.py:157} INFO - Started process (PID=11271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:28:18.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:28:18.672+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:28:18.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:28:18.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:28:18.700+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:28:18.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:28:18.711+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:28:18.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:28:18.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T06:28:49.062+0000] {processor.py:157} INFO - Started process (PID=11281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:28:49.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:28:49.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:28:49.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:28:49.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:28:49.090+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:28:49.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:28:49.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:28:49.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:28:49.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T06:29:19.360+0000] {processor.py:157} INFO - Started process (PID=11291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:29:19.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:29:19.363+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:29:19.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:29:19.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:29:19.390+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:29:19.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:29:19.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:29:19.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:29:19.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T06:29:49.712+0000] {processor.py:157} INFO - Started process (PID=11301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:29:49.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:29:49.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:29:49.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:29:49.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:29:49.741+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:29:49.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:29:49.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:29:49.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:29:49.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:30:20.095+0000] {processor.py:157} INFO - Started process (PID=11311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:30:20.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:30:20.098+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:30:20.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:30:20.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:30:20.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:30:20.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:30:20.136+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:30:20.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:30:20.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:30:50.509+0000] {processor.py:157} INFO - Started process (PID=11321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:30:50.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:30:50.512+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:30:50.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:30:50.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:30:50.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:30:50.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:30:50.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:30:50.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:30:50.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T06:31:20.935+0000] {processor.py:157} INFO - Started process (PID=11331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:31:20.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:31:20.939+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:31:20.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:31:20.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:31:20.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:31:20.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:31:20.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:31:20.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:31:20.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T06:31:51.245+0000] {processor.py:157} INFO - Started process (PID=11341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:31:51.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:31:51.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:31:51.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:31:51.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:31:51.275+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:31:51.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:31:51.285+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:31:51.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:31:51.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T06:32:21.622+0000] {processor.py:157} INFO - Started process (PID=11351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:32:21.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:32:21.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:32:21.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:32:21.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:32:21.655+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:32:21.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:32:21.667+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:32:21.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:32:21.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T06:32:52.000+0000] {processor.py:157} INFO - Started process (PID=11361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:32:52.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:32:52.003+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:32:52.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:32:52.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:32:52.032+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:32:52.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:32:52.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:32:52.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:32:52.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:33:22.347+0000] {processor.py:157} INFO - Started process (PID=11371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:33:22.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:33:22.350+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:33:22.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:33:22.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:33:22.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:33:22.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:33:22.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:33:22.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:33:22.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T06:33:52.695+0000] {processor.py:157} INFO - Started process (PID=11381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:33:52.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:33:52.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:33:52.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:33:52.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:33:52.725+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:33:52.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:33:52.737+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:33:52.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:33:52.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T06:34:23.067+0000] {processor.py:157} INFO - Started process (PID=11391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:34:23.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:34:23.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:34:23.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:34:23.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:34:23.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:34:23.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:34:23.114+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:34:23.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:34:23.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T06:34:53.459+0000] {processor.py:157} INFO - Started process (PID=11401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:34:53.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:34:53.462+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:34:53.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:34:53.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:34:53.494+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:34:53.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:34:53.506+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:34:53.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:34:53.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T06:35:23.784+0000] {processor.py:157} INFO - Started process (PID=11411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:35:23.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:35:23.786+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:35:23.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:35:23.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:35:23.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:35:23.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:35:23.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:35:23.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:35:23.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:35:54.186+0000] {processor.py:157} INFO - Started process (PID=11421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:35:54.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:35:54.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:35:54.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:35:54.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:35:54.215+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:35:54.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:35:54.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:35:54.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:35:54.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:36:24.542+0000] {processor.py:157} INFO - Started process (PID=11431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:36:24.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:36:24.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:36:24.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:36:24.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:36:24.569+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:36:24.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:36:24.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:36:24.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:36:24.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T06:36:54.952+0000] {processor.py:157} INFO - Started process (PID=11440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:36:54.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:36:54.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:36:54.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:36:54.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:36:54.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:36:54.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:36:54.992+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:36:54.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:36:55.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T06:37:25.361+0000] {processor.py:157} INFO - Started process (PID=11451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:37:25.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:37:25.368+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:37:25.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:37:25.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:37:25.404+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:37:25.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:37:25.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:37:25.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:37:25.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T06:37:55.629+0000] {processor.py:157} INFO - Started process (PID=11461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:37:55.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:37:55.631+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:37:55.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:37:55.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:37:55.657+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:37:55.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:37:55.670+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:37:55.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:37:55.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:38:26.012+0000] {processor.py:157} INFO - Started process (PID=11471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:38:26.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:38:26.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:38:26.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:38:26.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:38:26.041+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:38:26.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:38:26.052+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:38:26.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:38:26.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T06:38:56.367+0000] {processor.py:157} INFO - Started process (PID=11481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:38:56.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:38:56.370+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:38:56.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:38:56.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:38:56.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:38:56.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:38:56.407+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:38:56.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:38:56.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T06:39:26.702+0000] {processor.py:157} INFO - Started process (PID=11491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:39:26.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:39:26.704+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:39:26.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:39:26.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:39:26.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:39:26.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:39:26.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:39:26.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:39:26.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:39:57.107+0000] {processor.py:157} INFO - Started process (PID=11501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:39:57.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:39:57.110+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:39:57.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:39:57.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:39:57.138+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:39:57.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:39:57.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:39:57.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:39:57.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:40:27.482+0000] {processor.py:157} INFO - Started process (PID=11511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:40:27.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:40:27.487+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:40:27.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:40:27.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:40:27.528+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:40:27.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:40:27.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:40:27.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:40:27.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T06:40:57.827+0000] {processor.py:157} INFO - Started process (PID=11521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:40:57.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:40:57.831+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:40:57.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:40:57.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:40:57.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:40:57.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:40:57.870+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:40:57.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:40:57.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T06:41:28.197+0000] {processor.py:157} INFO - Started process (PID=11531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:41:28.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:41:28.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:41:28.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:41:28.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:41:28.228+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:41:28.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:41:28.238+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:41:28.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:41:28.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T06:41:58.526+0000] {processor.py:157} INFO - Started process (PID=11541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:41:58.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:41:58.531+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:41:58.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:41:58.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:41:58.561+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:41:58.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:41:58.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:41:58.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:41:58.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T06:42:28.921+0000] {processor.py:157} INFO - Started process (PID=11551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:42:28.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:42:28.926+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:42:28.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:42:28.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:42:28.963+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:42:28.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:42:28.976+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:42:28.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:42:28.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T06:42:59.319+0000] {processor.py:157} INFO - Started process (PID=11561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:42:59.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:42:59.322+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:42:59.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:42:59.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:42:59.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:42:59.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:42:59.362+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:42:59.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:42:59.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:43:29.690+0000] {processor.py:157} INFO - Started process (PID=11571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:43:29.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:43:29.697+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:43:29.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:43:29.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:43:29.736+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:43:29.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:43:29.749+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:43:29.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:43:29.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T06:43:59.958+0000] {processor.py:157} INFO - Started process (PID=11581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:43:59.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:43:59.961+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:43:59.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:43:59.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:43:59.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:43:59.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:43:59.997+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:43:59.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:44:00.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T06:44:30.356+0000] {processor.py:157} INFO - Started process (PID=11591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:44:30.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:44:30.358+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:44:30.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:44:30.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:44:30.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:44:30.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:44:30.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:44:30.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:44:30.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T06:45:00.742+0000] {processor.py:157} INFO - Started process (PID=11601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:45:00.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:45:00.747+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:45:00.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:45:00.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:45:00.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:45:00.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:45:00.793+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:45:00.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:45:00.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T06:45:31.042+0000] {processor.py:157} INFO - Started process (PID=11611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:45:31.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:45:31.045+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:45:31.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:45:31.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:45:31.069+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:45:31.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:45:31.078+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:45:31.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:45:31.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T06:46:01.448+0000] {processor.py:157} INFO - Started process (PID=11621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:46:01.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:46:01.452+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:46:01.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:46:01.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:46:01.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:46:01.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:46:01.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:46:01.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:46:01.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:46:31.835+0000] {processor.py:157} INFO - Started process (PID=11631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:46:31.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:46:31.838+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:46:31.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:46:31.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:46:31.867+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:46:31.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:46:31.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:46:31.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:46:31.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:47:02.161+0000] {processor.py:157} INFO - Started process (PID=11641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:47:02.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:47:02.165+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:47:02.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:47:02.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:47:02.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:47:02.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:47:02.204+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:47:02.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:47:02.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:47:32.579+0000] {processor.py:157} INFO - Started process (PID=11651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:47:32.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:47:32.582+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:47:32.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:47:32.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:47:32.607+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:47:32.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:47:32.617+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:47:32.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:47:32.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T06:48:02.950+0000] {processor.py:157} INFO - Started process (PID=11661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:48:02.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:48:02.955+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:48:02.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:48:02.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:48:02.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:48:02.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:48:03.003+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:48:03.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:48:03.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T06:48:33.247+0000] {processor.py:157} INFO - Started process (PID=11671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:48:33.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:48:33.250+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:48:33.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:48:33.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:48:33.276+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:48:33.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:48:33.287+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:48:33.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:48:33.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:49:03.637+0000] {processor.py:157} INFO - Started process (PID=11681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:49:03.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:49:03.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:49:03.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:49:03.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:49:03.667+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:49:03.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:49:03.677+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:49:03.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:49:03.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T06:49:34.026+0000] {processor.py:157} INFO - Started process (PID=11691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:49:34.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:49:34.029+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:49:34.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:49:34.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:49:34.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:49:34.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:49:34.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:49:34.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:49:34.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T06:50:04.399+0000] {processor.py:157} INFO - Started process (PID=11701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:50:04.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:50:04.403+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:50:04.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:50:04.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:50:04.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:50:04.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:50:04.440+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:50:04.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:50:04.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:50:34.786+0000] {processor.py:157} INFO - Started process (PID=11711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:50:34.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:50:34.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:50:34.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:50:34.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:50:34.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:50:34.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:50:34.824+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:50:34.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:50:34.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T06:51:05.172+0000] {processor.py:157} INFO - Started process (PID=11721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:51:05.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:51:05.174+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:51:05.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:51:05.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:51:05.198+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:51:05.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:51:05.210+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:51:05.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:51:05.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T06:51:35.512+0000] {processor.py:157} INFO - Started process (PID=11731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:51:35.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:51:35.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:51:35.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:51:35.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:51:35.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:51:35.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:51:35.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:51:35.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:51:35.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T06:52:05.820+0000] {processor.py:157} INFO - Started process (PID=11741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:52:05.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:52:05.824+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:52:05.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:52:05.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:52:05.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:52:05.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:52:05.864+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:52:05.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:52:05.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:52:36.208+0000] {processor.py:157} INFO - Started process (PID=11751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:52:36.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:52:36.213+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:52:36.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:52:36.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:52:36.238+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:52:36.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:52:36.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:52:36.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:52:36.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:53:06.601+0000] {processor.py:157} INFO - Started process (PID=11761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:53:06.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:53:06.604+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:53:06.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:53:06.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:53:06.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:53:06.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:53:06.643+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:53:06.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:53:06.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T06:53:36.943+0000] {processor.py:157} INFO - Started process (PID=11771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:53:36.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:53:36.946+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:53:36.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:53:36.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:53:36.974+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:53:36.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:53:36.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:53:36.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:53:36.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:54:07.265+0000] {processor.py:157} INFO - Started process (PID=11781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:54:07.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:54:07.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:54:07.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:54:07.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:54:07.291+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:54:07.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:54:07.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:54:07.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:54:07.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T06:54:37.608+0000] {processor.py:157} INFO - Started process (PID=11791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:54:37.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:54:37.613+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:54:37.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:54:37.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:54:37.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:54:37.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:54:37.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:54:37.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:54:37.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T06:55:08.012+0000] {processor.py:157} INFO - Started process (PID=11801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:55:08.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:55:08.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:55:08.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:55:08.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:55:08.041+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:55:08.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:55:08.051+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:55:08.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:55:08.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T06:55:38.396+0000] {processor.py:157} INFO - Started process (PID=11811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:55:38.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:55:38.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:55:38.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:55:38.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:55:38.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:55:38.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:55:38.432+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:55:38.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:55:38.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T06:56:08.774+0000] {processor.py:157} INFO - Started process (PID=11821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:56:08.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:56:08.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:56:08.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:56:08.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:56:08.804+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:56:08.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:56:08.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:56:08.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:56:08.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T06:56:39.146+0000] {processor.py:157} INFO - Started process (PID=11831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:56:39.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:56:39.151+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:56:39.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:56:39.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:56:39.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:56:39.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:56:39.198+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:56:39.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:56:39.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T06:57:09.452+0000] {processor.py:157} INFO - Started process (PID=11841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:57:09.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:57:09.455+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:57:09.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:57:09.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:57:09.481+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:57:09.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:57:09.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:57:09.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:57:09.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:57:39.829+0000] {processor.py:157} INFO - Started process (PID=11851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:57:39.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:57:39.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:57:39.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:57:39.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:57:39.861+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:57:39.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:57:39.874+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:57:39.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:57:39.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T06:58:10.167+0000] {processor.py:157} INFO - Started process (PID=11861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:58:10.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:58:10.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:58:10.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:58:10.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:58:10.199+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:58:10.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:58:10.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:58:10.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:58:10.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T06:58:40.475+0000] {processor.py:157} INFO - Started process (PID=11871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:58:40.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:58:40.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:58:40.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:58:40.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:58:40.506+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:58:40.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:58:40.517+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:58:40.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:58:40.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T06:59:10.839+0000] {processor.py:157} INFO - Started process (PID=11881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:59:10.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:59:10.844+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:59:10.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:59:10.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:59:10.872+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:59:10.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:59:10.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:59:10.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:59:10.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T06:59:41.153+0000] {processor.py:157} INFO - Started process (PID=11891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:59:41.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T06:59:41.156+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:59:41.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:59:41.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T06:59:41.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:59:41.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T06:59:41.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T06:59:41.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T06:59:41.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T07:00:11.537+0000] {processor.py:157} INFO - Started process (PID=11901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:00:11.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:00:11.544+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:00:11.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:00:11.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:00:11.580+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:00:11.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:00:11.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:00:11.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:00:11.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T07:00:41.834+0000] {processor.py:157} INFO - Started process (PID=11911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:00:41.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:00:41.837+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:00:41.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:00:41.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:00:41.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:00:41.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:00:41.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:00:41.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:00:41.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T07:01:12.250+0000] {processor.py:157} INFO - Started process (PID=11921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:01:12.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:01:12.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:01:12.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:01:12.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:01:12.288+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:01:12.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:01:12.300+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:01:12.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:01:12.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T07:01:42.583+0000] {processor.py:157} INFO - Started process (PID=11931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:01:42.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:01:42.585+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:01:42.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:01:42.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:01:42.613+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:01:42.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:01:42.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:01:42.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:01:42.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T07:02:12.942+0000] {processor.py:157} INFO - Started process (PID=11941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:02:12.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:02:12.944+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:02:12.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:02:12.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:02:12.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:02:12.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:02:12.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:02:12.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:02:12.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T07:02:43.284+0000] {processor.py:157} INFO - Started process (PID=11951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:02:43.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:02:43.287+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:02:43.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:02:43.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:02:43.315+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:02:43.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:02:43.328+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:02:43.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:02:43.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T07:03:13.663+0000] {processor.py:157} INFO - Started process (PID=11961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:03:13.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:03:13.665+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:03:13.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:03:13.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:03:13.691+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:03:13.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:03:13.700+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:03:13.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:03:13.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T07:03:43.992+0000] {processor.py:157} INFO - Started process (PID=11971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:03:43.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:03:43.996+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:03:43.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:03:44.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:03:44.024+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:03:44.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:03:44.036+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:03:44.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:03:44.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T07:04:14.385+0000] {processor.py:157} INFO - Started process (PID=11981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:04:14.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:04:14.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:04:14.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:04:14.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:04:14.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:04:14.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:04:14.428+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:04:14.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:04:14.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T07:04:44.721+0000] {processor.py:157} INFO - Started process (PID=11991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:04:44.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:04:44.726+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:04:44.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:04:44.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:04:44.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:04:44.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:04:44.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:04:44.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:04:44.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T07:05:15.111+0000] {processor.py:157} INFO - Started process (PID=12001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:05:15.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:05:15.114+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:05:15.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:05:15.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:05:15.141+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:05:15.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:05:15.153+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:05:15.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:05:15.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T07:05:45.504+0000] {processor.py:157} INFO - Started process (PID=12011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:05:45.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:05:45.508+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:05:45.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:05:45.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:05:45.532+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:05:45.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:05:45.542+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:05:45.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:05:45.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T07:06:15.920+0000] {processor.py:157} INFO - Started process (PID=12020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:06:15.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:06:15.929+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:06:15.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:06:15.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:06:15.978+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:06:15.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:06:15.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:06:15.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:06:16.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T07:06:46.214+0000] {processor.py:157} INFO - Started process (PID=12031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:06:46.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:06:46.218+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:06:46.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:06:46.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:06:46.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:06:46.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:06:46.259+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:06:46.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:06:46.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T07:07:16.589+0000] {processor.py:157} INFO - Started process (PID=12041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:07:16.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:07:16.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:07:16.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:07:16.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:07:16.619+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:07:16.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:07:16.629+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:07:16.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:07:16.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T07:07:46.960+0000] {processor.py:157} INFO - Started process (PID=12051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:07:46.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:07:46.967+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:07:46.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:07:46.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:07:47.004+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:07:47.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:07:47.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:07:47.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:07:47.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T07:08:17.256+0000] {processor.py:157} INFO - Started process (PID=12061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:08:17.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:08:17.261+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:08:17.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:08:17.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:08:17.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:08:17.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:08:17.296+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:08:17.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:08:17.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T07:08:47.654+0000] {processor.py:157} INFO - Started process (PID=12071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:08:47.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:08:47.658+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:08:47.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:08:47.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:08:47.685+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:08:47.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:08:47.696+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:08:47.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:08:47.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T07:09:17.991+0000] {processor.py:157} INFO - Started process (PID=12081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:09:17.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:09:17.994+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:09:17.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:09:18.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:09:18.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:09:18.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:09:18.028+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:09:18.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:09:18.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T07:09:48.273+0000] {processor.py:157} INFO - Started process (PID=12091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:09:48.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:09:48.275+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:09:48.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:09:48.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:09:48.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:09:48.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:09:48.313+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:09:48.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:09:48.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T07:10:18.649+0000] {processor.py:157} INFO - Started process (PID=12101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:10:18.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:10:18.653+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:10:18.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:10:18.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:10:18.688+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:10:18.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:10:18.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:10:18.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:10:18.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T07:10:48.986+0000] {processor.py:157} INFO - Started process (PID=12111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:10:48.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:10:48.992+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:10:48.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:10:49.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:10:49.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:10:49.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:10:49.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:10:49.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:10:49.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T07:11:19.300+0000] {processor.py:157} INFO - Started process (PID=12121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:11:19.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:11:19.303+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:11:19.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:11:19.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:11:19.331+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:11:19.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:11:19.342+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:11:19.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:11:19.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T07:11:49.685+0000] {processor.py:157} INFO - Started process (PID=12131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:11:49.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:11:49.690+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:11:49.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:11:49.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:11:49.726+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:11:49.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:11:49.738+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:11:49.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:11:49.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T07:12:20.028+0000] {processor.py:157} INFO - Started process (PID=12141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:12:20.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:12:20.032+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:12:20.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:12:20.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:12:20.060+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:12:20.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:12:20.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:12:20.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:12:20.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T07:12:50.404+0000] {processor.py:157} INFO - Started process (PID=12151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:12:50.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:12:50.407+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:12:50.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:12:50.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:12:50.447+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:12:50.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:12:50.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:12:50.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:12:50.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T07:13:20.745+0000] {processor.py:157} INFO - Started process (PID=12161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:13:20.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:13:20.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:13:20.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:13:20.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:13:20.797+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:13:20.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:13:20.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:13:20.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:13:20.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T07:13:51.146+0000] {processor.py:157} INFO - Started process (PID=12171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:13:51.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:13:51.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:13:51.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:13:51.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:13:51.184+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:13:51.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:13:51.195+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:13:51.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:13:51.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T07:14:21.512+0000] {processor.py:157} INFO - Started process (PID=12181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:14:21.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:14:21.515+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:14:21.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:14:21.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:14:21.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:14:21.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:14:21.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:14:21.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:14:21.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T07:14:51.895+0000] {processor.py:157} INFO - Started process (PID=12191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:14:51.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:14:51.898+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:14:51.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:14:51.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:14:51.924+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:14:51.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:14:51.936+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:14:51.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:14:51.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T07:15:22.254+0000] {processor.py:157} INFO - Started process (PID=12201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:15:22.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:15:22.259+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:15:22.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:15:22.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:15:22.296+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:15:22.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:15:22.308+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:15:22.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:15:22.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T07:15:52.563+0000] {processor.py:157} INFO - Started process (PID=12211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:15:52.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:15:52.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:15:52.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:15:52.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:15:52.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:15:52.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:15:52.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:15:52.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:15:52.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T07:16:22.943+0000] {processor.py:157} INFO - Started process (PID=12221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:16:22.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:16:22.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:16:22.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:16:22.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:16:22.971+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:16:22.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:16:22.981+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:16:22.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:16:22.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T07:16:53.335+0000] {processor.py:157} INFO - Started process (PID=12231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:16:53.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:16:53.339+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:16:53.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:16:53.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:16:53.364+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:16:53.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:16:53.373+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:16:53.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:16:53.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T07:17:23.655+0000] {processor.py:157} INFO - Started process (PID=12241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:17:23.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:17:23.660+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:17:23.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:17:23.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:17:23.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:17:23.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:17:23.704+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:17:23.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:17:23.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T07:17:54.072+0000] {processor.py:157} INFO - Started process (PID=12251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:17:54.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:17:54.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:17:54.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:17:54.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:17:54.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:17:54.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:17:54.115+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:17:54.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:17:54.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T07:18:24.461+0000] {processor.py:157} INFO - Started process (PID=12261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:18:24.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:18:24.465+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:18:24.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:18:24.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:18:24.497+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:18:24.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:18:24.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:18:24.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:18:24.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T07:18:54.796+0000] {processor.py:157} INFO - Started process (PID=12271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:18:54.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:18:54.798+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:18:54.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:18:54.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:18:54.826+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:18:54.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:18:54.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:18:54.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:18:54.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T07:19:25.172+0000] {processor.py:157} INFO - Started process (PID=12281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:19:25.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:19:25.175+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:19:25.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:19:25.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:19:25.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:19:25.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:19:25.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:19:25.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:19:25.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T07:19:55.536+0000] {processor.py:157} INFO - Started process (PID=12291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:19:55.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:19:55.539+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:19:55.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:19:55.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:19:55.575+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:19:55.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:19:55.595+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:19:55.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:19:55.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T07:20:25.798+0000] {processor.py:157} INFO - Started process (PID=12301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:20:25.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:20:25.799+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:20:25.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:20:25.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:20:25.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:20:25.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:20:25.839+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:20:25.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:20:25.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T07:20:56.145+0000] {processor.py:157} INFO - Started process (PID=12311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:20:56.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:20:56.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:20:56.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:20:56.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:20:56.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:20:56.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:20:56.188+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:20:56.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:20:56.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T07:21:26.544+0000] {processor.py:157} INFO - Started process (PID=12321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:21:26.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:21:26.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:21:26.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:21:26.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:21:26.570+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:21:26.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:21:26.580+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:21:26.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:21:26.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T07:21:56.915+0000] {processor.py:157} INFO - Started process (PID=12331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:21:56.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:21:56.918+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:21:56.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:21:56.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:21:56.953+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:21:56.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:21:56.965+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:21:56.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:21:56.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T07:22:27.250+0000] {processor.py:157} INFO - Started process (PID=12341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:22:27.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:22:27.253+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:22:27.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:22:27.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:22:27.280+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:22:27.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:22:27.290+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:22:27.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:22:27.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T07:22:57.637+0000] {processor.py:157} INFO - Started process (PID=12351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:22:57.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:22:57.642+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:22:57.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:22:57.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:22:57.669+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:22:57.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:22:57.680+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:22:57.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:22:57.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T07:23:27.991+0000] {processor.py:157} INFO - Started process (PID=12361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:23:27.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:23:27.994+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:23:27.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:23:28.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:23:28.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:23:28.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:23:28.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:23:28.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:23:28.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T07:23:58.319+0000] {processor.py:157} INFO - Started process (PID=12371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:23:58.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:23:58.322+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:23:58.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:23:58.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:23:58.356+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:23:58.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:23:58.367+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:23:58.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:23:58.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T07:24:28.738+0000] {processor.py:157} INFO - Started process (PID=12381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:24:28.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:24:28.744+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:24:28.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:24:28.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:24:28.779+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:24:28.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:24:28.797+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:24:28.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:24:28.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T07:24:59.064+0000] {processor.py:157} INFO - Started process (PID=12390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:24:59.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:24:59.067+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:24:59.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:24:59.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:24:59.094+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:24:59.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:24:59.105+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:24:59.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:24:59.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T07:41:37.777+0000] {processor.py:157} INFO - Started process (PID=12401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:41:37.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:41:37.784+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:41:37.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:41:37.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:41:37.835+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:41:37.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:41:37.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:41:37.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:41:37.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T07:42:08.091+0000] {processor.py:157} INFO - Started process (PID=12412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:42:08.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:42:08.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:42:08.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:42:08.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:42:08.169+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:42:08.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:42:08.194+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:42:08.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:42:08.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T07:42:38.421+0000] {processor.py:157} INFO - Started process (PID=12423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:42:38.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:42:38.426+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:42:38.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:42:38.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:42:38.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:42:38.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:42:38.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:42:38.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:42:38.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T07:43:08.873+0000] {processor.py:157} INFO - Started process (PID=12433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:43:08.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:43:08.876+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:43:08.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:43:08.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:43:08.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:43:08.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:43:08.917+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:43:08.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:43:08.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T07:43:39.236+0000] {processor.py:157} INFO - Started process (PID=12443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:43:39.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:43:39.240+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:43:39.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:43:39.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:43:39.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:43:39.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:43:39.275+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:43:39.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:43:39.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T07:44:09.599+0000] {processor.py:157} INFO - Started process (PID=12453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:44:09.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:44:09.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:44:09.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:44:09.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:44:09.651+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:44:09.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:44:09.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:44:09.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:44:09.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T07:44:40.009+0000] {processor.py:157} INFO - Started process (PID=12463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:44:40.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:44:40.011+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:44:40.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:44:40.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:44:40.038+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:44:40.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:44:40.049+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:44:40.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:44:40.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T07:45:10.375+0000] {processor.py:157} INFO - Started process (PID=12473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:45:10.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:45:10.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:45:10.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:45:10.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:45:10.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:45:10.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:45:10.417+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:45:10.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:45:10.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T07:45:40.776+0000] {processor.py:157} INFO - Started process (PID=12483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:45:40.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:45:40.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:45:40.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:45:40.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:45:40.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:45:40.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:45:40.828+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:45:40.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:45:40.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T07:46:11.087+0000] {processor.py:157} INFO - Started process (PID=12493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:46:11.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:46:11.090+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:46:11.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:46:11.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:46:11.117+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:46:11.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:46:11.128+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:46:11.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:46:11.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T07:46:41.526+0000] {processor.py:157} INFO - Started process (PID=12503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:46:41.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:46:41.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:46:41.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:46:41.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:46:41.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:46:41.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:46:41.574+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:46:41.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:46:41.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T07:47:12.006+0000] {processor.py:157} INFO - Started process (PID=12511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:47:12.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:47:12.011+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:47:12.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:47:12.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:47:12.050+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:47:12.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:47:12.068+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:47:12.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:47:12.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T07:47:42.345+0000] {processor.py:157} INFO - Started process (PID=12523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:47:42.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:47:42.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:47:42.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:47:42.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:47:42.372+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:47:42.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:47:42.382+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:47:42.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:47:42.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T07:48:12.720+0000] {processor.py:157} INFO - Started process (PID=12533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:48:12.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:48:12.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:48:12.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:48:12.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:48:12.751+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:48:12.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:48:12.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:48:12.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:48:12.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T07:48:43.086+0000] {processor.py:157} INFO - Started process (PID=12543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:48:43.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:48:43.090+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:48:43.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:48:43.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:48:43.125+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:48:43.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:48:43.136+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:48:43.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:48:43.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T07:49:13.522+0000] {processor.py:157} INFO - Started process (PID=12553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:49:13.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:49:13.527+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:49:13.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:49:13.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:49:13.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:49:13.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:49:13.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:49:13.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:49:13.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T07:49:43.949+0000] {processor.py:157} INFO - Started process (PID=12563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:49:43.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:49:43.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:49:43.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:49:43.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:49:43.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:49:43.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:49:43.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:49:43.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:49:44.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T07:50:14.385+0000] {processor.py:157} INFO - Started process (PID=12573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:50:14.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:50:14.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:50:14.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:50:14.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:50:14.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:50:14.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:50:14.427+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:50:14.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:50:14.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T07:50:44.759+0000] {processor.py:157} INFO - Started process (PID=12583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:50:44.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:50:44.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:50:44.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:50:44.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:50:44.796+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:50:44.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:50:44.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:50:44.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:50:44.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T07:51:15.153+0000] {processor.py:157} INFO - Started process (PID=12593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:51:15.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:51:15.155+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:51:15.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:51:15.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:51:15.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:51:15.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:51:15.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:51:15.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:51:15.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T07:51:45.571+0000] {processor.py:157} INFO - Started process (PID=12603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:51:45.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:51:45.573+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:51:45.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:51:45.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:51:45.604+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:51:45.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:51:45.613+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:51:45.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:51:45.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T07:52:16.010+0000] {processor.py:157} INFO - Started process (PID=12613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:52:16.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:52:16.013+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:52:16.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:52:16.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:52:16.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:52:16.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:52:16.059+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:52:16.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:52:16.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T07:52:46.411+0000] {processor.py:157} INFO - Started process (PID=12623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:52:46.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:52:46.414+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:52:46.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:52:46.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:52:46.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:52:46.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:52:46.464+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:52:46.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:52:46.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T07:53:16.711+0000] {processor.py:157} INFO - Started process (PID=12633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:53:16.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:53:16.712+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:53:16.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:53:16.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:53:16.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:53:16.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:53:16.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:53:16.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:53:16.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T07:53:47.016+0000] {processor.py:157} INFO - Started process (PID=12643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:53:47.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:53:47.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:53:47.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:53:47.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:53:47.047+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:53:47.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:53:47.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:53:47.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:53:47.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T07:54:17.497+0000] {processor.py:157} INFO - Started process (PID=12653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:54:17.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:54:17.502+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:54:17.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:54:17.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:54:17.534+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:54:17.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:54:17.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:54:17.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:54:17.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T07:54:47.920+0000] {processor.py:157} INFO - Started process (PID=12663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:54:47.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:54:47.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:54:47.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:54:47.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:54:47.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:54:47.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:54:47.965+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:54:47.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:54:47.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T07:55:18.333+0000] {processor.py:157} INFO - Started process (PID=12673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:55:18.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:55:18.336+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:55:18.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:55:18.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:55:18.363+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:55:18.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:55:18.376+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:55:18.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:55:18.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T07:55:48.732+0000] {processor.py:157} INFO - Started process (PID=12683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:55:48.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:55:48.737+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:55:48.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:55:48.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:55:48.766+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:55:48.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:55:48.778+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:55:48.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:55:48.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T07:56:19.104+0000] {processor.py:157} INFO - Started process (PID=12693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:56:19.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:56:19.107+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:56:19.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:56:19.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:56:19.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:56:19.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:56:19.148+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:56:19.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:56:19.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T07:56:49.540+0000] {processor.py:157} INFO - Started process (PID=12703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:56:49.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:56:49.544+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:56:49.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:56:49.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:56:49.574+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:56:49.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:56:49.583+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:56:49.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:56:49.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T07:57:19.953+0000] {processor.py:157} INFO - Started process (PID=12713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:57:19.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:57:19.956+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:57:19.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:57:19.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:57:19.984+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:57:19.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:57:19.998+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:57:19.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:57:20.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T07:57:50.409+0000] {processor.py:157} INFO - Started process (PID=12723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:57:50.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:57:50.413+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:57:50.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:57:50.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:57:50.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:57:50.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:57:50.456+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:57:50.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:57:50.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T07:58:20.819+0000] {processor.py:157} INFO - Started process (PID=12733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:58:20.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:58:20.822+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:58:20.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:58:20.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:58:20.878+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:58:20.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:58:20.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:58:20.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:58:20.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T07:58:51.172+0000] {processor.py:157} INFO - Started process (PID=12743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:58:51.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:58:51.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:58:51.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:58:51.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:58:51.225+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:58:51.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:58:51.245+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:58:51.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:58:51.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T07:59:21.578+0000] {processor.py:157} INFO - Started process (PID=12753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:59:21.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:59:21.583+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:59:21.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:59:21.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:59:21.616+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:59:21.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:59:21.627+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:59:21.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:59:21.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T07:59:52.009+0000] {processor.py:157} INFO - Started process (PID=12763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:59:52.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T07:59:52.012+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:59:52.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:59:52.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T07:59:52.044+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:59:52.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T07:59:52.054+0000] {logging_mixin.py:151} INFO - [2024-09-09T07:59:52.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T07:59:52.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T08:00:22.391+0000] {processor.py:157} INFO - Started process (PID=12773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:00:22.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:00:22.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:00:22.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:00:22.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:00:22.427+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:00:22.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:00:22.439+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:00:22.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:00:22.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T08:00:52.795+0000] {processor.py:157} INFO - Started process (PID=12783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:00:52.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:00:52.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:00:52.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:00:52.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:00:52.855+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:00:52.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:00:52.873+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:00:52.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:00:52.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-09T08:01:23.172+0000] {processor.py:157} INFO - Started process (PID=12793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:01:23.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:01:23.175+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:01:23.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:01:23.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:01:23.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:01:23.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:01:23.215+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:01:23.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:01:23.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T08:01:53.575+0000] {processor.py:157} INFO - Started process (PID=12803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:01:53.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:01:53.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:01:53.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:01:53.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:01:53.604+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:01:53.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:01:53.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:01:53.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:01:53.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T08:02:23.984+0000] {processor.py:157} INFO - Started process (PID=12813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:02:23.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:02:23.989+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:02:23.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:02:24.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:02:24.025+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:02:24.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:02:24.035+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:02:24.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:02:24.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T08:02:54.382+0000] {processor.py:157} INFO - Started process (PID=12823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:02:54.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:02:54.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:02:54.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:02:54.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:02:54.417+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:02:54.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:02:54.428+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:02:54.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:02:54.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T08:03:24.702+0000] {processor.py:157} INFO - Started process (PID=12833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:03:24.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:03:24.705+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:03:24.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:03:24.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:03:24.735+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:03:24.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:03:24.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:03:24.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:03:24.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:03:55.181+0000] {processor.py:157} INFO - Started process (PID=12843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:03:55.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:03:55.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:03:55.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:03:55.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:03:55.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:03:55.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:03:55.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:03:55.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:03:55.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T08:04:25.542+0000] {processor.py:157} INFO - Started process (PID=12852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:04:25.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:04:25.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:04:25.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:04:25.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:04:25.605+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:04:25.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:04:25.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:04:25.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:04:25.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T08:04:56.030+0000] {processor.py:157} INFO - Started process (PID=12863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:04:56.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:04:56.033+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:04:56.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:04:56.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:04:56.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:04:56.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:04:56.067+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:04:56.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:04:56.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T08:05:26.436+0000] {processor.py:157} INFO - Started process (PID=12873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:05:26.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:05:26.441+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:05:26.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:05:26.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:05:26.475+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:05:26.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:05:26.489+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:05:26.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:05:26.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T08:05:56.842+0000] {processor.py:157} INFO - Started process (PID=12883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:05:56.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:05:56.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:05:56.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:05:56.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:05:56.877+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:05:56.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:05:56.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:05:56.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:05:56.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T08:06:27.166+0000] {processor.py:157} INFO - Started process (PID=12893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:06:27.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:06:27.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:06:27.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:06:27.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:06:27.199+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:06:27.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:06:27.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:06:27.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:06:27.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T08:06:57.600+0000] {processor.py:157} INFO - Started process (PID=12903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:06:57.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:06:57.604+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:06:57.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:06:57.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:06:57.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:06:57.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:06:57.648+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:06:57.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:06:57.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T08:07:27.976+0000] {processor.py:157} INFO - Started process (PID=12913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:07:27.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:07:27.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:07:27.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:07:27.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:07:28.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:07:28.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:07:28.038+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:07:28.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:07:28.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T08:07:58.386+0000] {processor.py:157} INFO - Started process (PID=12923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:07:58.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:07:58.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:07:58.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:07:58.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:07:58.414+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:07:58.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:07:58.425+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:07:58.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:07:58.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T08:08:28.751+0000] {processor.py:157} INFO - Started process (PID=12933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:08:28.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:08:28.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:08:28.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:08:28.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:08:28.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:08:28.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:08:28.792+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:08:28.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:08:28.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T08:08:59.137+0000] {processor.py:157} INFO - Started process (PID=12943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:08:59.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:08:59.140+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:08:59.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:08:59.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:08:59.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:08:59.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:08:59.183+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:08:59.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:08:59.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T08:09:29.522+0000] {processor.py:157} INFO - Started process (PID=12953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:09:29.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:09:29.526+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:09:29.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:09:29.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:09:29.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:09:29.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:09:29.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:09:29.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:09:29.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:09:59.890+0000] {processor.py:157} INFO - Started process (PID=12963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:09:59.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:09:59.893+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:09:59.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:09:59.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:09:59.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:09:59.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:09:59.929+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:09:59.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:09:59.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T08:10:30.284+0000] {processor.py:157} INFO - Started process (PID=12973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:10:30.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:10:30.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:10:30.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:10:30.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:10:30.311+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:10:30.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:10:30.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:10:30.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:10:30.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T08:11:00.684+0000] {processor.py:157} INFO - Started process (PID=12983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:11:00.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:11:00.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:11:00.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:11:00.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:11:00.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:11:00.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:11:00.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:11:00.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:11:00.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T08:11:31.123+0000] {processor.py:157} INFO - Started process (PID=12993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:11:31.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:11:31.129+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:11:31.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:11:31.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:11:31.166+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:11:31.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:11:31.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:11:31.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:11:31.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T08:12:01.574+0000] {processor.py:157} INFO - Started process (PID=13003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:12:01.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:12:01.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:12:01.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:12:01.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:12:01.608+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:12:01.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:12:01.620+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:12:01.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:12:01.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T08:12:31.885+0000] {processor.py:157} INFO - Started process (PID=13013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:12:31.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:12:31.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:12:31.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:12:31.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:12:31.932+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:12:31.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:12:31.942+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:12:31.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:12:31.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T08:13:02.144+0000] {processor.py:157} INFO - Started process (PID=13023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:13:02.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:13:02.152+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:13:02.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:13:02.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:13:02.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:13:02.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:13:02.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:13:02.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:13:02.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T08:13:32.514+0000] {processor.py:157} INFO - Started process (PID=13033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:13:32.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:13:32.518+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:13:32.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:13:32.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:13:32.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:13:32.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:13:32.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:13:32.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:13:32.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:14:02.995+0000] {processor.py:157} INFO - Started process (PID=13041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:14:02.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:14:02.999+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:14:02.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:14:03.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:14:03.045+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:14:03.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:14:03.055+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:14:03.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:14:03.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T08:14:33.391+0000] {processor.py:157} INFO - Started process (PID=13053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:14:33.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:14:33.394+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:14:33.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:14:33.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:14:33.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:14:33.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:14:33.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:14:33.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:14:33.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T08:15:03.838+0000] {processor.py:157} INFO - Started process (PID=13063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:15:03.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:15:03.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:15:03.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:15:03.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:15:03.877+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:15:03.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:15:03.885+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:15:03.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:15:03.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T08:15:34.166+0000] {processor.py:157} INFO - Started process (PID=13073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:15:34.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:15:34.168+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:15:34.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:15:34.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:15:34.194+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:15:34.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:15:34.205+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:15:34.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:15:34.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T08:16:04.553+0000] {processor.py:157} INFO - Started process (PID=13083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:16:04.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:16:04.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:16:04.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:16:04.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:16:04.584+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:16:04.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:16:04.595+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:16:04.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:16:04.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T08:16:34.947+0000] {processor.py:157} INFO - Started process (PID=13093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:16:34.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:16:34.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:16:34.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:16:34.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:16:34.978+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:16:34.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:16:34.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:16:34.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:16:35.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T08:17:05.282+0000] {processor.py:157} INFO - Started process (PID=13103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:17:05.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:17:05.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:17:05.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:17:05.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:17:05.311+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:17:05.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:17:05.324+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:17:05.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:17:05.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T08:17:35.694+0000] {processor.py:157} INFO - Started process (PID=13112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:17:35.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:17:35.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:17:35.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:17:35.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:17:35.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:17:35.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:17:35.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:17:35.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:17:35.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T08:18:06.062+0000] {processor.py:157} INFO - Started process (PID=13123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:18:06.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:18:06.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:18:06.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:18:06.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:18:06.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:18:06.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:18:06.106+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:18:06.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:18:06.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:18:36.430+0000] {processor.py:157} INFO - Started process (PID=13133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:18:36.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:18:36.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:18:36.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:18:36.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:18:36.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:18:36.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:18:36.474+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:18:36.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:18:36.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T08:19:06.804+0000] {processor.py:157} INFO - Started process (PID=13143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:19:06.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:19:06.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:19:06.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:19:06.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:19:06.841+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:19:06.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:19:06.851+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:19:06.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:19:06.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T08:19:37.195+0000] {processor.py:157} INFO - Started process (PID=13153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:19:37.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:19:37.199+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:19:37.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:19:37.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:19:37.224+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:19:37.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:19:37.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:19:37.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:19:37.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T08:20:07.587+0000] {processor.py:157} INFO - Started process (PID=13163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:20:07.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:20:07.590+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:20:07.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:20:07.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:20:07.617+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:20:07.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:20:07.629+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:20:07.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:20:07.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T08:20:38.025+0000] {processor.py:157} INFO - Started process (PID=13172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:20:38.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:20:38.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:20:38.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:20:38.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:20:38.067+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:20:38.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:20:38.078+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:20:38.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:20:38.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T08:21:08.429+0000] {processor.py:157} INFO - Started process (PID=13183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:21:08.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:21:08.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:21:08.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:21:08.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:21:08.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:21:08.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:21:08.472+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:21:08.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:21:08.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T08:21:38.748+0000] {processor.py:157} INFO - Started process (PID=13193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:21:38.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:21:38.752+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:21:38.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:21:38.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:21:38.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:21:38.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:21:38.788+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:21:38.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:21:38.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T08:22:09.125+0000] {processor.py:157} INFO - Started process (PID=13203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:22:09.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:22:09.128+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:22:09.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:22:09.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:22:09.161+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:22:09.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:22:09.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:22:09.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:22:09.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T08:22:39.527+0000] {processor.py:157} INFO - Started process (PID=13213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:22:39.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:22:39.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:22:39.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:22:39.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:22:39.554+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:22:39.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:22:39.564+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:22:39.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:22:39.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T08:23:09.949+0000] {processor.py:157} INFO - Started process (PID=13223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:23:09.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:23:09.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:23:09.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:23:09.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:23:09.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:23:09.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:23:09.993+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:23:09.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:23:10.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:23:40.267+0000] {processor.py:157} INFO - Started process (PID=13232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:23:40.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:23:40.272+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:23:40.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:23:40.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:23:40.309+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:23:40.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:23:40.324+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:23:40.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:23:40.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T08:24:10.597+0000] {processor.py:157} INFO - Started process (PID=13243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:24:10.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:24:10.599+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:24:10.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:24:10.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:24:10.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:24:10.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:24:10.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:24:10.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:24:10.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T08:24:41.004+0000] {processor.py:157} INFO - Started process (PID=13253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:24:41.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:24:41.009+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:24:41.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:24:41.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:24:41.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:24:41.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:24:41.059+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:24:41.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:24:41.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T08:25:11.441+0000] {processor.py:157} INFO - Started process (PID=13263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:25:11.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:25:11.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:25:11.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:25:11.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:25:11.472+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:25:11.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:25:11.485+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:25:11.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:25:11.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:25:41.828+0000] {processor.py:157} INFO - Started process (PID=13273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:25:41.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:25:41.831+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:25:41.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:25:41.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:25:41.863+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:25:41.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:25:41.876+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:25:41.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:25:41.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T08:26:12.194+0000] {processor.py:157} INFO - Started process (PID=13283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:26:12.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:26:12.197+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:26:12.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:26:12.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:26:12.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:26:12.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:26:12.239+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:26:12.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:26:12.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:26:42.634+0000] {processor.py:157} INFO - Started process (PID=13292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:26:42.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:26:42.639+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:26:42.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:26:42.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:26:42.697+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:26:42.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:26:42.707+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:26:42.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:26:42.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T08:27:12.972+0000] {processor.py:157} INFO - Started process (PID=13303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:27:12.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:27:12.975+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:27:12.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:27:12.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:27:13.004+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:27:13.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:27:13.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:27:13.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:27:13.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T08:27:43.353+0000] {processor.py:157} INFO - Started process (PID=13313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:27:43.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:27:43.359+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:27:43.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:27:43.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:27:43.394+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:27:43.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:27:43.407+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:27:43.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:27:43.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T08:28:13.793+0000] {processor.py:157} INFO - Started process (PID=13323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:28:13.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:28:13.797+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:28:13.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:28:13.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:28:13.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:28:13.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:28:13.838+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:28:13.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:28:13.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T08:28:44.164+0000] {processor.py:157} INFO - Started process (PID=13333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:28:44.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:28:44.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:28:44.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:28:44.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:28:44.205+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:28:44.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:28:44.218+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:28:44.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:28:44.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T08:29:14.542+0000] {processor.py:157} INFO - Started process (PID=13343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:29:14.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:29:14.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:29:14.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:29:14.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:29:14.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:29:14.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:29:14.589+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:29:14.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:29:14.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T08:29:44.945+0000] {processor.py:157} INFO - Started process (PID=13353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:29:44.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:29:44.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:29:44.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:29:44.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:29:44.995+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:29:44.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:29:45.005+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:29:45.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:29:45.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T08:30:15.278+0000] {processor.py:157} INFO - Started process (PID=13363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:30:15.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:30:15.281+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:30:15.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:30:15.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:30:15.309+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:30:15.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:30:15.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:30:15.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:30:15.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T08:30:45.643+0000] {processor.py:157} INFO - Started process (PID=13373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:30:45.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:30:45.646+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:30:45.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:30:45.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:30:45.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:30:45.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:30:45.680+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:30:45.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:30:45.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T08:31:15.962+0000] {processor.py:157} INFO - Started process (PID=13383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:31:15.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:31:15.965+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:31:15.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:31:15.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:31:15.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:31:15.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:31:15.999+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:31:15.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:31:16.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T08:31:46.377+0000] {processor.py:157} INFO - Started process (PID=13393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:31:46.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:31:46.380+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:31:46.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:31:46.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:31:46.413+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:31:46.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:31:46.424+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:31:46.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:31:46.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T08:32:16.835+0000] {processor.py:157} INFO - Started process (PID=13403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:32:16.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:32:16.838+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:32:16.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:32:16.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:32:16.868+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:32:16.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:32:16.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:32:16.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:32:16.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T08:32:47.206+0000] {processor.py:157} INFO - Started process (PID=13413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:32:47.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:32:47.209+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:32:47.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:32:47.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:32:47.236+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:32:47.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:32:47.247+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:32:47.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:32:47.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T08:33:17.631+0000] {processor.py:157} INFO - Started process (PID=13423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:33:17.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:33:17.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:33:17.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:33:17.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:33:17.663+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:33:17.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:33:17.672+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:33:17.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:33:17.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T08:33:48.076+0000] {processor.py:157} INFO - Started process (PID=13433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:33:48.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:33:48.079+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:33:48.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:33:48.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:33:48.109+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:33:48.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:33:48.121+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:33:48.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:33:48.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T08:34:18.499+0000] {processor.py:157} INFO - Started process (PID=13443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:34:18.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:34:18.502+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:34:18.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:34:18.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:34:18.526+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:34:18.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:34:18.536+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:34:18.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:34:18.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T08:34:48.831+0000] {processor.py:157} INFO - Started process (PID=13453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:34:48.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:34:48.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:34:48.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:34:48.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:34:48.859+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:34:48.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:34:48.867+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:34:48.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:34:48.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T08:35:19.126+0000] {processor.py:157} INFO - Started process (PID=13463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:35:19.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:35:19.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:35:19.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:35:19.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:35:19.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:35:19.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:35:19.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:35:19.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:35:19.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T08:35:49.408+0000] {processor.py:157} INFO - Started process (PID=13473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:35:49.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:35:49.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:35:49.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:35:49.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:35:49.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:35:49.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:35:49.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:35:49.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:35:49.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-09T08:36:19.786+0000] {processor.py:157} INFO - Started process (PID=13483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:36:19.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:36:19.789+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:36:19.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:36:19.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:36:19.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:36:19.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:36:19.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:36:19.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:36:19.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T08:36:50.262+0000] {processor.py:157} INFO - Started process (PID=13492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:36:50.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:36:50.267+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:36:50.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:36:50.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:36:50.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:36:50.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:36:50.328+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:36:50.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:36:50.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T08:37:20.594+0000] {processor.py:157} INFO - Started process (PID=13503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:37:20.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:37:20.597+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:37:20.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:37:20.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:37:20.623+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:37:20.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:37:20.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:37:20.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:37:20.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T08:37:50.984+0000] {processor.py:157} INFO - Started process (PID=13513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:37:50.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:37:50.988+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:37:50.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:37:50.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:37:51.019+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:37:51.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:37:51.028+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:37:51.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:37:51.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T08:38:21.345+0000] {processor.py:157} INFO - Started process (PID=13523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:38:21.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:38:21.350+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:38:21.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:38:21.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:38:21.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:38:21.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:38:21.397+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:38:21.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:38:21.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T08:38:51.774+0000] {processor.py:157} INFO - Started process (PID=13533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:38:51.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:38:51.778+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:38:51.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:38:51.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:38:51.805+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:38:51.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:38:51.815+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:38:51.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:38:51.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T08:39:22.142+0000] {processor.py:157} INFO - Started process (PID=13543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:39:22.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:39:22.145+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:39:22.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:39:22.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:39:22.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:39:22.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:39:22.183+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:39:22.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:39:22.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T08:39:52.489+0000] {processor.py:157} INFO - Started process (PID=13553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:39:52.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:39:52.491+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:39:52.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:39:52.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:39:52.515+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:39:52.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:39:52.526+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:39:52.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:39:52.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T08:40:22.905+0000] {processor.py:157} INFO - Started process (PID=13563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:40:22.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:40:22.909+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:40:22.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:40:22.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:40:22.937+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:40:22.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:40:22.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:40:22.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:40:22.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T08:40:53.306+0000] {processor.py:157} INFO - Started process (PID=13572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:40:53.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:40:53.312+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:40:53.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:40:53.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:40:53.352+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:40:53.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:40:53.364+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:40:53.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:40:53.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T08:41:23.675+0000] {processor.py:157} INFO - Started process (PID=13583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:41:23.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:41:23.678+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:41:23.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:41:23.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:41:23.703+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:41:23.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:41:23.713+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:41:23.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:41:23.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T08:58:14.677+0000] {processor.py:157} INFO - Started process (PID=13595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:58:14.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:58:14.683+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:58:14.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:58:14.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:58:14.754+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:58:14.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:58:14.783+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:58:14.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:58:14.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-09T08:58:44.968+0000] {processor.py:157} INFO - Started process (PID=13604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:58:44.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:58:44.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:58:44.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:58:44.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:58:45.024+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:58:45.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:58:45.037+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:58:45.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:58:45.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-09T08:59:15.349+0000] {processor.py:157} INFO - Started process (PID=13615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:59:15.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:59:15.351+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:59:15.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:59:15.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:59:15.384+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:59:15.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:59:15.408+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:59:15.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:59:15.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T08:59:45.766+0000] {processor.py:157} INFO - Started process (PID=13625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:59:45.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T08:59:45.771+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:59:45.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:59:45.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T08:59:45.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:59:45.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T08:59:45.831+0000] {logging_mixin.py:151} INFO - [2024-09-09T08:59:45.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T08:59:45.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T09:00:16.141+0000] {processor.py:157} INFO - Started process (PID=13635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:00:16.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:00:16.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:00:16.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:00:16.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:00:16.174+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:00:16.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:00:16.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:00:16.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:00:16.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T09:00:46.514+0000] {processor.py:157} INFO - Started process (PID=13645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:00:46.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:00:46.519+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:00:46.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:00:46.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:00:46.558+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:00:46.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:00:46.570+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:00:46.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:00:46.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T09:01:16.866+0000] {processor.py:157} INFO - Started process (PID=13655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:01:16.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:01:16.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:01:16.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:01:16.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:01:16.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:01:16.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:01:16.924+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:01:16.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:01:16.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T09:01:47.249+0000] {processor.py:157} INFO - Started process (PID=13665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:01:47.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:01:47.252+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:01:47.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:01:47.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:01:47.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:01:47.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:01:47.295+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:01:47.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:01:47.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T09:02:17.589+0000] {processor.py:157} INFO - Started process (PID=13675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:02:17.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:02:17.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:02:17.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:02:17.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:02:17.617+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:02:17.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:02:17.629+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:02:17.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:02:17.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T09:02:47.968+0000] {processor.py:157} INFO - Started process (PID=13685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:02:47.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:02:47.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:02:47.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:02:47.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:02:48.021+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:02:48.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:02:48.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:02:48.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:02:48.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-09T09:03:18.407+0000] {processor.py:157} INFO - Started process (PID=13695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:03:18.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:03:18.410+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:03:18.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:03:18.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:03:18.441+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:03:18.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:03:18.452+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:03:18.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:03:18.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T09:03:48.752+0000] {processor.py:157} INFO - Started process (PID=13705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:03:48.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:03:48.756+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:03:48.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:03:48.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:03:48.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:03:48.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:03:48.792+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:03:48.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:03:48.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T09:04:19.056+0000] {processor.py:157} INFO - Started process (PID=13715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:04:19.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:04:19.060+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:04:19.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:04:19.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:04:19.085+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:04:19.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:04:19.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:04:19.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:04:19.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T09:04:49.419+0000] {processor.py:157} INFO - Started process (PID=13725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:04:49.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:04:49.424+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:04:49.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:04:49.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:04:49.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:04:49.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:04:49.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:04:49.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:04:49.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T09:05:19.769+0000] {processor.py:157} INFO - Started process (PID=13735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:05:19.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:05:19.772+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:05:19.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:05:19.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:05:19.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:05:19.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:05:19.811+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:05:19.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:05:19.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T09:05:50.091+0000] {processor.py:157} INFO - Started process (PID=13745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:05:50.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:05:50.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:05:50.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:05:50.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:05:50.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:05:50.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:05:50.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:05:50.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:05:50.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T09:06:20.456+0000] {processor.py:157} INFO - Started process (PID=13755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:06:20.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:06:20.459+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:06:20.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:06:20.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:06:20.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:06:20.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:06:20.500+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:06:20.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:06:20.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T09:06:50.838+0000] {processor.py:157} INFO - Started process (PID=13765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:06:50.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:06:50.842+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:06:50.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:06:50.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:06:50.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:06:50.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:06:50.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:06:50.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:06:50.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T09:07:21.237+0000] {processor.py:157} INFO - Started process (PID=13775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:07:21.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:07:21.242+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:07:21.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:07:21.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:07:21.273+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:07:21.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:07:21.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:07:21.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:07:21.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T09:07:51.579+0000] {processor.py:157} INFO - Started process (PID=13785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:07:51.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:07:51.581+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:07:51.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:07:51.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:07:51.608+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:07:51.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:07:51.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:07:51.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:07:51.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T09:08:21.961+0000] {processor.py:157} INFO - Started process (PID=13795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:08:21.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:08:21.964+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:08:21.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:08:21.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:08:21.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:08:21.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:08:21.999+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:08:21.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:08:22.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T09:08:52.343+0000] {processor.py:157} INFO - Started process (PID=13805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:08:52.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:08:52.349+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:08:52.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:08:52.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:08:52.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:08:52.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:08:52.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:08:52.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:08:52.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T09:09:22.643+0000] {processor.py:157} INFO - Started process (PID=13815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:09:22.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:09:22.647+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:09:22.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:09:22.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:09:22.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:09:22.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:09:22.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:09:22.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:09:22.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T09:09:53.003+0000] {processor.py:157} INFO - Started process (PID=13825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:09:53.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:09:53.008+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:09:53.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:09:53.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:09:53.032+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:09:53.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:09:53.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:09:53.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:09:53.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T09:10:23.379+0000] {processor.py:157} INFO - Started process (PID=13835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:10:23.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:10:23.384+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:10:23.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:10:23.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:10:23.411+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:10:23.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:10:23.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:10:23.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:10:23.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T09:10:53.722+0000] {processor.py:157} INFO - Started process (PID=13844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:10:53.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:10:53.727+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:10:53.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:10:53.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:10:53.760+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:10:53.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:10:53.774+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:10:53.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:10:53.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T09:11:24.087+0000] {processor.py:157} INFO - Started process (PID=13855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:11:24.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:11:24.092+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:11:24.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:11:24.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:11:24.122+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:11:24.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:11:24.132+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:11:24.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:11:24.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T09:11:54.464+0000] {processor.py:157} INFO - Started process (PID=13865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:11:54.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:11:54.468+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:11:54.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:11:54.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:11:54.494+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:11:54.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:11:54.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:11:54.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:11:54.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T09:12:24.846+0000] {processor.py:157} INFO - Started process (PID=13875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:12:24.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:12:24.851+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:12:24.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:12:24.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:12:24.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:12:24.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:12:24.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:12:24.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:12:24.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T09:12:55.156+0000] {processor.py:157} INFO - Started process (PID=13885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:12:55.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:12:55.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:12:55.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:12:55.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:12:55.192+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:12:55.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:12:55.202+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:12:55.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:12:55.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T09:13:25.571+0000] {processor.py:157} INFO - Started process (PID=13895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:13:25.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:13:25.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:13:25.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:13:25.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:13:25.607+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:13:25.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:13:25.617+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:13:25.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:13:25.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T09:30:13.154+0000] {processor.py:157} INFO - Started process (PID=13907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:30:13.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:30:13.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:30:13.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:30:13.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:30:13.195+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:30:13.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:30:13.207+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:30:13.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:30:13.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T09:30:43.489+0000] {processor.py:157} INFO - Started process (PID=13917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:30:43.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:30:43.494+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:30:43.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:30:43.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:30:43.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:30:43.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:30:43.543+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:30:43.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:30:43.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T09:31:13.862+0000] {processor.py:157} INFO - Started process (PID=13927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:31:13.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:31:13.866+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:31:13.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:31:13.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:31:13.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:31:13.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:31:13.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:31:13.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:31:13.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T09:31:44.256+0000] {processor.py:157} INFO - Started process (PID=13937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:31:44.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:31:44.262+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:31:44.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:31:44.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:31:44.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:31:44.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:31:44.313+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:31:44.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:31:44.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T09:48:00.903+0000] {processor.py:157} INFO - Started process (PID=13948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:48:00.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:48:00.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:48:00.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:48:00.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:48:00.961+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:48:00.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:48:00.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:48:00.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:48:00.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T09:48:31.274+0000] {processor.py:157} INFO - Started process (PID=13959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:48:31.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T09:48:31.279+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:48:31.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:48:31.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T09:48:31.334+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:48:31.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T09:48:31.347+0000] {logging_mixin.py:151} INFO - [2024-09-09T09:48:31.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T09:48:31.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-09T10:05:31.989+0000] {processor.py:157} INFO - Started process (PID=13967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:05:31.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:05:31.995+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:05:31.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:05:32.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:05:32.066+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:05:32.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:05:32.085+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:05:32.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:05:32.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-09T10:06:02.353+0000] {processor.py:157} INFO - Started process (PID=13979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:06:02.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:06:02.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:06:02.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:06:02.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:06:02.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:06:02.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:06:02.412+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:06:02.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:06:02.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T10:06:32.746+0000] {processor.py:157} INFO - Started process (PID=13989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:06:32.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:06:32.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:06:32.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:06:32.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:06:32.776+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:06:32.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:06:32.787+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:06:32.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:06:32.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:07:03.161+0000] {processor.py:157} INFO - Started process (PID=13999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:07:03.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:07:03.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:07:03.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:07:03.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:07:03.192+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:07:03.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:07:03.204+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:07:03.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:07:03.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T10:07:33.590+0000] {processor.py:157} INFO - Started process (PID=14009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:07:33.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:07:33.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:07:33.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:07:33.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:07:33.623+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:07:33.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:07:33.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:07:33.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:07:33.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:08:04.006+0000] {processor.py:157} INFO - Started process (PID=14019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:08:04.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:08:04.010+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:08:04.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:08:04.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:08:04.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:08:04.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:08:04.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:08:04.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:08:04.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T10:08:34.396+0000] {processor.py:157} INFO - Started process (PID=14029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:08:34.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:08:34.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:08:34.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:08:34.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:08:34.427+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:08:34.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:08:34.437+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:08:34.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:08:34.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:09:04.789+0000] {processor.py:157} INFO - Started process (PID=14039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:09:04.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:09:04.791+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:09:04.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:09:04.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:09:04.823+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:09:04.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:09:04.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:09:04.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:09:04.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:09:35.153+0000] {processor.py:157} INFO - Started process (PID=14049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:09:35.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:09:35.156+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:09:35.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:09:35.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:09:35.185+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:09:35.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:09:35.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:09:35.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:09:35.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T10:10:05.512+0000] {processor.py:157} INFO - Started process (PID=14059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:10:05.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:10:05.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:10:05.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:10:05.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:10:05.544+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:10:05.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:10:05.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:10:05.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:10:05.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:10:35.866+0000] {processor.py:157} INFO - Started process (PID=14069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:10:35.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:10:35.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:10:35.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:10:35.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:10:35.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:10:35.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:10:35.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:10:35.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:10:35.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:11:06.245+0000] {processor.py:157} INFO - Started process (PID=14079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:11:06.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:11:06.249+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:11:06.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:11:06.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:11:06.275+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:11:06.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:11:06.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:11:06.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:11:06.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:11:36.613+0000] {processor.py:157} INFO - Started process (PID=14089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:11:36.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:11:36.616+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:11:36.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:11:36.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:11:36.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:11:36.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:11:36.654+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:11:36.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:11:36.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:12:07.025+0000] {processor.py:157} INFO - Started process (PID=14099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:12:07.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:12:07.029+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:12:07.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:12:07.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:12:07.054+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:12:07.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:12:07.064+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:12:07.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:12:07.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T10:12:37.315+0000] {processor.py:157} INFO - Started process (PID=14108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:12:37.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:12:37.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:12:37.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:12:37.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:12:37.353+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:12:37.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:12:37.367+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:12:37.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:12:37.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T10:13:07.631+0000] {processor.py:157} INFO - Started process (PID=14119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:13:07.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:13:07.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:13:07.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:13:07.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:13:07.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:13:07.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:13:07.669+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:13:07.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:13:07.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T10:13:37.978+0000] {processor.py:157} INFO - Started process (PID=14129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:13:37.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:13:37.981+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:13:37.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:13:37.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:13:38.008+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:13:38.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:13:38.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:13:38.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:13:38.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:14:08.255+0000] {processor.py:157} INFO - Started process (PID=14139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:14:08.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:14:08.257+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:14:08.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:14:08.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:14:08.285+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:14:08.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:14:08.297+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:14:08.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:14:08.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T10:14:38.601+0000] {processor.py:157} INFO - Started process (PID=14149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:14:38.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:14:38.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:14:38.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:14:38.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:14:38.631+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:14:38.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:14:38.641+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:14:38.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:14:38.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:15:09.004+0000] {processor.py:157} INFO - Started process (PID=14159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:15:09.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:15:09.008+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:15:09.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:15:09.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:15:09.045+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:15:09.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:15:09.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:15:09.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:15:09.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T10:15:39.351+0000] {processor.py:157} INFO - Started process (PID=14169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:15:39.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:15:39.354+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:15:39.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:15:39.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:15:39.382+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:15:39.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:15:39.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:15:39.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:15:39.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:16:09.740+0000] {processor.py:157} INFO - Started process (PID=14179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:16:09.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:16:09.744+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:16:09.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:16:09.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:16:09.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:16:09.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:16:09.785+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:16:09.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:16:09.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:16:40.117+0000] {processor.py:157} INFO - Started process (PID=14189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:16:40.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:16:40.121+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:16:40.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:16:40.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:16:40.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:16:40.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:16:40.157+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:16:40.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:16:40.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:17:10.464+0000] {processor.py:157} INFO - Started process (PID=14199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:17:10.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:17:10.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:17:10.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:17:10.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:17:10.491+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:17:10.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:17:10.501+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:17:10.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:17:10.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T10:17:40.864+0000] {processor.py:157} INFO - Started process (PID=14209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:17:40.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:17:40.868+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:17:40.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:17:40.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:17:40.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:17:40.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:17:40.907+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:17:40.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:17:40.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:18:11.226+0000] {processor.py:157} INFO - Started process (PID=14219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:18:11.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:18:11.231+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:18:11.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:18:11.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:18:11.257+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:18:11.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:18:11.267+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:18:11.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:18:11.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:18:41.582+0000] {processor.py:157} INFO - Started process (PID=14229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:18:41.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:18:41.585+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:18:41.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:18:41.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:18:41.611+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:18:41.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:18:41.623+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:18:41.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:18:41.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T10:19:11.930+0000] {processor.py:157} INFO - Started process (PID=14239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:19:11.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:19:11.934+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:19:11.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:19:11.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:19:11.961+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:19:11.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:19:11.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:19:11.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:19:11.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:19:42.303+0000] {processor.py:157} INFO - Started process (PID=14249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:19:42.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:19:42.306+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:19:42.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:19:42.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:19:42.330+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:19:42.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:19:42.341+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:19:42.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:19:42.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T10:20:12.678+0000] {processor.py:157} INFO - Started process (PID=14259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:20:12.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:20:12.684+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:20:12.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:20:12.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:20:12.718+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:20:12.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:20:12.731+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:20:12.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:20:12.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T10:20:43.113+0000] {processor.py:157} INFO - Started process (PID=14269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:20:43.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:20:43.116+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:20:43.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:20:43.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:20:43.143+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:20:43.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:20:43.153+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:20:43.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:20:43.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:21:13.551+0000] {processor.py:157} INFO - Started process (PID=14279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:21:13.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:21:13.554+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:21:13.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:21:13.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:21:13.581+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:21:13.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:21:13.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:21:13.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:21:13.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T10:21:43.914+0000] {processor.py:157} INFO - Started process (PID=14289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:21:43.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:21:43.918+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:21:43.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:21:43.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:21:43.943+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:21:43.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:21:43.953+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:21:43.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:21:43.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T10:22:14.304+0000] {processor.py:157} INFO - Started process (PID=14299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:22:14.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:22:14.306+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:22:14.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:22:14.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:22:14.334+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:22:14.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:22:14.345+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:22:14.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:22:14.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T10:22:44.657+0000] {processor.py:157} INFO - Started process (PID=14309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:22:44.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:22:44.659+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:22:44.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:22:44.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:22:44.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:22:44.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:22:44.698+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:22:44.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:22:44.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:23:15.053+0000] {processor.py:157} INFO - Started process (PID=14319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:23:15.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:23:15.055+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:23:15.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:23:15.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:23:15.084+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:23:15.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:23:15.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:23:15.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:23:15.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:23:45.428+0000] {processor.py:157} INFO - Started process (PID=14329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:23:45.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:23:45.430+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:23:45.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:23:45.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:23:45.458+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:23:45.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:23:45.469+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:23:45.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:23:45.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:24:15.849+0000] {processor.py:157} INFO - Started process (PID=14339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:24:15.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:24:15.851+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:24:15.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:24:15.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:24:15.878+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:24:15.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:24:15.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:24:15.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:24:15.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T10:24:46.216+0000] {processor.py:157} INFO - Started process (PID=14349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:24:46.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:24:46.222+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:24:46.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:24:46.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:24:46.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:24:46.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:24:46.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:24:46.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:24:46.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:25:16.586+0000] {processor.py:157} INFO - Started process (PID=14359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:25:16.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:25:16.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:25:16.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:25:16.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:25:16.628+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:25:16.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:25:16.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:25:16.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:25:16.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T10:25:46.985+0000] {processor.py:157} INFO - Started process (PID=14369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:25:46.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:25:46.989+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:25:46.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:25:47.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:25:47.022+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:25:47.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:25:47.033+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:25:47.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:25:47.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T10:26:17.343+0000] {processor.py:157} INFO - Started process (PID=14379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:26:17.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:26:17.346+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:26:17.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:26:17.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:26:17.373+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:26:17.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:26:17.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:26:17.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:26:17.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:26:47.721+0000] {processor.py:157} INFO - Started process (PID=14389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:26:47.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:26:47.724+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:26:47.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:26:47.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:26:47.749+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:26:47.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:26:47.759+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:26:47.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:26:47.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:27:18.067+0000] {processor.py:157} INFO - Started process (PID=14399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:27:18.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:27:18.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:27:18.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:27:18.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:27:18.099+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:27:18.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:27:18.111+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:27:18.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:27:18.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:27:48.428+0000] {processor.py:157} INFO - Started process (PID=14409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:27:48.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:27:48.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:27:48.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:27:48.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:27:48.458+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:27:48.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:27:48.468+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:27:48.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:27:48.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:28:18.850+0000] {processor.py:157} INFO - Started process (PID=14419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:28:18.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:28:18.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:28:18.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:28:18.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:28:18.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:28:18.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:28:18.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:28:18.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:28:18.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:28:49.214+0000] {processor.py:157} INFO - Started process (PID=14429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:28:49.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:28:49.220+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:28:49.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:28:49.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:28:49.253+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:28:49.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:28:49.267+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:28:49.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:28:49.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T10:29:19.622+0000] {processor.py:157} INFO - Started process (PID=14439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:29:19.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:29:19.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:29:19.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:29:19.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:29:19.651+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:29:19.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:29:19.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:29:19.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:29:19.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:29:49.988+0000] {processor.py:157} INFO - Started process (PID=14449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:29:49.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:29:49.992+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:29:49.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:29:50.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:29:50.020+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:29:50.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:29:50.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:29:50.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:29:50.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:30:20.384+0000] {processor.py:157} INFO - Started process (PID=14459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:30:20.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:30:20.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:30:20.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:30:20.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:30:20.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:30:20.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:30:20.427+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:30:20.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:30:20.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:30:50.777+0000] {processor.py:157} INFO - Started process (PID=14469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:30:50.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:30:50.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:30:50.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:30:50.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:30:50.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:30:50.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:30:50.820+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:30:50.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:30:50.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:31:21.113+0000] {processor.py:157} INFO - Started process (PID=14479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:31:21.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:31:21.117+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:31:21.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:31:21.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:31:21.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:31:21.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:31:21.154+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:31:21.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:31:21.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:31:51.426+0000] {processor.py:157} INFO - Started process (PID=14489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:31:51.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:31:51.429+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:31:51.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:31:51.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:31:51.457+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:31:51.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:31:51.469+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:31:51.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:31:51.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:32:21.772+0000] {processor.py:157} INFO - Started process (PID=14499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:32:21.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:32:21.778+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:32:21.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:32:21.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:32:21.806+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:32:21.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:32:21.819+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:32:21.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:32:21.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T10:32:52.182+0000] {processor.py:157} INFO - Started process (PID=14509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:32:52.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:32:52.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:32:52.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:32:52.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:32:52.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:32:52.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:32:52.240+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:32:52.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:32:52.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T10:33:22.450+0000] {processor.py:157} INFO - Started process (PID=14519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:33:22.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:33:22.453+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:33:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:33:22.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:33:22.481+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:33:22.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:33:22.491+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:33:22.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:33:22.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:33:52.858+0000] {processor.py:157} INFO - Started process (PID=14529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:33:52.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:33:52.862+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:33:52.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:33:52.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:33:52.889+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:33:52.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:33:52.898+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:33:52.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:33:52.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:34:23.215+0000] {processor.py:157} INFO - Started process (PID=14539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:34:23.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:34:23.218+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:34:23.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:34:23.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:34:23.249+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:34:23.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:34:23.259+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:34:23.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:34:23.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:34:53.574+0000] {processor.py:157} INFO - Started process (PID=14548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:34:53.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:34:53.594+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:34:53.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:34:53.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:34:53.627+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:34:53.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:34:53.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:34:53.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:34:53.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-09T10:35:23.916+0000] {processor.py:157} INFO - Started process (PID=14559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:35:23.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:35:23.922+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:35:23.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:35:23.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:35:23.946+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:35:23.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:35:23.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:35:23.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:35:23.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T10:35:54.373+0000] {processor.py:157} INFO - Started process (PID=14569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:35:54.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:35:54.377+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:35:54.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:35:54.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:35:54.404+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:35:54.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:35:54.414+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:35:54.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:35:54.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:36:24.728+0000] {processor.py:157} INFO - Started process (PID=14579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:36:24.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:36:24.734+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:36:24.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:36:24.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:36:24.770+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:36:24.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:36:24.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:36:24.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:36:24.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T10:36:55.108+0000] {processor.py:157} INFO - Started process (PID=14589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:36:55.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:36:55.110+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:36:55.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:36:55.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:36:55.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:36:55.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:36:55.145+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:36:55.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:36:55.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T10:37:25.422+0000] {processor.py:157} INFO - Started process (PID=14599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:37:25.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:37:25.425+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:37:25.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:37:25.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:37:25.452+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:37:25.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:37:25.462+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:37:25.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:37:25.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:37:55.814+0000] {processor.py:157} INFO - Started process (PID=14609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:37:55.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:37:55.817+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:37:55.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:37:55.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:37:55.842+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:37:55.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:37:55.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:37:55.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:37:55.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:38:26.225+0000] {processor.py:157} INFO - Started process (PID=14619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:38:26.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:38:26.229+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:38:26.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:38:26.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:38:26.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:38:26.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:38:26.265+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:38:26.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:38:26.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T10:38:56.589+0000] {processor.py:157} INFO - Started process (PID=14629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:38:56.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:38:56.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:38:56.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:38:56.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:38:56.621+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:38:56.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:38:56.632+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:38:56.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:38:56.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T10:39:26.935+0000] {processor.py:157} INFO - Started process (PID=14639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:39:26.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:39:26.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:39:26.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:39:26.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:39:26.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:39:26.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:39:26.984+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:39:26.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:39:26.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T10:39:57.336+0000] {processor.py:157} INFO - Started process (PID=14649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:39:57.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:39:57.339+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:39:57.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:39:57.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:39:57.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:39:57.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:39:57.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:39:57.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:39:57.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T10:40:27.677+0000] {processor.py:157} INFO - Started process (PID=14659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:40:27.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:40:27.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:40:27.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:40:27.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:40:27.706+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:40:27.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:40:27.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:40:27.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:40:27.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:40:58.050+0000] {processor.py:157} INFO - Started process (PID=14669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:40:58.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:40:58.055+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:40:58.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:40:58.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:40:58.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:40:58.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:40:58.092+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:40:58.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:40:58.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T10:41:28.465+0000] {processor.py:157} INFO - Started process (PID=14679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:41:28.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:41:28.469+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:41:28.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:41:28.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:41:28.494+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:41:28.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:41:28.505+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:41:28.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:41:28.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T10:41:58.785+0000] {processor.py:157} INFO - Started process (PID=14689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:41:58.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:41:58.788+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:41:58.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:41:58.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:41:58.813+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:41:58.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:41:58.823+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:41:58.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:41:58.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T10:42:29.139+0000] {processor.py:157} INFO - Started process (PID=14699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:42:29.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:42:29.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:42:29.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:42:29.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:42:29.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:42:29.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:42:29.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:42:29.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:42:29.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:42:59.503+0000] {processor.py:157} INFO - Started process (PID=14709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:42:59.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:42:59.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:42:59.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:42:59.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:42:59.535+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:42:59.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:42:59.544+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:42:59.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:42:59.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:43:29.866+0000] {processor.py:157} INFO - Started process (PID=14719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:43:29.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:43:29.870+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:43:29.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:43:29.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:43:29.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:43:29.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:43:29.915+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:43:29.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:43:29.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T10:44:00.302+0000] {processor.py:157} INFO - Started process (PID=14729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:44:00.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:44:00.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:44:00.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:44:00.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:44:00.332+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:44:00.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:44:00.343+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:44:00.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:44:00.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:44:30.722+0000] {processor.py:157} INFO - Started process (PID=14739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:44:30.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:44:30.724+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:44:30.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:44:30.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:44:30.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:44:30.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:44:30.760+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:44:30.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:44:30.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:45:01.093+0000] {processor.py:157} INFO - Started process (PID=14749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:45:01.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:45:01.097+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:45:01.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:45:01.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:45:01.124+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:45:01.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:45:01.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:45:01.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:45:01.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:45:31.486+0000] {processor.py:157} INFO - Started process (PID=14759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:45:31.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:45:31.491+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:45:31.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:45:31.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:45:31.524+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:45:31.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:45:31.538+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:45:31.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:45:31.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T10:46:01.891+0000] {processor.py:157} INFO - Started process (PID=14769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:46:01.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:46:01.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:46:01.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:46:01.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:46:01.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:46:01.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:46:01.935+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:46:01.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:46:01.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:46:32.215+0000] {processor.py:157} INFO - Started process (PID=14779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:46:32.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:46:32.218+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:46:32.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:46:32.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:46:32.249+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:46:32.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:46:32.260+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:46:32.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:46:32.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T10:47:02.528+0000] {processor.py:157} INFO - Started process (PID=14789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:47:02.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:47:02.531+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:47:02.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:47:02.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:47:02.558+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:47:02.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:47:02.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:47:02.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:47:02.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:47:32.813+0000] {processor.py:157} INFO - Started process (PID=14799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:47:32.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:47:32.815+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:47:32.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:47:32.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:47:32.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:47:32.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:47:32.855+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:47:32.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:47:32.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:48:03.177+0000] {processor.py:157} INFO - Started process (PID=14809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:48:03.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:48:03.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:48:03.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:48:03.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:48:03.203+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:48:03.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:48:03.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:48:03.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:48:03.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T10:48:33.545+0000] {processor.py:157} INFO - Started process (PID=14819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:48:33.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:48:33.548+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:48:33.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:48:33.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:48:33.577+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:48:33.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:48:33.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:48:33.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:48:33.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:49:03.868+0000] {processor.py:157} INFO - Started process (PID=14829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:49:03.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:49:03.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:49:03.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:49:03.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:49:03.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:49:03.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:49:03.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:49:03.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:49:03.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:49:34.264+0000] {processor.py:157} INFO - Started process (PID=14839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:49:34.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:49:34.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:49:34.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:49:34.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:49:34.298+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:49:34.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:49:34.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:49:34.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:49:34.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:50:04.650+0000] {processor.py:157} INFO - Started process (PID=14849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:50:04.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:50:04.656+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:50:04.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:50:04.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:50:04.690+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:50:04.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:50:04.700+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:50:04.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:50:04.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T10:50:35.034+0000] {processor.py:157} INFO - Started process (PID=14859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:50:35.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:50:35.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:50:35.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:50:35.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:50:35.069+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:50:35.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:50:35.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:50:35.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:50:35.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T10:51:05.390+0000] {processor.py:157} INFO - Started process (PID=14869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:51:05.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:51:05.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:51:05.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:51:05.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:51:05.419+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:51:05.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:51:05.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:51:05.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:51:05.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T10:51:35.792+0000] {processor.py:157} INFO - Started process (PID=14879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:51:35.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:51:35.796+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:51:35.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:51:35.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:51:35.826+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:51:35.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:51:35.838+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:51:35.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:51:35.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T10:52:06.133+0000] {processor.py:157} INFO - Started process (PID=14889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:52:06.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:52:06.136+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:52:06.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:52:06.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:52:06.165+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:52:06.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:52:06.174+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:52:06.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:52:06.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:52:36.464+0000] {processor.py:157} INFO - Started process (PID=14898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:52:36.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:52:36.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:52:36.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:52:36.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:52:36.489+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:52:36.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:52:36.499+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:52:36.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:52:36.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T10:53:06.912+0000] {processor.py:157} INFO - Started process (PID=14909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:53:06.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:53:06.914+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:53:06.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:53:06.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:53:06.941+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:53:06.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:53:06.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:53:06.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:53:06.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T10:53:37.360+0000] {processor.py:157} INFO - Started process (PID=14919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:53:37.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:53:37.362+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:53:37.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:53:37.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:53:37.393+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:53:37.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:53:37.404+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:53:37.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:53:37.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:54:07.745+0000] {processor.py:157} INFO - Started process (PID=14929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:54:07.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:54:07.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:54:07.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:54:07.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:54:07.779+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:54:07.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:54:07.789+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:54:07.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:54:07.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T10:54:38.139+0000] {processor.py:157} INFO - Started process (PID=14939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:54:38.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:54:38.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:54:38.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:54:38.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:54:38.175+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:54:38.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:54:38.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:54:38.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:54:38.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T10:55:08.558+0000] {processor.py:157} INFO - Started process (PID=14949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:55:08.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:55:08.561+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:55:08.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:55:08.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:55:08.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:55:08.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:55:08.606+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:55:08.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:55:08.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T10:55:38.953+0000] {processor.py:157} INFO - Started process (PID=14959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:55:38.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:55:38.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:55:38.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:55:38.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:55:38.983+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:55:38.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:55:38.992+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:55:38.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:55:39.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T10:56:09.337+0000] {processor.py:157} INFO - Started process (PID=14969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:56:09.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:56:09.341+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:56:09.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:56:09.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:56:09.369+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:56:09.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:56:09.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:56:09.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:56:09.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T10:56:39.682+0000] {processor.py:157} INFO - Started process (PID=14979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:56:39.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:56:39.685+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:56:39.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:56:39.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:56:39.709+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:56:39.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:56:39.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:56:39.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:56:39.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T10:57:10.036+0000] {processor.py:157} INFO - Started process (PID=14989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:57:10.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:57:10.039+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:57:10.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:57:10.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:57:10.066+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:57:10.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:57:10.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:57:10.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:57:10.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T10:57:40.497+0000] {processor.py:157} INFO - Started process (PID=14999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:57:40.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:57:40.501+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:57:40.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:57:40.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:57:40.526+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:57:40.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:57:40.536+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:57:40.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:57:40.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T10:58:10.872+0000] {processor.py:157} INFO - Started process (PID=15009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:58:10.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:58:10.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:58:10.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:58:10.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:58:10.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:58:10.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:58:10.918+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:58:10.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:58:10.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T10:58:41.288+0000] {processor.py:157} INFO - Started process (PID=15019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:58:41.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:58:41.295+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:58:41.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:58:41.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:58:41.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:58:41.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:58:41.332+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:58:41.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:58:41.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T10:59:11.668+0000] {processor.py:157} INFO - Started process (PID=15029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:59:11.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:59:11.672+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:59:11.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:59:11.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:59:11.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:59:11.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:59:11.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:59:11.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:59:11.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T10:59:42.047+0000] {processor.py:157} INFO - Started process (PID=15039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:59:42.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T10:59:42.050+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:59:42.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:59:42.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T10:59:42.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:59:42.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T10:59:42.085+0000] {logging_mixin.py:151} INFO - [2024-09-09T10:59:42.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T10:59:42.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T11:00:12.368+0000] {processor.py:157} INFO - Started process (PID=15049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:00:12.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:00:12.371+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:00:12.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:00:12.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:00:12.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:00:12.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:00:12.406+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:00:12.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:00:12.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T11:00:42.768+0000] {processor.py:157} INFO - Started process (PID=15059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:00:42.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:00:42.774+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:00:42.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:00:42.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:00:42.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:00:42.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:00:42.822+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:00:42.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:00:42.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T11:01:13.141+0000] {processor.py:157} INFO - Started process (PID=15069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:01:13.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:01:13.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:01:13.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:01:13.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:01:13.175+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:01:13.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:01:13.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:01:13.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:01:13.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T11:01:43.505+0000] {processor.py:157} INFO - Started process (PID=15079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:01:43.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:01:43.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:01:43.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:01:43.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:01:43.536+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:01:43.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:01:43.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:01:43.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:01:43.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:02:13.940+0000] {processor.py:157} INFO - Started process (PID=15089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:02:13.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:02:13.942+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:02:13.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:02:13.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:02:13.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:02:13.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:02:13.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:02:13.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:02:13.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T11:02:44.284+0000] {processor.py:157} INFO - Started process (PID=15099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:02:44.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:02:44.288+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:02:44.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:02:44.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:02:44.327+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:02:44.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:02:44.344+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:02:44.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:02:44.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T11:03:14.671+0000] {processor.py:157} INFO - Started process (PID=15109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:03:14.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:03:14.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:03:14.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:03:14.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:03:14.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:03:14.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:03:14.713+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:03:14.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:03:14.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:03:45.113+0000] {processor.py:157} INFO - Started process (PID=15119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:03:45.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:03:45.115+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:03:45.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:03:45.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:03:45.143+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:03:45.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:03:45.152+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:03:45.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:03:45.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T11:04:15.507+0000] {processor.py:157} INFO - Started process (PID=15129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:04:15.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:04:15.512+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:04:15.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:04:15.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:04:15.561+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:04:15.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:04:15.574+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:04:15.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:04:15.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T11:04:45.863+0000] {processor.py:157} INFO - Started process (PID=15139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:04:45.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:04:45.866+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:04:45.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:04:45.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:04:45.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:04:45.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:04:45.905+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:04:45.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:04:45.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:05:16.316+0000] {processor.py:157} INFO - Started process (PID=15149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:05:16.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:05:16.320+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:05:16.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:05:16.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:05:16.354+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:05:16.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:05:16.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:05:16.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:05:16.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T11:05:46.713+0000] {processor.py:157} INFO - Started process (PID=15159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:05:46.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:05:46.716+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:05:46.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:05:46.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:05:46.744+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:05:46.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:05:46.757+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:05:46.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:05:46.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T11:06:17.175+0000] {processor.py:157} INFO - Started process (PID=15169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:06:17.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:06:17.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:06:17.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:06:17.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:06:17.216+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:06:17.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:06:17.228+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:06:17.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:06:17.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T11:08:11.290+0000] {processor.py:157} INFO - Started process (PID=15181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:08:11.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:08:11.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:08:11.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:08:11.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:08:11.353+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:08:11.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:08:11.376+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:08:11.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:08:11.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-09T11:08:41.722+0000] {processor.py:157} INFO - Started process (PID=15191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:08:41.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:08:41.725+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:08:41.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:08:41.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:08:41.765+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:08:41.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:08:41.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:08:41.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:08:41.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T11:09:12.021+0000] {processor.py:157} INFO - Started process (PID=15201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:09:12.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:09:12.025+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:09:12.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:09:12.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:09:12.052+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:09:12.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:09:12.062+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:09:12.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:09:12.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T11:09:42.321+0000] {processor.py:157} INFO - Started process (PID=15211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:09:42.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:09:42.325+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:09:42.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:09:42.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:09:42.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:09:42.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:09:42.369+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:09:42.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:09:42.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T11:10:12.691+0000] {processor.py:157} INFO - Started process (PID=15221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:10:12.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:10:12.694+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:10:12.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:10:12.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:10:12.720+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:10:12.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:10:12.733+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:10:12.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:10:12.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T11:10:43.072+0000] {processor.py:157} INFO - Started process (PID=15231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:10:43.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:10:43.074+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:10:43.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:10:43.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:10:43.105+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:10:43.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:10:43.116+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:10:43.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:10:43.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T11:11:13.362+0000] {processor.py:157} INFO - Started process (PID=15241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:11:13.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:11:13.364+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:11:13.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:11:13.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:11:13.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:11:13.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:11:13.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:11:13.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:11:13.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:11:43.686+0000] {processor.py:157} INFO - Started process (PID=15251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:11:43.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:11:43.690+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:11:43.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:11:43.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:11:43.718+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:11:43.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:11:43.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:11:43.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:11:43.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T11:12:14.076+0000] {processor.py:157} INFO - Started process (PID=15261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:12:14.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:12:14.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:12:14.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:12:14.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:12:14.117+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:12:14.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:12:14.130+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:12:14.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:12:14.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T11:12:44.434+0000] {processor.py:157} INFO - Started process (PID=15271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:12:44.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:12:44.437+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:12:44.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:12:44.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:12:44.462+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:12:44.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:12:44.473+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:12:44.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:12:44.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:13:14.734+0000] {processor.py:157} INFO - Started process (PID=15281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:13:14.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:13:14.738+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:13:14.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:13:14.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:13:14.765+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:13:14.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:13:14.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:13:14.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:13:14.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:13:45.133+0000] {processor.py:157} INFO - Started process (PID=15291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:13:45.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:13:45.138+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:13:45.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:13:45.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:13:45.166+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:13:45.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:13:45.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:13:45.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:13:45.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T11:14:15.477+0000] {processor.py:157} INFO - Started process (PID=15301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:14:15.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:14:15.481+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:14:15.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:14:15.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:14:15.506+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:14:15.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:14:15.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:14:15.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:14:15.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T11:14:45.838+0000] {processor.py:157} INFO - Started process (PID=15311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:14:45.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:14:45.842+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:14:45.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:14:45.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:14:45.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:14:45.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:14:45.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:14:45.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:14:45.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:15:16.242+0000] {processor.py:157} INFO - Started process (PID=15321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:15:16.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:15:16.247+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:15:16.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:15:16.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:15:16.279+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:15:16.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:15:16.290+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:15:16.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:15:16.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T11:15:46.584+0000] {processor.py:157} INFO - Started process (PID=15331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:15:46.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:15:46.589+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:15:46.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:15:46.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:15:46.617+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:15:46.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:15:46.629+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:15:46.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:15:46.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T11:16:16.921+0000] {processor.py:157} INFO - Started process (PID=15341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:16:16.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:16:16.924+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:16:16.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:16:16.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:16:16.953+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:16:16.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:16:16.965+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:16:16.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:16:16.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T11:16:47.276+0000] {processor.py:157} INFO - Started process (PID=15351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:16:47.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:16:47.280+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:16:47.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:16:47.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:16:47.312+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:16:47.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:16:47.322+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:16:47.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:16:47.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T11:17:17.619+0000] {processor.py:157} INFO - Started process (PID=15361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:17:17.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:17:17.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:17:17.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:17:17.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:17:17.652+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:17:17.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:17:17.663+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:17:17.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:17:17.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T11:17:47.970+0000] {processor.py:157} INFO - Started process (PID=15371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:17:47.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:17:47.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:17:47.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:17:47.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:17:48.001+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:17:48.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:17:48.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:17:48.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:17:48.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:18:18.344+0000] {processor.py:157} INFO - Started process (PID=15381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:18:18.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:18:18.347+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:18:18.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:18:18.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:18:18.376+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:18:18.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:18:18.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:18:18.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:18:18.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T11:18:48.685+0000] {processor.py:157} INFO - Started process (PID=15391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:18:48.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:18:48.689+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:18:48.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:18:48.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:18:48.717+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:18:48.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:18:48.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:18:48.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:18:48.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:19:19.006+0000] {processor.py:157} INFO - Started process (PID=15401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:19:19.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:19:19.009+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:19:19.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:19:19.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:19:19.036+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:19:19.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:19:19.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:19:19.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:19:19.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T11:19:49.394+0000] {processor.py:157} INFO - Started process (PID=15411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:19:49.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:19:49.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:19:49.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:19:49.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:19:49.430+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:19:49.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:19:49.443+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:19:49.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:19:49.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T11:20:19.750+0000] {processor.py:157} INFO - Started process (PID=15421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:20:19.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:20:19.752+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:20:19.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:20:19.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:20:19.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:20:19.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:20:19.791+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:20:19.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:20:19.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:20:50.090+0000] {processor.py:157} INFO - Started process (PID=15431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:20:50.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:20:50.095+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:20:50.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:20:50.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:20:50.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:20:50.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:20:50.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:20:50.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:20:50.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T11:21:20.450+0000] {processor.py:157} INFO - Started process (PID=15441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:21:20.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:21:20.453+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:21:20.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:21:20.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:21:20.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:21:20.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:21:20.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:21:20.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:21:20.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T11:21:50.797+0000] {processor.py:157} INFO - Started process (PID=15451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:21:50.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:21:50.800+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:21:50.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:21:50.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:21:50.832+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:21:50.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:21:50.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:21:50.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:21:50.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T11:22:21.172+0000] {processor.py:157} INFO - Started process (PID=15460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:22:21.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:22:21.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:22:21.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:22:21.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:22:21.208+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:22:21.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:22:21.222+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:22:21.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:22:21.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T11:22:51.568+0000] {processor.py:157} INFO - Started process (PID=15471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:22:51.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:22:51.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:22:51.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:22:51.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:22:51.595+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:22:51.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:22:51.605+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:22:51.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:22:51.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T11:23:21.892+0000] {processor.py:157} INFO - Started process (PID=15481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:23:21.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:23:21.897+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:23:21.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:23:21.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:23:21.926+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:23:21.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:23:21.937+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:23:21.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:23:21.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T11:23:52.253+0000] {processor.py:157} INFO - Started process (PID=15491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:23:52.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:23:52.256+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:23:52.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:23:52.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:23:52.285+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:23:52.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:23:52.297+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:23:52.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:23:52.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T11:24:22.554+0000] {processor.py:157} INFO - Started process (PID=15501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:24:22.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:24:22.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:24:22.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:24:22.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:24:22.590+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:24:22.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:24:22.601+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:24:22.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:24:22.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T11:24:52.861+0000] {processor.py:157} INFO - Started process (PID=15511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:24:52.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:24:52.865+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:24:52.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:24:52.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:24:52.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:24:52.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:24:52.901+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:24:52.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:24:52.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:25:23.134+0000] {processor.py:157} INFO - Started process (PID=15521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:25:23.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:25:23.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:25:23.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:25:23.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:25:23.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:25:23.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:25:23.174+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:25:23.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:25:23.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:25:53.521+0000] {processor.py:157} INFO - Started process (PID=15531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:25:53.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:25:53.523+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:25:53.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:25:53.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:25:53.558+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:25:53.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:25:53.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:25:53.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:25:53.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T11:26:23.871+0000] {processor.py:157} INFO - Started process (PID=15541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:26:23.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:26:23.874+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:26:23.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:26:23.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:26:23.898+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:26:23.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:26:23.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:26:23.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:26:23.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T11:26:54.182+0000] {processor.py:157} INFO - Started process (PID=15551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:26:54.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:26:54.184+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:26:54.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:26:54.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:26:54.215+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:26:54.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:26:54.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:26:54.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:26:54.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:27:24.550+0000] {processor.py:157} INFO - Started process (PID=15561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:27:24.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:27:24.555+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:27:24.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:27:24.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:27:24.590+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:27:24.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:27:24.600+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:27:24.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:27:24.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T11:27:54.913+0000] {processor.py:157} INFO - Started process (PID=15571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:27:54.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:27:54.917+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:27:54.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:27:54.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:27:54.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:27:54.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:27:54.955+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:27:54.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:27:54.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T11:28:25.247+0000] {processor.py:157} INFO - Started process (PID=15581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:28:25.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:28:25.251+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:28:25.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:28:25.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:28:25.287+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:28:25.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:28:25.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:28:25.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:28:25.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T11:28:55.543+0000] {processor.py:157} INFO - Started process (PID=15591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:28:55.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:28:55.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:28:55.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:28:55.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:28:55.573+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:28:55.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:28:55.583+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:28:55.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:28:55.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T11:29:25.918+0000] {processor.py:157} INFO - Started process (PID=15601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:29:25.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:29:25.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:29:25.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:29:25.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:29:25.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:29:25.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:29:25.967+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:29:25.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:29:25.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T11:29:56.286+0000] {processor.py:157} INFO - Started process (PID=15611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:29:56.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:29:56.290+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:29:56.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:29:56.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:29:56.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:29:56.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:29:56.332+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:29:56.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:29:56.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T11:30:26.620+0000] {processor.py:157} INFO - Started process (PID=15621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:30:26.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:30:26.622+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:30:26.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:30:26.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:30:26.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:30:26.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:30:26.658+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:30:26.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:30:26.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T11:30:56.998+0000] {processor.py:157} INFO - Started process (PID=15631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:30:56.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:30:57.001+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:30:57.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:30:57.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:30:57.029+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:30:57.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:30:57.039+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:30:57.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:30:57.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T11:31:27.371+0000] {processor.py:157} INFO - Started process (PID=15641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:31:27.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:31:27.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:31:27.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:31:27.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:31:27.407+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:31:27.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:31:27.419+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:31:27.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:31:27.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T11:31:57.762+0000] {processor.py:157} INFO - Started process (PID=15651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:31:57.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:31:57.767+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:31:57.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:31:57.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:31:57.797+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:31:57.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:31:57.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:31:57.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:31:57.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T11:32:28.150+0000] {processor.py:157} INFO - Started process (PID=15661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:32:28.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:32:28.153+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:32:28.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:32:28.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:32:28.178+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:32:28.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:32:28.188+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:32:28.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:32:28.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T11:32:58.459+0000] {processor.py:157} INFO - Started process (PID=15671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:32:58.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:32:58.463+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:32:58.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:32:58.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:32:58.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:32:58.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:32:58.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:32:58.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:32:58.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:33:28.751+0000] {processor.py:157} INFO - Started process (PID=15681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:33:28.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:33:28.756+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:33:28.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:33:28.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:33:28.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:33:28.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:33:28.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:33:28.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:33:28.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T11:33:59.039+0000] {processor.py:157} INFO - Started process (PID=15691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:33:59.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:33:59.041+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:33:59.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:33:59.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:33:59.068+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:33:59.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:33:59.079+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:33:59.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:33:59.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:34:29.376+0000] {processor.py:157} INFO - Started process (PID=15701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:34:29.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:34:29.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:34:29.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:34:29.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:34:29.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:34:29.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:34:29.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:34:29.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:34:29.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T11:34:59.732+0000] {processor.py:157} INFO - Started process (PID=15711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:34:59.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:34:59.735+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:34:59.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:34:59.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:34:59.768+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:34:59.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:34:59.779+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:34:59.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:34:59.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T11:35:30.063+0000] {processor.py:157} INFO - Started process (PID=15721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:35:30.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:35:30.069+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:35:30.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:35:30.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:35:30.104+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:35:30.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:35:30.118+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:35:30.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:35:30.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T11:36:00.429+0000] {processor.py:157} INFO - Started process (PID=15731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:36:00.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:36:00.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:36:00.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:36:00.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:36:00.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:36:00.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:36:00.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:36:00.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:36:00.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T11:36:30.809+0000] {processor.py:157} INFO - Started process (PID=15741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:36:30.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:36:30.813+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:36:30.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:36:30.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:36:30.848+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:36:30.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:36:30.860+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:36:30.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:36:30.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T11:37:01.155+0000] {processor.py:157} INFO - Started process (PID=15750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:37:01.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:37:01.169+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:37:01.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:37:01.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:37:01.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:37:01.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:37:01.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:37:01.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:37:01.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-09T11:37:31.478+0000] {processor.py:157} INFO - Started process (PID=15761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:37:31.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:37:31.481+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:37:31.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:37:31.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:37:31.520+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:37:31.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:37:31.537+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:37:31.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:37:31.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T11:38:01.747+0000] {processor.py:157} INFO - Started process (PID=15771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:38:01.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:38:01.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:38:01.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:38:01.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:38:01.786+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:38:01.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:38:01.797+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:38:01.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:38:01.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T11:38:32.135+0000] {processor.py:157} INFO - Started process (PID=15781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:38:32.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:38:32.139+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:38:32.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:38:32.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:38:32.168+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:38:32.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:38:32.178+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:38:32.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:38:32.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:39:02.468+0000] {processor.py:157} INFO - Started process (PID=15791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:39:02.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:39:02.471+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:39:02.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:39:02.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:39:02.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:39:02.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:39:02.511+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:39:02.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:39:02.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:39:32.787+0000] {processor.py:157} INFO - Started process (PID=15801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:39:32.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:39:32.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:39:32.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:39:32.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:39:32.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:39:32.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:39:32.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:39:32.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:39:32.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T11:40:03.137+0000] {processor.py:157} INFO - Started process (PID=15811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:40:03.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:40:03.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:40:03.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:40:03.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:40:03.175+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:40:03.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:40:03.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:40:03.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:40:03.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T11:40:33.427+0000] {processor.py:157} INFO - Started process (PID=15821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:40:33.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:40:33.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:40:33.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:40:33.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:40:33.458+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:40:33.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:40:33.468+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:40:33.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:40:33.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:41:03.823+0000] {processor.py:157} INFO - Started process (PID=15831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:41:03.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:41:03.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:41:03.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:41:03.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:41:03.856+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:41:03.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:41:03.869+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:41:03.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:41:03.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T11:41:34.197+0000] {processor.py:157} INFO - Started process (PID=15841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:41:34.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:41:34.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:41:34.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:41:34.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:41:34.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:41:34.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:41:34.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:41:34.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:41:34.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T11:42:04.498+0000] {processor.py:157} INFO - Started process (PID=15851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:42:04.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:42:04.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:42:04.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:42:04.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:42:04.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:42:04.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:42:04.539+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:42:04.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:42:04.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T11:42:34.853+0000] {processor.py:157} INFO - Started process (PID=15861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:42:34.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:42:34.856+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:42:34.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:42:34.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:42:34.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:42:34.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:42:34.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:42:34.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:42:34.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:43:05.240+0000] {processor.py:157} INFO - Started process (PID=15871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:43:05.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:43:05.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:43:05.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:43:05.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:43:05.270+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:43:05.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:43:05.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:43:05.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:43:05.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T11:43:35.638+0000] {processor.py:157} INFO - Started process (PID=15881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:43:35.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:43:35.643+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:43:35.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:43:35.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:43:35.669+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:43:35.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:43:35.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:43:35.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:43:35.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T11:44:05.987+0000] {processor.py:157} INFO - Started process (PID=15891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:44:05.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:44:05.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:44:05.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:44:06.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:44:06.021+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:44:06.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:44:06.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:44:06.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:44:06.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:44:36.279+0000] {processor.py:157} INFO - Started process (PID=15901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:44:36.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:44:36.281+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:44:36.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:44:36.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:44:36.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:44:36.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:44:36.317+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:44:36.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:44:36.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T11:45:06.687+0000] {processor.py:157} INFO - Started process (PID=15911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:45:06.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:45:06.691+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:45:06.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:45:06.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:45:06.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:45:06.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:45:06.735+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:45:06.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:45:06.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T11:45:37.018+0000] {processor.py:157} INFO - Started process (PID=15921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:45:37.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:45:37.024+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:45:37.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:45:37.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:45:37.059+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:45:37.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:45:37.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:45:37.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:45:37.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T11:46:07.416+0000] {processor.py:157} INFO - Started process (PID=15931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:46:07.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:46:07.418+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:46:07.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:46:07.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:46:07.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:46:07.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:46:07.455+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:46:07.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:46:07.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T11:46:37.808+0000] {processor.py:157} INFO - Started process (PID=15941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:46:37.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:46:37.811+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:46:37.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:46:37.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:46:37.839+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:46:37.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:46:37.850+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:46:37.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:46:37.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:47:08.122+0000] {processor.py:157} INFO - Started process (PID=15951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:47:08.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:47:08.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:47:08.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:47:08.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:47:08.156+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:47:08.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:47:08.166+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:47:08.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:47:08.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:47:38.467+0000] {processor.py:157} INFO - Started process (PID=15960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:47:38.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:47:38.472+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:47:38.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:47:38.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:47:38.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:47:38.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:47:38.518+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:47:38.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:47:38.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T11:48:08.846+0000] {processor.py:157} INFO - Started process (PID=15971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:48:08.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:48:08.849+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:48:08.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:48:08.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:48:08.877+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:48:08.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:48:08.887+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:48:08.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:48:08.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T11:48:39.206+0000] {processor.py:157} INFO - Started process (PID=15981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:48:39.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:48:39.209+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:48:39.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:48:39.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:48:39.235+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:48:39.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:48:39.245+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:48:39.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:48:39.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T11:49:09.505+0000] {processor.py:157} INFO - Started process (PID=15991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:49:09.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:49:09.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:49:09.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:49:09.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:49:09.534+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:49:09.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:49:09.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:49:09.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:49:09.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:49:39.848+0000] {processor.py:157} INFO - Started process (PID=16001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:49:39.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:49:39.854+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:49:39.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:49:39.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:49:39.888+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:49:39.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:49:39.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:49:39.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:49:39.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T11:50:10.225+0000] {processor.py:157} INFO - Started process (PID=16011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:50:10.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:50:10.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:50:10.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:50:10.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:50:10.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:50:10.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:50:10.264+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:50:10.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:50:10.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:50:40.583+0000] {processor.py:157} INFO - Started process (PID=16021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:50:40.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:50:40.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:50:40.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:50:40.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:50:40.620+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:50:40.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:50:40.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:50:40.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:50:40.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T11:51:10.928+0000] {processor.py:157} INFO - Started process (PID=16031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:51:10.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:51:10.931+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:51:10.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:51:10.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:51:10.962+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:51:10.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:51:10.974+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:51:10.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:51:10.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T11:51:41.301+0000] {processor.py:157} INFO - Started process (PID=16040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:51:41.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:51:41.308+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:51:41.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:51:41.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:51:41.339+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:51:41.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:51:41.349+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:51:41.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:51:41.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T11:52:11.596+0000] {processor.py:157} INFO - Started process (PID=16051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:52:11.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:52:11.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:52:11.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:52:11.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:52:11.628+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:52:11.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:52:11.638+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:52:11.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:52:11.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:52:41.976+0000] {processor.py:157} INFO - Started process (PID=16061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:52:41.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:52:41.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:52:41.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:52:41.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:52:42.008+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:52:42.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:52:42.021+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:52:42.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:52:42.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T11:53:12.310+0000] {processor.py:157} INFO - Started process (PID=16071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:53:12.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:53:12.315+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:53:12.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:53:12.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:53:12.349+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:53:12.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:53:12.363+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:53:12.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:53:12.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T11:53:42.643+0000] {processor.py:157} INFO - Started process (PID=16081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:53:42.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:53:42.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:53:42.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:53:42.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:53:42.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:53:42.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:53:42.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:53:42.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:53:42.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T11:54:12.962+0000] {processor.py:157} INFO - Started process (PID=16091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:54:12.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:54:12.965+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:54:12.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:54:12.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:54:13.000+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:54:12.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:54:13.012+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:54:13.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:54:13.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T11:54:43.262+0000] {processor.py:157} INFO - Started process (PID=16101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:54:43.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:54:43.265+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:54:43.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:54:43.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:54:43.292+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:54:43.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:54:43.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:54:43.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:54:43.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T11:55:13.625+0000] {processor.py:157} INFO - Started process (PID=16111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:55:13.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:55:13.628+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:55:13.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:55:13.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:55:13.652+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:55:13.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:55:13.662+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:55:13.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:55:13.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T11:55:44.016+0000] {processor.py:157} INFO - Started process (PID=16121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:55:44.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:55:44.022+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:55:44.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:55:44.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:55:44.055+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:55:44.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:55:44.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:55:44.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:55:44.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T11:56:14.393+0000] {processor.py:157} INFO - Started process (PID=16131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:56:14.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:56:14.395+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:56:14.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:56:14.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:56:14.424+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:56:14.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:56:14.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:56:14.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:56:14.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T11:56:44.712+0000] {processor.py:157} INFO - Started process (PID=16141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:56:44.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:56:44.716+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:56:44.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:56:44.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:56:44.747+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:56:44.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:56:44.758+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:56:44.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:56:44.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T11:57:15.018+0000] {processor.py:157} INFO - Started process (PID=16151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:57:15.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:57:15.022+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:57:15.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:57:15.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:57:15.050+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:57:15.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:57:15.061+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:57:15.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:57:15.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T11:57:45.399+0000] {processor.py:157} INFO - Started process (PID=16161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:57:45.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:57:45.402+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:57:45.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:57:45.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:57:45.428+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:57:45.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:57:45.438+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:57:45.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:57:45.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T11:58:15.738+0000] {processor.py:157} INFO - Started process (PID=16170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:58:15.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:58:15.743+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:58:15.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:58:15.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:58:15.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:58:15.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:58:15.793+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:58:15.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:58:15.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T11:58:46.124+0000] {processor.py:157} INFO - Started process (PID=16181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:58:46.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:58:46.127+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:58:46.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:58:46.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:58:46.156+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:58:46.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:58:46.166+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:58:46.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:58:46.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T11:59:16.450+0000] {processor.py:157} INFO - Started process (PID=16191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:59:16.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:59:16.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:59:16.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:59:16.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:59:16.482+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:59:16.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:59:16.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:59:16.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:59:16.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T11:59:46.835+0000] {processor.py:157} INFO - Started process (PID=16201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:59:46.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T11:59:46.841+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:59:46.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:59:46.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T11:59:46.875+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:59:46.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T11:59:46.886+0000] {logging_mixin.py:151} INFO - [2024-09-09T11:59:46.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T11:59:46.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T12:00:17.161+0000] {processor.py:157} INFO - Started process (PID=16211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:00:17.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:00:17.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:00:17.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:00:17.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:00:17.191+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:00:17.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:00:17.200+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:00:17.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:00:17.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T12:00:47.574+0000] {processor.py:157} INFO - Started process (PID=16221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:00:47.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:00:47.581+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:00:47.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:00:47.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:00:47.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:00:47.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:00:47.650+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:00:47.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:00:47.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T12:01:17.868+0000] {processor.py:157} INFO - Started process (PID=16231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:01:17.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:01:17.874+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:01:17.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:01:17.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:01:17.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:01:17.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:01:17.924+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:01:17.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:01:17.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T12:01:48.117+0000] {processor.py:157} INFO - Started process (PID=16241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:01:48.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:01:48.120+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:01:48.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:01:48.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:01:48.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:01:48.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:01:48.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:01:48.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:01:48.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T12:02:18.485+0000] {processor.py:157} INFO - Started process (PID=16251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:02:18.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:02:18.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:02:18.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:02:18.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:02:18.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:02:18.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:02:18.527+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:02:18.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:02:18.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T12:02:48.804+0000] {processor.py:157} INFO - Started process (PID=16261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:02:48.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:02:48.806+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:02:48.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:02:48.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:02:48.833+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:02:48.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:02:48.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:02:48.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:02:48.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T12:03:19.110+0000] {processor.py:157} INFO - Started process (PID=16271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:03:19.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:03:19.112+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:03:19.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:03:19.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:03:19.136+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:03:19.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:03:19.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:03:19.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:03:19.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T12:03:49.485+0000] {processor.py:157} INFO - Started process (PID=16281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:03:49.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:03:49.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:03:49.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:03:49.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:03:49.517+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:03:49.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:03:49.527+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:03:49.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:03:49.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T12:04:19.856+0000] {processor.py:157} INFO - Started process (PID=16291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:04:19.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:04:19.859+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:04:19.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:04:19.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:04:19.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:04:19.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:04:19.900+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:04:19.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:04:19.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T12:04:50.138+0000] {processor.py:157} INFO - Started process (PID=16301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:04:50.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:04:50.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:04:50.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:04:50.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:04:50.167+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:04:50.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:04:50.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:04:50.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:04:50.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T12:05:20.418+0000] {processor.py:157} INFO - Started process (PID=16311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:05:20.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:05:20.421+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:05:20.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:05:20.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:05:20.448+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:05:20.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:05:20.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:05:20.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:05:20.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T12:05:50.849+0000] {processor.py:157} INFO - Started process (PID=16321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:05:50.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:05:50.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:05:50.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:05:50.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:05:50.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:05:50.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:05:50.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:05:50.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:05:50.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T12:06:21.230+0000] {processor.py:157} INFO - Started process (PID=16331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:06:21.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:06:21.235+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:06:21.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:06:21.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:06:21.271+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:06:21.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:06:21.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:06:21.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:06:21.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T12:06:51.631+0000] {processor.py:157} INFO - Started process (PID=16341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:06:51.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:06:51.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:06:51.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:06:51.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:06:51.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:06:51.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:06:51.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:06:51.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:06:51.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T12:07:21.947+0000] {processor.py:157} INFO - Started process (PID=16351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:07:21.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:07:21.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:07:21.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:07:21.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:07:21.975+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:07:21.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:07:21.985+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:07:21.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:07:21.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T12:07:52.263+0000] {processor.py:157} INFO - Started process (PID=16361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:07:52.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:07:52.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:07:52.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:07:52.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:07:52.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:07:52.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:07:52.298+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:07:52.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:07:52.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T12:08:22.618+0000] {processor.py:157} INFO - Started process (PID=16370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:08:22.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:08:22.623+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:08:22.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:08:22.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:08:22.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:08:22.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:08:22.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:08:22.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:08:22.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T12:17:13.020+0000] {processor.py:157} INFO - Started process (PID=16383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:17:13.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:17:13.025+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:17:13.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:17:13.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:17:13.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:17:13.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:17:13.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:17:13.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:17:13.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-09T12:31:54.013+0000] {processor.py:157} INFO - Started process (PID=16391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:31:54.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:31:54.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:31:54.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:31:54.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:31:54.060+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:31:54.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:31:54.076+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:31:54.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:31:54.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T12:32:24.441+0000] {processor.py:157} INFO - Started process (PID=16403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:32:24.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:32:24.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:32:24.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:32:24.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:32:24.475+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:32:24.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:32:24.485+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:32:24.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:32:24.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T12:47:55.449+0000] {processor.py:157} INFO - Started process (PID=16413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:47:55.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:47:55.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:47:55.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:47:55.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:47:55.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:47:55.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:47:55.543+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:47:55.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:47:55.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-09T12:48:25.913+0000] {processor.py:157} INFO - Started process (PID=16423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:48:25.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T12:48:25.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:48:25.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:48:25.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T12:48:25.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:48:25.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T12:48:25.963+0000] {logging_mixin.py:151} INFO - [2024-09-09T12:48:25.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T12:48:25.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T13:04:47.039+0000] {processor.py:157} INFO - Started process (PID=16434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:04:47.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:04:47.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:04:47.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:04:47.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:04:47.110+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:04:47.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:04:47.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:04:47.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:04:47.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T13:05:17.364+0000] {processor.py:157} INFO - Started process (PID=16444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:05:17.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:05:17.371+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:05:17.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:05:17.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:05:17.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:05:17.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:05:17.425+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:05:17.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:05:17.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T13:05:47.711+0000] {processor.py:157} INFO - Started process (PID=16455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:05:47.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:05:47.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:05:47.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:05:47.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:05:47.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:05:47.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:05:47.757+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:05:47.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:05:47.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T13:09:09.861+0000] {processor.py:157} INFO - Started process (PID=16464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:09:09.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:09:09.866+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:09:09.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:09:09.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:09:09.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:09:09.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:09:09.935+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:09:09.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:09:09.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-09T13:09:40.176+0000] {processor.py:157} INFO - Started process (PID=16475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:09:40.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:09:40.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:09:40.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:09:40.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:09:40.214+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:09:40.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:09:40.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:09:40.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:09:40.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T13:10:10.480+0000] {processor.py:157} INFO - Started process (PID=16485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:10:10.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:10:10.483+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:10:10.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:10:10.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:10:10.512+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:10:10.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:10:10.523+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:10:10.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:10:10.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T13:10:40.854+0000] {processor.py:157} INFO - Started process (PID=16495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:10:40.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:10:40.863+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:10:40.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:10:40.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:10:40.886+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:10:40.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:10:40.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:10:40.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:10:40.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T13:11:11.199+0000] {processor.py:157} INFO - Started process (PID=16505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:11:11.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:11:11.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:11:11.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:11:11.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:11:11.225+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:11:11.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:11:11.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:11:11.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:11:11.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T13:27:21.940+0000] {processor.py:157} INFO - Started process (PID=16514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:27:21.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:27:21.943+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:27:21.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:27:21.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:27:21.974+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:27:21.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:27:21.985+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:27:21.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:27:21.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T13:28:52.688+0000] {processor.py:157} INFO - Started process (PID=16525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:28:52.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:28:52.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:28:52.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:28:52.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:28:52.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:28:52.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:28:52.759+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:28:52.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:28:52.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-09T13:29:23.091+0000] {processor.py:157} INFO - Started process (PID=16537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:29:23.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:29:23.099+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:29:23.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:29:23.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:29:23.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:29:23.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:29:23.134+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:29:23.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:29:23.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T13:29:53.533+0000] {processor.py:157} INFO - Started process (PID=16546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:29:53.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:29:53.537+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:29:53.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:29:53.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:29:53.569+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:29:53.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:29:53.583+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:29:53.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:29:53.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T13:30:23.980+0000] {processor.py:157} INFO - Started process (PID=16557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:30:23.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:30:23.983+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:30:23.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:30:23.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:30:24.011+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:30:24.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:30:24.022+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:30:24.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:30:24.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T13:30:54.331+0000] {processor.py:157} INFO - Started process (PID=16567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:30:54.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:30:54.334+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:30:54.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:30:54.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:30:54.362+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:30:54.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:30:54.371+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:30:54.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:30:54.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T13:31:24.685+0000] {processor.py:157} INFO - Started process (PID=16577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:31:24.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:31:24.688+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:31:24.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:31:24.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:31:24.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:31:24.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:31:24.729+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:31:24.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:31:24.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T13:35:55.653+0000] {processor.py:157} INFO - Started process (PID=16588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:35:55.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:35:55.658+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:35:55.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:35:55.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:35:55.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:35:55.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:35:55.727+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:35:55.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:35:55.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-09T13:51:48.850+0000] {processor.py:157} INFO - Started process (PID=16598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:51:48.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:51:48.859+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:51:48.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:51:48.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:51:48.977+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:51:48.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:51:49.009+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:51:49.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:51:49.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-09-09T13:52:19.191+0000] {processor.py:157} INFO - Started process (PID=16609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:52:19.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:52:19.203+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:52:19.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:52:19.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:52:19.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:52:19.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:52:19.263+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:52:19.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:52:19.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-09T13:52:49.524+0000] {processor.py:157} INFO - Started process (PID=16618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:52:49.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:52:49.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:52:49.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:52:49.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:52:49.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:52:49.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:52:49.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:52:49.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:52:49.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T13:53:19.842+0000] {processor.py:157} INFO - Started process (PID=16629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:53:19.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:53:19.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:53:19.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:53:19.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:53:19.872+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:53:19.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:53:19.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:53:19.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:53:19.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T13:53:50.195+0000] {processor.py:157} INFO - Started process (PID=16639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:53:50.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:53:50.199+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:53:50.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:53:50.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:53:50.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:53:50.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:53:50.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:53:50.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:53:50.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T13:54:20.558+0000] {processor.py:157} INFO - Started process (PID=16649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:54:20.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:54:20.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:54:20.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:54:20.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:54:20.591+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:54:20.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:54:20.604+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:54:20.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:54:20.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T13:54:50.928+0000] {processor.py:157} INFO - Started process (PID=16659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:54:50.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:54:50.931+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:54:50.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:54:50.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:54:50.960+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:54:50.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:54:50.971+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:54:50.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:54:50.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T13:55:21.354+0000] {processor.py:157} INFO - Started process (PID=16669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:55:21.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:55:21.361+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:55:21.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:55:21.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:55:21.395+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:55:21.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:55:21.406+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:55:21.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:55:21.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T13:55:51.692+0000] {processor.py:157} INFO - Started process (PID=16679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:55:51.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:55:51.696+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:55:51.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:55:51.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:55:51.733+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:55:51.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:55:51.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:55:51.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:55:51.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T13:56:22.155+0000] {processor.py:157} INFO - Started process (PID=16687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:56:22.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:56:22.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:56:22.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:56:22.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:56:22.197+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:56:22.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:56:22.207+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:56:22.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:56:22.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T13:56:52.555+0000] {processor.py:157} INFO - Started process (PID=16699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:56:52.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:56:52.558+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:56:52.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:56:52.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:56:52.586+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:56:52.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:56:52.597+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:56:52.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:56:52.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T13:57:22.984+0000] {processor.py:157} INFO - Started process (PID=16709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:57:22.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:57:22.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:57:22.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:57:23.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:57:23.021+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:57:23.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:57:23.036+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:57:23.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:57:23.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T13:57:53.377+0000] {processor.py:157} INFO - Started process (PID=16719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:57:53.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:57:53.380+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:57:53.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:57:53.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:57:53.408+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:57:53.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:57:53.424+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:57:53.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:57:53.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T13:58:23.781+0000] {processor.py:157} INFO - Started process (PID=16729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:58:23.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:58:23.784+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:58:23.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:58:23.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:58:23.822+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:58:23.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:58:23.839+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:58:23.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:58:23.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T13:58:54.175+0000] {processor.py:157} INFO - Started process (PID=16739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:58:54.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:58:54.182+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:58:54.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:58:54.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:58:54.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:58:54.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:58:54.224+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:58:54.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:58:54.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T13:59:24.620+0000] {processor.py:157} INFO - Started process (PID=16749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:59:24.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:59:24.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:59:24.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:59:24.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:59:24.662+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:59:24.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:59:24.672+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:59:24.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:59:24.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T13:59:54.961+0000] {processor.py:157} INFO - Started process (PID=16759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:59:54.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T13:59:54.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:59:54.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:59:54.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T13:59:54.995+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:59:54.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T13:59:55.008+0000] {logging_mixin.py:151} INFO - [2024-09-09T13:59:55.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T13:59:55.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T14:00:25.317+0000] {processor.py:157} INFO - Started process (PID=16769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:00:25.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:00:25.322+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:00:25.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:00:25.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:00:25.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:00:25.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:00:25.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:00:25.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:00:25.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T14:00:55.658+0000] {processor.py:157} INFO - Started process (PID=16779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:00:55.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:00:55.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:00:55.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:00:55.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:00:55.708+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:00:55.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:00:55.725+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:00:55.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:00:55.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T14:01:25.990+0000] {processor.py:157} INFO - Started process (PID=16789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:01:25.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:01:25.996+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:01:25.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:01:26.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:01:26.024+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:01:26.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:01:26.037+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:01:26.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:01:26.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T14:01:56.344+0000] {processor.py:157} INFO - Started process (PID=16799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:01:56.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:01:56.347+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:01:56.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:01:56.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:01:56.371+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:01:56.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:01:56.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:01:56.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:01:56.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:02:26.703+0000] {processor.py:157} INFO - Started process (PID=16809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:02:26.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:02:26.706+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:02:26.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:02:26.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:02:26.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:02:26.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:02:26.741+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:02:26.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:02:26.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:02:57.096+0000] {processor.py:157} INFO - Started process (PID=16819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:02:57.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:02:57.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:02:57.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:02:57.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:02:57.128+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:02:57.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:02:57.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:02:57.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:02:57.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T14:03:27.559+0000] {processor.py:157} INFO - Started process (PID=16829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:03:27.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:03:27.564+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:03:27.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:03:27.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:03:27.602+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:03:27.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:03:27.612+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:03:27.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:03:27.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T14:03:57.952+0000] {processor.py:157} INFO - Started process (PID=16839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:03:57.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:03:57.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:03:57.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:03:57.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:03:57.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:03:57.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:03:57.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:03:57.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:03:57.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T14:04:28.355+0000] {processor.py:157} INFO - Started process (PID=16849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:04:28.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:04:28.359+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:04:28.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:04:28.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:04:28.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:04:28.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:04:28.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:04:28.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:04:28.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T14:04:58.739+0000] {processor.py:157} INFO - Started process (PID=16859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:04:58.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:04:58.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:04:58.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:04:58.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:04:58.770+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:04:58.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:04:58.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:04:58.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:04:58.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:05:29.166+0000] {processor.py:157} INFO - Started process (PID=16869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:05:29.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:05:29.169+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:05:29.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:05:29.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:05:29.198+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:05:29.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:05:29.207+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:05:29.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:05:29.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:05:59.568+0000] {processor.py:157} INFO - Started process (PID=16879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:05:59.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:05:59.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:05:59.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:05:59.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:05:59.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:05:59.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:05:59.609+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:05:59.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:05:59.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T14:06:30.042+0000] {processor.py:157} INFO - Started process (PID=16889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:06:30.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:06:30.047+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:06:30.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:06:30.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:06:30.073+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:06:30.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:06:30.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:06:30.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:06:30.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:07:00.501+0000] {processor.py:157} INFO - Started process (PID=16899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:07:00.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:07:00.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:07:00.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:07:00.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:07:00.543+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:07:00.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:07:00.555+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:07:00.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:07:00.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T14:07:30.889+0000] {processor.py:157} INFO - Started process (PID=16909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:07:30.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:07:30.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:07:30.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:07:30.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:07:30.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:07:30.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:07:30.931+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:07:30.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:07:30.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:08:01.334+0000] {processor.py:157} INFO - Started process (PID=16919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:08:01.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:08:01.337+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:08:01.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:08:01.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:08:01.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:08:01.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:08:01.376+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:08:01.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:08:01.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:08:31.716+0000] {processor.py:157} INFO - Started process (PID=16927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:08:31.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:08:31.720+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:08:31.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:08:31.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:08:31.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:08:31.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:08:31.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:08:31.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:08:31.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T14:09:02.069+0000] {processor.py:157} INFO - Started process (PID=16939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:09:02.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:09:02.071+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:09:02.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:09:02.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:09:02.102+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:09:02.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:09:02.114+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:09:02.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:09:02.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T14:09:32.456+0000] {processor.py:157} INFO - Started process (PID=16949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:09:32.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:09:32.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:09:32.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:09:32.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:09:32.496+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:09:32.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:09:32.508+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:09:32.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:09:32.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T14:10:02.852+0000] {processor.py:157} INFO - Started process (PID=16959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:10:02.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:10:02.857+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:10:02.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:10:02.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:10:02.886+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:10:02.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:10:02.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:10:02.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:10:02.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T14:10:33.320+0000] {processor.py:157} INFO - Started process (PID=16969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:10:33.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:10:33.326+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:10:33.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:10:33.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:10:33.361+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:10:33.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:10:33.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:10:33.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:10:33.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T14:11:03.672+0000] {processor.py:157} INFO - Started process (PID=16979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:11:03.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:11:03.676+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:11:03.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:11:03.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:11:03.704+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:11:03.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:11:03.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:11:03.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:11:03.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:11:34.058+0000] {processor.py:157} INFO - Started process (PID=16989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:11:34.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:11:34.063+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:11:34.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:11:34.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:11:34.098+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:11:34.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:11:34.108+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:11:34.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:11:34.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T14:12:04.475+0000] {processor.py:157} INFO - Started process (PID=16999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:12:04.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:12:04.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:12:04.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:12:04.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:12:04.502+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:12:04.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:12:04.512+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:12:04.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:12:04.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T14:12:34.816+0000] {processor.py:157} INFO - Started process (PID=17009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:12:34.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:12:34.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:12:34.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:12:34.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:12:34.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:12:34.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:12:34.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:12:34.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:12:34.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:13:05.147+0000] {processor.py:157} INFO - Started process (PID=17019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:13:05.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:13:05.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:13:05.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:13:05.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:13:05.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:13:05.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:13:05.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:13:05.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:13:05.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:13:35.545+0000] {processor.py:157} INFO - Started process (PID=17029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:13:35.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:13:35.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:13:35.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:13:35.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:13:35.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:13:35.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:13:35.609+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:13:35.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:13:35.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T14:14:05.849+0000] {processor.py:157} INFO - Started process (PID=17039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:14:05.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:14:05.851+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:14:05.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:14:05.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:14:05.878+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:14:05.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:14:05.888+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:14:05.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:14:05.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:14:36.281+0000] {processor.py:157} INFO - Started process (PID=17049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:14:36.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:14:36.285+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:14:36.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:14:36.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:14:36.315+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:14:36.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:14:36.331+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:14:36.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:14:36.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T14:15:06.677+0000] {processor.py:157} INFO - Started process (PID=17059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:15:06.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:15:06.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:15:06.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:15:06.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:15:06.713+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:15:06.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:15:06.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:15:06.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:15:06.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T14:15:37.027+0000] {processor.py:157} INFO - Started process (PID=17069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:15:37.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:15:37.030+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:15:37.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:15:37.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:15:37.058+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:15:37.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:15:37.069+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:15:37.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:15:37.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T14:16:07.470+0000] {processor.py:157} INFO - Started process (PID=17079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:16:07.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:16:07.472+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:16:07.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:16:07.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:16:07.497+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:16:07.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:16:07.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:16:07.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:16:07.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T14:16:37.867+0000] {processor.py:157} INFO - Started process (PID=17089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:16:37.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:16:37.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:16:37.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:16:37.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:16:37.896+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:16:37.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:16:37.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:16:37.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:16:37.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T14:17:08.196+0000] {processor.py:157} INFO - Started process (PID=17099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:17:08.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:17:08.200+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:17:08.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:17:08.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:17:08.230+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:17:08.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:17:08.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:17:08.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:17:08.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T14:17:38.516+0000] {processor.py:157} INFO - Started process (PID=17109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:17:38.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:17:38.519+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:17:38.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:17:38.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:17:38.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:17:38.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:17:38.555+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:17:38.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:17:38.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T14:18:08.893+0000] {processor.py:157} INFO - Started process (PID=17119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:18:08.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:18:08.896+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:18:08.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:18:08.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:18:08.920+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:18:08.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:18:08.933+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:18:08.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:18:08.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:18:39.347+0000] {processor.py:157} INFO - Started process (PID=17129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:18:39.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:18:39.353+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:18:39.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:18:39.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:18:39.380+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:18:39.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:18:39.393+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:18:39.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:18:39.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T14:19:09.716+0000] {processor.py:157} INFO - Started process (PID=17139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:19:09.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:19:09.720+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:19:09.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:19:09.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:19:09.754+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:19:09.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:19:09.767+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:19:09.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:19:09.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T14:19:40.120+0000] {processor.py:157} INFO - Started process (PID=17149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:19:40.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:19:40.122+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:19:40.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:19:40.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:19:40.145+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:19:40.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:19:40.154+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:19:40.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:19:40.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-09-09T14:20:10.494+0000] {processor.py:157} INFO - Started process (PID=17159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:20:10.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:20:10.497+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:20:10.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:20:10.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:20:10.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:20:10.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:20:10.542+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:20:10.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:20:10.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T14:20:40.951+0000] {processor.py:157} INFO - Started process (PID=17169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:20:40.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:20:40.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:20:40.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:20:40.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:20:40.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:20:40.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:20:40.998+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:20:40.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:20:41.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T14:21:11.259+0000] {processor.py:157} INFO - Started process (PID=17179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:21:11.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:21:11.262+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:21:11.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:21:11.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:21:11.293+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:21:11.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:21:11.303+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:21:11.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:21:11.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T14:21:41.568+0000] {processor.py:157} INFO - Started process (PID=17189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:21:41.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:21:41.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:21:41.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:21:41.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:21:41.599+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:21:41.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:21:41.613+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:21:41.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:21:41.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T14:22:11.965+0000] {processor.py:157} INFO - Started process (PID=17199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:22:11.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:22:11.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:22:11.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:22:11.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:22:12.013+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:22:12.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:22:12.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:22:12.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:22:12.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T14:22:42.352+0000] {processor.py:157} INFO - Started process (PID=17209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:22:42.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:22:42.356+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:22:42.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:22:42.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:22:42.384+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:22:42.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:22:42.393+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:22:42.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:22:42.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:23:12.701+0000] {processor.py:157} INFO - Started process (PID=17219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:23:12.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:23:12.704+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:23:12.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:23:12.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:23:12.730+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:23:12.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:23:12.740+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:23:12.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:23:12.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T14:23:43.121+0000] {processor.py:157} INFO - Started process (PID=17229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:23:43.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:23:43.125+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:23:43.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:23:43.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:23:43.156+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:23:43.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:23:43.166+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:23:43.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:23:43.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T14:24:13.526+0000] {processor.py:157} INFO - Started process (PID=17239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:24:13.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:24:13.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:24:13.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:24:13.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:24:13.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:24:13.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:24:13.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:24:13.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:24:13.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:24:43.911+0000] {processor.py:157} INFO - Started process (PID=17249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:24:43.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:24:43.912+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:24:43.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:24:43.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:24:43.935+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:24:43.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:24:43.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:24:43.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:24:43.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T14:25:14.268+0000] {processor.py:157} INFO - Started process (PID=17259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:25:14.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:25:14.272+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:25:14.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:25:14.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:25:14.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:25:14.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:25:14.314+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:25:14.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:25:14.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T14:25:44.620+0000] {processor.py:157} INFO - Started process (PID=17269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:25:44.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:25:44.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:25:44.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:25:44.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:25:44.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:25:44.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:25:44.659+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:25:44.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:25:44.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T14:26:14.967+0000] {processor.py:157} INFO - Started process (PID=17279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:26:14.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:26:14.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:26:14.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:26:14.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:26:14.998+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:26:14.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:26:15.008+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:26:15.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:26:15.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:26:45.348+0000] {processor.py:157} INFO - Started process (PID=17289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:26:45.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:26:45.352+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:26:45.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:26:45.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:26:45.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:26:45.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:26:45.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:26:45.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:26:45.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:27:15.724+0000] {processor.py:157} INFO - Started process (PID=17299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:27:15.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:27:15.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:27:15.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:27:15.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:27:15.751+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:27:15.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:27:15.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:27:15.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:27:15.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T14:27:46.185+0000] {processor.py:157} INFO - Started process (PID=17309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:27:46.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:27:46.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:27:46.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:27:46.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:27:46.214+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:27:46.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:27:46.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:27:46.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:27:46.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T14:28:16.595+0000] {processor.py:157} INFO - Started process (PID=17319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:28:16.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:28:16.597+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:28:16.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:28:16.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:28:16.623+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:28:16.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:28:16.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:28:16.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:28:16.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:28:46.983+0000] {processor.py:157} INFO - Started process (PID=17329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:28:46.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:28:46.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:28:46.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:28:46.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:28:47.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:28:47.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:28:47.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:28:47.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:28:47.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:29:17.402+0000] {processor.py:157} INFO - Started process (PID=17339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:29:17.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:29:17.406+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:29:17.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:29:17.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:29:17.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:29:17.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:29:17.443+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:29:17.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:29:17.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:29:47.788+0000] {processor.py:157} INFO - Started process (PID=17349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:29:47.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:29:47.793+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:29:47.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:29:47.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:29:47.829+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:29:47.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:29:47.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:29:47.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:29:47.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T14:30:18.194+0000] {processor.py:157} INFO - Started process (PID=17359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:30:18.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:30:18.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:30:18.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:30:18.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:30:18.222+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:30:18.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:30:18.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:30:18.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:30:18.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:30:48.623+0000] {processor.py:157} INFO - Started process (PID=17369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:30:48.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:30:48.626+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:30:48.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:30:48.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:30:48.654+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:30:48.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:30:48.666+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:30:48.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:30:48.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:31:19.004+0000] {processor.py:157} INFO - Started process (PID=17379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:31:19.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:31:19.007+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:31:19.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:31:19.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:31:19.030+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:31:19.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:31:19.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:31:19.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:31:19.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T14:31:49.445+0000] {processor.py:157} INFO - Started process (PID=17389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:31:49.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:31:49.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:31:49.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:31:49.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:31:49.475+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:31:49.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:31:49.484+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:31:49.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:31:49.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:32:19.805+0000] {processor.py:157} INFO - Started process (PID=17399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:32:19.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:32:19.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:32:19.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:32:19.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:32:19.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:32:19.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:32:19.846+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:32:19.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:32:19.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:32:50.238+0000] {processor.py:157} INFO - Started process (PID=17409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:32:50.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:32:50.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:32:50.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:32:50.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:32:50.269+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:32:50.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:32:50.280+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:32:50.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:32:50.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T14:33:20.608+0000] {processor.py:157} INFO - Started process (PID=17419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:33:20.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:33:20.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:33:20.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:33:20.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:33:20.638+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:33:20.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:33:20.647+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:33:20.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:33:20.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T14:33:51.019+0000] {processor.py:157} INFO - Started process (PID=17429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:33:51.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:33:51.023+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:33:51.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:33:51.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:33:51.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:33:51.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:33:51.059+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:33:51.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:33:51.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:34:21.395+0000] {processor.py:157} INFO - Started process (PID=17439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:34:21.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:34:21.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:34:21.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:34:21.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:34:21.425+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:34:21.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:34:21.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:34:21.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:34:21.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:34:51.801+0000] {processor.py:157} INFO - Started process (PID=17449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:34:51.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:34:51.804+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:34:51.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:34:51.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:34:51.832+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:34:51.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:34:51.844+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:34:51.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:34:51.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:35:22.212+0000] {processor.py:157} INFO - Started process (PID=17459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:35:22.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:35:22.215+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:35:22.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:35:22.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:35:22.241+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:35:22.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:35:22.253+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:35:22.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:35:22.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:35:52.657+0000] {processor.py:157} INFO - Started process (PID=17469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:35:52.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:35:52.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:35:52.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:35:52.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:35:52.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:35:52.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:35:52.698+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:35:52.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:35:52.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:36:23.046+0000] {processor.py:157} INFO - Started process (PID=17479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:36:23.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:36:23.049+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:36:23.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:36:23.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:36:23.074+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:36:23.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:36:23.085+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:36:23.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:36:23.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:36:53.350+0000] {processor.py:157} INFO - Started process (PID=17489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:36:53.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:36:53.352+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:36:53.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:36:53.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:36:53.378+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:36:53.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:36:53.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:36:53.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:36:53.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:37:23.672+0000] {processor.py:157} INFO - Started process (PID=17499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:37:23.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:37:23.675+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:37:23.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:37:23.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:37:23.708+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:37:23.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:37:23.720+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:37:23.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:37:23.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T14:37:53.974+0000] {processor.py:157} INFO - Started process (PID=17509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:37:53.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:37:53.982+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:37:53.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:37:53.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:37:54.002+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:37:54.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:37:54.012+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:37:54.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:37:54.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T14:38:24.380+0000] {processor.py:157} INFO - Started process (PID=17519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:38:24.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:38:24.383+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:38:24.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:38:24.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:38:24.412+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:38:24.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:38:24.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:38:24.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:38:24.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T14:38:54.778+0000] {processor.py:157} INFO - Started process (PID=17529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:38:54.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:38:54.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:38:54.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:38:54.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:38:54.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:38:54.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:38:54.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:38:54.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:38:54.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:39:25.188+0000] {processor.py:157} INFO - Started process (PID=17539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:39:25.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:39:25.192+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:39:25.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:39:25.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:39:25.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:39:25.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:39:25.242+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:39:25.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:39:25.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T14:39:55.601+0000] {processor.py:157} INFO - Started process (PID=17549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:39:55.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:39:55.605+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:39:55.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:39:55.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:39:55.632+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:39:55.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:39:55.641+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:39:55.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:39:55.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:40:25.981+0000] {processor.py:157} INFO - Started process (PID=17559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:40:25.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:40:25.983+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:40:25.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:40:25.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:40:26.009+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:40:26.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:40:26.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:40:26.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:40:26.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:40:56.433+0000] {processor.py:157} INFO - Started process (PID=17569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:40:56.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:40:56.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:40:56.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:40:56.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:40:56.463+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:40:56.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:40:56.474+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:40:56.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:40:56.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:41:26.871+0000] {processor.py:157} INFO - Started process (PID=17579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:41:26.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:41:26.873+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:41:26.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:41:26.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:41:26.900+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:41:26.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:41:26.912+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:41:26.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:41:26.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:41:57.257+0000] {processor.py:157} INFO - Started process (PID=17589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:41:57.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:41:57.261+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:41:57.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:41:57.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:41:57.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:41:57.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:41:57.296+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:41:57.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:41:57.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:42:27.677+0000] {processor.py:157} INFO - Started process (PID=17599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:42:27.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:42:27.680+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:42:27.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:42:27.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:42:27.708+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:42:27.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:42:27.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:42:27.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:42:27.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:42:58.061+0000] {processor.py:157} INFO - Started process (PID=17609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:42:58.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:42:58.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:42:58.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:42:58.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:42:58.091+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:42:58.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:42:58.102+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:42:58.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:42:58.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:43:28.448+0000] {processor.py:157} INFO - Started process (PID=17619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:43:28.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:43:28.451+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:43:28.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:43:28.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:43:28.485+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:43:28.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:43:28.497+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:43:28.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:43:28.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T14:43:58.824+0000] {processor.py:157} INFO - Started process (PID=17629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:43:58.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:43:58.826+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:43:58.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:43:58.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:43:58.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:43:58.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:43:58.862+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:43:58.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:43:58.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T14:44:29.183+0000] {processor.py:157} INFO - Started process (PID=17639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:44:29.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:44:29.185+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:44:29.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:44:29.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:44:29.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:44:29.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:44:29.224+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:44:29.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:44:29.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T14:44:59.558+0000] {processor.py:157} INFO - Started process (PID=17649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:44:59.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:44:59.561+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:44:59.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:44:59.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:44:59.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:44:59.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:44:59.599+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:44:59.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:44:59.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:45:29.962+0000] {processor.py:157} INFO - Started process (PID=17659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:45:29.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:45:29.964+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:45:29.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:45:29.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:45:29.992+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:45:29.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:45:30.004+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:45:30.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:45:30.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:46:00.357+0000] {processor.py:157} INFO - Started process (PID=17669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:46:00.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:46:00.359+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:46:00.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:46:00.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:46:00.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:46:00.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:46:00.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:46:00.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:46:00.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:46:30.720+0000] {processor.py:157} INFO - Started process (PID=17679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:46:30.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:46:30.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:46:30.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:46:30.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:46:30.749+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:46:30.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:46:30.759+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:46:30.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:46:30.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:47:01.092+0000] {processor.py:157} INFO - Started process (PID=17689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:47:01.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:47:01.097+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:47:01.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:47:01.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:47:01.124+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:47:01.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:47:01.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:47:01.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:47:01.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:47:31.408+0000] {processor.py:157} INFO - Started process (PID=17699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:47:31.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:47:31.410+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:47:31.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:47:31.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:47:31.439+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:47:31.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:47:31.448+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:47:31.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:47:31.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:48:01.824+0000] {processor.py:157} INFO - Started process (PID=17709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:48:01.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:48:01.828+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:48:01.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:48:01.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:48:01.854+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:48:01.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:48:01.865+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:48:01.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:48:01.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T14:48:32.185+0000] {processor.py:157} INFO - Started process (PID=17719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:48:32.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:48:32.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:48:32.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:48:32.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:48:32.214+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:48:32.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:48:32.224+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:48:32.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:48:32.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:49:02.520+0000] {processor.py:157} INFO - Started process (PID=17729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:49:02.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:49:02.523+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:49:02.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:49:02.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:49:02.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:49:02.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:49:02.564+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:49:02.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:49:02.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:49:32.955+0000] {processor.py:157} INFO - Started process (PID=17739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:49:32.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:49:32.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:49:32.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:49:32.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:49:32.982+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:49:32.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:49:32.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:49:32.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:49:32.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T14:50:03.392+0000] {processor.py:157} INFO - Started process (PID=17749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:50:03.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:50:03.397+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:50:03.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:50:03.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:50:03.430+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:50:03.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:50:03.442+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:50:03.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:50:03.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T14:50:33.819+0000] {processor.py:157} INFO - Started process (PID=17759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:50:33.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:50:33.822+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:50:33.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:50:33.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:50:33.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:50:33.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:50:33.863+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:50:33.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:50:33.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T14:51:04.219+0000] {processor.py:157} INFO - Started process (PID=17769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:51:04.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:51:04.223+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:51:04.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:51:04.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:51:04.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:51:04.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:51:04.262+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:51:04.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:51:04.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:51:34.618+0000] {processor.py:157} INFO - Started process (PID=17779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:51:34.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:51:34.621+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:51:34.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:51:34.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:51:34.651+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:51:34.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:51:34.663+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:51:34.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:51:34.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:52:05.054+0000] {processor.py:157} INFO - Started process (PID=17789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:52:05.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:52:05.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:52:05.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:52:05.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:52:05.084+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:52:05.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:52:05.094+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:52:05.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:52:05.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:52:35.471+0000] {processor.py:157} INFO - Started process (PID=17799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:52:35.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:52:35.473+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:52:35.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:52:35.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:52:35.499+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:52:35.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:52:35.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:52:35.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:52:35.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:53:05.858+0000] {processor.py:157} INFO - Started process (PID=17809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:53:05.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:53:05.860+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:53:05.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:53:05.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:53:05.887+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:53:05.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:53:05.900+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:53:05.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:53:05.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:53:36.203+0000] {processor.py:157} INFO - Started process (PID=17819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:53:36.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:53:36.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:53:36.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:53:36.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:53:36.232+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:53:36.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:53:36.244+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:53:36.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:53:36.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T14:54:06.582+0000] {processor.py:157} INFO - Started process (PID=17829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:54:06.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:54:06.584+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:54:06.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:54:06.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:54:06.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:54:06.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:54:06.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:54:06.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:54:06.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T14:54:36.976+0000] {processor.py:157} INFO - Started process (PID=17839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:54:36.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:54:36.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:54:36.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:54:36.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:54:37.007+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:54:37.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:54:37.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:54:37.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:54:37.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T14:55:07.378+0000] {processor.py:157} INFO - Started process (PID=17849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:55:07.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:55:07.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:55:07.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:55:07.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:55:07.407+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:55:07.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:55:07.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:55:07.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:55:07.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:55:37.721+0000] {processor.py:157} INFO - Started process (PID=17859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:55:37.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:55:37.725+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:55:37.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:55:37.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:55:37.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:55:37.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:55:37.760+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:55:37.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:55:37.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T14:56:08.090+0000] {processor.py:157} INFO - Started process (PID=17869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:56:08.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:56:08.097+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:56:08.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:56:08.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:56:08.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:56:08.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:56:08.145+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:56:08.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:56:08.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T14:56:38.467+0000] {processor.py:157} INFO - Started process (PID=17879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:56:38.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:56:38.470+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:56:38.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:56:38.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:56:38.497+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:56:38.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:56:38.508+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:56:38.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:56:38.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T14:57:08.855+0000] {processor.py:157} INFO - Started process (PID=17889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:57:08.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:57:08.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:57:08.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:57:08.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:57:08.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:57:08.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:57:08.897+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:57:08.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:57:08.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T14:57:39.229+0000] {processor.py:157} INFO - Started process (PID=17899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:57:39.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:57:39.232+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:57:39.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:57:39.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:57:39.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:57:39.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:57:39.269+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:57:39.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:57:39.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T14:58:09.631+0000] {processor.py:157} INFO - Started process (PID=17909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:58:09.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:58:09.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:58:09.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:58:09.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:58:09.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:58:09.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:58:09.675+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:58:09.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:58:09.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T14:58:40.018+0000] {processor.py:157} INFO - Started process (PID=17919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:58:40.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:58:40.020+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:58:40.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:58:40.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:58:40.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:58:40.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:58:40.058+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:58:40.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:58:40.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T14:59:10.418+0000] {processor.py:157} INFO - Started process (PID=17929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:59:10.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:59:10.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:59:10.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:59:10.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:59:10.447+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:59:10.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:59:10.456+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:59:10.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:59:10.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T14:59:40.824+0000] {processor.py:157} INFO - Started process (PID=17939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:59:40.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T14:59:40.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:59:40.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:59:40.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T14:59:40.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:59:40.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T14:59:40.862+0000] {logging_mixin.py:151} INFO - [2024-09-09T14:59:40.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T14:59:40.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:00:11.166+0000] {processor.py:157} INFO - Started process (PID=17949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:00:11.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:00:11.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:00:11.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:00:11.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:00:11.205+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:00:11.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:00:11.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:00:11.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:00:11.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T15:00:41.519+0000] {processor.py:157} INFO - Started process (PID=17959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:00:41.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:00:41.523+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:00:41.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:00:41.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:00:41.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:00:41.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:00:41.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:00:41.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:00:41.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:01:11.963+0000] {processor.py:157} INFO - Started process (PID=17969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:01:11.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:01:11.964+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:01:11.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:01:11.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:01:11.988+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:01:11.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:01:12.000+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:01:11.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:01:12.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T15:01:42.299+0000] {processor.py:157} INFO - Started process (PID=17979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:01:42.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:01:42.302+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:01:42.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:01:42.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:01:42.327+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:01:42.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:01:42.337+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:01:42.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:01:42.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T15:02:12.702+0000] {processor.py:157} INFO - Started process (PID=17989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:02:12.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:02:12.706+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:02:12.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:02:12.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:02:12.737+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:02:12.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:02:12.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:02:12.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:02:12.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T15:02:43.098+0000] {processor.py:157} INFO - Started process (PID=17999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:02:43.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:02:43.104+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:02:43.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:02:43.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:02:43.157+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:02:43.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:02:43.172+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:02:43.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:02:43.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T15:03:13.513+0000] {processor.py:157} INFO - Started process (PID=18009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:03:13.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:03:13.518+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:03:13.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:03:13.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:03:13.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:03:13.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:03:13.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:03:13.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:03:13.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T15:03:43.885+0000] {processor.py:157} INFO - Started process (PID=18019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:03:43.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:03:43.888+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:03:43.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:03:43.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:03:43.912+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:03:43.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:03:43.922+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:03:43.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:03:43.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T15:04:14.445+0000] {processor.py:157} INFO - Started process (PID=18029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:04:14.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:04:14.456+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:04:14.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:04:14.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:04:14.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:04:14.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:04:14.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:04:14.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:04:14.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-09T15:04:45.140+0000] {processor.py:157} INFO - Started process (PID=18039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:04:45.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:04:45.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:04:45.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:04:45.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:04:45.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:04:45.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:04:45.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:04:45.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:04:45.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:05:15.759+0000] {processor.py:157} INFO - Started process (PID=18048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:05:15.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:05:15.774+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:05:15.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:05:15.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:05:15.822+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:05:15.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:05:15.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:05:15.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:05:15.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T15:05:46.757+0000] {processor.py:157} INFO - Started process (PID=18059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:05:46.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:05:46.759+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:05:46.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:05:46.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:05:46.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:05:46.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:05:46.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:05:46.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:05:46.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T15:06:17.151+0000] {processor.py:157} INFO - Started process (PID=18069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:06:17.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:06:17.154+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:06:17.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:06:17.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:06:17.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:06:17.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:06:17.188+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:06:17.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:06:17.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T15:06:47.228+0000] {processor.py:157} INFO - Started process (PID=18076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:06:47.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:06:47.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:06:47.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:06:47.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:06:47.270+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:06:47.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:06:47.288+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:06:47.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:06:47.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T15:07:17.586+0000] {processor.py:157} INFO - Started process (PID=18088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:07:17.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:07:17.591+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:07:17.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:07:17.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:07:17.641+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:07:17.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:07:17.652+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:07:17.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:07:17.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T15:07:47.930+0000] {processor.py:157} INFO - Started process (PID=18099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:07:47.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:07:47.932+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:07:47.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:07:47.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:07:47.960+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:07:47.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:07:47.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:07:47.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:07:47.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T15:13:43.029+0000] {processor.py:157} INFO - Started process (PID=18111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:13:43.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:13:43.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:13:43.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:13:43.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:13:43.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:13:43.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:13:43.129+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:13:43.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:13:43.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-09T15:29:30.331+0000] {processor.py:157} INFO - Started process (PID=18120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:29:30.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:29:30.338+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:29:30.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:29:30.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:29:30.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:29:30.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:29:30.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:29:30.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:29:30.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-09T15:30:00.747+0000] {processor.py:157} INFO - Started process (PID=18129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:30:00.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:30:00.752+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:30:00.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:30:00.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:30:00.792+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:30:00.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:30:00.805+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:30:00.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:30:00.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T15:30:31.053+0000] {processor.py:157} INFO - Started process (PID=18141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:30:31.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:30:31.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:30:31.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:30:31.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:30:31.095+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:30:31.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:30:31.107+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:30:31.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:30:31.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T15:31:01.423+0000] {processor.py:157} INFO - Started process (PID=18151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:31:01.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:31:01.429+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:31:01.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:31:01.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:31:01.456+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:31:01.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:31:01.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:31:01.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:31:01.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T15:31:31.880+0000] {processor.py:157} INFO - Started process (PID=18161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:31:31.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:31:31.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:31:31.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:31:31.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:31:31.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:31:31.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:31:31.917+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:31:31.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:31:31.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T15:32:02.310+0000] {processor.py:157} INFO - Started process (PID=18171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:32:02.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:32:02.311+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:32:02.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:32:02.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:32:02.336+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:32:02.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:32:02.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:32:02.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:32:02.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T15:32:32.706+0000] {processor.py:157} INFO - Started process (PID=18180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:32:32.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:32:32.710+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:32:32.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:32:32.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:32:32.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:32:32.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:32:32.760+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:32:32.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:32:32.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T15:33:03.030+0000] {processor.py:157} INFO - Started process (PID=18191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:33:03.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:33:03.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:33:03.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:33:03.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:33:03.061+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:33:03.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:33:03.071+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:33:03.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:33:03.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T15:33:33.400+0000] {processor.py:157} INFO - Started process (PID=18201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:33:33.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:33:33.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:33:33.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:33:33.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:33:33.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:33:33.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:33:33.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:33:33.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:33:33.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T15:34:03.813+0000] {processor.py:157} INFO - Started process (PID=18211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:34:03.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:34:03.817+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:34:03.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:34:03.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:34:03.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:34:03.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:34:03.854+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:34:03.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:34:03.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T15:34:34.261+0000] {processor.py:157} INFO - Started process (PID=18221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:34:34.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:34:34.263+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:34:34.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:34:34.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:34:34.290+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:34:34.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:34:34.304+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:34:34.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:34:34.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T15:35:04.646+0000] {processor.py:157} INFO - Started process (PID=18231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:35:04.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:35:04.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:35:04.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:35:04.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:35:04.677+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:35:04.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:35:04.689+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:35:04.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:35:04.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T15:35:35.011+0000] {processor.py:157} INFO - Started process (PID=18241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:35:35.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:35:35.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:35:35.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:35:35.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:35:35.038+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:35:35.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:35:35.048+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:35:35.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:35:35.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T15:36:05.396+0000] {processor.py:157} INFO - Started process (PID=18251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:36:05.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:36:05.402+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:36:05.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:36:05.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:36:05.441+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:36:05.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:36:05.455+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:36:05.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:36:05.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T15:36:35.770+0000] {processor.py:157} INFO - Started process (PID=18261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:36:35.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:36:35.774+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:36:35.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:36:35.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:36:35.800+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:36:35.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:36:35.810+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:36:35.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:36:35.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:37:06.104+0000] {processor.py:157} INFO - Started process (PID=18271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:37:06.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:37:06.106+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:37:06.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:37:06.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:37:06.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:37:06.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:37:06.145+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:37:06.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:37:06.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T15:37:36.431+0000] {processor.py:157} INFO - Started process (PID=18281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:37:36.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:37:36.435+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:37:36.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:37:36.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:37:36.459+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:37:36.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:37:36.470+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:37:36.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:37:36.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T15:38:06.771+0000] {processor.py:157} INFO - Started process (PID=18291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:38:06.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:38:06.775+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:38:06.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:38:06.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:38:06.799+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:38:06.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:38:06.811+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:38:06.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:38:06.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:38:37.127+0000] {processor.py:157} INFO - Started process (PID=18301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:38:37.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:38:37.129+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:38:37.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:38:37.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:38:37.153+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:38:37.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:38:37.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:38:37.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:38:37.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T15:39:07.558+0000] {processor.py:157} INFO - Started process (PID=18311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:39:07.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:39:07.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:39:07.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:39:07.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:39:07.586+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:39:07.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:39:07.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:39:07.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:39:07.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T15:39:37.950+0000] {processor.py:157} INFO - Started process (PID=18321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:39:37.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:39:37.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:39:37.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:39:37.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:39:37.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:39:37.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:39:38.000+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:39:38.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:39:38.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T15:40:08.402+0000] {processor.py:157} INFO - Started process (PID=18331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:40:08.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:40:08.404+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:40:08.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:40:08.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:40:08.437+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:40:08.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:40:08.446+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:40:08.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:40:08.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T15:40:38.781+0000] {processor.py:157} INFO - Started process (PID=18341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:40:38.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:40:38.783+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:40:38.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:40:38.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:40:38.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:40:38.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:40:38.819+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:40:38.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:40:38.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:41:09.224+0000] {processor.py:157} INFO - Started process (PID=18351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:41:09.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:41:09.226+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:41:09.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:41:09.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:41:09.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:41:09.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:41:09.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:41:09.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:41:09.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T15:41:39.582+0000] {processor.py:157} INFO - Started process (PID=18361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:41:39.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:41:39.585+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:41:39.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:41:39.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:41:39.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:41:39.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:41:39.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:41:39.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:41:39.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T15:42:09.923+0000] {processor.py:157} INFO - Started process (PID=18371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:42:09.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:42:09.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:42:09.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:42:09.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:42:09.948+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:42:09.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:42:09.958+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:42:09.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:42:09.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T15:42:40.293+0000] {processor.py:157} INFO - Started process (PID=18381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:42:40.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:42:40.295+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:42:40.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:42:40.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:42:40.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:42:40.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:42:40.331+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:42:40.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:42:40.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T15:43:10.758+0000] {processor.py:157} INFO - Started process (PID=18391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:43:10.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:43:10.763+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:43:10.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:43:10.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:43:10.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:43:10.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:43:10.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:43:10.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:43:10.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T15:43:41.037+0000] {processor.py:157} INFO - Started process (PID=18401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:43:41.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:43:41.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:43:41.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:43:41.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:43:41.069+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:43:41.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:43:41.078+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:43:41.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:43:41.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T15:44:11.447+0000] {processor.py:157} INFO - Started process (PID=18411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:44:11.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:44:11.450+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:44:11.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:44:11.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:44:11.475+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:44:11.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:44:11.484+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:44:11.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:44:11.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T15:44:41.869+0000] {processor.py:157} INFO - Started process (PID=18421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:44:41.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:44:41.872+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:44:41.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:44:41.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:44:41.896+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:44:41.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:44:41.905+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:44:41.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:44:41.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T15:45:12.218+0000] {processor.py:157} INFO - Started process (PID=18430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:45:12.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:45:12.221+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:45:12.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:45:12.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:45:12.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:45:12.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:45:12.260+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:45:12.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:45:12.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T15:45:42.596+0000] {processor.py:157} INFO - Started process (PID=18441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:45:42.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:45:42.601+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:45:42.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:45:42.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:45:42.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:45:42.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:45:42.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:45:42.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:45:42.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T15:46:12.917+0000] {processor.py:157} INFO - Started process (PID=18451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:46:12.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:46:12.920+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:46:12.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:46:12.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:46:12.946+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:46:12.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:46:12.958+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:46:12.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:46:12.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:46:43.335+0000] {processor.py:157} INFO - Started process (PID=18461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:46:43.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:46:43.342+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:46:43.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:46:43.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:46:43.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:46:43.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:46:43.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:46:43.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:46:43.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T15:47:13.782+0000] {processor.py:157} INFO - Started process (PID=18471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:47:13.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:47:13.785+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:47:13.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:47:13.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:47:13.815+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:47:13.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:47:13.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:47:13.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:47:13.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T15:47:44.160+0000] {processor.py:157} INFO - Started process (PID=18481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:47:44.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:47:44.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:47:44.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:47:44.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:47:44.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:47:44.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:47:44.199+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:47:44.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:47:44.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:48:14.596+0000] {processor.py:157} INFO - Started process (PID=18491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:48:14.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:48:14.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:48:14.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:48:14.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:48:14.642+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:48:14.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:48:14.653+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:48:14.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:48:14.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T15:48:44.932+0000] {processor.py:157} INFO - Started process (PID=18501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:48:44.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:48:44.935+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:48:44.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:48:44.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:48:44.962+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:48:44.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:48:44.975+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:48:44.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:48:44.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T15:49:15.226+0000] {processor.py:157} INFO - Started process (PID=18511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:49:15.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:49:15.229+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:49:15.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:49:15.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:49:15.259+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:49:15.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:49:15.269+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:49:15.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:49:15.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T15:49:45.638+0000] {processor.py:157} INFO - Started process (PID=18521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:49:45.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:49:45.641+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:49:45.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:49:45.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:49:45.666+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:49:45.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:49:45.676+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:49:45.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:49:45.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:50:15.978+0000] {processor.py:157} INFO - Started process (PID=18531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:50:15.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:50:15.982+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:50:15.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:50:15.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:50:16.015+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:50:16.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:50:16.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:50:16.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:50:16.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T15:50:46.246+0000] {processor.py:157} INFO - Started process (PID=18541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:50:46.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:50:46.249+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:50:46.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:50:46.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:50:46.278+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:50:46.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:50:46.288+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:50:46.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:50:46.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T15:51:16.643+0000] {processor.py:157} INFO - Started process (PID=18551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:51:16.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:51:16.646+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:51:16.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:51:16.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:51:16.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:51:16.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:51:16.683+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:51:16.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:51:16.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:51:47.051+0000] {processor.py:157} INFO - Started process (PID=18561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:51:47.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:51:47.054+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:51:47.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:51:47.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:51:47.079+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:51:47.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:51:47.089+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:51:47.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:51:47.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:52:17.364+0000] {processor.py:157} INFO - Started process (PID=18571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:52:17.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:52:17.368+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:52:17.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:52:17.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:52:17.393+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:52:17.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:52:17.406+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:52:17.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:52:17.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T15:52:47.764+0000] {processor.py:157} INFO - Started process (PID=18581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:52:47.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:52:47.769+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:52:47.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:52:47.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:52:47.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:52:47.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:52:47.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:52:47.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:52:47.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T15:53:18.144+0000] {processor.py:157} INFO - Started process (PID=18591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:53:18.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:53:18.147+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:53:18.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:53:18.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:53:18.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:53:18.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:53:18.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:53:18.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:53:18.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T15:53:48.528+0000] {processor.py:157} INFO - Started process (PID=18601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:53:48.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:53:48.531+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:53:48.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:53:48.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:53:48.559+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:53:48.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:53:48.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:53:48.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:53:48.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T15:54:18.999+0000] {processor.py:157} INFO - Started process (PID=18611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:54:19.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:54:19.003+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:54:19.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:54:19.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:54:19.029+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:54:19.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:54:19.038+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:54:19.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:54:19.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:54:49.287+0000] {processor.py:157} INFO - Started process (PID=18621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:54:49.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:54:49.291+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:54:49.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:54:49.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:54:49.318+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:54:49.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:54:49.327+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:54:49.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:54:49.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:55:19.615+0000] {processor.py:157} INFO - Started process (PID=18631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:55:19.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:55:19.619+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:55:19.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:55:19.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:55:19.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:55:19.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:55:19.657+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:55:19.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:55:19.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T15:55:49.999+0000] {processor.py:157} INFO - Started process (PID=18641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:55:50.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:55:50.002+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:55:50.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:55:50.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:55:50.028+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:55:50.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:55:50.038+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:55:50.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:55:50.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:56:20.407+0000] {processor.py:157} INFO - Started process (PID=18651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:56:20.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:56:20.410+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:56:20.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:56:20.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:56:20.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:56:20.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:56:20.446+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:56:20.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:56:20.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T15:56:50.742+0000] {processor.py:157} INFO - Started process (PID=18661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:56:50.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:56:50.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:56:50.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:56:50.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:56:50.772+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:56:50.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:56:50.783+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:56:50.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:56:50.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T15:57:21.154+0000] {processor.py:157} INFO - Started process (PID=18671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:57:21.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:57:21.161+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:57:21.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:57:21.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:57:21.184+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:57:21.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:57:21.193+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:57:21.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:57:21.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T15:57:51.549+0000] {processor.py:157} INFO - Started process (PID=18681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:57:51.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:57:51.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:57:51.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:57:51.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:57:51.578+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:57:51.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:57:51.588+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:57:51.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:57:51.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T15:58:21.963+0000] {processor.py:157} INFO - Started process (PID=18690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:58:21.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:58:21.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:58:21.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:58:21.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:58:22.019+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:58:22.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:58:22.035+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:58:22.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:58:22.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-09T15:58:52.274+0000] {processor.py:157} INFO - Started process (PID=18701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:58:52.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:58:52.277+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:58:52.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:58:52.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:58:52.308+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:58:52.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:58:52.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:58:52.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:58:52.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T15:59:22.608+0000] {processor.py:157} INFO - Started process (PID=18711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:59:22.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:59:22.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:59:22.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:59:22.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:59:22.637+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:59:22.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:59:22.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:59:22.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:59:22.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T15:59:53.024+0000] {processor.py:157} INFO - Started process (PID=18721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:59:53.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T15:59:53.028+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:59:53.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:59:53.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T15:59:53.063+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:59:53.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T15:59:53.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T15:59:53.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T15:59:53.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T16:00:23.310+0000] {processor.py:157} INFO - Started process (PID=18731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:00:23.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:00:23.314+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:00:23.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:00:23.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:00:23.344+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:00:23.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:00:23.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:00:23.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:00:23.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T16:00:53.827+0000] {processor.py:157} INFO - Started process (PID=18741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:00:53.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:00:53.833+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:00:53.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:00:53.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:00:53.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:00:53.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:00:53.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:00:53.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:00:53.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T16:01:24.163+0000] {processor.py:157} INFO - Started process (PID=18751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:01:24.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:01:24.166+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:01:24.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:01:24.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:01:24.195+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:01:24.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:01:24.207+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:01:24.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:01:24.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T16:01:54.629+0000] {processor.py:157} INFO - Started process (PID=18761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:01:54.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:01:54.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:01:54.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:01:54.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:01:54.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:01:54.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:01:54.672+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:01:54.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:01:54.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T16:02:25.003+0000] {processor.py:157} INFO - Started process (PID=18771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:02:25.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:02:25.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:02:25.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:02:25.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:02:25.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:02:25.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:02:25.045+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:02:25.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:02:25.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T16:02:55.292+0000] {processor.py:157} INFO - Started process (PID=18781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:02:55.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:02:55.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:02:55.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:02:55.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:02:55.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:02:55.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:02:55.332+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:02:55.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:02:55.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T16:03:25.672+0000] {processor.py:157} INFO - Started process (PID=18791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:03:25.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:03:25.677+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:03:25.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:03:25.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:03:25.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:03:25.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:03:25.727+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:03:25.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:03:25.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T16:03:56.070+0000] {processor.py:157} INFO - Started process (PID=18801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:03:56.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:03:56.073+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:03:56.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:03:56.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:03:56.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:03:56.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:03:56.113+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:03:56.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:03:56.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T16:04:26.449+0000] {processor.py:157} INFO - Started process (PID=18811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:04:26.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:04:26.452+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:04:26.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:04:26.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:04:26.481+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:04:26.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:04:26.490+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:04:26.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:04:26.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:04:56.844+0000] {processor.py:157} INFO - Started process (PID=18821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:04:56.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:04:56.847+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:04:56.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:04:56.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:04:56.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:04:56.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:04:56.882+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:04:56.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:04:56.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T16:05:27.142+0000] {processor.py:157} INFO - Started process (PID=18831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:05:27.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:05:27.145+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:05:27.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:05:27.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:05:27.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:05:27.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:05:27.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:05:27.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:05:27.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T16:05:57.560+0000] {processor.py:157} INFO - Started process (PID=18841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:05:57.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:05:57.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:05:57.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:05:57.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:05:57.589+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:05:57.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:05:57.599+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:05:57.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:05:57.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T16:06:28.305+0000] {processor.py:157} INFO - Started process (PID=18851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:06:28.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:06:28.311+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:06:28.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:06:28.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:06:28.471+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:06:28.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:06:28.534+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:06:28.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:06:28.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.288 seconds
[2024-09-09T16:06:58.851+0000] {processor.py:157} INFO - Started process (PID=18861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:06:58.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:06:58.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:06:58.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:06:58.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:06:58.912+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:06:58.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:06:58.931+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:06:58.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:06:58.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-09T16:07:29.123+0000] {processor.py:157} INFO - Started process (PID=18871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:07:29.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:07:29.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:07:29.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:07:29.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:07:29.154+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:07:29.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:07:29.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:07:29.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:07:29.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T16:07:59.440+0000] {processor.py:157} INFO - Started process (PID=18881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:07:59.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:07:59.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:07:59.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:07:59.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:07:59.474+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:07:59.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:07:59.484+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:07:59.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:07:59.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T16:08:29.777+0000] {processor.py:157} INFO - Started process (PID=18891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:08:29.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:08:29.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:08:29.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:08:29.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:08:29.813+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:08:29.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:08:29.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:08:29.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:08:29.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T16:09:00.174+0000] {processor.py:157} INFO - Started process (PID=18901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:09:00.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:09:00.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:09:00.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:09:00.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:09:00.218+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:09:00.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:09:00.232+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:09:00.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:09:00.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T16:09:30.458+0000] {processor.py:157} INFO - Started process (PID=18910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:09:30.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:09:30.462+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:09:30.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:09:30.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:09:30.491+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:09:30.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:09:30.500+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:09:30.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:09:30.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T16:10:00.850+0000] {processor.py:157} INFO - Started process (PID=18921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:10:00.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:10:00.854+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:10:00.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:10:00.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:10:00.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:10:00.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:10:00.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:10:00.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:10:00.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T16:10:31.192+0000] {processor.py:157} INFO - Started process (PID=18931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:10:31.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:10:31.194+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:10:31.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:10:31.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:10:31.220+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:10:31.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:10:31.230+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:10:31.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:10:31.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T16:11:01.518+0000] {processor.py:157} INFO - Started process (PID=18941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:11:01.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:11:01.522+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:11:01.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:11:01.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:11:01.548+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:11:01.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:11:01.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:11:01.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:11:01.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T16:11:31.819+0000] {processor.py:157} INFO - Started process (PID=18951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:11:31.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:11:31.829+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:11:31.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:11:31.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:11:31.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:11:31.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:11:31.867+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:11:31.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:11:31.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T16:12:02.196+0000] {processor.py:157} INFO - Started process (PID=18961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:12:02.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:12:02.202+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:12:02.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:12:02.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:12:02.237+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:12:02.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:12:02.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:12:02.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:12:02.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T16:12:32.562+0000] {processor.py:157} INFO - Started process (PID=18971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:12:32.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:12:32.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:12:32.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:12:32.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:12:32.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:12:32.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:12:32.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:12:32.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:12:32.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T16:13:02.934+0000] {processor.py:157} INFO - Started process (PID=18981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:13:02.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:13:02.939+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:13:02.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:13:02.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:13:02.963+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:13:02.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:13:02.974+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:13:02.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:13:02.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:13:33.330+0000] {processor.py:157} INFO - Started process (PID=18991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:13:33.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:13:33.333+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:13:33.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:13:33.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:13:33.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:13:33.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:13:33.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:13:33.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:13:33.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T16:14:03.689+0000] {processor.py:157} INFO - Started process (PID=19001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:14:03.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:14:03.692+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:14:03.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:14:03.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:14:03.721+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:14:03.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:14:03.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:14:03.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:14:03.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T16:14:34.072+0000] {processor.py:157} INFO - Started process (PID=19011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:14:34.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:14:34.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:14:34.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:14:34.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:14:34.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:14:34.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:14:34.112+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:14:34.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:14:34.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T16:15:04.449+0000] {processor.py:157} INFO - Started process (PID=19021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:15:04.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:15:04.451+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:15:04.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:15:04.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:15:04.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:15:04.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:15:04.487+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:15:04.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:15:04.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T16:15:34.907+0000] {processor.py:157} INFO - Started process (PID=19031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:15:34.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:15:34.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:15:34.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:15:34.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:15:34.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:15:34.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:15:34.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:15:34.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:15:34.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T16:16:05.267+0000] {processor.py:157} INFO - Started process (PID=19041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:16:05.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:16:05.272+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:16:05.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:16:05.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:16:05.309+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:16:05.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:16:05.321+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:16:05.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:16:05.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T16:16:35.594+0000] {processor.py:157} INFO - Started process (PID=19051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:16:35.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:16:35.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:16:35.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:16:35.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:16:35.622+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:16:35.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:16:35.631+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:16:35.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:16:35.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T16:17:05.999+0000] {processor.py:157} INFO - Started process (PID=19061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:17:06.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:17:06.002+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:17:06.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:17:06.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:17:06.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:17:06.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:17:06.044+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:17:06.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:17:06.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T16:17:36.374+0000] {processor.py:157} INFO - Started process (PID=19071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:17:36.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:17:36.376+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:17:36.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:17:36.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:17:36.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:17:36.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:17:36.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:17:36.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:17:36.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T16:18:06.765+0000] {processor.py:157} INFO - Started process (PID=19081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:18:06.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:18:06.767+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:18:06.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:18:06.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:18:06.803+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:18:06.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:18:06.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:18:06.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:18:06.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T16:18:37.184+0000] {processor.py:157} INFO - Started process (PID=19091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:18:37.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:18:37.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:18:37.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:18:37.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:18:37.213+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:18:37.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:18:37.223+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:18:37.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:18:37.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T16:19:07.564+0000] {processor.py:157} INFO - Started process (PID=19101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:19:07.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:19:07.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:19:07.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:19:07.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:19:07.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:19:07.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:19:07.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:19:07.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:19:07.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:19:37.965+0000] {processor.py:157} INFO - Started process (PID=19111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:19:37.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:19:37.968+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:19:37.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:19:37.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:19:37.993+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:19:37.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:19:38.002+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:19:38.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:19:38.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T16:20:08.353+0000] {processor.py:157} INFO - Started process (PID=19121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:20:08.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:20:08.356+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:20:08.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:20:08.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:20:08.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:20:08.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:20:08.394+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:20:08.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:20:08.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T16:20:38.694+0000] {processor.py:157} INFO - Started process (PID=19131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:20:38.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:20:38.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:20:38.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:20:38.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:20:38.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:20:38.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:20:38.733+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:20:38.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:20:38.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:21:09.078+0000] {processor.py:157} INFO - Started process (PID=19141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:21:09.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:21:09.081+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:21:09.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:21:09.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:21:09.108+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:21:09.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:21:09.119+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:21:09.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:21:09.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:21:39.487+0000] {processor.py:157} INFO - Started process (PID=19151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:21:39.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:21:39.490+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:21:39.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:21:39.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:21:39.525+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:21:39.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:21:39.536+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:21:39.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:21:39.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T16:22:09.797+0000] {processor.py:157} INFO - Started process (PID=19161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:22:09.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:22:09.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:22:09.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:22:09.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:22:09.841+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:22:09.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:22:09.853+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:22:09.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:22:09.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T16:22:40.103+0000] {processor.py:157} INFO - Started process (PID=19171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:22:40.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:22:40.107+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:22:40.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:22:40.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:22:40.132+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:22:40.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:22:40.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:22:40.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:22:40.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T16:23:10.518+0000] {processor.py:157} INFO - Started process (PID=19181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:23:10.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:23:10.520+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:23:10.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:23:10.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:23:10.549+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:23:10.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:23:10.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:23:10.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:23:10.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:23:40.836+0000] {processor.py:157} INFO - Started process (PID=19191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:23:40.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:23:40.840+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:23:40.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:23:40.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:23:40.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:23:40.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:23:40.928+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:23:40.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:23:40.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-09T16:24:11.181+0000] {processor.py:157} INFO - Started process (PID=19201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:24:11.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:24:11.185+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:24:11.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:24:11.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:24:11.228+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:24:11.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:24:11.240+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:24:11.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:24:11.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T16:24:41.514+0000] {processor.py:157} INFO - Started process (PID=19211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:24:41.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:24:41.517+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:24:41.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:24:41.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:24:41.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:24:41.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:24:41.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:24:41.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:24:41.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T16:25:11.915+0000] {processor.py:157} INFO - Started process (PID=19221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:25:11.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:25:11.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:25:11.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:25:11.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:25:11.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:25:11.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:25:11.985+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:25:11.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:25:11.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T16:25:42.202+0000] {processor.py:157} INFO - Started process (PID=19231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:25:42.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:25:42.205+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:25:42.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:25:42.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:25:42.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:25:42.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:25:42.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:25:42.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:25:42.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:26:12.607+0000] {processor.py:157} INFO - Started process (PID=19241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:26:12.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:26:12.612+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:26:12.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:26:12.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:26:12.663+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:26:12.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:26:12.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:26:12.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:26:12.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-09T16:26:42.904+0000] {processor.py:157} INFO - Started process (PID=19251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:26:42.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:26:42.907+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:26:42.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:26:42.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:26:42.937+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:26:42.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:26:42.947+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:26:42.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:26:42.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T16:27:13.313+0000] {processor.py:157} INFO - Started process (PID=19261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:27:13.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:27:13.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:27:13.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:27:13.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:27:13.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:27:13.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:27:13.390+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:27:13.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:27:13.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T16:27:43.657+0000] {processor.py:157} INFO - Started process (PID=19271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:27:43.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:27:43.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:27:43.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:27:43.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:27:43.714+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:27:43.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:27:43.726+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:27:43.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:27:43.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T16:28:13.956+0000] {processor.py:157} INFO - Started process (PID=19281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:28:13.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:28:13.958+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:28:13.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:28:13.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:28:13.984+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:28:13.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:28:13.997+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:28:13.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:28:14.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T16:28:44.271+0000] {processor.py:157} INFO - Started process (PID=19291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:28:44.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:28:44.275+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:28:44.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:28:44.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:28:44.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:28:44.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:28:44.312+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:28:44.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:28:44.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T16:29:14.649+0000] {processor.py:157} INFO - Started process (PID=19301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:29:14.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:29:14.655+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:29:14.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:29:14.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:29:14.705+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:29:14.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:29:14.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:29:14.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:29:14.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T16:29:44.972+0000] {processor.py:157} INFO - Started process (PID=19311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:29:44.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:29:44.977+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:29:44.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:29:44.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:29:45.003+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:29:45.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:29:45.013+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:29:45.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:29:45.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T16:30:15.368+0000] {processor.py:157} INFO - Started process (PID=19321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:30:15.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:30:15.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:30:15.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:30:15.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:30:15.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:30:15.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:30:15.450+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:30:15.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:30:15.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T16:30:45.736+0000] {processor.py:157} INFO - Started process (PID=19331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:30:45.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:30:45.744+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:30:45.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:30:45.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:30:45.784+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:30:45.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:30:45.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:30:45.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:30:45.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T16:31:16.082+0000] {processor.py:157} INFO - Started process (PID=19341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:31:16.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:31:16.088+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:31:16.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:31:16.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:31:16.127+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:31:16.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:31:16.140+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:31:16.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:31:16.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T16:31:46.557+0000] {processor.py:157} INFO - Started process (PID=19351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:31:46.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:31:46.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:31:46.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:31:46.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:31:46.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:31:46.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:31:46.627+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:31:46.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:31:46.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T16:32:16.861+0000] {processor.py:157} INFO - Started process (PID=19361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:32:16.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:32:16.865+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:32:16.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:32:16.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:32:16.904+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:32:16.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:32:16.924+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:32:16.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:32:16.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T16:32:47.132+0000] {processor.py:157} INFO - Started process (PID=19371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:32:47.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:32:47.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:32:47.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:32:47.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:32:47.162+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:32:47.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:32:47.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:32:47.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:32:47.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T16:33:17.612+0000] {processor.py:157} INFO - Started process (PID=19380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:33:17.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:33:17.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:33:17.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:33:17.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:33:17.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:33:17.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:33:17.677+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:33:17.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:33:17.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T16:50:01.300+0000] {processor.py:157} INFO - Started process (PID=19391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:50:01.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T16:50:01.302+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:50:01.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:50:01.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T16:50:01.327+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:50:01.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T16:50:01.336+0000] {logging_mixin.py:151} INFO - [2024-09-09T16:50:01.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T16:50:01.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T17:08:06.788+0000] {processor.py:157} INFO - Started process (PID=19404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:08:06.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T17:08:06.793+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:08:06.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:08:06.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:08:06.862+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:08:06.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T17:08:06.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:08:06.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T17:08:06.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-09T17:08:37.054+0000] {processor.py:157} INFO - Started process (PID=19413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:08:37.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T17:08:37.059+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:08:37.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:08:37.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:08:37.113+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:08:37.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T17:08:37.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:08:37.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T17:08:37.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T17:37:30.614+0000] {processor.py:157} INFO - Started process (PID=19426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:37:30.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T17:37:30.642+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:37:30.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:37:30.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:37:30.718+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:37:30.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T17:37:30.731+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:37:30.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T17:37:30.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-09T17:38:00.947+0000] {processor.py:157} INFO - Started process (PID=19437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:38:00.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T17:38:00.953+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:38:00.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:38:00.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T17:38:00.993+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:38:00.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T17:38:01.005+0000] {logging_mixin.py:151} INFO - [2024-09-09T17:38:01.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T17:38:01.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T18:10:30.676+0000] {processor.py:157} INFO - Started process (PID=19447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:10:30.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:10:30.683+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:10:30.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:10:30.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:10:30.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:10:30.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:10:30.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:10:30.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:10:30.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T18:11:29.519+0000] {processor.py:157} INFO - Started process (PID=19457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:11:29.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:11:29.524+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:11:29.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:11:29.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:11:29.589+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:11:29.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:11:29.601+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:11:29.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:11:29.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-09T18:11:59.837+0000] {processor.py:157} INFO - Started process (PID=19467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:11:59.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:11:59.840+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:11:59.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:11:59.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:11:59.863+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:11:59.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:11:59.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:11:59.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:11:59.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T18:12:30.435+0000] {processor.py:157} INFO - Started process (PID=19477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:12:30.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:12:30.442+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:12:30.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:12:30.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:12:30.506+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:12:30.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:12:30.533+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:12:30.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:12:30.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-09T18:13:00.775+0000] {processor.py:157} INFO - Started process (PID=19487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:13:00.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:13:00.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:13:00.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:13:00.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:13:00.806+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:13:00.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:13:00.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:13:00.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:13:00.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T18:13:31.120+0000] {processor.py:157} INFO - Started process (PID=19497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:13:31.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:13:31.124+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:13:31.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:13:31.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:13:31.151+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:13:31.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:13:31.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:13:31.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:13:31.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:14:01.457+0000] {processor.py:157} INFO - Started process (PID=19507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:14:01.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:14:01.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:14:01.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:14:01.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:14:01.486+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:14:01.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:14:01.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:14:01.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:14:01.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:14:31.824+0000] {processor.py:157} INFO - Started process (PID=19517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:14:31.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:14:31.832+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:14:31.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:14:31.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:14:31.866+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:14:31.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:14:31.878+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:14:31.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:14:31.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T18:15:02.137+0000] {processor.py:157} INFO - Started process (PID=19527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:15:02.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:15:02.139+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:15:02.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:15:02.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:15:02.165+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:15:02.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:15:02.174+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:15:02.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:15:02.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T18:15:32.420+0000] {processor.py:157} INFO - Started process (PID=19537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:15:32.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:15:32.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:15:32.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:15:32.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:15:32.450+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:15:32.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:15:32.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:15:32.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:15:32.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:16:02.700+0000] {processor.py:157} INFO - Started process (PID=19547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:16:02.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:16:02.703+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:16:02.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:16:02.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:16:02.729+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:16:02.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:16:02.739+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:16:02.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:16:02.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T18:16:33.063+0000] {processor.py:157} INFO - Started process (PID=19557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:16:33.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:16:33.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:16:33.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:16:33.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:16:33.092+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:16:33.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:16:33.102+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:16:33.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:16:33.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T18:17:03.410+0000] {processor.py:157} INFO - Started process (PID=19567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:17:03.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:17:03.412+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:17:03.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:17:03.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:17:03.440+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:17:03.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:17:03.452+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:17:03.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:17:03.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:17:33.768+0000] {processor.py:157} INFO - Started process (PID=19577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:17:33.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:17:33.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:17:33.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:17:33.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:17:33.808+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:17:33.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:17:33.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:17:33.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:17:33.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T18:18:04.149+0000] {processor.py:157} INFO - Started process (PID=19587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:18:04.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:18:04.152+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:18:04.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:18:04.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:18:04.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:18:04.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:18:04.191+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:18:04.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:18:04.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T18:18:34.457+0000] {processor.py:157} INFO - Started process (PID=19597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:18:34.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:18:34.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:18:34.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:18:34.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:18:34.491+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:18:34.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:18:34.505+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:18:34.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:18:34.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T18:19:04.863+0000] {processor.py:157} INFO - Started process (PID=19607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:19:04.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:19:04.867+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:19:04.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:19:04.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:19:04.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:19:04.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:19:04.914+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:19:04.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:19:04.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T18:19:35.195+0000] {processor.py:157} INFO - Started process (PID=19617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:19:35.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:19:35.197+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:19:35.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:19:35.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:19:35.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:19:35.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:19:35.239+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:19:35.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:19:35.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:20:05.517+0000] {processor.py:157} INFO - Started process (PID=19627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:20:05.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:20:05.520+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:20:05.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:20:05.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:20:05.549+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:20:05.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:20:05.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:20:05.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:20:05.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T18:20:35.997+0000] {processor.py:157} INFO - Started process (PID=19636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:20:36.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:20:36.004+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:20:36.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:20:36.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:20:36.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:20:36.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:20:36.055+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:20:36.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:20:36.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T18:21:06.255+0000] {processor.py:157} INFO - Started process (PID=19647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:21:06.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:21:06.259+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:21:06.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:21:06.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:21:06.293+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:21:06.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:21:06.304+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:21:06.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:21:06.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T18:21:36.611+0000] {processor.py:157} INFO - Started process (PID=19657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:21:36.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:21:36.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:21:36.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:21:36.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:21:36.643+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:21:36.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:21:36.657+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:21:36.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:21:36.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T18:22:07.041+0000] {processor.py:157} INFO - Started process (PID=19667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:22:07.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:22:07.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:22:07.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:22:07.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:22:07.081+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:22:07.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:22:07.094+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:22:07.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:22:07.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T18:22:37.442+0000] {processor.py:157} INFO - Started process (PID=19677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:22:37.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:22:37.444+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:22:37.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:22:37.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:22:37.472+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:22:37.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:22:37.482+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:22:37.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:22:37.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:23:07.859+0000] {processor.py:157} INFO - Started process (PID=19687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:23:07.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:23:07.866+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:23:07.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:23:07.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:23:07.904+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:23:07.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:23:07.916+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:23:07.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:23:07.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T18:23:38.282+0000] {processor.py:157} INFO - Started process (PID=19697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:23:38.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:23:38.286+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:23:38.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:23:38.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:23:38.314+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:23:38.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:23:38.323+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:23:38.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:23:38.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:24:08.654+0000] {processor.py:157} INFO - Started process (PID=19707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:24:08.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:24:08.656+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:24:08.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:24:08.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:24:08.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:24:08.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:24:08.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:24:08.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:24:08.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T18:24:39.049+0000] {processor.py:157} INFO - Started process (PID=19717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:24:39.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:24:39.054+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:24:39.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:24:39.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:24:39.092+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:24:39.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:24:39.104+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:24:39.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:24:39.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T18:25:09.431+0000] {processor.py:157} INFO - Started process (PID=19726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:25:09.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:25:09.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:25:09.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:25:09.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:25:09.466+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:25:09.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:25:09.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:25:09.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:25:09.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T18:25:39.750+0000] {processor.py:157} INFO - Started process (PID=19737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:25:39.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:25:39.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:25:39.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:25:39.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:25:39.778+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:25:39.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:25:39.789+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:25:39.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:25:39.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T18:26:10.165+0000] {processor.py:157} INFO - Started process (PID=19747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:26:10.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:26:10.169+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:26:10.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:26:10.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:26:10.195+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:26:10.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:26:10.207+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:26:10.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:26:10.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T18:26:40.554+0000] {processor.py:157} INFO - Started process (PID=19757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:26:40.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:26:40.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:26:40.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:26:40.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:26:40.583+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:26:40.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:26:40.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:26:40.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:26:40.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:27:10.927+0000] {processor.py:157} INFO - Started process (PID=19767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:27:10.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:27:10.932+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:27:10.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:27:10.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:27:10.967+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:27:10.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:27:10.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:27:10.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:27:10.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T18:27:41.345+0000] {processor.py:157} INFO - Started process (PID=19777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:27:41.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:27:41.349+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:27:41.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:27:41.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:27:41.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:27:41.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:27:41.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:27:41.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:27:41.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T18:28:11.782+0000] {processor.py:157} INFO - Started process (PID=19787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:28:11.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:28:11.789+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:28:11.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:28:11.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:28:11.820+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:28:11.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:28:11.830+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:28:11.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:28:11.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T18:28:42.148+0000] {processor.py:157} INFO - Started process (PID=19797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:28:42.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:28:42.153+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:28:42.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:28:42.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:28:42.177+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:28:42.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:28:42.187+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:28:42.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:28:42.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:29:12.469+0000] {processor.py:157} INFO - Started process (PID=19807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:29:12.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:29:12.474+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:29:12.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:29:12.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:29:12.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:29:12.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:29:12.517+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:29:12.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:29:12.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T18:29:42.765+0000] {processor.py:157} INFO - Started process (PID=19817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:29:42.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:29:42.768+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:29:42.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:29:42.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:29:42.798+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:29:42.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:29:42.812+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:29:42.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:29:42.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T18:30:13.124+0000] {processor.py:157} INFO - Started process (PID=19827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:30:13.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:30:13.129+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:30:13.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:30:13.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:30:13.158+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:30:13.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:30:13.168+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:30:13.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:30:13.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:30:43.547+0000] {processor.py:157} INFO - Started process (PID=19837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:30:43.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:30:43.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:30:43.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:30:43.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:30:43.580+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:30:43.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:30:43.590+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:30:43.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:30:43.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T18:31:13.948+0000] {processor.py:157} INFO - Started process (PID=19847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:31:13.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:31:13.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:31:13.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:31:13.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:31:13.978+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:31:13.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:31:13.989+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:31:13.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:31:13.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T18:31:44.321+0000] {processor.py:157} INFO - Started process (PID=19857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:31:44.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:31:44.352+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:31:44.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:31:44.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:31:44.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:31:44.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:31:44.414+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:31:44.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:31:44.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-09T18:32:14.667+0000] {processor.py:157} INFO - Started process (PID=19867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:32:14.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:32:14.672+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:32:14.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:32:14.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:32:14.711+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:32:14.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:32:14.724+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:32:14.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:32:14.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T18:32:45.041+0000] {processor.py:157} INFO - Started process (PID=19877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:32:45.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:32:45.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:32:45.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:32:45.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:32:45.074+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:32:45.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:32:45.086+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:32:45.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:32:45.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T18:33:15.357+0000] {processor.py:157} INFO - Started process (PID=19887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:33:15.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:33:15.362+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:33:15.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:33:15.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:33:15.407+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:33:15.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:33:15.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:33:15.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:33:15.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T18:33:45.673+0000] {processor.py:157} INFO - Started process (PID=19897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:33:45.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:33:45.676+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:33:45.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:33:45.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:33:45.704+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:33:45.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:33:45.718+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:33:45.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:33:45.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T18:34:16.079+0000] {processor.py:157} INFO - Started process (PID=19907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:34:16.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:34:16.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:34:16.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:34:16.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:34:16.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:34:16.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:34:16.162+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:34:16.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:34:16.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-09T18:34:46.398+0000] {processor.py:157} INFO - Started process (PID=19917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:34:46.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:34:46.403+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:34:46.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:34:46.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:34:46.451+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:34:46.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:34:46.462+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:34:46.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:34:46.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T18:35:16.713+0000] {processor.py:157} INFO - Started process (PID=19927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:35:16.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:35:16.716+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:35:16.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:35:16.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:35:16.751+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:35:16.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:35:16.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:35:16.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:35:16.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T18:35:46.999+0000] {processor.py:157} INFO - Started process (PID=19937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:35:47.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:35:47.001+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:35:47.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:35:47.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:35:47.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:35:47.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:35:47.039+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:35:47.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:35:47.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:36:17.384+0000] {processor.py:157} INFO - Started process (PID=19947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:36:17.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:36:17.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:36:17.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:36:17.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:36:17.431+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:36:17.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:36:17.445+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:36:17.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:36:17.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T18:36:47.789+0000] {processor.py:157} INFO - Started process (PID=19957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:36:47.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:36:47.793+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:36:47.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:36:47.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:36:47.824+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:36:47.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:36:47.836+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:36:47.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:36:47.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T18:37:18.178+0000] {processor.py:157} INFO - Started process (PID=19967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:37:18.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:37:18.182+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:37:18.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:37:18.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:37:18.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:37:18.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:37:18.229+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:37:18.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:37:18.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T18:37:48.480+0000] {processor.py:157} INFO - Started process (PID=19977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:37:48.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:37:48.484+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:37:48.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:37:48.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:37:48.510+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:37:48.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:37:48.520+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:37:48.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:37:48.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:38:18.844+0000] {processor.py:157} INFO - Started process (PID=19987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:38:18.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:38:18.848+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:38:18.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:38:18.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:38:18.874+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:38:18.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:38:18.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:38:18.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:38:18.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T18:38:49.200+0000] {processor.py:157} INFO - Started process (PID=19997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:38:49.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:38:49.204+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:38:49.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:38:49.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:38:49.229+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:38:49.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:38:49.238+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:38:49.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:38:49.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:39:19.562+0000] {processor.py:157} INFO - Started process (PID=20007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:39:19.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:39:19.568+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:39:19.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:39:19.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:39:19.602+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:39:19.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:39:19.614+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:39:19.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:39:19.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T18:39:49.924+0000] {processor.py:157} INFO - Started process (PID=20017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:39:49.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:39:49.927+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:39:49.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:39:49.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:39:49.954+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:39:49.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:39:49.968+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:39:49.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:39:49.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T18:40:20.268+0000] {processor.py:157} INFO - Started process (PID=20027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:40:20.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:40:20.272+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:40:20.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:40:20.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:40:20.304+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:40:20.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:40:20.317+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:40:20.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:40:20.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T18:40:50.656+0000] {processor.py:157} INFO - Started process (PID=20037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:40:50.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:40:50.659+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:40:50.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:40:50.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:40:50.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:40:50.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:40:50.698+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:40:50.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:40:50.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:41:21.050+0000] {processor.py:157} INFO - Started process (PID=20047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:41:21.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:41:21.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:41:21.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:41:21.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:41:21.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:41:21.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:41:21.092+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:41:21.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:41:21.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:41:51.381+0000] {processor.py:157} INFO - Started process (PID=20057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:41:51.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:41:51.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:41:51.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:41:51.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:41:51.421+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:41:51.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:41:51.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:41:51.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:41:51.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T18:42:21.778+0000] {processor.py:157} INFO - Started process (PID=20067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:42:21.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:42:21.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:42:21.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:42:21.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:42:21.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:42:21.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:42:21.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:42:21.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:42:21.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T18:42:52.188+0000] {processor.py:157} INFO - Started process (PID=20077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:42:52.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:42:52.191+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:42:52.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:42:52.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:42:52.219+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:42:52.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:42:52.232+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:42:52.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:42:52.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T18:43:22.586+0000] {processor.py:157} INFO - Started process (PID=20087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:43:22.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:43:22.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:43:22.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:43:22.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:43:22.622+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:43:22.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:43:22.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:43:22.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:43:22.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T18:43:52.989+0000] {processor.py:157} INFO - Started process (PID=20097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:43:52.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:43:52.990+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:43:52.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:43:52.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:43:53.015+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:43:53.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:43:53.025+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:43:53.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:43:53.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T18:44:23.359+0000] {processor.py:157} INFO - Started process (PID=20107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:44:23.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:44:23.363+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:44:23.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:44:23.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:44:23.400+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:44:23.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:44:23.413+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:44:23.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:44:23.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T18:44:53.661+0000] {processor.py:157} INFO - Started process (PID=20117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:44:53.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:44:53.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:44:53.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:44:53.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:44:53.689+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:44:53.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:44:53.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:44:53.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:44:53.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T18:45:24.042+0000] {processor.py:157} INFO - Started process (PID=20127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:45:24.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:45:24.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:45:24.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:45:24.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:45:24.076+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:45:24.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:45:24.086+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:45:24.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:45:24.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T18:45:54.372+0000] {processor.py:157} INFO - Started process (PID=20137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:45:54.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:45:54.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:45:54.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:45:54.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:45:54.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:45:54.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:45:54.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:45:54.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:45:54.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:46:24.741+0000] {processor.py:157} INFO - Started process (PID=20147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:46:24.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:46:24.744+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:46:24.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:46:24.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:46:24.775+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:46:24.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:46:24.787+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:46:24.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:46:24.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T18:46:55.096+0000] {processor.py:157} INFO - Started process (PID=20157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:46:55.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:46:55.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:46:55.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:46:55.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:46:55.127+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:46:55.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:46:55.137+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:46:55.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:46:55.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T18:47:25.526+0000] {processor.py:157} INFO - Started process (PID=20167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:47:25.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:47:25.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:47:25.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:47:25.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:47:25.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:47:25.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:47:25.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:47:25.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:47:25.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:47:55.947+0000] {processor.py:157} INFO - Started process (PID=20177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:47:55.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:47:55.964+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:47:55.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:47:55.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:47:56.003+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:47:56.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:47:56.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:47:56.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:47:56.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T18:48:26.234+0000] {processor.py:157} INFO - Started process (PID=20187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:48:26.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:48:26.238+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:48:26.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:48:26.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:48:26.267+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:48:26.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:48:26.279+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:48:26.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:48:26.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T18:48:56.603+0000] {processor.py:157} INFO - Started process (PID=20197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:48:56.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:48:56.606+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:48:56.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:48:56.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:48:56.632+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:48:56.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:48:56.643+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:48:56.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:48:56.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T18:49:26.894+0000] {processor.py:157} INFO - Started process (PID=20207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:49:26.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:49:26.897+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:49:26.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:49:26.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:49:26.931+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:49:26.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:49:26.946+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:49:26.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:49:26.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T18:49:57.282+0000] {processor.py:157} INFO - Started process (PID=20217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:49:57.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:49:57.285+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:49:57.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:49:57.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:49:57.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:49:57.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:49:57.330+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:49:57.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:49:57.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T18:50:27.576+0000] {processor.py:157} INFO - Started process (PID=20227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:50:27.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:50:27.578+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:50:27.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:50:27.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:50:27.605+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:50:27.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:50:27.617+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:50:27.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:50:27.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T18:50:57.922+0000] {processor.py:157} INFO - Started process (PID=20237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:50:57.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:50:57.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:50:57.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:50:57.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:50:57.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:50:57.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:50:57.964+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:50:57.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:50:57.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:51:28.314+0000] {processor.py:157} INFO - Started process (PID=20247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:51:28.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:51:28.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:51:28.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:51:28.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:51:28.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:51:28.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:51:28.369+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:51:28.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:51:28.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T18:51:58.636+0000] {processor.py:157} INFO - Started process (PID=20257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:51:58.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:51:58.638+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:51:58.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:51:58.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:51:58.669+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:51:58.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:51:58.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:51:58.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:51:58.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T18:52:28.994+0000] {processor.py:157} INFO - Started process (PID=20267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:52:28.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:52:28.996+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:52:28.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:52:29.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:52:29.021+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:52:29.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:52:29.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:52:29.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:52:29.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T18:52:59.381+0000] {processor.py:157} INFO - Started process (PID=20277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:52:59.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:52:59.384+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:52:59.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:52:59.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:52:59.417+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:52:59.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:52:59.428+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:52:59.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:52:59.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T18:53:29.782+0000] {processor.py:157} INFO - Started process (PID=20287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:53:29.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:53:29.786+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:53:29.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:53:29.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:53:29.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:53:29.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:53:29.828+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:53:29.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:53:29.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T18:54:00.168+0000] {processor.py:157} INFO - Started process (PID=20297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:54:00.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:54:00.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:54:00.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:54:00.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:54:00.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:54:00.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:54:00.230+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:54:00.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:54:00.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T18:54:30.547+0000] {processor.py:157} INFO - Started process (PID=20307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:54:30.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:54:30.549+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:54:30.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:54:30.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:54:30.573+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:54:30.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:54:30.583+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:54:30.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:54:30.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T18:55:00.876+0000] {processor.py:157} INFO - Started process (PID=20317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:55:00.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:55:00.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:55:00.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:55:00.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:55:00.909+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:55:00.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:55:00.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:55:00.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:55:00.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T18:55:31.222+0000] {processor.py:157} INFO - Started process (PID=20327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:55:31.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:55:31.225+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:55:31.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:55:31.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:55:31.250+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:55:31.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:55:31.261+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:55:31.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:55:31.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T18:56:01.630+0000] {processor.py:157} INFO - Started process (PID=20337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:56:01.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:56:01.635+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:56:01.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:56:01.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:56:01.670+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:56:01.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:56:01.685+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:56:01.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:56:01.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T18:56:31.975+0000] {processor.py:157} INFO - Started process (PID=20347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:56:31.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:56:31.979+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:56:31.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:56:31.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:56:32.007+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:56:32.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:56:32.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:56:32.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:56:32.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T18:57:02.294+0000] {processor.py:157} INFO - Started process (PID=20357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:57:02.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:57:02.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:57:02.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:57:02.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:57:02.335+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:57:02.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:57:02.349+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:57:02.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:57:02.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T18:57:32.709+0000] {processor.py:157} INFO - Started process (PID=20367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:57:32.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:57:32.712+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:57:32.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:57:32.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:57:32.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:57:32.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:57:32.754+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:57:32.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:57:32.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T18:58:03.038+0000] {processor.py:157} INFO - Started process (PID=20377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:58:03.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:58:03.042+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:58:03.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:58:03.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:58:03.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:58:03.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:58:03.081+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:58:03.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:58:03.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T18:58:33.433+0000] {processor.py:157} INFO - Started process (PID=20387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:58:33.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:58:33.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:58:33.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:58:33.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:58:33.465+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:58:33.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:58:33.476+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:58:33.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:58:33.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T18:59:03.852+0000] {processor.py:157} INFO - Started process (PID=20397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:59:03.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:59:03.855+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:59:03.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:59:03.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:59:03.890+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:59:03.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:59:03.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:59:03.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:59:03.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T18:59:34.246+0000] {processor.py:157} INFO - Started process (PID=20407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:59:34.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T18:59:34.250+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:59:34.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:59:34.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T18:59:34.279+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:59:34.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T18:59:34.291+0000] {logging_mixin.py:151} INFO - [2024-09-09T18:59:34.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T18:59:34.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:00:04.548+0000] {processor.py:157} INFO - Started process (PID=20417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:00:04.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:00:04.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:00:04.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:00:04.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:00:04.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:00:04.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:00:04.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:00:04.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:00:04.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:00:34.903+0000] {processor.py:157} INFO - Started process (PID=20427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:00:34.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:00:34.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:00:34.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:00:34.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:00:34.936+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:00:34.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:00:34.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:00:34.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:00:34.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T19:01:05.298+0000] {processor.py:157} INFO - Started process (PID=20437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:01:05.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:01:05.303+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:01:05.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:01:05.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:01:05.334+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:01:05.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:01:05.346+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:01:05.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:01:05.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T19:01:35.661+0000] {processor.py:157} INFO - Started process (PID=20447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:01:35.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:01:35.665+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:01:35.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:01:35.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:01:35.690+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:01:35.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:01:35.700+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:01:35.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:01:35.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:02:06.093+0000] {processor.py:157} INFO - Started process (PID=20457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:02:06.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:02:06.097+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:02:06.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:02:06.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:02:06.143+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:02:06.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:02:06.157+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:02:06.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:02:06.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T19:02:36.392+0000] {processor.py:157} INFO - Started process (PID=20467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:02:36.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:02:36.393+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:02:36.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:02:36.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:02:36.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:02:36.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:02:36.430+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:02:36.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:02:36.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:03:06.805+0000] {processor.py:157} INFO - Started process (PID=20477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:03:06.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:03:06.810+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:03:06.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:03:06.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:03:06.848+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:03:06.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:03:06.860+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:03:06.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:03:06.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T19:03:37.199+0000] {processor.py:157} INFO - Started process (PID=20487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:03:37.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:03:37.202+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:03:37.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:03:37.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:03:37.230+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:03:37.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:03:37.240+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:03:37.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:03:37.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:04:07.577+0000] {processor.py:157} INFO - Started process (PID=20497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:04:07.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:04:07.581+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:04:07.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:04:07.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:04:07.620+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:04:07.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:04:07.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:04:07.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:04:07.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T19:04:37.897+0000] {processor.py:157} INFO - Started process (PID=20507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:04:37.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:04:37.901+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:04:37.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:04:37.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:04:37.949+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:04:37.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:04:37.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:04:37.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:04:37.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T19:05:08.268+0000] {processor.py:157} INFO - Started process (PID=20517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:05:08.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:05:08.272+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:05:08.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:05:08.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:05:08.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:05:08.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:05:08.309+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:05:08.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:05:08.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:05:38.644+0000] {processor.py:157} INFO - Started process (PID=20527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:05:38.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:05:38.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:05:38.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:05:38.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:05:38.683+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:05:38.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:05:38.695+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:05:38.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:05:38.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T19:06:09.042+0000] {processor.py:157} INFO - Started process (PID=20537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:06:09.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:06:09.044+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:06:09.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:06:09.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:06:09.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:06:09.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:06:09.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:06:09.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:06:09.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T19:06:39.462+0000] {processor.py:157} INFO - Started process (PID=20547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:06:39.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:06:39.464+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:06:39.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:06:39.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:06:39.490+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:06:39.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:06:39.502+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:06:39.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:06:39.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:07:09.859+0000] {processor.py:157} INFO - Started process (PID=20557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:07:09.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:07:09.864+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:07:09.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:07:09.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:07:09.901+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:07:09.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:07:09.912+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:07:09.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:07:09.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T19:07:40.273+0000] {processor.py:157} INFO - Started process (PID=20567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:07:40.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:07:40.276+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:07:40.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:07:40.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:07:40.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:07:40.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:07:40.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:07:40.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:07:40.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:08:10.614+0000] {processor.py:157} INFO - Started process (PID=20577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:08:10.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:08:10.622+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:08:10.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:08:10.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:08:10.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:08:10.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:08:10.654+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:08:10.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:08:10.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T19:08:40.974+0000] {processor.py:157} INFO - Started process (PID=20587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:08:40.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:08:40.976+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:08:40.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:08:40.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:08:41.008+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:08:41.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:08:41.020+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:08:41.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:08:41.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T19:09:11.375+0000] {processor.py:157} INFO - Started process (PID=20597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:09:11.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:09:11.377+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:09:11.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:09:11.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:09:11.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:09:11.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:09:11.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:09:11.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:09:11.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:09:41.699+0000] {processor.py:157} INFO - Started process (PID=20607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:09:41.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:09:41.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:09:41.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:09:41.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:09:41.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:09:41.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:09:41.740+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:09:41.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:09:41.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:10:12.053+0000] {processor.py:157} INFO - Started process (PID=20617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:10:12.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:10:12.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:10:12.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:10:12.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:10:12.084+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:10:12.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:10:12.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:10:12.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:10:12.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T19:10:42.469+0000] {processor.py:157} INFO - Started process (PID=20627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:10:42.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:10:42.474+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:10:42.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:10:42.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:10:42.508+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:10:42.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:10:42.519+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:10:42.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:10:42.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T19:11:12.798+0000] {processor.py:157} INFO - Started process (PID=20637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:11:12.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:11:12.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:11:12.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:11:12.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:11:12.829+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:11:12.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:11:12.839+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:11:12.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:11:12.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:11:43.160+0000] {processor.py:157} INFO - Started process (PID=20647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:11:43.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:11:43.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:11:43.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:11:43.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:11:43.191+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:11:43.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:11:43.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:11:43.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:11:43.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:12:13.548+0000] {processor.py:157} INFO - Started process (PID=20657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:12:13.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:12:13.552+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:12:13.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:12:13.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:12:13.578+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:12:13.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:12:13.588+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:12:13.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:12:13.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:12:43.876+0000] {processor.py:157} INFO - Started process (PID=20667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:12:43.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:12:43.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:12:43.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:12:43.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:12:43.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:12:43.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:12:43.911+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:12:43.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:12:43.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-09-09T19:13:14.272+0000] {processor.py:157} INFO - Started process (PID=20677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:13:14.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:13:14.277+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:13:14.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:13:14.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:13:14.306+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:13:14.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:13:14.316+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:13:14.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:13:14.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T19:13:44.645+0000] {processor.py:157} INFO - Started process (PID=20687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:13:44.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:13:44.650+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:13:44.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:13:44.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:13:44.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:13:44.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:13:44.683+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:13:44.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:13:44.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T19:14:15.012+0000] {processor.py:157} INFO - Started process (PID=20697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:14:15.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:14:15.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:14:15.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:14:15.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:14:15.050+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:14:15.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:14:15.062+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:14:15.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:14:15.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T19:14:45.335+0000] {processor.py:157} INFO - Started process (PID=20707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:14:45.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:14:45.340+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:14:45.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:14:45.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:14:45.369+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:14:45.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:14:45.382+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:14:45.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:14:45.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T19:15:15.699+0000] {processor.py:157} INFO - Started process (PID=20717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:15:15.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:15:15.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:15:15.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:15:15.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:15:15.735+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:15:15.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:15:15.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:15:15.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:15:15.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T19:15:46.065+0000] {processor.py:157} INFO - Started process (PID=20727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:15:46.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:15:46.069+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:15:46.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:15:46.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:15:46.095+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:15:46.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:15:46.104+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:15:46.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:15:46.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T19:16:16.361+0000] {processor.py:157} INFO - Started process (PID=20737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:16:16.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:16:16.363+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:16:16.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:16:16.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:16:16.390+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:16:16.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:16:16.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:16:16.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:16:16.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:16:46.774+0000] {processor.py:157} INFO - Started process (PID=20747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:16:46.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:16:46.776+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:16:46.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:16:46.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:16:46.810+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:16:46.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:16:46.820+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:16:46.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:16:46.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:17:17.103+0000] {processor.py:157} INFO - Started process (PID=20757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:17:17.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:17:17.106+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:17:17.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:17:17.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:17:17.141+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:17:17.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:17:17.154+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:17:17.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:17:17.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T19:17:47.510+0000] {processor.py:157} INFO - Started process (PID=20767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:17:47.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:17:47.514+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:17:47.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:17:47.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:17:47.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:17:47.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:17:47.553+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:17:47.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:17:47.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T19:18:17.931+0000] {processor.py:157} INFO - Started process (PID=20777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:18:17.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:18:17.934+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:18:17.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:18:17.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:18:17.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:18:17.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:18:17.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:18:17.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:18:17.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T19:18:48.341+0000] {processor.py:157} INFO - Started process (PID=20787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:18:48.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:18:48.345+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:18:48.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:18:48.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:18:48.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:18:48.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:18:48.384+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:18:48.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:18:48.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:19:18.735+0000] {processor.py:157} INFO - Started process (PID=20797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:19:18.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:19:18.740+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:19:18.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:19:18.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:19:18.774+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:19:18.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:19:18.785+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:19:18.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:19:18.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T19:19:49.097+0000] {processor.py:157} INFO - Started process (PID=20807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:19:49.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:19:49.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:19:49.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:19:49.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:19:49.128+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:19:49.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:19:49.141+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:19:49.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:19:49.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:20:19.450+0000] {processor.py:157} INFO - Started process (PID=20817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:20:19.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:20:19.455+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:20:19.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:20:19.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:20:19.490+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:20:19.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:20:19.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:20:19.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:20:19.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T19:20:49.791+0000] {processor.py:157} INFO - Started process (PID=20827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:20:49.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:20:49.795+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:20:49.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:20:49.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:20:49.823+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:20:49.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:20:49.833+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:20:49.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:20:49.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:21:20.105+0000] {processor.py:157} INFO - Started process (PID=20837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:21:20.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:21:20.108+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:21:20.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:21:20.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:21:20.136+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:21:20.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:21:20.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:21:20.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:21:20.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T19:21:50.470+0000] {processor.py:157} INFO - Started process (PID=20847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:21:50.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:21:50.476+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:21:50.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:21:50.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:21:50.502+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:21:50.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:21:50.511+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:21:50.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:21:50.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T19:22:20.839+0000] {processor.py:157} INFO - Started process (PID=20857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:22:20.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:22:20.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:22:20.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:22:20.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:22:20.877+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:22:20.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:22:20.891+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:22:20.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:22:20.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T19:22:51.272+0000] {processor.py:157} INFO - Started process (PID=20867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:22:51.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:22:51.274+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:22:51.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:22:51.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:22:51.301+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:22:51.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:22:51.313+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:22:51.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:22:51.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:23:21.636+0000] {processor.py:157} INFO - Started process (PID=20877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:23:21.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:23:21.639+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:23:21.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:23:21.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:23:21.663+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:23:21.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:23:21.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:23:21.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:23:21.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T19:23:52.004+0000] {processor.py:157} INFO - Started process (PID=20887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:23:52.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:23:52.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:23:52.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:23:52.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:23:52.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:23:52.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:23:52.042+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:23:52.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:23:52.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:24:22.368+0000] {processor.py:157} INFO - Started process (PID=20897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:24:22.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:24:22.371+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:24:22.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:24:22.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:24:22.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:24:22.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:24:22.413+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:24:22.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:24:22.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T19:24:52.807+0000] {processor.py:157} INFO - Started process (PID=20907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:24:52.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:24:52.812+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:24:52.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:24:52.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:24:52.856+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:24:52.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:24:52.869+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:24:52.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:24:52.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T19:25:23.109+0000] {processor.py:157} INFO - Started process (PID=20917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:25:23.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:25:23.113+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:25:23.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:25:23.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:25:23.139+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:25:23.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:25:23.149+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:25:23.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:25:23.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T19:25:53.494+0000] {processor.py:157} INFO - Started process (PID=20927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:25:53.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:25:53.496+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:25:53.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:25:53.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:25:53.521+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:25:53.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:25:53.531+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:25:53.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:25:53.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-09T19:26:23.787+0000] {processor.py:157} INFO - Started process (PID=20937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:26:23.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:26:23.791+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:26:23.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:26:23.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:26:23.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:26:23.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:26:23.838+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:26:23.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:26:23.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T19:26:54.078+0000] {processor.py:157} INFO - Started process (PID=20947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:26:54.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:26:54.080+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:26:54.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:26:54.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:26:54.111+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:26:54.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:26:54.121+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:26:54.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:26:54.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T19:27:24.452+0000] {processor.py:157} INFO - Started process (PID=20957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:27:24.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:27:24.455+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:27:24.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:27:24.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:27:24.481+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:27:24.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:27:24.491+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:27:24.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:27:24.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T19:27:54.829+0000] {processor.py:157} INFO - Started process (PID=20967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:27:54.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:27:54.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:27:54.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:27:54.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:27:54.860+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:27:54.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:27:54.869+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:27:54.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:27:54.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T19:28:25.191+0000] {processor.py:157} INFO - Started process (PID=20977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:28:25.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:28:25.194+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:28:25.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:28:25.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:28:25.221+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:28:25.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:28:25.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:28:25.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:28:25.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:28:55.534+0000] {processor.py:157} INFO - Started process (PID=20987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:28:55.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:28:55.538+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:28:55.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:28:55.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:28:55.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:28:55.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:28:55.573+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:28:55.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:28:55.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T19:29:25.810+0000] {processor.py:157} INFO - Started process (PID=20997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:29:25.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:29:25.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:29:25.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:29:25.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:29:25.839+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:29:25.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:29:25.850+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:29:25.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:29:25.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:29:56.137+0000] {processor.py:157} INFO - Started process (PID=21007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:29:56.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:29:56.141+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:29:56.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:29:56.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:29:56.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:29:56.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:29:56.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:29:56.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:29:56.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T19:30:26.505+0000] {processor.py:157} INFO - Started process (PID=21017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:30:26.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:30:26.510+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:30:26.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:30:26.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:30:26.545+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:30:26.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:30:26.556+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:30:26.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:30:26.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T19:30:56.869+0000] {processor.py:157} INFO - Started process (PID=21027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:30:56.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:30:56.877+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:30:56.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:30:56.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:30:56.911+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:30:56.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:30:56.920+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:30:56.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:30:56.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T19:31:27.241+0000] {processor.py:157} INFO - Started process (PID=21037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:31:27.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:31:27.244+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:31:27.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:31:27.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:31:27.271+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:31:27.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:31:27.281+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:31:27.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:31:27.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:31:57.597+0000] {processor.py:157} INFO - Started process (PID=21047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:31:57.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:31:57.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:31:57.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:31:57.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:31:57.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:31:57.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:31:57.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:31:57.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:31:57.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T19:32:27.947+0000] {processor.py:157} INFO - Started process (PID=21056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:32:27.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:32:27.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:32:27.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:32:27.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:32:27.984+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:32:27.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:32:27.996+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:32:27.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:32:28.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T19:32:58.357+0000] {processor.py:157} INFO - Started process (PID=21067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:32:58.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:32:58.362+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:32:58.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:32:58.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:32:58.412+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:32:58.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:32:58.426+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:32:58.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:32:58.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T19:33:29.202+0000] {processor.py:157} INFO - Started process (PID=21079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:33:29.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:33:29.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:33:29.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:33:29.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:33:29.235+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:33:29.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:33:29.245+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:33:29.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:33:29.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T19:33:59.707+0000] {processor.py:157} INFO - Started process (PID=21089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:33:59.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:33:59.712+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:33:59.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:33:59.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:33:59.744+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:33:59.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:33:59.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:33:59.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:33:59.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T19:49:31.893+0000] {processor.py:157} INFO - Started process (PID=21099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:49:31.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:49:31.898+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:49:31.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:49:31.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:49:31.944+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:49:31.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:49:31.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:49:31.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:49:31.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-09T19:50:02.220+0000] {processor.py:157} INFO - Started process (PID=21109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:50:02.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:50:02.223+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:50:02.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:50:02.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:50:02.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:50:02.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:50:02.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:50:02.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:50:02.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T19:50:32.616+0000] {processor.py:157} INFO - Started process (PID=21119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:50:32.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:50:32.620+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:50:32.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:50:32.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:50:32.660+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:50:32.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:50:32.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:50:32.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:50:32.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T19:51:02.922+0000] {processor.py:157} INFO - Started process (PID=21129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:51:02.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:51:02.926+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:51:02.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:51:02.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:51:02.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:51:02.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:51:02.962+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:51:02.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:51:02.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T19:51:33.339+0000] {processor.py:157} INFO - Started process (PID=21139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:51:33.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:51:33.342+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:51:33.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:51:33.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:51:33.370+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:51:33.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:51:33.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:51:33.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:51:33.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:52:03.706+0000] {processor.py:157} INFO - Started process (PID=21149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:52:03.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:52:03.710+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:52:03.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:52:03.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:52:03.738+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:52:03.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:52:03.748+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:52:03.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:52:03.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T19:52:34.022+0000] {processor.py:157} INFO - Started process (PID=21159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:52:34.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:52:34.026+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:52:34.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:52:34.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:52:34.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:52:34.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:52:34.062+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:52:34.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:52:34.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:53:04.383+0000] {processor.py:157} INFO - Started process (PID=21169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:53:04.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:53:04.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:53:04.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:53:04.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:53:04.422+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:53:04.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:53:04.433+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:53:04.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:53:04.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T19:53:34.792+0000] {processor.py:157} INFO - Started process (PID=21179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:53:34.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:53:34.795+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:53:34.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:53:34.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:53:34.823+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:53:34.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:53:34.835+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:53:34.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:53:34.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T19:54:05.135+0000] {processor.py:157} INFO - Started process (PID=21189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:54:05.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:54:05.138+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:54:05.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:54:05.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:54:05.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:54:05.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:54:05.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:54:05.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:54:05.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:54:35.548+0000] {processor.py:157} INFO - Started process (PID=21199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:54:35.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:54:35.552+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:54:35.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:54:35.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:54:35.582+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:54:35.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:54:35.591+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:54:35.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:54:35.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:55:05.845+0000] {processor.py:157} INFO - Started process (PID=21209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:55:05.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:55:05.848+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:55:05.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:55:05.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:55:05.874+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:55:05.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:55:05.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:55:05.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:55:05.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:55:36.212+0000] {processor.py:157} INFO - Started process (PID=21219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:55:36.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:55:36.214+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:55:36.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:55:36.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:55:36.242+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:55:36.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:55:36.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:55:36.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:55:36.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T19:56:06.623+0000] {processor.py:157} INFO - Started process (PID=21229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:56:06.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:56:06.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:56:06.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:56:06.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:56:06.654+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:56:06.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:56:06.665+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:56:06.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:56:06.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T19:56:36.963+0000] {processor.py:157} INFO - Started process (PID=21239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:56:36.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:56:36.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:56:36.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:56:36.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:56:36.989+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:56:36.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:56:36.998+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:56:36.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:56:37.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T19:57:07.313+0000] {processor.py:157} INFO - Started process (PID=21249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:57:07.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:57:07.315+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:57:07.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:57:07.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:57:07.345+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:57:07.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:57:07.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:57:07.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:57:07.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:57:37.671+0000] {processor.py:157} INFO - Started process (PID=21259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:57:37.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:57:37.673+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:57:37.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:57:37.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:57:37.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:57:37.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:57:37.711+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:57:37.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:57:37.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T19:58:08.018+0000] {processor.py:157} INFO - Started process (PID=21269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:58:08.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:58:08.020+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:58:08.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:58:08.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:58:08.049+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:58:08.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:58:08.060+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:58:08.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:58:08.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T19:58:38.364+0000] {processor.py:157} INFO - Started process (PID=21279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:58:38.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:58:38.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:58:38.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:58:38.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:58:38.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:58:38.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:58:38.402+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:58:38.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:58:38.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T19:59:08.726+0000] {processor.py:157} INFO - Started process (PID=21289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:59:08.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:59:08.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:59:08.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:59:08.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:59:08.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:59:08.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:59:08.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:59:08.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:59:08.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T19:59:39.145+0000] {processor.py:157} INFO - Started process (PID=21299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:59:39.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T19:59:39.148+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:59:39.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:59:39.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T19:59:39.176+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:59:39.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T19:59:39.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T19:59:39.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T19:59:39.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T20:00:09.525+0000] {processor.py:157} INFO - Started process (PID=21309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:00:09.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:00:09.528+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:00:09.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:00:09.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:00:09.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:00:09.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:00:09.566+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:00:09.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:00:09.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T20:00:39.901+0000] {processor.py:157} INFO - Started process (PID=21319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:00:39.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:00:39.904+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:00:39.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:00:39.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:00:39.929+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:00:39.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:00:39.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:00:39.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:00:39.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T20:01:10.266+0000] {processor.py:157} INFO - Started process (PID=21329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:01:10.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:01:10.273+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:01:10.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:01:10.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:01:10.312+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:01:10.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:01:10.327+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:01:10.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:01:10.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T20:01:40.575+0000] {processor.py:157} INFO - Started process (PID=21339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:01:40.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:01:40.578+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:01:40.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:01:40.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:01:40.606+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:01:40.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:01:40.616+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:01:40.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:01:40.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:02:10.976+0000] {processor.py:157} INFO - Started process (PID=21349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:02:10.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:02:10.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:02:10.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:02:10.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:02:11.005+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:02:11.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:02:11.015+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:02:11.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:02:11.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T20:02:41.339+0000] {processor.py:157} INFO - Started process (PID=21359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:02:41.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:02:41.344+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:02:41.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:02:41.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:02:41.368+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:02:41.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:02:41.378+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:02:41.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:02:41.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T20:03:11.623+0000] {processor.py:157} INFO - Started process (PID=21369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:03:11.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:03:11.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:03:11.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:03:11.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:03:11.654+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:03:11.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:03:11.668+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:03:11.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:03:11.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T20:03:41.943+0000] {processor.py:157} INFO - Started process (PID=21379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:03:41.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:03:41.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:03:41.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:03:41.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:03:41.972+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:03:41.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:03:41.981+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:03:41.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:03:41.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T20:04:12.326+0000] {processor.py:157} INFO - Started process (PID=21389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:04:12.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:04:12.329+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:04:12.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:04:12.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:04:12.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:04:12.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:04:12.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:04:12.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:04:12.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T20:04:42.742+0000] {processor.py:157} INFO - Started process (PID=21399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:04:42.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:04:42.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:04:42.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:04:42.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:04:42.771+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:04:42.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:04:42.781+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:04:42.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:04:42.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T20:05:13.129+0000] {processor.py:157} INFO - Started process (PID=21409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:05:13.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:05:13.132+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:05:13.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:05:13.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:05:13.167+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:05:13.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:05:13.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:05:13.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:05:13.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T20:05:43.453+0000] {processor.py:157} INFO - Started process (PID=21419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:05:43.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:05:43.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:05:43.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:05:43.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:05:43.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:05:43.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:05:43.489+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:05:43.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:05:43.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-09T20:06:13.841+0000] {processor.py:157} INFO - Started process (PID=21429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:06:13.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:06:13.844+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:06:13.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:06:13.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:06:13.873+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:06:13.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:06:13.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:06:13.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:06:13.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T20:06:44.239+0000] {processor.py:157} INFO - Started process (PID=21439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:06:44.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:06:44.241+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:06:44.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:06:44.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:06:44.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:06:44.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:06:44.277+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:06:44.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:06:44.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T20:07:14.565+0000] {processor.py:157} INFO - Started process (PID=21449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:07:14.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:07:14.569+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:07:14.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:07:14.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:07:14.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:07:14.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:07:14.606+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:07:14.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:07:14.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:07:44.946+0000] {processor.py:157} INFO - Started process (PID=21459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:07:44.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:07:44.948+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:07:44.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:07:44.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:07:44.975+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:07:44.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:07:44.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:07:44.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:07:44.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:08:15.318+0000] {processor.py:157} INFO - Started process (PID=21469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:08:15.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:08:15.322+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:08:15.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:08:15.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:08:15.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:08:15.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:08:15.360+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:08:15.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:08:15.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.520 seconds
[2024-09-09T20:08:46.119+0000] {processor.py:157} INFO - Started process (PID=21479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:08:46.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:08:46.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:08:46.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:08:46.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:08:46.152+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:08:46.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:08:46.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:08:46.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:08:46.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T20:09:16.522+0000] {processor.py:157} INFO - Started process (PID=21489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:09:16.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:09:16.525+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:09:16.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:09:16.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:09:16.561+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:09:16.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:09:16.574+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:09:16.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:09:16.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T20:09:46.822+0000] {processor.py:157} INFO - Started process (PID=21499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:09:46.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:09:46.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:09:46.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:09:46.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:09:46.848+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:09:46.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:09:46.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:09:46.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:09:46.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T20:10:17.191+0000] {processor.py:157} INFO - Started process (PID=21509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:10:17.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:10:17.195+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:10:17.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:10:17.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:10:17.219+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:10:17.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:10:17.229+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:10:17.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:10:17.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T20:10:47.567+0000] {processor.py:157} INFO - Started process (PID=21519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:10:47.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:10:47.570+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:10:47.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:10:47.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:10:47.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:10:47.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:10:47.610+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:10:47.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:10:47.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:11:17.919+0000] {processor.py:157} INFO - Started process (PID=21529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:11:17.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:11:17.921+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:11:17.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:11:17.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:11:17.944+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:11:17.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:11:17.956+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:11:17.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:11:18.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-09T20:11:48.228+0000] {processor.py:157} INFO - Started process (PID=21539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:11:48.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:11:48.231+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:11:48.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:11:48.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:11:48.257+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:11:48.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:11:48.267+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:11:48.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:11:48.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:12:18.584+0000] {processor.py:157} INFO - Started process (PID=21549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:12:18.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:12:18.586+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:12:18.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:12:18.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:12:18.612+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:12:18.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:12:18.622+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:12:18.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:12:18.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T20:12:48.877+0000] {processor.py:157} INFO - Started process (PID=21559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:12:48.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:12:48.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:12:48.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:12:48.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:12:48.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:12:48.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:12:48.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:12:48.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:12:48.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:13:19.238+0000] {processor.py:157} INFO - Started process (PID=21569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:13:19.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:13:19.240+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:13:19.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:13:19.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:13:19.270+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:13:19.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:13:19.280+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:13:19.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:13:19.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T20:13:49.644+0000] {processor.py:157} INFO - Started process (PID=21579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:13:49.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:13:49.648+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:13:49.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:13:49.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:13:49.680+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:13:49.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:13:49.692+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:13:49.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:13:49.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T20:14:20.012+0000] {processor.py:157} INFO - Started process (PID=21589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:14:20.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:14:20.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:14:20.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:14:20.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:14:20.043+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:14:20.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:14:20.053+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:14:20.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:14:20.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-09T20:14:50.354+0000] {processor.py:157} INFO - Started process (PID=21599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:14:50.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:14:50.357+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:14:50.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:14:50.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:14:50.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:14:50.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:14:50.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:14:50.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:14:50.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T20:15:20.713+0000] {processor.py:157} INFO - Started process (PID=21609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:15:20.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:15:20.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:15:20.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:15:20.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:15:20.741+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:15:20.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:15:20.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:15:20.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:15:20.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T20:15:51.067+0000] {processor.py:157} INFO - Started process (PID=21619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:15:51.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:15:51.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:15:51.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:15:51.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:15:51.102+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:15:51.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:15:51.112+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:15:51.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:15:51.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T20:16:21.475+0000] {processor.py:157} INFO - Started process (PID=21629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:16:21.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:16:21.480+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:16:21.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:16:21.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:16:21.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:16:21.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:16:21.519+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:16:21.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:16:21.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T20:16:51.882+0000] {processor.py:157} INFO - Started process (PID=21639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:16:51.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:16:51.886+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:16:51.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:16:51.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:16:51.913+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:16:51.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:16:51.925+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:16:51.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:16:51.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T20:17:22.205+0000] {processor.py:157} INFO - Started process (PID=21649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:17:22.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:17:22.210+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:17:22.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:17:22.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:17:22.244+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:17:22.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:17:22.256+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:17:22.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:17:22.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-09T20:17:52.700+0000] {processor.py:157} INFO - Started process (PID=21659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:17:52.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:17:52.704+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:17:52.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:17:52.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:17:52.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:17:52.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:17:52.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:17:52.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:17:52.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T20:18:23.086+0000] {processor.py:157} INFO - Started process (PID=21669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:18:23.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:18:23.089+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:18:23.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:18:23.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:18:23.111+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:18:23.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:18:23.121+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:18:23.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:18:23.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-09T20:18:53.473+0000] {processor.py:157} INFO - Started process (PID=21679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:18:53.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:18:53.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:18:53.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:18:53.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:18:53.504+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:18:53.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:18:53.516+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:18:53.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:18:53.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T20:19:23.854+0000] {processor.py:157} INFO - Started process (PID=21689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:19:23.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:19:23.859+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:19:23.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:19:23.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:19:23.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:19:23.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:19:23.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:19:23.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:19:23.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T20:19:54.266+0000] {processor.py:157} INFO - Started process (PID=21699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:19:54.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:19:54.269+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:19:54.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:19:54.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:19:54.295+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:19:54.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:19:54.306+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:19:54.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:19:54.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:20:24.587+0000] {processor.py:157} INFO - Started process (PID=21709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:20:24.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:20:24.593+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:20:24.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:20:24.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:20:24.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:20:24.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:20:24.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:20:24.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:20:24.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T20:20:54.916+0000] {processor.py:157} INFO - Started process (PID=21719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:20:54.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:20:54.919+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:20:54.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:20:54.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:20:54.951+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:20:54.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:20:54.962+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:20:54.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:20:54.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T20:21:25.255+0000] {processor.py:157} INFO - Started process (PID=21729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:21:25.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:21:25.257+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:21:25.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:21:25.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:21:25.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:21:25.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:21:25.296+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:21:25.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:21:25.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T20:21:55.629+0000] {processor.py:157} INFO - Started process (PID=21739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:21:55.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:21:55.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:21:55.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:21:55.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:21:55.665+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:21:55.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:21:55.675+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:21:55.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:21:55.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T20:22:25.912+0000] {processor.py:157} INFO - Started process (PID=21749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:22:25.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:22:25.915+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:22:25.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:22:25.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:22:25.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:22:25.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:22:25.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:22:25.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:22:25.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T20:22:56.261+0000] {processor.py:157} INFO - Started process (PID=21759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:22:56.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:22:56.265+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:22:56.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:22:56.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:22:56.292+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:22:56.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:22:56.303+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:22:56.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:22:56.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T20:23:26.601+0000] {processor.py:157} INFO - Started process (PID=21769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:23:26.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:23:26.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:23:26.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:23:26.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:23:26.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:23:26.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:23:26.644+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:23:26.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:23:26.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T20:23:56.932+0000] {processor.py:157} INFO - Started process (PID=21779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:23:56.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:23:56.937+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:23:56.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:23:56.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:23:56.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:23:56.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:23:56.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:23:56.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:23:56.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T20:24:27.326+0000] {processor.py:157} INFO - Started process (PID=21789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:24:27.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:24:27.328+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:24:27.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:24:27.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:24:27.362+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:24:27.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:24:27.373+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:24:27.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:24:27.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T20:24:57.723+0000] {processor.py:157} INFO - Started process (PID=21799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:24:57.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:24:57.726+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:24:57.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:24:57.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:24:57.751+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:24:57.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:24:57.763+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:24:57.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:24:57.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T20:25:28.150+0000] {processor.py:157} INFO - Started process (PID=21809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:25:28.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:25:28.154+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:25:28.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:25:28.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:25:28.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:25:28.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:25:28.191+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:25:28.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:25:28.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T20:25:58.497+0000] {processor.py:157} INFO - Started process (PID=21819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:25:58.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:25:58.501+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:25:58.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:25:58.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:25:58.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:25:58.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:25:58.540+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:25:58.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:25:58.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-09T20:26:28.804+0000] {processor.py:157} INFO - Started process (PID=21829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:26:28.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:26:28.807+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:26:28.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:26:28.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:26:28.839+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:26:28.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:26:28.851+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:26:28.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:26:28.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T20:26:59.220+0000] {processor.py:157} INFO - Started process (PID=21839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:26:59.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:26:59.227+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:26:59.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:26:59.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:26:59.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:26:59.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:26:59.256+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:26:59.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:26:59.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T20:27:29.506+0000] {processor.py:157} INFO - Started process (PID=21849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:27:29.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:27:29.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:27:29.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:27:29.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:27:29.533+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:27:29.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:27:29.542+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:27:29.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:27:29.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T20:27:59.867+0000] {processor.py:157} INFO - Started process (PID=21859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:27:59.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:27:59.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:27:59.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:27:59.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:27:59.897+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:27:59.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:27:59.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:27:59.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:27:59.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T20:28:30.259+0000] {processor.py:157} INFO - Started process (PID=21869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:28:30.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:28:30.262+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:28:30.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:28:30.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:28:30.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:28:30.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:28:30.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:28:30.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:28:30.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T20:29:00.644+0000] {processor.py:157} INFO - Started process (PID=21879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:29:00.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:29:00.647+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:29:00.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:29:00.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:29:00.677+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:29:00.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:29:00.691+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:29:00.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:29:00.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-09T20:29:30.989+0000] {processor.py:157} INFO - Started process (PID=21889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:29:30.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:29:30.996+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:29:30.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:29:31.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:29:31.033+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:29:31.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:29:31.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:29:31.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:29:31.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T20:30:01.352+0000] {processor.py:157} INFO - Started process (PID=21899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:30:01.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:30:01.355+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:30:01.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:30:01.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:30:01.382+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:30:01.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:30:01.395+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:30:01.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:30:01.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T20:30:31.716+0000] {processor.py:157} INFO - Started process (PID=21908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:30:31.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:30:31.721+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:30:31.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:30:31.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:30:31.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:30:31.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:30:31.770+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:30:31.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:30:31.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T20:31:02.116+0000] {processor.py:157} INFO - Started process (PID=21919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:31:02.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:31:02.118+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:31:02.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:31:02.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:31:02.148+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:31:02.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:31:02.159+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:31:02.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:31:02.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T20:31:32.510+0000] {processor.py:157} INFO - Started process (PID=21929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:31:32.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:31:32.514+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:31:32.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:31:32.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:31:32.541+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:31:32.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:31:32.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:31:32.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:31:32.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T20:32:02.813+0000] {processor.py:157} INFO - Started process (PID=21939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:32:02.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:32:02.815+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:32:02.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:32:02.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:32:02.838+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:32:02.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:32:02.847+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:32:02.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:32:02.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T20:32:33.203+0000] {processor.py:157} INFO - Started process (PID=21949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:32:33.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:32:33.205+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:32:33.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:32:33.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:32:33.239+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:32:33.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:32:33.250+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:32:33.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:32:33.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T20:33:03.563+0000] {processor.py:157} INFO - Started process (PID=21959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:33:03.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:33:03.566+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:33:03.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:33:03.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:33:03.594+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:33:03.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:33:03.607+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:33:03.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:33:03.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T20:48:47.976+0000] {processor.py:157} INFO - Started process (PID=21969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:48:47.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:48:47.997+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:48:47.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:48:48.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:48:48.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:48:48.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:48:48.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:48:48.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:48:48.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-09T20:49:18.287+0000] {processor.py:157} INFO - Started process (PID=21980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:49:18.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:49:18.292+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:49:18.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:49:18.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:49:18.331+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:49:18.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:49:18.345+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:49:18.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:49:18.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T20:49:48.590+0000] {processor.py:157} INFO - Started process (PID=21991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:49:48.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:49:48.594+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:49:48.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:49:48.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:49:48.621+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:49:48.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:49:48.630+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:49:48.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:49:48.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T20:50:18.946+0000] {processor.py:157} INFO - Started process (PID=22001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:50:18.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:50:18.949+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:50:18.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:50:18.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:50:18.977+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:50:18.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:50:18.987+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:50:18.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:50:19.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-09T20:50:49.517+0000] {processor.py:157} INFO - Started process (PID=22010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:50:49.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T20:50:49.521+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:50:49.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:50:49.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T20:50:49.561+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:50:49.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T20:50:49.572+0000] {logging_mixin.py:151} INFO - [2024-09-09T20:50:49.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T20:50:49.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T21:07:30.722+0000] {processor.py:157} INFO - Started process (PID=22021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:07:30.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:07:30.725+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:07:30.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:07:30.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:07:30.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:07:30.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:07:30.766+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:07:30.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:07:30.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T21:08:01.126+0000] {processor.py:157} INFO - Started process (PID=22033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:08:01.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:08:01.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:08:01.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:08:01.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:08:01.189+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:08:01.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:08:01.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:08:01.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:08:01.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-09T21:08:31.449+0000] {processor.py:157} INFO - Started process (PID=22043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:08:31.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:08:31.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:08:31.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:08:31.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:08:31.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:08:31.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:08:31.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:08:31.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:08:31.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T21:09:01.845+0000] {processor.py:157} INFO - Started process (PID=22053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:09:01.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:09:01.850+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:09:01.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:09:01.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:09:01.882+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:09:01.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:09:01.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:09:01.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:09:01.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T21:09:32.166+0000] {processor.py:157} INFO - Started process (PID=22063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:09:32.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:09:32.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:09:32.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:09:32.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:09:32.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:09:32.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:09:32.367+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:09:32.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:09:32.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.211 seconds
[2024-09-09T21:10:02.530+0000] {processor.py:157} INFO - Started process (PID=22073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:10:02.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:10:02.533+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:10:02.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:10:02.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:10:02.563+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:10:02.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:10:02.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:10:02.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:10:02.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T21:10:32.951+0000] {processor.py:157} INFO - Started process (PID=22083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:10:32.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:10:32.956+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:10:32.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:10:32.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:10:32.981+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:10:32.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:10:32.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:10:32.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:10:33.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T21:11:03.335+0000] {processor.py:157} INFO - Started process (PID=22093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:11:03.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:11:03.339+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:11:03.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:11:03.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:11:03.376+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:11:03.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:11:03.388+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:11:03.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:11:03.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T21:11:33.944+0000] {processor.py:157} INFO - Started process (PID=22103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:11:33.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:11:33.949+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:11:33.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:11:33.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:11:33.995+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:11:33.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:11:34.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:11:34.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:11:34.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T21:12:04.217+0000] {processor.py:157} INFO - Started process (PID=22113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:12:04.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:12:04.221+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:12:04.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:12:04.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:12:04.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:12:04.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:12:04.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:12:04.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:12:04.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T21:12:34.829+0000] {processor.py:157} INFO - Started process (PID=22123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:12:34.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:12:34.831+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:12:34.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:12:34.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:12:34.855+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:12:34.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:12:35.010+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:12:35.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:12:35.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-09-09T21:13:05.175+0000] {processor.py:157} INFO - Started process (PID=22133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:13:05.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:13:05.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:13:05.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:13:05.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:13:05.216+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:13:05.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:13:05.228+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:13:05.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:13:05.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T21:14:40.025+0000] {processor.py:157} INFO - Started process (PID=22144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:14:40.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:14:40.049+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:14:40.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:14:40.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:14:40.203+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:14:40.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:14:40.266+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:14:40.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:14:40.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.289 seconds
[2024-09-09T21:15:10.613+0000] {processor.py:157} INFO - Started process (PID=22155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:15:10.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:15:10.619+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:15:10.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:15:10.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:15:10.663+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:15:10.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:15:10.676+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:15:10.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:15:10.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-09T21:15:40.910+0000] {processor.py:157} INFO - Started process (PID=22165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:15:40.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:15:40.915+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:15:40.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:15:40.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:15:40.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:15:40.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:15:40.978+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:15:40.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:15:40.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T21:16:11.209+0000] {processor.py:157} INFO - Started process (PID=22175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:16:11.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:16:11.214+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:16:11.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:16:11.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:16:11.241+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:16:11.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:16:11.252+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:16:11.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:16:11.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T21:16:41.604+0000] {processor.py:157} INFO - Started process (PID=22185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:16:41.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:16:41.609+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:16:41.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:16:41.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:16:41.653+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:16:41.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:16:41.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:16:41.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:16:41.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-09-09T21:17:11.941+0000] {processor.py:157} INFO - Started process (PID=22195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:17:11.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:17:11.946+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:17:11.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:17:11.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:17:11.999+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:17:11.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:17:12.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:17:12.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:17:12.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T21:17:42.272+0000] {processor.py:157} INFO - Started process (PID=22205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:17:42.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:17:42.277+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:17:42.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:17:42.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:17:42.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:17:42.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:17:42.317+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:17:42.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:17:42.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T21:18:12.596+0000] {processor.py:157} INFO - Started process (PID=22215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:18:12.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:18:12.601+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:18:12.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:18:12.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:18:12.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:18:12.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:18:12.675+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:18:12.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:18:12.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T21:18:42.981+0000] {processor.py:157} INFO - Started process (PID=22224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:18:42.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:18:42.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:18:42.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:18:43.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:18:43.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:18:43.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:18:43.052+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:18:43.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:18:43.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-09T21:19:13.335+0000] {processor.py:157} INFO - Started process (PID=22235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:19:13.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:19:13.340+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:19:13.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:19:13.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:19:13.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:19:13.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:19:13.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:19:13.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:19:13.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-09T21:19:43.761+0000] {processor.py:157} INFO - Started process (PID=22245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:19:43.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:19:43.767+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:19:43.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:19:43.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:19:43.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:19:43.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:19:43.970+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:19:43.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:19:43.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-09-09T21:20:14.276+0000] {processor.py:157} INFO - Started process (PID=22255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:20:14.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:20:14.280+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:20:14.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:20:14.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:20:14.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:20:14.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:20:14.335+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:20:14.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:20:14.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T21:20:44.571+0000] {processor.py:157} INFO - Started process (PID=22265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:20:44.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:20:44.577+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:20:44.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:20:44.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:20:44.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:20:44.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:20:44.652+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:20:44.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:20:44.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T21:21:14.885+0000] {processor.py:157} INFO - Started process (PID=22275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:21:14.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:21:14.889+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:21:14.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:21:14.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:21:14.938+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:21:14.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:21:14.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:21:14.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:21:14.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T21:21:45.218+0000] {processor.py:157} INFO - Started process (PID=22285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:21:45.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:21:45.221+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:21:45.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:21:45.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:21:45.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:21:45.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:21:45.268+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:21:45.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:21:45.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T21:22:15.552+0000] {processor.py:157} INFO - Started process (PID=22295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:22:15.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:22:15.567+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:22:15.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:22:15.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:22:15.607+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:22:15.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:22:15.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:22:15.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:22:15.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T21:22:45.909+0000] {processor.py:157} INFO - Started process (PID=22305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:22:45.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:22:45.914+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:22:45.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:22:45.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:22:45.950+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:22:45.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:22:46.104+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:22:46.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:22:46.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-09T21:23:16.319+0000] {processor.py:157} INFO - Started process (PID=22315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:23:16.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:23:16.325+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:23:16.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:23:16.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:23:16.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:23:16.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:23:16.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:23:16.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:23:16.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T21:24:08.028+0000] {processor.py:157} INFO - Started process (PID=22327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:24:08.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:24:08.030+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:24:08.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:24:08.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:24:08.058+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:24:08.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:24:08.066+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:24:08.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:24:08.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T21:41:30.762+0000] {processor.py:157} INFO - Started process (PID=22337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:41:30.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:41:30.776+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:41:30.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:41:30.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:41:30.887+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:41:30.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:41:30.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:41:30.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:41:30.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-09T21:42:01.290+0000] {processor.py:157} INFO - Started process (PID=22347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:42:01.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:42:01.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:42:01.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:42:01.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:42:01.339+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:42:01.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:42:01.350+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:42:01.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:42:01.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T21:42:31.655+0000] {processor.py:157} INFO - Started process (PID=22357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:42:31.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:42:31.660+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:42:31.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:42:31.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:42:31.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:42:31.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:42:31.727+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:42:31.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:42:31.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T21:43:02.035+0000] {processor.py:157} INFO - Started process (PID=22367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:43:02.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:43:02.039+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:43:02.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:43:02.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:43:02.071+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:43:02.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:43:02.273+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:43:02.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:43:02.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-09-09T21:43:32.574+0000] {processor.py:157} INFO - Started process (PID=22377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:43:32.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:43:32.577+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:43:32.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:43:32.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:43:32.611+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:43:32.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:43:32.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:43:32.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:43:32.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T21:44:03.037+0000] {processor.py:157} INFO - Started process (PID=22387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:44:03.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:44:03.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:44:03.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:44:03.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:44:03.074+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:44:03.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:44:03.086+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:44:03.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:44:03.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T21:44:33.391+0000] {processor.py:157} INFO - Started process (PID=22396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:44:33.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:44:33.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:44:33.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:44:33.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:44:33.429+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:44:33.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:44:33.440+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:44:33.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:44:33.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T21:45:03.759+0000] {processor.py:157} INFO - Started process (PID=22407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:45:03.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:45:03.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:45:03.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:45:03.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:45:03.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:45:03.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:45:03.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:45:03.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:45:03.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T21:45:34.140+0000] {processor.py:157} INFO - Started process (PID=22417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:45:34.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:45:34.144+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:45:34.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:45:34.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:45:34.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:45:34.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:45:34.180+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:45:34.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:45:34.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-09T21:46:04.435+0000] {processor.py:157} INFO - Started process (PID=22427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:46:04.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:46:04.443+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:46:04.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:46:04.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:46:04.466+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:46:04.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:46:04.550+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:46:04.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:46:04.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-09T21:46:34.906+0000] {processor.py:157} INFO - Started process (PID=22437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:46:34.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:46:34.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:46:34.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:46:34.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:46:34.935+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:46:34.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:46:34.945+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:46:34.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:46:34.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-09T21:47:05.226+0000] {processor.py:157} INFO - Started process (PID=22447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:47:05.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:47:05.230+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:47:05.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:47:05.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:47:05.264+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:47:05.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:47:05.277+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:47:05.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:47:05.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-09T21:47:35.584+0000] {processor.py:157} INFO - Started process (PID=22457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:47:35.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:47:35.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:47:35.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:47:35.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:47:35.616+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:47:35.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:47:35.625+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:47:35.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:47:35.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T21:48:05.890+0000] {processor.py:157} INFO - Started process (PID=22467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:48:05.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:48:05.895+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:48:05.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:48:05.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:48:05.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:48:05.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:48:05.936+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:48:05.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:48:05.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-09T21:48:36.279+0000] {processor.py:157} INFO - Started process (PID=22477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:48:36.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:48:36.283+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:48:36.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:48:36.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:48:36.331+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:48:36.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:48:36.346+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:48:36.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:48:36.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.216 seconds
[2024-09-09T21:49:06.616+0000] {processor.py:157} INFO - Started process (PID=22486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:49:06.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:49:06.620+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:49:06.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:49:06.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:49:06.650+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:49:06.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:49:06.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:49:06.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:49:06.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-09T21:49:37.124+0000] {processor.py:157} INFO - Started process (PID=22497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:49:37.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:49:37.130+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:49:37.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:49:37.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:49:37.161+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:49:37.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:49:37.272+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:49:37.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:49:37.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-09T21:50:07.473+0000] {processor.py:157} INFO - Started process (PID=22507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:50:07.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:50:07.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:50:07.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:50:07.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:50:07.513+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:50:07.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:50:07.522+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:50:07.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:50:07.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-09T21:50:37.825+0000] {processor.py:157} INFO - Started process (PID=22517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:50:37.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:50:37.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:50:37.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:50:37.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:50:37.871+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:50:37.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:50:37.884+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:50:37.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:50:37.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-09T21:51:08.263+0000] {processor.py:157} INFO - Started process (PID=22527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:51:08.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:51:08.267+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:51:08.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:51:08.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:51:08.295+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:51:08.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:51:08.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:51:08.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:51:08.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T21:51:38.679+0000] {processor.py:157} INFO - Started process (PID=22537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:51:38.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:51:38.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:51:38.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:51:38.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:51:38.716+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:51:38.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:51:38.732+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:51:38.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:51:38.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-09T21:52:08.983+0000] {processor.py:157} INFO - Started process (PID=22547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:52:08.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:52:08.985+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:52:08.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:52:08.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:52:09.013+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:52:09.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:52:09.104+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:52:09.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:52:09.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-09T21:52:39.420+0000] {processor.py:157} INFO - Started process (PID=22557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:52:39.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:52:39.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:52:39.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:52:39.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:52:39.452+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:52:39.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:52:39.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:52:39.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:52:39.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T21:53:09.855+0000] {processor.py:157} INFO - Started process (PID=22567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:53:09.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:53:09.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:53:09.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:53:09.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:53:09.888+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:53:09.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:53:09.898+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:53:09.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:53:09.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T21:53:40.322+0000] {processor.py:157} INFO - Started process (PID=22577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:53:40.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:53:40.326+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:53:40.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:53:40.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:53:40.362+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:53:40.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:53:40.375+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:53:40.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:53:40.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T21:54:10.759+0000] {processor.py:157} INFO - Started process (PID=22587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:54:10.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:54:10.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:54:10.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:54:10.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:54:10.790+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:54:10.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:54:10.801+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:54:10.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:54:10.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T21:54:41.160+0000] {processor.py:157} INFO - Started process (PID=22597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:54:41.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:54:41.164+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:54:41.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:54:41.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:54:41.193+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:54:41.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:54:41.203+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:54:41.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:54:41.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-09T21:55:11.711+0000] {processor.py:157} INFO - Started process (PID=22607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:55:11.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:55:11.715+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:55:11.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:55:11.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:55:11.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:55:11.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:55:11.827+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:55:11.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:55:11.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-09T21:55:42.037+0000] {processor.py:157} INFO - Started process (PID=22617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:55:42.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:55:42.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:55:42.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:55:42.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:55:42.066+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:55:42.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:55:42.148+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:55:42.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:55:42.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T21:56:12.504+0000] {processor.py:157} INFO - Started process (PID=22627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:56:12.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:56:12.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:56:12.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:56:12.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:56:12.543+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:56:12.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:56:12.557+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:56:12.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:56:12.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T21:56:42.937+0000] {processor.py:157} INFO - Started process (PID=22637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:56:42.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:56:42.942+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:56:42.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:56:42.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:56:42.973+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:56:42.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:56:42.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:56:42.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:56:42.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T21:57:13.346+0000] {processor.py:157} INFO - Started process (PID=22647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:57:13.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:57:13.350+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:57:13.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:57:13.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:57:13.385+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:57:13.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:57:13.396+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:57:13.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:57:13.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T21:57:43.646+0000] {processor.py:157} INFO - Started process (PID=22657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:57:43.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:57:43.651+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:57:43.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:57:43.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:57:43.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:57:43.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:57:43.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:57:43.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:57:43.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-09T21:58:14.170+0000] {processor.py:157} INFO - Started process (PID=22667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:58:14.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:58:14.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:58:14.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:58:14.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:58:14.198+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:58:14.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:58:14.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:58:14.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:58:14.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T21:58:44.651+0000] {processor.py:157} INFO - Started process (PID=22677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:58:44.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:58:44.655+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:58:44.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:58:44.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:58:44.686+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:58:44.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:58:44.701+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:58:44.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:58:44.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T21:59:15.120+0000] {processor.py:157} INFO - Started process (PID=22687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:59:15.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:59:15.126+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:59:15.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:59:15.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:59:15.184+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:59:15.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:59:15.201+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:59:15.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:59:15.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T21:59:45.688+0000] {processor.py:157} INFO - Started process (PID=22697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:59:45.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T21:59:45.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:59:45.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:59:45.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T21:59:45.740+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:59:45.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T21:59:45.752+0000] {logging_mixin.py:151} INFO - [2024-09-09T21:59:45.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T21:59:45.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T22:00:17.028+0000] {processor.py:157} INFO - Started process (PID=22707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:00:17.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:00:17.034+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:00:17.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:00:17.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:00:17.070+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:00:17.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:00:17.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:00:17.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:00:17.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T22:00:47.291+0000] {processor.py:157} INFO - Started process (PID=22719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:00:47.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:00:47.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:00:47.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:00:47.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:00:47.319+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:00:47.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:00:47.329+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:00:47.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:00:47.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-09-09T22:01:51.836+0000] {processor.py:157} INFO - Started process (PID=22731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:01:51.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:01:51.839+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:01:51.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:01:51.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:01:51.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:01:51.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:01:52.052+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:01:52.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:01:52.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-09-09T22:02:27.646+0000] {processor.py:157} INFO - Started process (PID=22741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:02:27.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:02:27.652+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:02:27.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:02:27.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:02:27.709+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:02:27.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:02:27.887+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:02:27.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:02:27.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.259 seconds
[2024-09-09T22:02:57.961+0000] {processor.py:157} INFO - Started process (PID=22751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:02:57.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:02:57.964+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:02:57.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:02:57.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:02:57.996+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:02:57.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:02:58.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:02:58.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:02:58.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T22:03:43.338+0000] {processor.py:157} INFO - Started process (PID=22762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:03:43.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:03:43.343+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:03:43.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:03:43.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:03:43.386+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:03:43.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:03:43.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:03:43.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:03:43.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T22:04:23.646+0000] {processor.py:157} INFO - Started process (PID=22773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:04:23.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:04:23.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:04:23.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:04:23.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:04:23.674+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:04:23.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:04:23.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:04:23.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:04:23.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T22:04:54.076+0000] {processor.py:157} INFO - Started process (PID=22783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:04:54.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:04:54.080+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:04:54.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:04:54.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:04:54.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:04:54.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:04:54.155+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:04:54.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:04:54.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-09-09T22:05:53.097+0000] {processor.py:157} INFO - Started process (PID=22795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:05:53.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:05:53.100+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:05:53.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:05:53.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:05:53.124+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:05:53.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:05:53.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:05:53.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:05:53.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-09T22:06:27.307+0000] {processor.py:157} INFO - Started process (PID=22805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:06:27.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:06:27.311+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:06:27.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:06:27.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:06:27.340+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:06:27.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:06:27.421+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:06:27.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:06:27.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-09T22:06:57.804+0000] {processor.py:157} INFO - Started process (PID=22815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:06:57.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:06:57.806+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:06:57.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:06:57.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:06:57.833+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:06:57.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:06:57.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:06:57.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:06:57.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T22:12:59.308+0000] {processor.py:157} INFO - Started process (PID=22824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:12:59.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:12:59.312+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:12:59.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:12:59.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:12:59.372+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:12:59.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:12:59.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:12:59.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:12:59.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-09T22:18:58.679+0000] {processor.py:157} INFO - Started process (PID=22834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:18:58.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:18:58.696+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:18:58.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:18:58.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:18:58.797+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:18:58.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:18:58.819+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:18:58.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:18:58.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-09T22:19:28.936+0000] {processor.py:157} INFO - Started process (PID=22845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:19:28.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:19:28.943+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:19:28.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:19:28.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:19:28.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:19:28.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:19:29.007+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:19:29.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:19:29.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-09-09T22:19:59.391+0000] {processor.py:157} INFO - Started process (PID=22855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:19:59.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:19:59.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:19:59.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:19:59.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:19:59.437+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:19:59.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:19:59.562+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:19:59.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:19:59.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-09T22:20:29.730+0000] {processor.py:157} INFO - Started process (PID=22865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:20:29.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:20:29.739+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:20:29.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:20:29.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:20:29.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:20:29.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:20:29.962+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:20:29.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:20:29.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.258 seconds
[2024-09-09T22:21:00.285+0000] {processor.py:157} INFO - Started process (PID=22875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:21:00.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:21:00.290+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:21:00.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:21:00.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:21:00.323+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:21:00.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:21:00.338+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:21:00.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:21:00.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T22:21:30.608+0000] {processor.py:157} INFO - Started process (PID=22885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:21:30.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:21:30.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:21:30.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:21:30.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:21:30.664+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:21:30.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:21:30.678+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:21:30.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:21:30.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T22:22:01.026+0000] {processor.py:157} INFO - Started process (PID=22895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:22:01.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:22:01.040+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:22:01.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:22:01.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:22:01.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:22:01.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:22:01.096+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:22:01.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:22:01.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-09T22:22:31.456+0000] {processor.py:157} INFO - Started process (PID=22905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:22:31.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:22:31.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:22:31.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:22:31.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:22:31.507+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:22:31.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:22:31.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:22:31.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:22:31.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-09-09T22:23:01.781+0000] {processor.py:157} INFO - Started process (PID=22915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:23:01.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:23:01.786+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:23:01.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:23:01.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:23:01.824+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:23:01.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:23:02.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:23:02.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:23:02.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-09-09T22:23:32.235+0000] {processor.py:157} INFO - Started process (PID=22925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:23:32.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:23:32.250+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:23:32.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:23:32.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:23:32.519+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:23:32.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:23:32.528+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:23:32.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:23:32.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.312 seconds
[2024-09-09T22:24:02.684+0000] {processor.py:157} INFO - Started process (PID=22934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:24:02.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:24:02.702+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:24:02.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:24:02.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:24:02.764+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:24:02.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:24:02.789+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:24:02.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:24:02.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T22:24:33.160+0000] {processor.py:157} INFO - Started process (PID=22945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:24:33.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:24:33.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:24:33.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:24:33.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:24:33.238+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:24:33.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:24:33.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:24:33.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:24:33.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T22:25:03.582+0000] {processor.py:157} INFO - Started process (PID=22955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:25:03.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:25:03.587+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:25:03.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:25:03.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:25:03.630+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:25:03.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:25:03.641+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:25:03.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:25:03.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T22:25:34.048+0000] {processor.py:157} INFO - Started process (PID=22965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:25:34.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:25:34.054+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:25:34.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:25:34.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:25:34.109+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:25:34.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:25:34.295+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:25:34.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:25:34.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.263 seconds
[2024-09-09T22:26:04.567+0000] {processor.py:157} INFO - Started process (PID=22975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:26:04.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:26:04.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:26:04.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:26:04.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:26:04.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:26:04.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:26:04.791+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:26:04.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:26:04.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.251 seconds
[2024-09-09T22:26:35.052+0000] {processor.py:157} INFO - Started process (PID=22985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:26:35.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:26:35.057+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:26:35.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:26:35.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:26:35.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:26:35.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:26:35.205+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:26:35.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:26:35.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-09T22:27:05.331+0000] {processor.py:157} INFO - Started process (PID=22995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:27:05.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:27:05.335+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:27:05.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:27:05.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:27:05.367+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:27:05.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:27:05.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:27:05.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:27:05.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T22:27:35.596+0000] {processor.py:157} INFO - Started process (PID=23005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:27:35.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:27:35.604+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:27:35.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:27:35.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:27:35.649+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:27:35.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:27:35.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:27:35.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:27:35.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T22:28:05.977+0000] {processor.py:157} INFO - Started process (PID=23015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:28:05.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:28:05.985+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:28:05.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:28:06.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:28:06.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:28:06.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:28:06.087+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:28:06.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:28:06.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-09T22:28:36.336+0000] {processor.py:157} INFO - Started process (PID=23025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:28:36.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:28:36.363+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:28:36.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:28:36.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:28:36.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:28:36.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:28:36.592+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:28:36.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:28:36.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.272 seconds
[2024-09-09T22:29:06.968+0000] {processor.py:157} INFO - Started process (PID=23034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:29:06.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:29:06.991+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:29:06.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:29:07.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:29:07.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:29:07.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:29:07.545+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:29:07.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:29:07.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.621 seconds
[2024-09-09T22:29:38.025+0000] {processor.py:157} INFO - Started process (PID=23045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:29:38.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:29:38.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:29:38.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:29:38.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:29:38.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:29:38.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:29:38.256+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:29:38.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:29:38.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.255 seconds
[2024-09-09T22:30:08.325+0000] {processor.py:157} INFO - Started process (PID=23055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:30:08.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:30:08.330+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:30:08.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:30:08.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:30:08.368+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:30:08.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:30:08.381+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:30:08.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:30:08.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-09T22:30:38.623+0000] {processor.py:157} INFO - Started process (PID=23065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:30:38.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:30:38.629+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:30:38.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:30:38.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:30:38.666+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:30:38.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:30:38.678+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:30:38.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:30:38.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T22:31:09.029+0000] {processor.py:157} INFO - Started process (PID=23075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:31:09.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:31:09.035+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:31:09.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:31:09.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:31:09.075+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:31:09.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:31:09.094+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:31:09.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:31:09.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-09-09T22:31:39.342+0000] {processor.py:157} INFO - Started process (PID=23085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:31:39.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:31:39.354+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:31:39.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:31:39.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:31:39.414+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:31:39.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:31:39.603+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:31:39.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:31:39.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.277 seconds
[2024-09-09T22:32:09.722+0000] {processor.py:157} INFO - Started process (PID=23095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:32:09.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:32:09.740+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:32:09.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:32:09.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:32:09.806+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:32:09.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:32:10.010+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:32:10.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:32:10.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.310 seconds
[2024-09-09T22:32:40.172+0000] {processor.py:157} INFO - Started process (PID=23104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:32:40.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:32:40.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:32:40.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:32:40.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:32:40.378+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:32:40.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:32:40.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:32:40.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:32:40.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-09-09T22:33:10.578+0000] {processor.py:157} INFO - Started process (PID=23115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:33:10.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:33:10.585+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:33:10.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:33:10.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:33:10.629+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:33:10.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:33:10.640+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:33:10.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:33:10.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-09T22:33:40.872+0000] {processor.py:157} INFO - Started process (PID=23125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:33:40.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:33:40.879+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:33:40.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:33:40.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:33:40.935+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:33:40.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:33:40.949+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:33:40.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:33:40.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T22:34:11.247+0000] {processor.py:157} INFO - Started process (PID=23134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:34:11.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:34:11.254+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:34:11.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:34:11.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:34:11.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:34:11.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:34:11.328+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:34:11.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:34:11.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.286 seconds
[2024-09-09T22:34:41.750+0000] {processor.py:157} INFO - Started process (PID=23145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:34:41.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:34:41.760+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:34:41.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:34:41.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:34:41.828+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:34:41.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:34:42.009+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:34:42.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:34:42.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.276 seconds
[2024-09-09T22:35:12.312+0000] {processor.py:157} INFO - Started process (PID=23154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:35:12.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:35:12.324+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:35:12.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:35:12.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:35:12.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:35:12.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:35:12.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:35:12.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:35:12.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.321 seconds
[2024-09-09T22:35:42.841+0000] {processor.py:157} INFO - Started process (PID=23164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:35:42.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:35:42.851+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:35:42.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:35:42.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:35:43.076+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:35:43.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:35:43.087+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:35:43.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:35:43.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.267 seconds
[2024-09-09T22:36:13.432+0000] {processor.py:157} INFO - Started process (PID=23175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:36:13.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:36:13.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:36:13.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:36:13.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:36:13.551+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:36:13.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:36:13.579+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:36:13.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:36:13.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-09T22:36:43.740+0000] {processor.py:157} INFO - Started process (PID=23185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:36:43.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:36:43.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:36:43.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:36:43.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:36:43.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:36:43.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:36:43.823+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:36:43.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:36:43.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-09T22:37:14.152+0000] {processor.py:157} INFO - Started process (PID=23195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:37:14.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:37:14.158+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:37:14.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:37:14.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:37:14.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:37:14.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:37:14.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:37:14.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:37:14.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-09-09T22:37:44.481+0000] {processor.py:157} INFO - Started process (PID=23205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:37:44.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:37:44.492+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:37:44.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:37:44.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:37:44.545+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:37:44.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:37:44.663+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:37:44.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:37:44.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-09T22:38:14.984+0000] {processor.py:157} INFO - Started process (PID=23215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:38:14.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:38:14.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:38:14.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:38:14.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:38:15.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:38:15.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:38:15.095+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:38:15.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:38:15.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-09T22:38:45.404+0000] {processor.py:157} INFO - Started process (PID=23225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:38:45.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:38:45.410+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:38:45.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:38:45.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:38:45.544+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:38:45.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:38:45.552+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:38:45.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:38:45.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-09T22:39:15.896+0000] {processor.py:157} INFO - Started process (PID=23235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:39:15.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:39:15.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:39:15.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:39:15.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:39:15.927+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:39:15.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:39:15.938+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:39:15.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:39:15.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T22:39:46.246+0000] {processor.py:157} INFO - Started process (PID=23245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:39:46.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:39:46.251+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:39:46.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:39:46.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:39:46.287+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:39:46.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:39:46.299+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:39:46.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:39:46.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T22:40:16.652+0000] {processor.py:157} INFO - Started process (PID=23255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:40:16.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:40:16.655+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:40:16.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:40:16.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:40:16.682+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:40:16.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:40:16.693+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:40:16.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:40:16.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-09-09T22:40:46.954+0000] {processor.py:157} INFO - Started process (PID=23264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:40:46.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:40:46.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:40:46.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:40:46.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:40:47.017+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:40:47.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:40:47.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:40:47.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:40:47.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-09T22:41:17.426+0000] {processor.py:157} INFO - Started process (PID=23275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:41:17.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:41:17.430+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:41:17.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:41:17.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:41:17.458+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:41:17.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:41:17.600+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:41:17.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:41:17.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-09T22:41:47.764+0000] {processor.py:157} INFO - Started process (PID=23285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:41:47.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:41:47.770+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:41:47.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:41:47.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:41:47.883+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:41:47.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:41:47.893+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:41:47.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:41:47.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-09T22:42:18.152+0000] {processor.py:157} INFO - Started process (PID=23295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:42:18.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:42:18.155+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:42:18.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:42:18.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:42:18.184+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:42:18.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:42:18.197+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:42:18.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:42:18.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T22:42:48.492+0000] {processor.py:157} INFO - Started process (PID=23305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:42:48.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:42:48.495+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:42:48.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:42:48.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:42:48.519+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:42:48.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:42:48.529+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:42:48.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:42:48.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-09T22:43:18.892+0000] {processor.py:157} INFO - Started process (PID=23315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:43:18.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:43:18.899+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:43:18.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:43:18.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:43:18.947+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:43:18.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:43:18.960+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:43:18.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:43:19.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-09T22:43:49.212+0000] {processor.py:157} INFO - Started process (PID=23325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:43:49.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:43:49.235+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:43:49.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:43:49.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:43:49.284+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:43:49.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:43:49.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:43:49.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:43:49.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.261 seconds
[2024-09-09T22:44:19.758+0000] {processor.py:157} INFO - Started process (PID=23335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:44:19.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:44:19.770+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:44:19.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:44:19.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:44:19.960+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:44:19.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:44:19.969+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:44:19.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:44:19.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-09-09T22:44:50.110+0000] {processor.py:157} INFO - Started process (PID=23345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:44:50.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:44:50.129+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:44:50.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:44:50.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:44:50.340+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:44:50.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:44:50.350+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:44:50.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:44:50.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.252 seconds
[2024-09-09T22:45:20.749+0000] {processor.py:157} INFO - Started process (PID=23353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:45:20.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:45:20.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:45:20.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:45:20.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:45:20.803+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:45:20.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:45:20.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:45:20.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:45:20.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-09T22:45:51.106+0000] {processor.py:157} INFO - Started process (PID=23365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:45:51.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:45:51.119+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:45:51.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:45:51.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:45:51.155+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:45:51.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:45:51.167+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:45:51.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:45:51.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-09T22:46:21.413+0000] {processor.py:157} INFO - Started process (PID=23375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:46:21.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:46:21.419+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:46:21.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:46:21.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:46:21.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:46:21.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:46:21.602+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:46:21.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:46:21.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-09-09T22:46:51.945+0000] {processor.py:157} INFO - Started process (PID=23385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:46:51.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:46:51.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:46:51.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:46:51.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:46:51.974+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:46:51.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:46:52.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:46:52.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:46:52.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-09T22:47:22.301+0000] {processor.py:157} INFO - Started process (PID=23395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:47:22.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:47:22.305+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:47:22.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:47:22.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:47:22.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:47:22.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:47:22.493+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:47:22.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:47:22.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-09-09T22:47:52.881+0000] {processor.py:157} INFO - Started process (PID=23405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:47:52.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:47:52.887+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:47:52.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:47:53.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:47:53.025+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:47:53.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:47:53.033+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:47:53.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:47:53.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-09T22:48:23.368+0000] {processor.py:157} INFO - Started process (PID=23414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:48:23.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:48:23.374+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:48:23.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:48:23.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:48:23.410+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:48:23.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:48:23.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:48:23.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:48:23.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T22:48:53.768+0000] {processor.py:157} INFO - Started process (PID=23425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:48:53.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:48:53.773+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:48:53.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:48:53.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:48:53.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:48:53.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:48:53.814+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:48:53.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:48:53.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T22:49:24.207+0000] {processor.py:157} INFO - Started process (PID=23435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:49:24.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:49:24.212+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:49:24.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:49:24.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:49:24.255+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:49:24.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:49:24.434+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:49:24.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:49:24.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.238 seconds
[2024-09-09T22:49:54.540+0000] {processor.py:157} INFO - Started process (PID=23445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:49:54.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:49:54.545+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:49:54.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:49:54.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:49:54.584+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:49:54.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:49:54.757+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:49:54.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:49:54.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-09-09T22:50:25.046+0000] {processor.py:157} INFO - Started process (PID=23455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:50:25.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:50:25.050+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:50:25.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:50:25.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:50:25.167+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:50:25.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:50:25.175+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:50:25.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:50:25.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-09T22:50:55.363+0000] {processor.py:157} INFO - Started process (PID=23465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:50:55.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:50:55.366+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:50:55.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:50:55.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:50:55.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:50:55.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:50:55.406+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:50:55.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:50:55.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-09T22:51:25.734+0000] {processor.py:157} INFO - Started process (PID=23475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:51:25.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:51:25.743+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:51:25.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:51:25.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:51:25.786+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:51:25.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:51:25.799+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:51:25.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:51:25.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T22:51:56.043+0000] {processor.py:157} INFO - Started process (PID=23485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:51:56.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:51:56.046+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:51:56.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:51:56.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:51:56.076+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:51:56.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:51:56.087+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:51:56.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:51:56.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-09T22:52:26.387+0000] {processor.py:157} INFO - Started process (PID=23495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:52:26.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:52:26.389+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:52:26.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:52:26.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:52:26.420+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:52:26.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:52:26.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:52:26.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:52:26.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-09T22:52:56.803+0000] {processor.py:157} INFO - Started process (PID=23505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:52:56.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:52:56.809+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:52:56.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:52:56.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:52:56.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:52:56.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:52:56.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:52:56.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:52:56.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-09T22:53:27.284+0000] {processor.py:157} INFO - Started process (PID=23515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:53:27.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:53:27.287+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:53:27.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:53:27.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:53:27.383+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:53:27.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:53:27.390+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:53:27.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:53:27.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T22:53:57.717+0000] {processor.py:157} INFO - Started process (PID=23525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:53:57.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:53:57.722+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:53:57.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:53:57.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:53:57.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:53:57.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:53:57.860+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:53:57.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:53:57.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-09T22:54:28.239+0000] {processor.py:157} INFO - Started process (PID=23535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:54:28.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:54:28.244+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:54:28.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:54:28.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:54:28.269+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:54:28.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:54:28.278+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:54:28.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:54:28.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T22:54:58.635+0000] {processor.py:157} INFO - Started process (PID=23545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:54:58.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:54:58.639+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:54:58.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:54:58.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:54:58.671+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:54:58.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:54:58.681+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:54:58.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:54:58.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-09T22:55:29.116+0000] {processor.py:157} INFO - Started process (PID=23555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:55:29.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:55:29.120+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:55:29.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:55:29.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:55:29.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:55:29.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:55:29.261+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:55:29.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:55:29.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-09T22:55:59.556+0000] {processor.py:157} INFO - Started process (PID=23565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:55:59.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:55:59.559+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:55:59.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:55:59.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:55:59.584+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:55:59.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:55:59.665+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:55:59.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:55:59.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-09T22:56:30.014+0000] {processor.py:157} INFO - Started process (PID=23575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:56:30.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:56:30.018+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:56:30.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:56:30.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:56:30.121+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:56:30.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:56:30.129+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:56:30.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:56:30.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-09T22:57:00.457+0000] {processor.py:157} INFO - Started process (PID=23585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:57:00.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:57:00.460+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:57:00.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:57:00.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:57:00.487+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:57:00.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:57:00.498+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:57:00.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:57:00.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T22:57:30.810+0000] {processor.py:157} INFO - Started process (PID=23595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:57:30.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:57:30.813+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:57:30.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:57:30.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:57:30.841+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:57:30.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:57:30.852+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:57:30.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:57:30.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T22:58:01.133+0000] {processor.py:157} INFO - Started process (PID=23605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:58:01.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:58:01.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:58:01.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:58:01.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:58:01.161+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:58:01.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:58:01.171+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:58:01.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:58:01.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-09T22:58:31.477+0000] {processor.py:157} INFO - Started process (PID=23615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:58:31.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:58:31.484+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:58:31.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:58:31.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:58:31.533+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:58:31.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:58:31.630+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:58:31.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:58:31.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-09T22:59:01.830+0000] {processor.py:157} INFO - Started process (PID=23625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:59:01.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:59:01.833+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:59:01.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:59:01.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:59:01.861+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:59:01.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:59:02.106+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:59:02.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:59:02.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.286 seconds
[2024-09-09T22:59:32.418+0000] {processor.py:157} INFO - Started process (PID=23635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:59:32.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T22:59:32.421+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:59:32.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:59:32.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T22:59:32.533+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:59:32.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T22:59:32.540+0000] {logging_mixin.py:151} INFO - [2024-09-09T22:59:32.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T22:59:32.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-09T23:00:02.698+0000] {processor.py:157} INFO - Started process (PID=23645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:00:02.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:00:02.701+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:00:02.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:00:02.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:00:02.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:00:02.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:00:02.902+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:00:02.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:00:02.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.219 seconds
[2024-09-09T23:00:33.241+0000] {processor.py:157} INFO - Started process (PID=23655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:00:33.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:00:33.246+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:00:33.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:00:33.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:00:33.296+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:00:33.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:00:33.308+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:00:33.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:00:33.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T23:01:03.639+0000] {processor.py:157} INFO - Started process (PID=23665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:01:03.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:01:03.647+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:01:03.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:01:03.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:01:03.705+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:01:03.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:01:03.723+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:01:03.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:01:03.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-09T23:01:33.935+0000] {processor.py:157} INFO - Started process (PID=23675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:01:33.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:01:33.939+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:01:33.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:01:33.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:01:33.967+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:01:33.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:01:33.978+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:01:33.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:01:33.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T23:02:04.349+0000] {processor.py:157} INFO - Started process (PID=23684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:02:04.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:02:04.353+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:02:04.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:02:04.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:02:04.401+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:02:04.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:02:04.415+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:02:04.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:02:04.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T23:02:34.666+0000] {processor.py:157} INFO - Started process (PID=23695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:02:34.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:02:34.669+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:02:34.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:02:34.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:02:34.698+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:02:34.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:02:34.709+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:02:34.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:02:34.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T23:03:05.084+0000] {processor.py:157} INFO - Started process (PID=23705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:03:05.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:03:05.090+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:03:05.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:03:05.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:03:05.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:03:05.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:03:05.163+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:03:05.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:03:05.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-09T23:03:35.424+0000] {processor.py:157} INFO - Started process (PID=23715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:03:35.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:03:35.427+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:03:35.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:03:35.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:03:35.454+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:03:35.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:03:35.465+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:03:35.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:03:35.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T23:04:05.891+0000] {processor.py:157} INFO - Started process (PID=23725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:04:05.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:04:05.896+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:04:05.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:04:05.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:04:05.944+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:04:05.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:04:05.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:04:05.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:04:05.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T23:04:36.179+0000] {processor.py:157} INFO - Started process (PID=23735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:04:36.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:04:36.183+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:04:36.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:04:36.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:04:36.209+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:04:36.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:04:36.219+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:04:36.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:04:36.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:05:06.564+0000] {processor.py:157} INFO - Started process (PID=23744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:05:06.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:05:06.571+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:05:06.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:05:06.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:05:06.619+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:05:06.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:05:06.633+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:05:06.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:05:06.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-09T23:05:36.954+0000] {processor.py:157} INFO - Started process (PID=23755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:05:36.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:05:36.957+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:05:36.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:05:36.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:05:36.982+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:05:36.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:05:36.996+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:05:36.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:05:37.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T23:06:07.337+0000] {processor.py:157} INFO - Started process (PID=23765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:06:07.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:06:07.344+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:06:07.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:06:07.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:06:07.408+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:06:07.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:06:07.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:06:07.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:06:07.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-09T23:06:37.774+0000] {processor.py:157} INFO - Started process (PID=23775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:06:37.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:06:37.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:06:37.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:06:37.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:06:37.812+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:06:37.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:06:37.822+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:06:37.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:06:37.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-09T23:07:08.113+0000] {processor.py:157} INFO - Started process (PID=23785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:07:08.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:07:08.117+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:07:08.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:07:08.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:07:08.150+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:07:08.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:07:08.162+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:07:08.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:07:08.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T23:07:38.502+0000] {processor.py:157} INFO - Started process (PID=23795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:07:38.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:07:38.506+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:07:38.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:07:38.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:07:38.535+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:07:38.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:07:38.547+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:07:38.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:07:38.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T23:08:08.939+0000] {processor.py:157} INFO - Started process (PID=23805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:08:08.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:08:08.944+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:08:08.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:08:08.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:08:08.994+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:08:08.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:08:09.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:08:09.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:08:09.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-09T23:08:39.244+0000] {processor.py:157} INFO - Started process (PID=23815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:08:39.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:08:39.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:08:39.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:08:39.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:08:39.277+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:08:39.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:08:39.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:08:39.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:08:39.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T23:09:09.731+0000] {processor.py:157} INFO - Started process (PID=23824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:09:09.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:09:09.736+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:09:09.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:09:09.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:09:09.784+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:09:09.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:09:09.799+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:09:09.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:09:09.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-09T23:09:40.115+0000] {processor.py:157} INFO - Started process (PID=23835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:09:40.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:09:40.118+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:09:40.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:09:40.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:09:40.147+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:09:40.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:09:40.159+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:09:40.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:09:40.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T23:10:10.593+0000] {processor.py:157} INFO - Started process (PID=23845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:10:10.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:10:10.599+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:10:10.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:10:10.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:10:10.638+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:10:10.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:10:10.651+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:10:10.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:10:10.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-09T23:10:40.977+0000] {processor.py:157} INFO - Started process (PID=23855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:10:40.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:10:40.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:10:40.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:10:40.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:10:41.009+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:10:41.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:10:41.019+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:10:41.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:10:41.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:11:11.305+0000] {processor.py:157} INFO - Started process (PID=23865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:11:11.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:11:11.314+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:11:11.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:11:11.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:11:11.348+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:11:11.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:11:11.360+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:11:11.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:11:11.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T23:11:41.676+0000] {processor.py:157} INFO - Started process (PID=23875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:11:41.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:11:41.679+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:11:41.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:11:41.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:11:41.711+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:11:41.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:11:41.722+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:11:41.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:11:41.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:12:12.073+0000] {processor.py:157} INFO - Started process (PID=23883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:12:12.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:12:12.079+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:12:12.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:12:12.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:12:12.128+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:12:12.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:12:12.140+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:12:12.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:12:12.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-09T23:12:42.463+0000] {processor.py:157} INFO - Started process (PID=23895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:12:42.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:12:42.467+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:12:42.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:12:42.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:12:42.496+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:12:42.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:12:42.510+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:12:42.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:12:42.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T23:13:12.848+0000] {processor.py:157} INFO - Started process (PID=23904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:13:12.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:13:12.853+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:13:12.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:13:12.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:13:12.889+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:13:12.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:13:12.914+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:13:12.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:13:12.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-09T23:13:43.139+0000] {processor.py:157} INFO - Started process (PID=23915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:13:43.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:13:43.143+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:13:43.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:13:43.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:13:43.170+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:13:43.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:13:43.180+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:13:43.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:13:43.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T23:14:13.627+0000] {processor.py:157} INFO - Started process (PID=23924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:14:13.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:14:13.639+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:14:13.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:14:13.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:14:13.687+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:14:13.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:14:13.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:14:13.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:14:13.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-09T23:14:43.972+0000] {processor.py:157} INFO - Started process (PID=23935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:14:43.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:14:43.975+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:14:43.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:14:43.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:14:44.006+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:14:44.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:14:44.016+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:14:44.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:14:44.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:15:14.378+0000] {processor.py:157} INFO - Started process (PID=23945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:15:14.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:15:14.383+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:15:14.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:15:14.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:15:14.445+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:15:14.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:15:14.457+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:15:14.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:15:14.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-09T23:15:44.723+0000] {processor.py:157} INFO - Started process (PID=23955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:15:44.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:15:44.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:15:44.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:15:44.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:15:44.762+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:15:44.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:15:44.775+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:15:44.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:15:44.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T23:16:15.057+0000] {processor.py:157} INFO - Started process (PID=23965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:16:15.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:16:15.064+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:16:15.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:16:15.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:16:15.105+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:16:15.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:16:15.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:16:15.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:16:15.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T23:16:45.494+0000] {processor.py:157} INFO - Started process (PID=23975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:16:45.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:16:45.499+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:16:45.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:16:45.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:16:45.534+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:16:45.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:16:45.545+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:16:45.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:16:45.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T23:17:15.876+0000] {processor.py:157} INFO - Started process (PID=23985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:17:15.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:17:15.880+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:17:15.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:17:15.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:17:15.932+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:17:15.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:17:15.943+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:17:15.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:17:15.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T23:17:46.210+0000] {processor.py:157} INFO - Started process (PID=23995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:17:46.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:17:46.213+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:17:46.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:17:46.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:17:46.243+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:17:46.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:17:46.253+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:17:46.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:17:46.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:18:16.601+0000] {processor.py:157} INFO - Started process (PID=24005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:18:16.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:18:16.606+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:18:16.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:18:16.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:18:16.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:18:16.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:18:16.657+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:18:16.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:18:16.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T23:18:46.912+0000] {processor.py:157} INFO - Started process (PID=24015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:18:46.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:18:46.916+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:18:46.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:18:46.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:18:46.941+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:18:46.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:18:46.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:18:46.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:18:46.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T23:19:17.289+0000] {processor.py:157} INFO - Started process (PID=24024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:19:17.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:19:17.294+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:19:17.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:19:17.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:19:17.349+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:19:17.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:19:17.364+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:19:17.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:19:17.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-09T23:19:47.738+0000] {processor.py:157} INFO - Started process (PID=24035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:19:47.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:19:47.745+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:19:47.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:19:47.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:19:47.768+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:19:47.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:19:47.780+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:19:47.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:19:47.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T23:20:18.179+0000] {processor.py:157} INFO - Started process (PID=24045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:20:18.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:20:18.185+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:20:18.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:20:18.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:20:18.236+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:20:18.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:20:18.248+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:20:18.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:20:18.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-09T23:20:48.527+0000] {processor.py:157} INFO - Started process (PID=24055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:20:48.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:20:48.533+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:20:48.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:20:48.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:20:48.560+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:20:48.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:20:48.574+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:20:48.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:20:48.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T23:21:18.935+0000] {processor.py:157} INFO - Started process (PID=24065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:21:18.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:21:18.942+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:21:18.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:21:18.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:21:19.002+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:21:19.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:21:19.014+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:21:19.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:21:19.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T23:21:49.300+0000] {processor.py:157} INFO - Started process (PID=24075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:21:49.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:21:49.302+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:21:49.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:21:49.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:21:49.330+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:21:49.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:21:49.343+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:21:49.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:21:49.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:22:19.750+0000] {processor.py:157} INFO - Started process (PID=24085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:22:19.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:22:19.752+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:22:19.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:22:19.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:22:19.779+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:22:19.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:22:19.791+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:22:19.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:22:19.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:22:50.088+0000] {processor.py:157} INFO - Started process (PID=24095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:22:50.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:22:50.093+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:22:50.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:22:50.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:22:50.147+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:22:50.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:22:50.160+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:22:50.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:22:50.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-09T23:23:20.545+0000] {processor.py:157} INFO - Started process (PID=24105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:23:20.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:23:20.548+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:23:20.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:23:20.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:23:20.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:23:20.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:23:20.586+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:23:20.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:23:20.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T23:23:50.876+0000] {processor.py:157} INFO - Started process (PID=24115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:23:50.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:23:50.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:23:50.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:23:50.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:23:50.917+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:23:50.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:23:50.931+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:23:50.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:23:50.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T23:24:21.176+0000] {processor.py:157} INFO - Started process (PID=24125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:24:21.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:24:21.179+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:24:21.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:24:21.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:24:21.206+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:24:21.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:24:21.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:24:21.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:24:21.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T23:24:51.587+0000] {processor.py:157} INFO - Started process (PID=24135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:24:51.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:24:51.590+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:24:51.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:24:51.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:24:51.618+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:24:51.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:24:51.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:24:51.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:24:51.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T23:25:22.036+0000] {processor.py:157} INFO - Started process (PID=24145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:25:22.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:25:22.041+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:25:22.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:25:22.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:25:22.088+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:25:22.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:25:22.101+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:25:22.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:25:22.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-09T23:25:52.337+0000] {processor.py:157} INFO - Started process (PID=24155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:25:52.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:25:52.344+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:25:52.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:25:52.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:25:52.368+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:25:52.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:25:52.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:25:52.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:25:52.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:26:22.748+0000] {processor.py:157} INFO - Started process (PID=24165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:26:22.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:26:22.753+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:26:22.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:26:22.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:26:22.810+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:26:22.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:26:22.830+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:26:22.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:26:22.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-09T23:26:53.102+0000] {processor.py:157} INFO - Started process (PID=24175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:26:53.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:26:53.111+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:26:53.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:26:53.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:26:53.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:26:53.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:26:53.142+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:26:53.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:26:53.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T23:27:23.484+0000] {processor.py:157} INFO - Started process (PID=24185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:27:23.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:27:23.488+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:27:23.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:27:23.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:27:23.525+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:27:23.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:27:23.537+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:27:23.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:27:23.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T23:27:53.839+0000] {processor.py:157} INFO - Started process (PID=24195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:27:53.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:27:53.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:27:53.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:27:53.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:27:53.881+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:27:53.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:27:53.892+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:27:53.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:27:53.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T23:28:24.250+0000] {processor.py:157} INFO - Started process (PID=24205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:28:24.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:28:24.253+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:28:24.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:28:24.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:28:24.279+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:28:24.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:28:24.289+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:28:24.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:28:24.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-09T23:28:54.630+0000] {processor.py:157} INFO - Started process (PID=24215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:28:54.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:28:54.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:28:54.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:28:54.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:28:54.675+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:28:54.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:28:54.688+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:28:54.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:28:54.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T23:29:25.023+0000] {processor.py:157} INFO - Started process (PID=24225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:29:25.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:29:25.028+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:29:25.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:29:25.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:29:25.055+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:29:25.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:29:25.065+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:29:25.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:29:25.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:29:55.334+0000] {processor.py:157} INFO - Started process (PID=24235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:29:55.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:29:55.341+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:29:55.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:29:55.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:29:55.379+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:29:55.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:29:55.391+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:29:55.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:29:55.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T23:30:25.713+0000] {processor.py:157} INFO - Started process (PID=24245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:30:25.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:30:25.719+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:30:25.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:30:25.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:30:25.755+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:30:25.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:30:25.769+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:30:25.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:30:25.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T23:30:56.027+0000] {processor.py:157} INFO - Started process (PID=24255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:30:56.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:30:56.031+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:30:56.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:30:56.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:30:56.061+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:30:56.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:30:56.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:30:56.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:30:56.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:31:26.451+0000] {processor.py:157} INFO - Started process (PID=24264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:31:26.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:31:26.463+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:31:26.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:31:26.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:31:26.521+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:31:26.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:31:26.544+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:31:26.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:31:26.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-09T23:31:56.795+0000] {processor.py:157} INFO - Started process (PID=24275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:31:56.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:31:56.805+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:31:56.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:31:56.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:31:56.842+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:31:56.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:31:56.857+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:31:56.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:31:56.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T23:32:27.085+0000] {processor.py:157} INFO - Started process (PID=24285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:32:27.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:32:27.091+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:32:27.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:32:27.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:32:27.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:32:27.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:32:27.161+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:32:27.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:32:27.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-09T23:32:57.362+0000] {processor.py:157} INFO - Started process (PID=24294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:32:57.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:32:57.371+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:32:57.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:32:57.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:32:57.423+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:32:57.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:32:57.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:32:57.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:32:57.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-09T23:33:27.601+0000] {processor.py:157} INFO - Started process (PID=24305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:33:27.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:33:27.606+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:33:27.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:33:27.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:33:27.639+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:33:27.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:33:27.652+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:33:27.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:33:27.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-09T23:33:57.936+0000] {processor.py:157} INFO - Started process (PID=24315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:33:57.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:33:57.940+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:33:57.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:33:57.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:33:57.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:33:57.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:33:57.980+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:33:57.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:33:57.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T23:34:28.348+0000] {processor.py:157} INFO - Started process (PID=24325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:34:28.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:34:28.354+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:34:28.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:34:28.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:34:28.409+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:34:28.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:34:28.421+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:34:28.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:34:28.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-09T23:34:58.746+0000] {processor.py:157} INFO - Started process (PID=24335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:34:58.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:34:58.750+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:34:58.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:34:58.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:34:58.776+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:34:58.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:34:58.786+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:34:58.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:34:58.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T23:35:29.136+0000] {processor.py:157} INFO - Started process (PID=24345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:35:29.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:35:29.141+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:35:29.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:35:29.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:35:29.181+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:35:29.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:35:29.196+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:35:29.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:35:29.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-09T23:35:59.435+0000] {processor.py:157} INFO - Started process (PID=24355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:35:59.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:35:59.438+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:35:59.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:35:59.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:35:59.466+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:35:59.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:35:59.478+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:35:59.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:35:59.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:36:29.790+0000] {processor.py:157} INFO - Started process (PID=24365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:36:29.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:36:29.795+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:36:29.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:36:29.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:36:29.832+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:36:29.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:36:29.845+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:36:29.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:36:29.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T23:37:00.165+0000] {processor.py:157} INFO - Started process (PID=24375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:37:00.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:37:00.169+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:37:00.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:37:00.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:37:00.197+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:37:00.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:37:00.208+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:37:00.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:37:00.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T23:37:30.525+0000] {processor.py:157} INFO - Started process (PID=24385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:37:30.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:37:30.530+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:37:30.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:37:30.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:37:30.564+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:37:30.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:37:30.576+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:37:30.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:37:30.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T23:38:00.870+0000] {processor.py:157} INFO - Started process (PID=24395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:38:00.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:38:00.873+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:38:00.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:38:00.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:38:00.901+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:38:00.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:38:00.913+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:38:00.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:38:00.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:38:31.190+0000] {processor.py:157} INFO - Started process (PID=24405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:38:31.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:38:31.192+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:38:31.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:38:31.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:38:31.220+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:38:31.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:38:31.233+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:38:31.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:38:31.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T23:39:01.593+0000] {processor.py:157} INFO - Started process (PID=24414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:39:01.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:39:01.596+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:39:01.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:39:01.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:39:01.630+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:39:01.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:39:01.642+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:39:01.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:39:01.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-09T23:39:32.008+0000] {processor.py:157} INFO - Started process (PID=24425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:39:32.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:39:32.012+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:39:32.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:39:32.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:39:32.041+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:39:32.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:39:32.051+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:39:32.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:39:32.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:40:02.361+0000] {processor.py:157} INFO - Started process (PID=24435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:40:02.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:40:02.370+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:40:02.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:40:02.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:40:02.395+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:40:02.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:40:02.405+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:40:02.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:40:02.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T23:40:32.722+0000] {processor.py:157} INFO - Started process (PID=24445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:40:32.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:40:32.728+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:40:32.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:40:32.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:40:32.765+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:40:32.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:40:32.777+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:40:32.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:40:32.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T23:41:03.026+0000] {processor.py:157} INFO - Started process (PID=24455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:41:03.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:41:03.032+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:41:03.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:41:03.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:41:03.059+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:41:03.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:41:03.072+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:41:03.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:41:03.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-09T23:41:33.475+0000] {processor.py:157} INFO - Started process (PID=24465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:41:33.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:41:33.479+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:41:33.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:41:33.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:41:33.503+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:41:33.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:41:33.513+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:41:33.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:41:33.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-09T23:42:03.853+0000] {processor.py:157} INFO - Started process (PID=24475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:42:03.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:42:03.858+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:42:03.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:42:03.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:42:03.894+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:42:03.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:42:03.906+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:42:03.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:42:03.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T23:42:34.186+0000] {processor.py:157} INFO - Started process (PID=24485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:42:34.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:42:34.188+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:42:34.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:42:34.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:42:34.216+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:42:34.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:42:34.228+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:42:34.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:42:34.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T23:43:04.594+0000] {processor.py:157} INFO - Started process (PID=24495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:43:04.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:43:04.598+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:43:04.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:43:04.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:43:04.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:43:04.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:43:04.634+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:43:04.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:43:04.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-09T23:43:34.920+0000] {processor.py:157} INFO - Started process (PID=24505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:43:34.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:43:34.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:43:34.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:43:34.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:43:34.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:43:34.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:43:34.965+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:43:34.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:43:34.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-09T23:44:05.386+0000] {processor.py:157} INFO - Started process (PID=24515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:44:05.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:44:05.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:44:05.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:44:05.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:44:05.436+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:44:05.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:44:05.449+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:44:05.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:44:05.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-09T23:44:35.793+0000] {processor.py:157} INFO - Started process (PID=24525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:44:35.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:44:35.796+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:44:35.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:44:35.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:44:35.825+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:44:35.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:44:35.834+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:44:35.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:44:35.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-09T23:45:06.182+0000] {processor.py:157} INFO - Started process (PID=24535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:45:06.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:45:06.188+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:45:06.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:45:06.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:45:06.220+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:45:06.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:45:06.234+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:45:06.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:45:06.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-09T23:45:36.505+0000] {processor.py:157} INFO - Started process (PID=24545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:45:36.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:45:36.509+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:45:36.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:45:36.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:45:36.536+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:45:36.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:45:36.546+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:45:36.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:45:36.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-09T23:46:06.867+0000] {processor.py:157} INFO - Started process (PID=24555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:46:06.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:46:06.872+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:46:06.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:46:06.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:46:06.908+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:46:06.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:46:06.921+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:46:06.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:46:06.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T23:46:37.292+0000] {processor.py:157} INFO - Started process (PID=24565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:46:37.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:46:37.296+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:46:37.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:46:37.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:46:37.326+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:46:37.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:46:37.336+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:46:37.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:46:37.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:47:07.713+0000] {processor.py:157} INFO - Started process (PID=24575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:47:07.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:47:07.717+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:47:07.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:47:07.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:47:07.747+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:47:07.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:47:07.761+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:47:07.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:47:07.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T23:47:38.047+0000] {processor.py:157} INFO - Started process (PID=24585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:47:38.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:47:38.052+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:47:38.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:47:38.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:47:38.087+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:47:38.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:47:38.103+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:47:38.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:47:38.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T23:48:08.372+0000] {processor.py:157} INFO - Started process (PID=24595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:48:08.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:48:08.377+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:48:08.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:48:08.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:48:08.403+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:48:08.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:48:08.416+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:48:08.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:48:08.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-09T23:48:38.884+0000] {processor.py:157} INFO - Started process (PID=24605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:48:38.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:48:38.896+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:48:38.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:48:38.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:48:38.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:48:38.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:48:38.966+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:48:38.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:48:38.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-09T23:49:09.302+0000] {processor.py:157} INFO - Started process (PID=24615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:49:09.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:49:09.307+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:49:09.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:49:09.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:49:09.343+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:49:09.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:49:09.356+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:49:09.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:49:09.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-09T23:49:39.656+0000] {processor.py:157} INFO - Started process (PID=24625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:49:39.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:49:39.661+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:49:39.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:49:39.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:49:39.699+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:49:39.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:49:39.712+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:49:39.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:49:39.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-09T23:50:10.211+0000] {processor.py:157} INFO - Started process (PID=24635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:50:10.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:50:10.217+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:50:10.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:50:10.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:50:10.283+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:50:10.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:50:10.304+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:50:10.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:50:10.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-09T23:50:40.732+0000] {processor.py:157} INFO - Started process (PID=24645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:50:40.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:50:40.742+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:50:40.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:50:40.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:50:40.791+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:50:40.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:50:40.818+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:50:40.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:50:40.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-09T23:51:11.023+0000] {processor.py:157} INFO - Started process (PID=24655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:51:11.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:51:11.042+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:51:11.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:51:11.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:51:11.082+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:51:11.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:51:11.094+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:51:11.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:51:11.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T23:51:41.332+0000] {processor.py:157} INFO - Started process (PID=24665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:51:41.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:51:41.338+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:51:41.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:51:41.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:51:41.387+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:51:41.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:51:41.398+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:51:41.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:51:41.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-09T23:52:11.684+0000] {processor.py:157} INFO - Started process (PID=24675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:52:11.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:52:11.690+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:52:11.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:52:11.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:52:11.749+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:52:11.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:52:11.762+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:52:11.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:52:11.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T23:52:42.094+0000] {processor.py:157} INFO - Started process (PID=24685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:52:42.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:52:42.098+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:52:42.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:52:42.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:52:42.133+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:52:42.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:52:42.146+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:52:42.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:52:42.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-09T23:53:12.398+0000] {processor.py:157} INFO - Started process (PID=24695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:53:12.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:53:12.400+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:53:12.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:53:12.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:53:12.427+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:53:12.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:53:12.437+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:53:12.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:53:12.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-09T23:53:42.770+0000] {processor.py:157} INFO - Started process (PID=24705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:53:42.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:53:42.784+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:53:42.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:53:42.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:53:42.843+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:53:42.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:53:42.856+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:53:42.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:53:42.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-09T23:54:13.113+0000] {processor.py:157} INFO - Started process (PID=24715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:54:13.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:54:13.118+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:54:13.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:54:13.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:54:13.154+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:54:13.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:54:13.168+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:54:13.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:54:13.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-09T23:54:43.396+0000] {processor.py:157} INFO - Started process (PID=24725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:54:43.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:54:43.399+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:54:43.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:54:43.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:54:43.461+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:54:43.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:54:43.477+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:54:43.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:54:43.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T23:55:13.739+0000] {processor.py:157} INFO - Started process (PID=24735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:55:13.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:55:13.746+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:55:13.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:55:13.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:55:13.802+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:55:13.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:55:13.816+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:55:13.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:55:13.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T23:55:44.059+0000] {processor.py:157} INFO - Started process (PID=24745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:55:44.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:55:44.083+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:55:44.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:55:44.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:55:44.123+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:55:44.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:55:44.135+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:55:44.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:55:44.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-09T23:56:14.533+0000] {processor.py:157} INFO - Started process (PID=24755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:56:14.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:56:14.540+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:56:14.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:56:14.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:56:14.615+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:56:14.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:56:14.632+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:56:14.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:56:14.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-09T23:56:44.855+0000] {processor.py:157} INFO - Started process (PID=24765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:56:44.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:56:44.861+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:56:44.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:56:44.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:56:44.910+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:56:44.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:56:44.923+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:56:44.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:56:44.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-09T23:57:15.133+0000] {processor.py:157} INFO - Started process (PID=24775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:57:15.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:57:15.138+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:57:15.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:57:15.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:57:15.173+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:57:15.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:57:15.186+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:57:15.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:57:15.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-09T23:57:45.562+0000] {processor.py:157} INFO - Started process (PID=24785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:57:45.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:57:45.569+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:57:45.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:57:45.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:57:45.624+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:57:45.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:57:45.636+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:57:45.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:57:45.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-09T23:58:15.950+0000] {processor.py:157} INFO - Started process (PID=24795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:58:15.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:58:15.959+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:58:15.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:58:15.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:58:16.030+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:58:16.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:58:16.056+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:58:16.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:58:16.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-09T23:58:46.332+0000] {processor.py:157} INFO - Started process (PID=24805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:58:46.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:58:46.339+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:58:46.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:58:46.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:58:46.392+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:58:46.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:58:46.409+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:58:46.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:58:46.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-09T23:59:16.641+0000] {processor.py:157} INFO - Started process (PID=24815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:59:16.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:59:16.645+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:59:16.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:59:16.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:59:16.692+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:59:16.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:59:16.705+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:59:16.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:59:16.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-09T23:59:46.948+0000] {processor.py:157} INFO - Started process (PID=24825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:59:46.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-09T23:59:46.952+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:59:46.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:59:46.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-09T23:59:46.977+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:59:46.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-09T23:59:46.986+0000] {logging_mixin.py:151} INFO - [2024-09-09T23:59:46.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-09T23:59:46.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
