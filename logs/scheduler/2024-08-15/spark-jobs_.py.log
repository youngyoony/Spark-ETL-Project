[2024-08-15T00:04:07.651+0000] {processor.py:157} INFO - Started process (PID=43038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:04:07.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:04:07.655+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:04:07.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:04:07.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:04:07.696+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:04:07.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:04:07.712+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:04:07.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:04:07.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-15T00:04:38.012+0000] {processor.py:157} INFO - Started process (PID=43049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:04:38.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:04:38.018+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:04:38.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:04:38.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:04:38.066+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:04:38.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:04:38.079+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:04:38.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:04:38.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T00:05:08.286+0000] {processor.py:157} INFO - Started process (PID=43059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:05:08.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:05:08.288+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:05:08.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:05:08.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:05:08.317+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:05:08.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:05:08.328+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:05:08.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:05:08.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T00:05:38.619+0000] {processor.py:157} INFO - Started process (PID=43069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:05:38.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:05:38.621+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:05:38.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:05:38.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:05:38.647+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:05:38.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:05:38.658+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:05:38.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:05:38.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T00:06:08.982+0000] {processor.py:157} INFO - Started process (PID=43079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:06:08.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:06:08.985+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:06:08.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:06:09.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:06:09.022+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:06:09.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:06:09.035+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:06:09.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:06:09.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-15T00:06:39.323+0000] {processor.py:157} INFO - Started process (PID=43089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:06:39.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:06:39.331+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:06:39.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:06:39.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:06:39.354+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:06:39.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:06:39.363+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:06:39.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:06:39.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T00:07:09.594+0000] {processor.py:157} INFO - Started process (PID=43099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:07:09.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:07:09.597+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:07:09.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:07:09.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:07:09.623+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:07:09.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:07:09.633+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:07:09.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:07:09.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T00:07:39.868+0000] {processor.py:157} INFO - Started process (PID=43109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:07:39.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:07:39.871+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:07:39.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:07:39.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:07:39.900+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:07:39.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:07:39.910+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:07:39.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:07:39.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-15T00:08:10.173+0000] {processor.py:157} INFO - Started process (PID=43119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:08:10.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:08:10.175+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:08:10.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:08:10.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:08:10.200+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:08:10.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:08:10.211+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:08:10.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:08:10.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-15T00:20:07.513+0000] {processor.py:157} INFO - Started process (PID=43129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:20:07.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:20:07.519+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:20:07.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:20:07.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:20:07.570+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:20:07.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:20:07.586+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:20:07.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:20:07.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T00:20:37.807+0000] {processor.py:157} INFO - Started process (PID=43140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:20:37.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:20:37.813+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:20:37.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:20:37.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:20:37.851+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:20:37.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:20:37.864+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:20:37.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:20:37.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-15T00:21:08.161+0000] {processor.py:157} INFO - Started process (PID=43150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:21:08.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:21:08.164+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:21:08.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:21:08.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:21:08.192+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:21:08.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:21:08.203+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:21:08.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:21:08.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T00:21:38.534+0000] {processor.py:157} INFO - Started process (PID=43160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:21:38.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:21:38.537+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:21:38.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:21:38.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:21:38.576+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:21:38.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:21:38.590+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:21:38.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:21:38.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-15T00:22:09.005+0000] {processor.py:157} INFO - Started process (PID=43170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:22:09.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:22:09.008+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:22:09.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:22:09.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:22:09.053+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:22:09.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:22:09.070+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:22:09.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:22:09.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-15T00:38:06.893+0000] {processor.py:157} INFO - Started process (PID=43185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:38:06.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:38:06.907+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:38:06.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:38:06.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:38:06.992+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:38:06.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:38:07.031+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:38:07.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:38:07.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-15T00:38:37.173+0000] {processor.py:157} INFO - Started process (PID=43756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:38:37.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:38:37.185+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:38:37.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:38:37.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:38:37.238+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:38:37.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:38:37.251+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:38:37.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:38:37.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-15T00:39:07.388+0000] {processor.py:157} INFO - Started process (PID=43766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:39:07.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:39:07.390+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:39:07.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:39:07.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:39:07.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:39:07.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:39:07.429+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:39:07.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:39:07.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T00:39:37.720+0000] {processor.py:157} INFO - Started process (PID=43776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:39:37.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:39:37.725+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:39:37.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:39:37.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:39:37.763+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:39:37.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:39:37.775+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:39:37.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:39:37.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-15T00:40:08.020+0000] {processor.py:157} INFO - Started process (PID=43786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:40:08.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:40:08.024+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:40:08.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:40:08.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:40:08.056+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:40:08.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:40:08.065+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:40:08.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:40:08.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-15T00:50:40.860+0000] {processor.py:157} INFO - Started process (PID=43965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:50:40.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:50:40.868+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:50:40.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:50:40.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:50:40.973+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:50:40.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:50:41.013+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:50:41.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:50:41.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-15T00:51:11.096+0000] {processor.py:157} INFO - Started process (PID=43975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:51:11.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:51:11.108+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:51:11.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:51:11.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:51:11.162+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:51:11.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:51:11.178+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:51:11.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:51:11.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-15T00:51:41.482+0000] {processor.py:157} INFO - Started process (PID=43985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:51:41.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:51:41.489+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:51:41.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:51:41.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:51:41.552+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:51:41.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:51:41.568+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:51:41.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:51:41.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-15T00:52:11.788+0000] {processor.py:157} INFO - Started process (PID=43994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:52:11.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:52:11.799+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:52:11.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:52:11.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:52:11.843+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:52:11.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:52:11.858+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:52:11.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:52:11.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-15T00:52:42.204+0000] {processor.py:157} INFO - Started process (PID=44005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:52:42.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:52:42.216+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:52:42.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:52:42.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:52:42.273+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:52:42.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:52:42.289+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:52:42.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:52:42.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-15T00:53:12.499+0000] {processor.py:157} INFO - Started process (PID=44015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:53:12.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:53:12.515+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:53:12.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:53:12.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:53:12.563+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:53:12.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:53:12.628+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:53:12.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:53:12.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-15T00:53:42.789+0000] {processor.py:157} INFO - Started process (PID=44025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:53:42.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:53:42.804+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:53:42.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:53:42.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:53:42.865+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:53:42.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:53:42.882+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:53:42.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:53:42.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-15T00:54:13.195+0000] {processor.py:157} INFO - Started process (PID=44035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:54:13.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:54:13.203+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:54:13.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:54:13.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:54:13.265+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:54:13.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:54:13.281+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:54:13.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:54:13.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-15T00:54:43.539+0000] {processor.py:157} INFO - Started process (PID=44045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:54:43.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:54:43.542+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:54:43.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:54:43.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:54:43.567+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:54:43.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:54:43.577+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:54:43.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:54:43.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-15T00:55:13.859+0000] {processor.py:157} INFO - Started process (PID=44055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:55:13.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:55:13.866+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:55:13.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:55:13.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:55:13.911+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:55:13.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:55:13.933+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:55:13.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:55:13.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-15T00:55:44.204+0000] {processor.py:157} INFO - Started process (PID=44065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:55:44.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:55:44.211+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:55:44.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:55:44.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:55:44.255+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:55:44.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:55:44.269+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:55:44.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:55:44.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-15T00:56:14.470+0000] {processor.py:157} INFO - Started process (PID=44075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:56:14.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:56:14.474+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:56:14.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:56:14.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:56:14.502+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:56:14.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:56:14.512+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:56:14.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:56:14.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T00:56:44.847+0000] {processor.py:157} INFO - Started process (PID=44085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:56:44.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:56:44.852+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:56:44.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:56:44.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:56:44.900+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:56:44.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:56:44.914+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:56:44.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:56:44.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-15T00:57:15.270+0000] {processor.py:157} INFO - Started process (PID=44095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:57:15.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:57:15.275+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:57:15.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:57:15.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:57:15.321+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:57:15.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:57:15.335+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:57:15.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:57:15.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-15T00:57:45.616+0000] {processor.py:157} INFO - Started process (PID=44105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:57:45.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:57:45.619+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:57:45.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:57:45.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:57:45.647+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:57:45.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:57:45.657+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:57:45.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:57:45.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T00:58:15.990+0000] {processor.py:157} INFO - Started process (PID=44115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:58:15.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:58:15.998+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:58:15.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:58:16.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:58:16.040+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:58:16.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:58:16.054+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:58:16.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:58:16.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-15T00:58:46.327+0000] {processor.py:157} INFO - Started process (PID=44125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:58:46.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:58:46.334+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:58:46.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:58:46.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:58:46.390+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:58:46.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:58:46.404+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:58:46.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:58:46.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-15T00:59:16.576+0000] {processor.py:157} INFO - Started process (PID=44135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:59:16.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:59:16.578+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:59:16.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:59:16.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:59:16.608+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:59:16.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:59:16.618+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:59:16.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:59:16.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-15T00:59:46.915+0000] {processor.py:157} INFO - Started process (PID=44145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:59:46.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T00:59:46.922+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:59:46.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:59:46.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T00:59:46.968+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:59:46.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T00:59:46.984+0000] {logging_mixin.py:151} INFO - [2024-08-15T00:59:46.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-13T01:00:00+00:00, run_after=2024-08-14T01:00:00+00:00
[2024-08-15T00:59:46.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-15T01:00:17.220+0000] {processor.py:157} INFO - Started process (PID=44155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:00:17.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:00:17.224+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:00:17.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:00:17.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:00:17.256+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:00:17.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:00:17.269+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:00:17.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:00:17.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-15T01:00:47.551+0000] {processor.py:157} INFO - Started process (PID=44165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:00:47.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:00:47.559+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:00:47.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:00:47.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:00:47.631+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:00:47.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:00:47.646+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:00:47.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:00:47.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-15T01:01:17.864+0000] {processor.py:157} INFO - Started process (PID=44175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:01:17.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:01:17.873+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:01:17.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:01:17.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:01:17.912+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:01:17.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:01:17.924+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:01:17.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:01:17.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-15T01:01:48.293+0000] {processor.py:157} INFO - Started process (PID=44185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:01:48.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:01:48.299+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:01:48.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:01:48.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:01:48.342+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:01:48.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:01:48.357+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:01:48.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:01:48.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-15T01:02:18.626+0000] {processor.py:157} INFO - Started process (PID=44195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:02:18.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:02:18.633+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:02:18.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:02:18.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:02:18.670+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:02:18.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:02:18.683+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:02:18.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:02:18.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-15T01:02:48.945+0000] {processor.py:157} INFO - Started process (PID=44205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:02:48.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:02:48.949+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:02:48.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:02:48.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:02:48.976+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:02:48.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:02:48.988+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:02:48.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:02:48.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T01:03:19.323+0000] {processor.py:157} INFO - Started process (PID=44215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:03:19.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:03:19.331+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:03:19.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:03:19.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:03:19.368+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:03:19.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:03:19.381+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:03:19.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:03:19.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-15T01:03:49.677+0000] {processor.py:157} INFO - Started process (PID=44225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:03:49.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:03:49.680+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:03:49.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:03:49.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:03:49.708+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:03:49.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:03:49.720+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:03:49.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:03:49.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T01:04:20.028+0000] {processor.py:157} INFO - Started process (PID=44235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:04:20.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:04:20.034+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:04:20.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:04:20.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:04:20.069+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:04:20.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:04:20.084+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:04:20.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:04:20.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-15T01:04:50.412+0000] {processor.py:157} INFO - Started process (PID=44245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:04:50.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:04:50.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:04:50.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:04:50.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:04:50.446+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:04:50.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:04:50.457+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:04:50.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:04:50.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-15T01:05:20.744+0000] {processor.py:157} INFO - Started process (PID=44255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:05:20.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:05:20.748+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:05:20.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:05:20.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:05:20.778+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:05:20.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:05:20.791+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:05:20.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:05:20.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-15T01:05:51.114+0000] {processor.py:157} INFO - Started process (PID=44265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:05:51.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:05:51.117+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:05:51.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:05:51.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:05:51.153+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:05:51.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:05:51.170+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:05:51.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:05:51.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-15T01:06:21.506+0000] {processor.py:157} INFO - Started process (PID=44275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:06:21.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:06:21.513+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:06:21.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:06:21.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:06:21.543+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:06:21.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:06:21.553+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:06:21.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:06:21.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-15T01:06:51.816+0000] {processor.py:157} INFO - Started process (PID=44285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:06:51.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:06:51.829+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:06:51.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:06:51.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:06:51.872+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:06:51.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:06:51.888+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:06:51.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:06:51.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T01:07:22.107+0000] {processor.py:157} INFO - Started process (PID=44295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:07:22.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:07:22.114+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:07:22.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:07:22.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:07:22.138+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:07:22.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:07:22.149+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:07:22.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:07:22.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T01:07:52.487+0000] {processor.py:157} INFO - Started process (PID=44305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:07:52.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:07:52.491+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:07:52.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:07:52.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:07:52.541+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:07:52.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:07:52.561+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:07:52.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:07:52.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T01:08:22.871+0000] {processor.py:157} INFO - Started process (PID=44315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:08:22.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:08:22.878+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:08:22.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:08:22.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:08:22.934+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:08:22.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:08:22.950+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:08:22.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:08:22.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-15T01:08:53.157+0000] {processor.py:157} INFO - Started process (PID=44325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:08:53.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:08:53.166+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:08:53.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:08:53.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:08:53.225+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:08:53.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:08:53.245+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:08:53.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:08:53.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-15T01:09:23.467+0000] {processor.py:157} INFO - Started process (PID=44335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:09:23.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:09:23.473+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:09:23.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:09:23.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:09:23.514+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:09:23.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:09:23.529+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:09:23.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:09:23.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-15T01:09:53.794+0000] {processor.py:157} INFO - Started process (PID=44345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:09:53.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:09:53.801+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:09:53.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:09:53.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:09:53.843+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:09:53.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:09:53.857+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:09:53.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:09:53.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-15T01:10:24.080+0000] {processor.py:157} INFO - Started process (PID=44355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:10:24.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:10:24.087+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:10:24.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:10:24.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:10:24.133+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:10:24.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:10:24.147+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:10:24.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:10:24.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-15T01:10:54.441+0000] {processor.py:157} INFO - Started process (PID=44365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:10:54.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:10:54.450+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:10:54.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:10:54.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:10:54.506+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:10:54.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:10:54.523+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:10:54.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:10:54.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-15T01:11:24.725+0000] {processor.py:157} INFO - Started process (PID=44375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:11:24.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:11:24.733+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:11:24.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:11:24.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:11:24.777+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:11:24.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:11:24.791+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:11:24.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:11:24.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-15T01:11:55.064+0000] {processor.py:157} INFO - Started process (PID=44385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:11:55.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:11:55.075+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:11:55.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:11:55.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:11:55.139+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:11:55.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:11:55.160+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:11:55.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:11:55.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-15T01:12:25.390+0000] {processor.py:157} INFO - Started process (PID=44395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:12:25.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:12:25.399+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:12:25.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:12:25.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:12:25.458+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:12:25.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:12:25.472+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:12:25.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:12:25.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-15T01:13:08.963+0000] {processor.py:157} INFO - Started process (PID=44405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:13:08.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:13:08.966+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:13:08.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:13:08.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:13:08.997+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:13:08.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:13:09.006+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:13:09.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:13:09.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T01:29:12.191+0000] {processor.py:157} INFO - Started process (PID=44419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:29:12.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:29:12.197+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:29:12.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:29:12.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:29:12.234+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:29:12.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:29:12.249+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:29:12.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:29:12.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-15T01:29:42.513+0000] {processor.py:157} INFO - Started process (PID=44429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:29:42.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:29:42.519+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:29:42.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:29:42.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:29:42.570+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:29:42.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:29:42.587+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:29:42.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:29:42.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T01:30:17.245+0000] {processor.py:157} INFO - Started process (PID=44439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:30:17.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:30:17.249+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:30:17.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:30:17.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:30:17.274+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:30:17.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:30:17.284+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:30:17.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:30:17.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T01:30:47.632+0000] {processor.py:157} INFO - Started process (PID=44449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:30:47.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:30:47.638+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:30:47.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:30:47.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:30:47.675+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:30:47.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:30:47.689+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:30:47.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:30:47.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-15T01:31:17.917+0000] {processor.py:157} INFO - Started process (PID=44459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:31:17.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:31:17.920+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:31:17.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:31:17.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:31:17.945+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:31:17.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:31:17.955+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:31:17.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:31:17.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T01:31:48.344+0000] {processor.py:157} INFO - Started process (PID=44469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:31:48.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:31:48.348+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:31:48.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:31:48.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:31:48.374+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:31:48.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:31:48.384+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:31:48.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:31:48.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T01:48:04.343+0000] {processor.py:157} INFO - Started process (PID=44481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:48:04.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T01:48:04.356+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:48:04.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:48:04.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T01:48:04.425+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:48:04.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T01:48:04.455+0000] {logging_mixin.py:151} INFO - [2024-08-15T01:48:04.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T01:48:04.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-15T02:05:39.601+0000] {processor.py:157} INFO - Started process (PID=44491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:05:39.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:05:39.612+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:05:39.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:05:39.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:05:39.674+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:05:39.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:05:39.697+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:05:39.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:05:39.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-15T02:06:09.987+0000] {processor.py:157} INFO - Started process (PID=44500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:06:09.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:06:09.994+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:06:09.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:06:10.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:06:10.040+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:06:10.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:06:10.058+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:06:10.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:06:10.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T02:06:40.288+0000] {processor.py:157} INFO - Started process (PID=44511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:06:40.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:06:40.294+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:06:40.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:06:40.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:06:40.319+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:06:40.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:06:40.329+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:06:40.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:06:40.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-15T02:07:10.638+0000] {processor.py:157} INFO - Started process (PID=44521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:07:10.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:07:10.644+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:07:10.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:07:10.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:07:10.683+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:07:10.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:07:10.696+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:07:10.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:07:10.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T02:07:41.094+0000] {processor.py:157} INFO - Started process (PID=44531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:07:41.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:07:41.098+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:07:41.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:07:41.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:07:41.206+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:07:41.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:07:41.293+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:07:41.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:07:41.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.447 seconds
[2024-08-15T02:15:05.844+0000] {processor.py:157} INFO - Started process (PID=44540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:15:05.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:15:05.865+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:15:05.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:15:05.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:15:05.998+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:15:05.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:15:06.071+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:15:06.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:15:06.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.272 seconds
[2024-08-15T02:15:36.338+0000] {processor.py:157} INFO - Started process (PID=44553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:15:36.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:15:36.348+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:15:36.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:15:36.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:15:36.427+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:15:36.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:15:36.457+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:15:36.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:15:36.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-15T02:16:06.676+0000] {processor.py:157} INFO - Started process (PID=44563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:16:06.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:16:06.681+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:16:06.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:16:06.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:16:06.724+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:16:06.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:16:06.738+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:16:06.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:16:06.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-15T02:16:37.075+0000] {processor.py:157} INFO - Started process (PID=44573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:16:37.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:16:37.083+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:16:37.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:16:37.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:16:37.150+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:16:37.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:16:37.165+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:16:37.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:16:37.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-15T02:17:07.626+0000] {processor.py:157} INFO - Started process (PID=44583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:17:07.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:17:07.637+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:17:07.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:17:07.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:17:07.694+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:17:07.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:17:07.710+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:17:07.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:17:07.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-15T02:17:38.150+0000] {processor.py:157} INFO - Started process (PID=44593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:17:38.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:17:38.162+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:17:38.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:17:38.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:17:38.225+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:17:38.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:17:38.254+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:17:38.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:17:38.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-15T02:18:08.565+0000] {processor.py:157} INFO - Started process (PID=44603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:18:08.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:18:08.579+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:18:08.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:18:08.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:18:08.645+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:18:08.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:18:08.688+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:18:08.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:18:08.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-15T02:18:38.942+0000] {processor.py:157} INFO - Started process (PID=44613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:18:38.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:18:38.968+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:18:38.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:18:38.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:18:39.039+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:18:39.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:18:39.071+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:18:39.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:18:39.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-15T02:19:09.427+0000] {processor.py:157} INFO - Started process (PID=44623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:19:09.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:19:09.447+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:19:09.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:19:09.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:19:09.496+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:19:09.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:19:09.514+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:19:09.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:19:09.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-15T02:19:39.794+0000] {processor.py:157} INFO - Started process (PID=44633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:19:39.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:19:39.803+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:19:39.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:19:39.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:19:39.906+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:19:39.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:19:39.931+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:19:39.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:19:39.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-15T02:20:10.096+0000] {processor.py:157} INFO - Started process (PID=44643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:20:10.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:20:10.114+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:20:10.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:20:10.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:20:10.164+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:20:10.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:20:10.191+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:20:10.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:20:10.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-15T02:20:40.612+0000] {processor.py:157} INFO - Started process (PID=44653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:20:40.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:20:40.624+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:20:40.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:20:40.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:20:40.769+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:20:40.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:20:40.790+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:20:40.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:20:40.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-08-15T02:21:11.330+0000] {processor.py:157} INFO - Started process (PID=44663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:21:11.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:21:11.335+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:21:11.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:21:11.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:21:11.382+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:21:11.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:21:11.401+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:21:11.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:21:11.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T02:21:41.605+0000] {processor.py:157} INFO - Started process (PID=44673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:21:41.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:21:41.612+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:21:41.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:21:41.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:21:41.658+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:21:41.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:21:41.673+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:21:41.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:21:41.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-15T02:22:11.991+0000] {processor.py:157} INFO - Started process (PID=44683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:22:11.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:22:11.994+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:22:11.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:22:12.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:22:12.033+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:22:12.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:22:12.052+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:22:12.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:22:12.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-15T02:22:42.381+0000] {processor.py:157} INFO - Started process (PID=44693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:22:42.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:22:42.395+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:22:42.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:22:42.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:22:42.453+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:22:42.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:22:42.468+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:22:42.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:22:42.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-15T02:23:12.762+0000] {processor.py:157} INFO - Started process (PID=44703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:23:12.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:23:12.772+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:23:12.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:23:12.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:23:12.851+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:23:12.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:23:12.876+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:23:12.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:23:12.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-15T02:23:43.109+0000] {processor.py:157} INFO - Started process (PID=44713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:23:43.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:23:43.118+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:23:43.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:23:43.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:23:43.163+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:23:43.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:23:43.177+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:23:43.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:23:43.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-15T02:24:13.484+0000] {processor.py:157} INFO - Started process (PID=44723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:24:13.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:24:13.494+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:24:13.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:24:13.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:24:13.553+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:24:13.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:24:13.576+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:24:13.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:24:13.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-15T02:24:43.931+0000] {processor.py:157} INFO - Started process (PID=44733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:24:43.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:24:43.939+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:24:43.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:24:43.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:24:43.986+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:24:43.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:24:44.009+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:24:44.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:24:44.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-15T02:25:14.255+0000] {processor.py:157} INFO - Started process (PID=44742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:25:14.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:25:14.264+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:25:14.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:25:14.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:25:14.319+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:25:14.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:25:14.335+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:25:14.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:25:14.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-15T02:25:44.607+0000] {processor.py:157} INFO - Started process (PID=44753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:25:44.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:25:44.635+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:25:44.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:25:44.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:25:44.692+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:25:44.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:25:44.709+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:25:44.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:25:44.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-15T02:26:15.098+0000] {processor.py:157} INFO - Started process (PID=44763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:26:15.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:26:15.108+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:26:15.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:26:15.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:26:15.211+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:26:15.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:26:15.231+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:26:15.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:26:15.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-15T02:26:45.406+0000] {processor.py:157} INFO - Started process (PID=44773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:26:45.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:26:45.427+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:26:45.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:26:45.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:26:45.498+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:26:45.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:26:45.527+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:26:45.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:26:45.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-15T02:27:15.749+0000] {processor.py:157} INFO - Started process (PID=44783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:27:15.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:27:15.753+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:27:15.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:27:15.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:27:15.795+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:27:15.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:27:15.811+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:27:15.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:27:15.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-15T02:27:46.086+0000] {processor.py:157} INFO - Started process (PID=44793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:27:46.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:27:46.097+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:27:46.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:27:46.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:27:46.187+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:27:46.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:27:46.214+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:27:46.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:27:46.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-15T02:28:16.417+0000] {processor.py:157} INFO - Started process (PID=44803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:28:16.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:28:16.425+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:28:16.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:28:16.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:28:16.499+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:28:16.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:28:16.515+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:28:16.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:28:16.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-15T02:28:46.728+0000] {processor.py:157} INFO - Started process (PID=44813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:28:46.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:28:46.738+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:28:46.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:28:46.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:28:46.794+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:28:46.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:28:46.818+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:28:46.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:28:46.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-15T02:29:17.201+0000] {processor.py:157} INFO - Started process (PID=44822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:29:17.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:29:17.208+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:29:17.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:29:17.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:29:17.267+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:29:17.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:29:17.283+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:29:17.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:29:17.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-15T02:29:47.516+0000] {processor.py:157} INFO - Started process (PID=44833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:29:47.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:29:47.521+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:29:47.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:29:47.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:29:47.575+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:29:47.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:29:47.591+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:29:47.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:29:47.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-15T02:30:17.709+0000] {processor.py:157} INFO - Started process (PID=44843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:30:17.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:30:17.713+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:30:17.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:30:17.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:30:17.752+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:30:17.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:30:17.766+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:30:17.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:30:17.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T02:30:48.057+0000] {processor.py:157} INFO - Started process (PID=44853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:30:48.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:30:48.062+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:30:48.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:30:48.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:30:48.094+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:30:48.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:30:48.109+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:30:48.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:30:48.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-15T02:31:18.353+0000] {processor.py:157} INFO - Started process (PID=44862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:31:18.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:31:18.364+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:31:18.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:31:18.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:31:18.414+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:31:18.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:31:18.429+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:31:18.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:31:18.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T02:31:48.657+0000] {processor.py:157} INFO - Started process (PID=44873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:31:48.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:31:48.665+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:31:48.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:31:48.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:31:48.727+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:31:48.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:31:48.742+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:31:48.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:31:48.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-15T02:32:18.956+0000] {processor.py:157} INFO - Started process (PID=44883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:32:18.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:32:18.961+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:32:18.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:32:18.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:32:19.001+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:32:19.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:32:19.017+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:32:19.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:32:19.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-15T02:32:49.281+0000] {processor.py:157} INFO - Started process (PID=44893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:32:49.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:32:49.286+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:32:49.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:32:49.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:32:49.323+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:32:49.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:32:49.340+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:32:49.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:32:49.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-15T02:33:19.681+0000] {processor.py:157} INFO - Started process (PID=44903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:33:19.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:33:19.695+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:33:19.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:33:19.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:33:19.763+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:33:19.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:33:19.796+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:33:19.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:33:19.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-15T02:33:49.970+0000] {processor.py:157} INFO - Started process (PID=44913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:33:49.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:33:49.978+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:33:49.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:33:49.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:33:50.017+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:33:50.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:33:50.031+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:33:50.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:33:50.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-15T02:34:20.338+0000] {processor.py:157} INFO - Started process (PID=44923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:34:20.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:34:20.342+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:34:20.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:34:20.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:34:20.371+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:34:20.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:34:20.382+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:34:20.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:34:20.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-15T02:34:50.781+0000] {processor.py:157} INFO - Started process (PID=44933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:34:50.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:34:50.787+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:34:50.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:34:50.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:34:50.844+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:34:50.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:34:50.864+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:34:50.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:34:50.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-15T02:35:21.202+0000] {processor.py:157} INFO - Started process (PID=44943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:35:21.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:35:21.209+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:35:21.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:35:21.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:35:21.234+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:35:21.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:35:21.245+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:35:21.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:35:21.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T02:35:51.590+0000] {processor.py:157} INFO - Started process (PID=44953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:35:51.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:35:51.594+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:35:51.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:35:51.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:35:51.636+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:35:51.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:35:51.651+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:35:51.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:35:51.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T02:36:21.957+0000] {processor.py:157} INFO - Started process (PID=44963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:36:21.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:36:21.965+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:36:21.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:36:21.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:36:22.022+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:36:22.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:36:22.037+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:36:22.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:36:22.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-15T02:36:52.353+0000] {processor.py:157} INFO - Started process (PID=44972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:36:52.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:36:52.358+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:36:52.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:36:52.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:36:52.402+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:36:52.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:36:52.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:36:52.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:36:52.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-15T02:37:22.661+0000] {processor.py:157} INFO - Started process (PID=44983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:37:22.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:37:22.664+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:37:22.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:37:22.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:37:22.692+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:37:22.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:37:22.701+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:37:22.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:37:22.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-15T02:37:52.987+0000] {processor.py:157} INFO - Started process (PID=44993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:37:52.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:37:52.992+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:37:52.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:37:53.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:37:53.032+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:37:53.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:37:53.045+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:37:53.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:37:53.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-15T02:38:23.373+0000] {processor.py:157} INFO - Started process (PID=45003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:38:23.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:38:23.376+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:38:23.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:38:23.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:38:23.405+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:38:23.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:38:23.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:38:23.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:38:23.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-15T02:38:53.776+0000] {processor.py:157} INFO - Started process (PID=45013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:38:53.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:38:53.795+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:38:53.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:38:53.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:38:53.889+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:38:53.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:38:53.908+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:38:53.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:38:53.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-15T02:39:24.089+0000] {processor.py:157} INFO - Started process (PID=45023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:39:24.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:39:24.094+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:39:24.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:39:24.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:39:24.143+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:39:24.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:39:24.159+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:39:24.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:39:24.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-15T02:39:54.464+0000] {processor.py:157} INFO - Started process (PID=45033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:39:54.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:39:54.474+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:39:54.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:39:54.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:39:54.548+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:39:54.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:39:54.568+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:39:54.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:39:54.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-15T02:40:24.786+0000] {processor.py:157} INFO - Started process (PID=45043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:40:24.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:40:24.791+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:40:24.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:40:24.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:40:24.829+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:40:24.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:40:24.843+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:40:24.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:40:24.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-15T02:40:55.067+0000] {processor.py:157} INFO - Started process (PID=45053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:40:55.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:40:55.070+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:40:55.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:40:55.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:40:55.097+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:40:55.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:40:55.109+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:40:55.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:40:55.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T02:41:25.419+0000] {processor.py:157} INFO - Started process (PID=45063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:41:25.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:41:25.422+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:41:25.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:41:25.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:41:25.449+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:41:25.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:41:25.460+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:41:25.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:41:25.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-15T02:41:55.774+0000] {processor.py:157} INFO - Started process (PID=45073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:41:55.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:41:55.777+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:41:55.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:41:55.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:41:55.804+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:41:55.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:41:55.815+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:41:55.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:41:55.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T02:42:26.103+0000] {processor.py:157} INFO - Started process (PID=45083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:42:26.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:42:26.108+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:42:26.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:42:26.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:42:26.135+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:42:26.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:42:26.146+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:42:26.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:42:26.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T02:42:56.467+0000] {processor.py:157} INFO - Started process (PID=45093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:42:56.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:42:56.470+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:42:56.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:42:56.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:42:56.505+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:42:56.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:42:56.520+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:42:56.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:42:56.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-15T02:43:26.735+0000] {processor.py:157} INFO - Started process (PID=45103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:43:26.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:43:26.739+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:43:26.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:43:26.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:43:26.773+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:43:26.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:43:26.786+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:43:26.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:43:26.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-15T02:43:57.150+0000] {processor.py:157} INFO - Started process (PID=45113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:43:57.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:43:57.155+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:43:57.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:43:57.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:43:57.211+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:43:57.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:43:57.229+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:43:57.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:43:57.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-15T02:44:27.602+0000] {processor.py:157} INFO - Started process (PID=45122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:44:27.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:44:27.609+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:44:27.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:44:27.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:44:27.668+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:44:27.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:44:27.687+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:44:27.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:44:27.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-15T02:44:57.886+0000] {processor.py:157} INFO - Started process (PID=45133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:44:57.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:44:57.893+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:44:57.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:44:57.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:44:57.941+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:44:57.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:44:57.958+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:44:57.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:44:57.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-15T02:45:28.284+0000] {processor.py:157} INFO - Started process (PID=45143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:45:28.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:45:28.290+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:45:28.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:45:28.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:45:28.330+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:45:28.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:45:28.345+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:45:28.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:45:28.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T02:45:58.700+0000] {processor.py:157} INFO - Started process (PID=45153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:45:58.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:45:58.721+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:45:58.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:45:58.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:45:58.803+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:45:58.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:45:58.821+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:45:58.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:45:58.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-15T02:46:29.025+0000] {processor.py:157} INFO - Started process (PID=45163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:46:29.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:46:29.030+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:46:29.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:46:29.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:46:29.075+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:46:29.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:46:29.091+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:46:29.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:46:29.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T02:46:59.369+0000] {processor.py:157} INFO - Started process (PID=45173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:46:59.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:46:59.378+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:46:59.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:46:59.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:46:59.407+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:46:59.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:46:59.423+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:46:59.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:46:59.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-15T02:47:29.835+0000] {processor.py:157} INFO - Started process (PID=45183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:47:29.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:47:29.842+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:47:29.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:47:29.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:47:29.890+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:47:29.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:47:29.904+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:47:29.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:47:29.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-15T02:48:00.195+0000] {processor.py:157} INFO - Started process (PID=45193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:48:00.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:48:00.220+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:48:00.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:48:00.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:48:00.290+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:48:00.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:48:00.306+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:48:00.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:48:00.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-15T02:48:30.495+0000] {processor.py:157} INFO - Started process (PID=45203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:48:30.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:48:30.499+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:48:30.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:48:30.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:48:30.534+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:48:30.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:48:30.545+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:48:30.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:48:30.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-15T02:49:00.874+0000] {processor.py:157} INFO - Started process (PID=45213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:49:00.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:49:00.887+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:49:00.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:49:00.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:49:00.964+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:49:00.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:49:00.984+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:49:00.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:49:00.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-15T02:49:31.233+0000] {processor.py:157} INFO - Started process (PID=45223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:49:31.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:49:31.241+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:49:31.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:49:31.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:49:31.279+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:49:31.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:49:31.304+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:49:31.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:49:31.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T02:50:01.597+0000] {processor.py:157} INFO - Started process (PID=45233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:50:01.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:50:01.601+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:50:01.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:50:01.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:50:01.638+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:50:01.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:50:01.652+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:50:01.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:50:01.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-15T02:50:31.907+0000] {processor.py:157} INFO - Started process (PID=45243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:50:31.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:50:31.911+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:50:31.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:50:31.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:50:31.960+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:50:31.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:50:31.975+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:50:31.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:50:31.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-15T02:51:02.246+0000] {processor.py:157} INFO - Started process (PID=45253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:51:02.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:51:02.253+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:51:02.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:51:02.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:51:02.293+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:51:02.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:51:02.305+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:51:02.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:51:02.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-15T02:51:32.746+0000] {processor.py:157} INFO - Started process (PID=45263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:51:32.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:51:32.757+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:51:32.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:51:32.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:51:32.836+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:51:32.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:51:32.854+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:51:32.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:51:32.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-15T02:52:03.207+0000] {processor.py:157} INFO - Started process (PID=45273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:52:03.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:52:03.214+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:52:03.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:52:03.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:52:03.272+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:52:03.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:52:03.287+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:52:03.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:52:03.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-15T02:52:33.602+0000] {processor.py:157} INFO - Started process (PID=45283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:52:33.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:52:33.611+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:52:33.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:52:33.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:52:33.661+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:52:33.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:52:33.676+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:52:33.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:52:33.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-15T02:53:03.883+0000] {processor.py:157} INFO - Started process (PID=45293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:53:03.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:53:03.889+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:53:03.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:53:03.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:53:03.926+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:53:03.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:53:03.941+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:53:03.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:53:03.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T02:53:34.219+0000] {processor.py:157} INFO - Started process (PID=45303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:53:34.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:53:34.226+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:53:34.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:53:34.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:53:34.252+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:53:34.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:53:34.264+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:53:34.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:53:34.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T02:54:04.616+0000] {processor.py:157} INFO - Started process (PID=45313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:54:04.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:54:04.623+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:54:04.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:54:04.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:54:04.680+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:54:04.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:54:04.697+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:54:04.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:54:04.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-15T02:54:34.942+0000] {processor.py:157} INFO - Started process (PID=45323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:54:34.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:54:34.951+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:54:34.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:54:34.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:54:35.027+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:54:35.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:54:35.041+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:54:35.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:54:35.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-15T02:55:05.158+0000] {processor.py:157} INFO - Started process (PID=45333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:55:05.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:55:05.163+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:55:05.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:55:05.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:55:05.206+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:55:05.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:55:05.223+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:55:05.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:55:05.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-15T02:55:35.582+0000] {processor.py:157} INFO - Started process (PID=45343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:55:35.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:55:35.594+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:55:35.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:55:35.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:55:35.656+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:55:35.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:55:35.680+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:55:35.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:55:35.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-15T02:56:05.958+0000] {processor.py:157} INFO - Started process (PID=45353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:56:05.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:56:05.967+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:56:05.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:56:05.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:56:06.036+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:56:06.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:56:06.059+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:56:06.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:56:06.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-15T02:56:36.234+0000] {processor.py:157} INFO - Started process (PID=45363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:56:36.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:56:36.241+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:56:36.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:56:36.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:56:36.280+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:56:36.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:56:36.293+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:56:36.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:56:36.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-15T02:57:06.585+0000] {processor.py:157} INFO - Started process (PID=45373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:57:06.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:57:06.591+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:57:06.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:57:06.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:57:06.631+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:57:06.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:57:06.647+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:57:06.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:57:06.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-15T02:57:36.863+0000] {processor.py:157} INFO - Started process (PID=45383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:57:36.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:57:36.866+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:57:36.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:57:36.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:57:36.902+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:57:36.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:57:36.918+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:57:36.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:57:36.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-15T02:58:07.152+0000] {processor.py:157} INFO - Started process (PID=45393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:58:07.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:58:07.156+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:58:07.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:58:07.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:58:07.193+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:58:07.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:58:07.212+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:58:07.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:58:07.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-15T02:58:37.542+0000] {processor.py:157} INFO - Started process (PID=45403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:58:37.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:58:37.544+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:58:37.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:58:37.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:58:37.571+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:58:37.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:58:37.581+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:58:37.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:58:37.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T02:59:07.971+0000] {processor.py:157} INFO - Started process (PID=45413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:59:07.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:59:07.977+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:59:07.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:59:07.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:59:08.020+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:59:08.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:59:08.037+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:59:08.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:59:08.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-15T02:59:38.251+0000] {processor.py:157} INFO - Started process (PID=45423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:59:38.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T02:59:38.254+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:59:38.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:59:38.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T02:59:38.294+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:59:38.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T02:59:38.309+0000] {logging_mixin.py:151} INFO - [2024-08-15T02:59:38.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T02:59:38.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T03:00:08.687+0000] {processor.py:157} INFO - Started process (PID=45433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:00:08.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:00:08.694+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:00:08.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:00:08.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:00:08.749+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:00:08.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:00:08.768+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:00:08.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:00:08.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-15T03:00:38.962+0000] {processor.py:157} INFO - Started process (PID=45443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:00:38.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:00:38.967+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:00:38.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:00:38.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:00:39.010+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:00:39.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:00:39.026+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:00:39.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:00:39.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-15T03:01:09.227+0000] {processor.py:157} INFO - Started process (PID=45453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:01:09.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:01:09.230+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:01:09.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:01:09.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:01:09.262+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:01:09.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:01:09.272+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:01:09.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:01:09.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-15T03:01:39.589+0000] {processor.py:157} INFO - Started process (PID=45463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:01:39.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:01:39.591+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:01:39.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:01:39.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:01:39.623+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:01:39.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:01:39.638+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:01:39.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:01:39.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-15T03:02:09.992+0000] {processor.py:157} INFO - Started process (PID=45472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:02:09.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:02:10.005+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:02:10.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:02:10.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:02:10.063+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:02:10.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:02:10.084+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:02:10.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:02:10.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-15T03:02:40.351+0000] {processor.py:157} INFO - Started process (PID=45483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:02:40.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:02:40.357+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:02:40.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:02:40.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:02:40.398+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:02:40.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:02:40.412+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:02:40.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:02:40.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-15T03:03:10.811+0000] {processor.py:157} INFO - Started process (PID=45493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:03:10.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:03:10.819+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:03:10.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:03:10.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:03:10.889+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:03:10.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:03:10.918+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:03:10.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:03:10.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-15T03:03:41.146+0000] {processor.py:157} INFO - Started process (PID=45503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:03:41.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:03:41.153+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:03:41.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:03:41.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:03:41.197+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:03:41.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:03:41.224+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:03:41.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:03:41.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-15T03:04:11.468+0000] {processor.py:157} INFO - Started process (PID=45513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:04:11.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:04:11.475+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:04:11.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:04:11.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:04:11.528+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:04:11.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:04:11.550+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:04:11.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:04:11.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-15T03:04:41.844+0000] {processor.py:157} INFO - Started process (PID=45523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:04:41.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:04:41.849+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:04:41.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:04:41.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:04:41.926+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:04:41.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:04:41.947+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:04:41.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:04:41.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-15T03:05:12.204+0000] {processor.py:157} INFO - Started process (PID=45533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:05:12.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:05:12.208+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:05:12.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:05:12.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:05:12.254+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:05:12.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:05:12.267+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:05:12.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:05:12.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-15T03:05:42.563+0000] {processor.py:157} INFO - Started process (PID=45543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:05:42.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:05:42.569+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:05:42.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:05:42.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:05:42.604+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:05:42.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:05:42.618+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:05:42.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:05:42.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-15T03:06:12.970+0000] {processor.py:157} INFO - Started process (PID=45552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:06:12.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:06:12.977+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:06:12.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:06:12.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:06:13.036+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:06:13.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:06:13.054+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:06:13.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:06:13.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-15T03:06:43.775+0000] {processor.py:157} INFO - Started process (PID=45563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:06:43.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:06:43.781+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:06:43.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:06:43.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:06:43.837+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:06:43.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:06:43.858+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:06:43.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:06:43.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-15T03:07:14.171+0000] {processor.py:157} INFO - Started process (PID=45572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:07:14.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:07:14.183+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:07:14.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:07:14.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:07:14.274+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:07:14.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:07:14.366+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:07:14.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:07:14.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-08-15T03:07:44.528+0000] {processor.py:157} INFO - Started process (PID=45583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:07:44.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:07:44.543+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:07:44.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:07:44.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:07:44.625+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:07:44.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:07:44.644+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:07:44.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:07:44.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-15T03:08:15.399+0000] {processor.py:157} INFO - Started process (PID=45593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:08:15.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:08:15.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:08:15.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:08:15.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:08:15.496+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:08:15.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:08:15.536+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:08:15.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:08:15.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-15T03:08:45.958+0000] {processor.py:157} INFO - Started process (PID=45603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:08:45.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:08:45.963+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:08:45.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:08:45.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:08:46.014+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:08:46.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:08:46.031+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:08:46.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:08:46.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-15T03:09:16.402+0000] {processor.py:157} INFO - Started process (PID=45612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:09:16.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:09:16.407+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:09:16.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:09:16.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:09:16.466+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:09:16.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:09:16.481+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:09:16.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:09:16.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-15T03:09:46.741+0000] {processor.py:157} INFO - Started process (PID=45623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:09:46.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:09:46.783+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:09:46.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:09:46.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:09:46.850+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:09:46.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:09:46.873+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:09:46.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:09:46.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-15T03:10:17.107+0000] {processor.py:157} INFO - Started process (PID=45633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:10:17.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:10:17.114+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:10:17.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:10:17.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:10:17.165+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:10:17.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:10:17.184+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:10:17.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:10:17.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-15T03:10:47.552+0000] {processor.py:157} INFO - Started process (PID=45643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:10:47.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:10:47.559+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:10:47.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:10:47.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:10:47.622+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:10:47.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:10:47.642+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:10:47.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:10:47.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-15T03:11:18.231+0000] {processor.py:157} INFO - Started process (PID=45653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:11:18.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:11:18.245+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:11:18.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:11:18.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:11:18.290+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:11:18.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:11:18.314+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:11:18.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:11:18.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-15T03:11:48.916+0000] {processor.py:157} INFO - Started process (PID=45663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:11:48.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:11:48.928+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:11:48.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:11:48.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:11:49.003+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:11:49.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:11:49.021+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:11:49.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:11:49.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-15T03:12:19.303+0000] {processor.py:157} INFO - Started process (PID=45673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:12:19.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:12:19.317+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:12:19.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:12:19.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:12:19.407+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:12:19.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:12:19.432+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:12:19.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:12:19.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-15T03:12:49.787+0000] {processor.py:157} INFO - Started process (PID=45683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:12:49.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:12:49.801+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:12:49.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:12:49.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:12:49.844+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:12:49.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:12:49.868+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:12:49.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:12:49.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-15T03:13:20.095+0000] {processor.py:157} INFO - Started process (PID=45693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:13:20.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:13:20.103+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:13:20.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:13:20.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:13:20.141+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:13:20.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:13:20.156+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:13:20.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:13:20.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-15T03:13:50.561+0000] {processor.py:157} INFO - Started process (PID=45703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:13:50.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:13:50.570+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:13:50.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:13:50.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:13:50.614+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:13:50.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:13:50.629+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:13:50.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:13:50.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-15T03:14:20.850+0000] {processor.py:157} INFO - Started process (PID=45713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:14:20.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:14:20.856+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:14:20.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:14:20.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:14:20.900+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:14:20.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:14:20.915+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:14:20.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:14:20.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-15T03:14:51.158+0000] {processor.py:157} INFO - Started process (PID=45723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:14:51.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:14:51.165+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:14:51.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:14:51.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:14:51.230+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:14:51.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:14:51.244+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:14:51.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:14:51.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-15T03:15:21.490+0000] {processor.py:157} INFO - Started process (PID=45733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:15:21.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:15:21.497+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:15:21.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:15:21.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:15:21.588+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:15:21.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:15:21.615+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:15:21.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:15:21.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-15T03:15:51.782+0000] {processor.py:157} INFO - Started process (PID=45743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:15:51.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:15:51.805+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:15:51.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:15:51.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:15:52.053+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:15:52.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:15:52.084+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:15:52.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:15:52.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.331 seconds
[2024-08-15T03:16:22.220+0000] {processor.py:157} INFO - Started process (PID=45753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:16:22.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:16:22.230+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:16:22.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:16:22.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:16:22.278+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:16:22.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:16:22.295+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:16:22.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:16:22.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-15T03:16:52.585+0000] {processor.py:157} INFO - Started process (PID=45763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:16:52.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:16:52.590+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:16:52.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:16:52.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:16:52.645+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:16:52.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:16:52.658+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:16:52.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:16:52.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T03:17:22.920+0000] {processor.py:157} INFO - Started process (PID=45773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:17:22.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:17:22.925+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:17:22.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:17:22.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:17:22.979+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:17:22.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:17:22.995+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:17:22.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:17:23.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-15T03:17:53.256+0000] {processor.py:157} INFO - Started process (PID=45783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:17:53.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:17:53.263+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:17:53.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:17:53.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:17:53.338+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:17:53.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:17:53.361+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:17:53.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:17:53.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-15T03:18:23.592+0000] {processor.py:157} INFO - Started process (PID=45793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:18:23.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:18:23.597+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:18:23.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:18:23.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:18:23.638+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:18:23.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:18:23.652+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:18:23.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:18:23.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-15T03:18:53.942+0000] {processor.py:157} INFO - Started process (PID=45803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:18:53.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:18:53.944+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:18:53.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:18:53.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:18:53.969+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:18:53.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:18:53.979+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:18:53.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:18:53.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-15T03:19:24.261+0000] {processor.py:157} INFO - Started process (PID=45813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:19:24.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:19:24.270+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:19:24.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:19:24.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:19:24.328+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:19:24.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:19:24.346+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:19:24.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:19:24.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-15T03:19:54.589+0000] {processor.py:157} INFO - Started process (PID=45823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:19:54.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:19:54.594+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:19:54.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:19:54.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:19:54.643+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:19:54.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:19:54.662+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:19:54.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:19:54.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T03:20:24.928+0000] {processor.py:157} INFO - Started process (PID=45833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:20:24.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:20:24.932+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:20:24.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:20:24.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:20:24.976+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:20:24.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:20:24.992+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:20:24.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:20:25.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-15T03:20:55.326+0000] {processor.py:157} INFO - Started process (PID=45843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:20:55.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:20:55.334+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:20:55.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:20:55.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:20:55.377+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:20:55.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:20:55.392+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:20:55.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:20:55.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T03:21:25.762+0000] {processor.py:157} INFO - Started process (PID=45853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:21:25.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:21:25.783+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:21:25.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:21:25.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:21:26.019+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:21:26.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:21:26.069+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:21:26.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:21:26.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.348 seconds
[2024-08-15T03:21:56.369+0000] {processor.py:157} INFO - Started process (PID=45863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:21:56.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:21:56.376+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:21:56.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:21:56.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:21:56.405+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:21:56.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:21:56.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:21:56.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:21:56.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-15T03:22:26.705+0000] {processor.py:157} INFO - Started process (PID=45872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:22:26.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:22:26.710+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:22:26.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:22:26.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:22:26.761+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:22:26.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:22:26.779+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:22:26.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:22:26.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T03:22:57.012+0000] {processor.py:157} INFO - Started process (PID=45883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:22:57.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:22:57.017+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:22:57.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:22:57.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:22:57.054+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:22:57.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:22:57.069+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:22:57.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:22:57.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-15T03:23:27.379+0000] {processor.py:157} INFO - Started process (PID=45893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:23:27.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:23:27.384+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:23:27.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:23:27.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:23:27.413+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:23:27.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:23:27.424+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:23:27.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:23:27.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-15T03:23:57.791+0000] {processor.py:157} INFO - Started process (PID=45902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:23:57.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:23:57.797+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:23:57.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:23:57.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:23:57.842+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:23:57.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:23:57.861+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:23:57.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:23:57.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-15T03:24:28.131+0000] {processor.py:157} INFO - Started process (PID=45913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:24:28.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:24:28.138+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:24:28.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:24:28.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:24:28.166+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:24:28.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:24:28.178+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:24:28.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:24:28.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-15T03:24:58.489+0000] {processor.py:157} INFO - Started process (PID=45923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:24:58.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:24:58.501+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:24:58.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:24:58.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:24:58.547+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:24:58.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:24:58.564+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:24:58.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:24:58.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-15T03:25:28.913+0000] {processor.py:157} INFO - Started process (PID=45933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:25:28.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:25:28.916+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:25:28.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:25:28.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:25:28.947+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:25:28.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:25:28.960+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:25:28.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:25:28.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-15T03:25:59.354+0000] {processor.py:157} INFO - Started process (PID=45943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:25:59.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:25:59.363+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:25:59.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:25:59.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:25:59.443+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:25:59.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:25:59.474+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:25:59.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:25:59.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-15T03:26:29.934+0000] {processor.py:157} INFO - Started process (PID=45953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:26:29.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:26:29.944+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:26:29.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:26:29.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:26:30.017+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:26:30.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:26:30.037+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:26:30.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:26:30.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-15T03:27:00.168+0000] {processor.py:157} INFO - Started process (PID=45963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:27:00.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:27:00.175+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:27:00.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:27:00.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:27:00.203+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:27:00.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:27:00.213+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:27:00.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:27:00.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-15T03:27:30.546+0000] {processor.py:157} INFO - Started process (PID=45973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:27:30.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:27:30.566+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:27:30.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:27:30.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:27:30.640+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:27:30.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:27:30.681+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:27:30.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:27:30.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-15T03:28:00.937+0000] {processor.py:157} INFO - Started process (PID=45983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:28:00.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:28:00.949+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:28:00.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:28:01.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:28:01.056+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:28:01.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:28:01.082+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:28:01.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:28:01.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-15T03:28:31.331+0000] {processor.py:157} INFO - Started process (PID=45993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:28:31.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:28:31.339+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:28:31.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:28:31.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:28:31.392+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:28:31.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:28:31.408+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:28:31.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:28:31.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-15T03:29:01.642+0000] {processor.py:157} INFO - Started process (PID=46003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:29:01.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:29:01.647+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:29:01.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:29:01.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:29:01.697+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:29:01.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:29:01.714+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:29:01.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:29:01.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T03:29:31.933+0000] {processor.py:157} INFO - Started process (PID=46013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:29:31.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:29:31.936+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:29:31.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:29:31.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:29:31.972+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:29:31.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:29:31.986+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:29:31.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:29:31.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-15T03:30:02.452+0000] {processor.py:157} INFO - Started process (PID=46023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:30:02.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:30:02.461+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:30:02.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:30:02.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:30:02.551+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:30:02.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:30:02.569+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:30:02.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:30:02.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-15T03:30:32.871+0000] {processor.py:157} INFO - Started process (PID=46033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:30:32.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:30:32.904+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:30:32.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:30:32.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:30:32.997+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:30:32.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:30:33.032+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:30:33.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:30:33.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-08-15T03:31:03.167+0000] {processor.py:157} INFO - Started process (PID=46042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:31:03.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:31:03.175+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:31:03.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:31:03.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:31:03.235+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:31:03.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:31:03.249+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:31:03.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:31:03.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-15T03:31:33.535+0000] {processor.py:157} INFO - Started process (PID=46053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:31:33.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:31:33.539+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:31:33.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:31:33.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:31:33.583+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:31:33.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:31:33.597+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:31:33.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:31:33.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-15T03:32:03.842+0000] {processor.py:157} INFO - Started process (PID=46063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:32:03.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:32:03.849+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:32:03.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:32:03.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:32:03.892+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:32:03.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:32:03.907+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:32:03.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:32:03.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-15T03:32:34.253+0000] {processor.py:157} INFO - Started process (PID=46073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:32:34.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:32:34.266+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:32:34.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:32:34.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:32:34.326+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:32:34.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:32:34.346+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:32:34.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:32:34.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-15T03:33:04.522+0000] {processor.py:157} INFO - Started process (PID=46083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:33:04.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:33:04.527+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:33:04.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:33:04.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:33:04.584+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:33:04.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:33:04.599+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:33:04.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:33:04.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-15T03:33:34.950+0000] {processor.py:157} INFO - Started process (PID=46093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:33:34.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:33:34.959+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:33:34.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:33:34.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:33:35.011+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:33:35.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:33:35.027+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:33:35.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:33:35.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-15T03:34:05.260+0000] {processor.py:157} INFO - Started process (PID=46103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:34:05.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:34:05.268+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:34:05.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:34:05.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:34:05.334+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:34:05.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:34:05.357+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:34:05.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:34:05.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-15T03:34:35.595+0000] {processor.py:157} INFO - Started process (PID=46113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:34:35.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:34:35.604+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:34:35.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:34:35.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:34:35.670+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:34:35.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:34:35.684+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:34:35.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:34:35.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-15T03:35:05.944+0000] {processor.py:157} INFO - Started process (PID=46123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:35:05.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:35:05.951+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:35:05.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:35:05.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:35:06.004+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:35:06.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:35:06.019+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:35:06.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:35:06.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T03:35:36.289+0000] {processor.py:157} INFO - Started process (PID=46131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:35:36.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:35:36.301+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:35:36.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:35:36.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:35:36.395+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:35:36.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:35:36.415+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:35:36.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:35:36.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-15T03:36:06.580+0000] {processor.py:157} INFO - Started process (PID=46143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:36:06.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:36:06.589+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:36:06.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:36:06.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:36:06.641+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:36:06.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:36:06.659+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:36:06.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:36:06.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-15T03:36:36.987+0000] {processor.py:157} INFO - Started process (PID=46153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:36:36.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:36:36.991+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:36:36.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:36:37.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:36:37.034+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:36:37.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:36:37.051+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:36:37.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:36:37.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-15T03:37:07.512+0000] {processor.py:157} INFO - Started process (PID=46163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:37:07.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:37:07.532+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:37:07.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:37:07.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:37:07.598+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:37:07.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:37:07.618+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:37:07.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:37:07.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-15T03:37:37.949+0000] {processor.py:157} INFO - Started process (PID=46173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:37:37.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:37:37.962+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:37:37.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:37:37.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:37:38.016+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:37:38.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:37:38.044+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:37:38.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:37:38.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-15T03:38:08.564+0000] {processor.py:157} INFO - Started process (PID=46183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:38:08.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:38:08.574+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:38:08.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:38:08.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:38:08.652+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:38:08.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:38:08.678+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:38:08.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:38:08.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-15T03:38:38.826+0000] {processor.py:157} INFO - Started process (PID=46193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:38:38.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:38:38.829+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:38:38.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:38:38.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:38:38.857+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:38:38.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:38:38.867+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:38:38.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:38:38.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T03:39:09.141+0000] {processor.py:157} INFO - Started process (PID=46203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:39:09.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:39:09.145+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:39:09.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:39:09.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:39:09.173+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:39:09.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:39:09.182+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:39:09.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:39:09.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-15T03:39:39.484+0000] {processor.py:157} INFO - Started process (PID=46213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:39:39.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:39:39.490+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:39:39.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:39:39.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:39:39.537+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:39:39.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:39:39.556+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:39:39.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:39:39.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T03:40:09.756+0000] {processor.py:157} INFO - Started process (PID=46223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:40:09.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:40:09.759+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:40:09.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:40:09.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:40:09.794+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:40:09.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:40:09.809+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:40:09.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:40:09.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-15T03:40:40.112+0000] {processor.py:157} INFO - Started process (PID=46233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:40:40.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:40:40.116+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:40:40.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:40:40.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:40:40.147+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:40:40.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:40:40.163+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:40:40.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:40:40.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-15T03:41:10.402+0000] {processor.py:157} INFO - Started process (PID=46243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:41:10.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:41:10.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:41:10.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:41:10.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:41:10.474+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:41:10.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:41:10.489+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:41:10.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:41:10.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-15T03:41:40.754+0000] {processor.py:157} INFO - Started process (PID=46253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:41:40.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:41:40.756+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:41:40.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:41:40.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:41:40.785+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:41:40.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:41:40.796+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:41:40.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:41:40.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T03:42:11.088+0000] {processor.py:157} INFO - Started process (PID=46263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:42:11.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:42:11.093+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:42:11.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:42:11.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:42:11.134+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:42:11.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:42:11.148+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:42:11.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:42:11.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T03:42:41.367+0000] {processor.py:157} INFO - Started process (PID=46273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:42:41.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:42:41.370+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:42:41.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:42:41.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:42:41.399+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:42:41.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:42:41.410+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:42:41.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:42:41.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T03:43:11.652+0000] {processor.py:157} INFO - Started process (PID=46283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:43:11.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:43:11.656+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:43:11.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:43:11.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:43:11.694+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:43:11.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:43:11.705+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:43:11.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:43:11.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-15T03:43:42.020+0000] {processor.py:157} INFO - Started process (PID=46293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:43:42.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:43:42.027+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:43:42.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:43:42.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:43:42.073+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:43:42.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:43:42.086+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:43:42.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:43:42.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-15T03:44:12.395+0000] {processor.py:157} INFO - Started process (PID=46303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:44:12.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:44:12.403+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:44:12.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:44:12.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:44:12.445+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:44:12.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:44:12.461+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:44:12.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:44:12.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-15T03:44:42.700+0000] {processor.py:157} INFO - Started process (PID=46313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:44:42.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:44:42.706+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:44:42.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:44:42.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:44:42.754+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:44:42.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:44:42.774+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:44:42.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:44:42.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-15T03:45:12.995+0000] {processor.py:157} INFO - Started process (PID=46323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:45:12.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:45:12.998+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:45:12.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:45:13.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:45:13.053+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:45:13.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:45:13.067+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:45:13.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:45:13.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T03:45:43.392+0000] {processor.py:157} INFO - Started process (PID=46333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:45:43.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:45:43.402+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:45:43.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:45:43.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:45:43.441+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:45:43.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:45:43.454+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:45:43.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:45:43.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-15T03:46:13.693+0000] {processor.py:157} INFO - Started process (PID=46343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:46:13.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:46:13.697+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:46:13.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:46:13.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:46:13.725+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:46:13.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:46:13.736+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:46:13.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:46:13.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T03:46:44.120+0000] {processor.py:157} INFO - Started process (PID=46352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:46:44.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:46:44.127+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:46:44.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:46:44.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:46:44.170+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:46:44.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:46:44.186+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:46:44.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:46:44.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T03:47:14.408+0000] {processor.py:157} INFO - Started process (PID=46363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:47:14.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:47:14.416+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:47:14.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:47:14.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:47:14.457+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:47:14.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:47:14.478+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:47:14.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:47:14.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-15T03:47:44.675+0000] {processor.py:157} INFO - Started process (PID=46373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:47:44.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:47:44.680+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:47:44.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:47:44.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:47:44.732+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:47:44.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:47:44.770+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:47:44.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:47:44.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-15T03:48:14.989+0000] {processor.py:157} INFO - Started process (PID=46383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:48:14.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:48:14.996+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:48:14.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:48:15.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:48:15.049+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:48:15.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:48:15.072+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:48:15.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:48:15.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-15T03:48:45.449+0000] {processor.py:157} INFO - Started process (PID=46393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:48:45.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:48:45.459+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:48:45.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:48:45.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:48:45.527+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:48:45.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:48:45.553+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:48:45.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:48:45.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-15T03:49:15.846+0000] {processor.py:157} INFO - Started process (PID=46403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:49:15.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:49:15.853+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:49:15.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:49:15.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:49:15.914+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:49:15.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:49:15.931+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:49:15.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:49:15.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-15T03:49:46.198+0000] {processor.py:157} INFO - Started process (PID=46413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:49:46.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:49:46.206+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:49:46.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:49:46.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:49:46.278+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:49:46.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:49:46.295+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:49:46.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:49:46.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-15T03:50:16.550+0000] {processor.py:157} INFO - Started process (PID=46422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:50:16.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:50:16.566+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:50:16.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:50:16.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:50:16.629+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:50:16.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:50:16.663+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:50:16.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:50:16.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-15T03:50:46.884+0000] {processor.py:157} INFO - Started process (PID=46433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:50:46.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:50:46.892+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:50:46.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:50:46.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:50:46.980+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:50:46.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:50:47.002+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:50:47.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:50:47.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-15T03:51:17.214+0000] {processor.py:157} INFO - Started process (PID=46443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:51:17.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:51:17.221+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:51:17.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:51:17.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:51:17.271+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:51:17.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:51:17.287+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:51:17.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:51:17.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T03:51:47.591+0000] {processor.py:157} INFO - Started process (PID=46453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:51:47.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:51:47.605+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:51:47.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:51:47.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:51:47.681+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:51:47.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:51:47.711+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:51:47.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:51:47.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-15T03:52:17.938+0000] {processor.py:157} INFO - Started process (PID=46463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:52:17.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:52:17.946+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:52:17.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:52:17.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:52:17.993+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:52:17.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:52:18.009+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:52:18.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:52:18.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T03:52:48.409+0000] {processor.py:157} INFO - Started process (PID=46473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:52:48.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:52:48.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:52:48.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:52:48.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:52:48.485+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:52:48.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:52:48.511+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:52:48.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:52:48.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-15T03:53:31.662+0000] {processor.py:157} INFO - Started process (PID=46483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:53:31.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:53:31.666+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:53:31.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:53:31.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:53:31.695+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:53:31.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:53:31.708+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:53:31.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:53:31.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-15T03:54:02.313+0000] {processor.py:157} INFO - Started process (PID=46495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:54:02.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:54:02.318+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:54:02.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:54:02.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:54:02.386+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:54:02.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:54:02.415+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:54:02.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:54:02.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-15T03:54:32.567+0000] {processor.py:157} INFO - Started process (PID=46505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:54:32.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T03:54:32.570+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:54:32.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:54:32.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T03:54:32.599+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:54:32.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T03:54:32.611+0000] {logging_mixin.py:151} INFO - [2024-08-15T03:54:32.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T03:54:32.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T04:10:11.313+0000] {processor.py:157} INFO - Started process (PID=46515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:10:11.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:10:11.322+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:10:11.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:10:11.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:10:11.419+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:10:11.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:10:11.450+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:10:11.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:10:11.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-15T04:10:41.680+0000] {processor.py:157} INFO - Started process (PID=46527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:10:41.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:10:41.686+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:10:41.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:10:41.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:10:41.732+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:10:41.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:10:41.748+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:10:41.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:10:41.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-15T04:11:12.000+0000] {processor.py:157} INFO - Started process (PID=46537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:11:12.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:11:12.008+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:11:12.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:11:12.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:11:12.036+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:11:12.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:11:12.047+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:11:12.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:11:12.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-15T04:27:26.070+0000] {processor.py:157} INFO - Started process (PID=46549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:27:26.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:27:26.078+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:27:26.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:27:26.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:27:26.132+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:27:26.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:27:26.148+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:27:26.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:27:26.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-15T04:27:56.423+0000] {processor.py:157} INFO - Started process (PID=46558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:27:56.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:27:56.428+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:27:56.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:27:56.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:27:56.479+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:27:56.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:27:56.492+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:27:56.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:27:56.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-15T04:28:26.781+0000] {processor.py:157} INFO - Started process (PID=46569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:28:26.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:28:26.784+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:28:26.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:28:26.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:28:26.816+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:28:26.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:28:26.831+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:28:26.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:28:26.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-15T04:28:57.030+0000] {processor.py:157} INFO - Started process (PID=46579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:28:57.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:28:57.033+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:28:57.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:28:57.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:28:57.069+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:28:57.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:28:57.079+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:28:57.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:28:57.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-15T04:29:27.403+0000] {processor.py:157} INFO - Started process (PID=46588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:29:27.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:29:27.410+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:29:27.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:29:27.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:29:27.455+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:29:27.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:29:27.470+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:29:27.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:29:27.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-15T04:45:35.554+0000] {processor.py:157} INFO - Started process (PID=46598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:45:35.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T04:45:35.560+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:45:35.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:45:35.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T04:45:35.604+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:45:35.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T04:45:35.617+0000] {logging_mixin.py:151} INFO - [2024-08-15T04:45:35.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T04:45:35.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-15T05:01:24.011+0000] {processor.py:157} INFO - Started process (PID=46611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:01:24.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:01:24.025+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:01:24.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:01:24.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:01:24.077+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:01:24.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:01:24.104+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:01:24.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:01:24.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-15T05:01:54.372+0000] {processor.py:157} INFO - Started process (PID=46621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:01:54.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:01:54.382+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:01:54.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:01:54.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:01:54.453+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:01:54.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:01:54.466+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:01:54.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:01:54.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-15T05:17:46.813+0000] {processor.py:157} INFO - Started process (PID=46633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:17:46.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:17:46.821+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:17:46.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:17:46.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:17:46.883+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:17:46.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:17:46.899+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:17:46.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:17:46.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-15T05:18:17.161+0000] {processor.py:157} INFO - Started process (PID=46642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:18:17.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:18:17.171+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:18:17.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:18:17.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:18:17.214+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:18:17.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:18:17.228+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:18:17.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:18:17.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-15T05:18:47.517+0000] {processor.py:157} INFO - Started process (PID=46653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:18:47.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:18:47.520+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:18:47.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:18:47.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:18:47.543+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:18:47.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:18:47.551+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:18:47.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:18:47.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-15T05:19:17.827+0000] {processor.py:157} INFO - Started process (PID=46663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:19:17.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:19:17.832+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:19:17.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:19:17.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:19:17.869+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:19:17.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:19:17.882+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:19:17.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:19:17.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-15T05:19:48.202+0000] {processor.py:157} INFO - Started process (PID=46673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:19:48.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:19:48.204+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:19:48.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:19:48.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:19:48.231+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:19:48.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:19:48.241+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:19:48.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:19:48.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T05:20:18.553+0000] {processor.py:157} INFO - Started process (PID=46683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:20:18.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:20:18.557+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:20:18.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:20:18.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:20:18.584+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:20:18.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:20:18.594+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:20:18.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:20:18.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T05:37:17.947+0000] {processor.py:157} INFO - Started process (PID=46695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:37:17.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:37:17.951+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:37:17.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:37:17.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:37:17.984+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:37:17.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:37:17.996+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:37:17.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:37:18.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-15T05:37:48.382+0000] {processor.py:157} INFO - Started process (PID=46705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:37:48.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:37:48.387+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:37:48.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:37:48.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:37:48.450+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:37:48.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:37:48.469+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:37:48.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:37:48.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-15T05:53:36.436+0000] {processor.py:157} INFO - Started process (PID=46715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:53:36.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:53:36.448+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:53:36.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:53:36.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:53:36.550+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:53:36.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:53:36.576+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:53:36.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:53:36.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-15T05:54:06.749+0000] {processor.py:157} INFO - Started process (PID=46724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:54:06.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:54:06.759+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:54:06.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:54:06.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:54:06.803+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:54:06.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:54:06.827+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:54:06.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:54:06.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-15T05:54:37.129+0000] {processor.py:157} INFO - Started process (PID=46735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:54:37.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T05:54:37.132+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:54:37.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:54:37.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T05:54:37.161+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:54:37.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T05:54:37.171+0000] {logging_mixin.py:151} INFO - [2024-08-15T05:54:37.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T05:54:37.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T06:12:14.769+0000] {processor.py:157} INFO - Started process (PID=46745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:12:14.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:12:14.790+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:12:14.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:12:14.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:12:14.887+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:12:14.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:12:14.908+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:12:14.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:12:14.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-15T06:12:45.272+0000] {processor.py:157} INFO - Started process (PID=46756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:12:45.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:12:45.278+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:12:45.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:12:45.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:12:45.325+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:12:45.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:12:45.341+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:12:45.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:12:45.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-15T06:13:15.581+0000] {processor.py:157} INFO - Started process (PID=46767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:13:15.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:13:15.584+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:13:15.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:13:15.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:13:15.611+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:13:15.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:13:15.626+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:13:15.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:13:15.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-15T06:13:45.950+0000] {processor.py:157} INFO - Started process (PID=46777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:13:45.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:13:45.953+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:13:45.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:13:45.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:13:45.979+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:13:45.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:13:45.989+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:13:45.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:13:45.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-15T06:14:16.263+0000] {processor.py:157} INFO - Started process (PID=46787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:14:16.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:14:16.268+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:14:16.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:14:16.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:14:16.307+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:14:16.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:14:16.321+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:14:16.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:14:16.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-15T06:14:46.638+0000] {processor.py:157} INFO - Started process (PID=46797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:14:46.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:14:46.641+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:14:46.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:14:46.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:14:46.672+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:14:46.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:14:46.685+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:14:46.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:14:46.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-15T06:15:17.002+0000] {processor.py:157} INFO - Started process (PID=46807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:15:17.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:15:17.005+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:15:17.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:15:17.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:15:17.034+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:15:17.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:15:17.045+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:15:17.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:15:17.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-15T06:15:47.399+0000] {processor.py:157} INFO - Started process (PID=46817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:15:47.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:15:47.404+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:15:47.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:15:47.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:15:47.449+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:15:47.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:15:47.466+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:15:47.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:15:47.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-15T06:32:59.605+0000] {processor.py:157} INFO - Started process (PID=46827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:32:59.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:32:59.611+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:32:59.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:32:59.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:32:59.649+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:32:59.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:32:59.663+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:32:59.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:32:59.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-15T06:50:58.156+0000] {processor.py:157} INFO - Started process (PID=46837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:50:58.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:50:58.174+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:50:58.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:50:58.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:50:58.261+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:50:58.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:50:58.298+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:50:58.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:50:58.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-15T06:51:28.473+0000] {processor.py:157} INFO - Started process (PID=46847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:51:28.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:51:28.482+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:51:28.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:51:28.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:51:28.554+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:51:28.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:51:28.581+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:51:28.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:51:28.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-15T06:51:58.902+0000] {processor.py:157} INFO - Started process (PID=46857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:51:58.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:51:58.908+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:51:58.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:51:58.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:51:58.939+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:51:58.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:51:58.948+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:51:58.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:51:58.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-15T06:52:29.220+0000] {processor.py:157} INFO - Started process (PID=46867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:52:29.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:52:29.228+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:52:29.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:52:29.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:52:29.267+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:52:29.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:52:29.281+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:52:29.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:52:29.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-15T06:52:59.518+0000] {processor.py:157} INFO - Started process (PID=46877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:52:59.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T06:52:59.521+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:52:59.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:52:59.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T06:52:59.553+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:52:59.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T06:52:59.564+0000] {logging_mixin.py:151} INFO - [2024-08-15T06:52:59.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T06:52:59.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-15T07:08:27.449+0000] {processor.py:157} INFO - Started process (PID=46887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:08:27.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:08:27.456+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:08:27.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:08:27.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:08:27.501+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:08:27.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:08:27.532+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:08:27.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:08:27.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-15T07:08:57.755+0000] {processor.py:157} INFO - Started process (PID=46899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:08:57.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:08:57.760+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:08:57.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:08:57.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:08:57.807+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:08:57.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:08:57.820+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:08:57.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:08:57.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-15T07:09:28.132+0000] {processor.py:157} INFO - Started process (PID=46909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:09:28.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:09:28.134+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:09:28.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:09:28.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:09:28.160+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:09:28.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:09:28.170+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:09:28.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:09:28.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T07:09:58.447+0000] {processor.py:157} INFO - Started process (PID=46919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:09:58.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:09:58.449+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:09:58.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:09:58.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:09:58.475+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:09:58.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:09:58.485+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:09:58.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:09:58.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T07:10:28.752+0000] {processor.py:157} INFO - Started process (PID=46929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:10:28.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:10:28.754+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:10:28.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:10:28.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:10:28.784+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:10:28.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:10:28.793+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:10:28.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:10:28.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T07:26:19.256+0000] {processor.py:157} INFO - Started process (PID=46941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:26:19.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:26:19.260+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:26:19.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:26:19.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:26:19.319+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:26:19.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:26:19.346+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:26:19.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:26:19.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-15T07:26:49.721+0000] {processor.py:157} INFO - Started process (PID=46951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:26:49.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:26:49.725+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:26:49.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:26:49.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:26:49.780+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:26:49.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:26:49.796+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:26:49.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:26:49.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T07:27:20.067+0000] {processor.py:157} INFO - Started process (PID=46961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:27:20.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:27:20.073+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:27:20.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:27:20.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:27:20.095+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:27:20.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:27:20.105+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:27:20.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:27:20.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-15T07:27:50.444+0000] {processor.py:157} INFO - Started process (PID=46971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:27:50.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:27:50.447+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:27:50.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:27:50.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:27:50.479+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:27:50.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:27:50.491+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:27:50.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:27:50.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-15T07:28:20.782+0000] {processor.py:157} INFO - Started process (PID=46981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:28:20.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:28:20.785+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:28:20.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:28:20.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:28:20.816+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:28:20.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:28:20.827+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:28:20.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:28:20.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-15T07:45:16.111+0000] {processor.py:157} INFO - Started process (PID=46993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:45:16.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:45:16.119+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:45:16.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:45:16.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:45:16.223+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:45:16.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:45:16.248+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:45:16.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:45:16.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-15T07:45:46.458+0000] {processor.py:157} INFO - Started process (PID=47002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:45:46.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:45:46.463+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:45:46.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:45:46.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:45:46.512+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:45:46.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:45:46.538+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:45:46.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:45:46.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-15T07:46:16.831+0000] {processor.py:157} INFO - Started process (PID=47013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:46:16.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:46:16.832+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:46:16.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:46:16.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:46:16.855+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:46:16.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:46:16.865+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:46:16.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:46:16.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-15T07:46:47.127+0000] {processor.py:157} INFO - Started process (PID=47023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:46:47.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:46:47.133+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:46:47.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:46:47.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:46:47.173+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:46:47.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:46:47.188+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:46:47.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:46:47.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T07:47:17.585+0000] {processor.py:157} INFO - Started process (PID=47033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:47:17.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:47:17.590+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:47:17.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:47:17.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:47:17.616+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:47:17.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:47:17.628+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:47:17.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:47:17.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T07:47:48.036+0000] {processor.py:157} INFO - Started process (PID=47043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:47:48.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:47:48.042+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:47:48.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:47:48.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:47:48.103+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:47:48.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:47:48.118+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:47:48.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:47:48.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-15T07:48:18.326+0000] {processor.py:157} INFO - Started process (PID=47053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:48:18.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:48:18.330+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:48:18.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:48:18.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:48:18.367+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:48:18.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:48:18.380+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:48:18.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:48:18.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-15T07:48:48.726+0000] {processor.py:157} INFO - Started process (PID=47063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:48:48.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:48:48.729+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:48:48.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:48:48.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:48:48.755+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:48:48.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:48:48.765+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:48:48.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:48:48.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T07:49:19.137+0000] {processor.py:157} INFO - Started process (PID=47073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:49:19.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T07:49:19.139+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:49:19.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:49:19.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T07:49:19.167+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:49:19.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T07:49:19.178+0000] {logging_mixin.py:151} INFO - [2024-08-15T07:49:19.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T07:49:19.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-15T08:02:14.776+0000] {processor.py:157} INFO - Started process (PID=47082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:02:14.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:02:14.782+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:02:14.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:02:14.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:02:14.831+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:02:14.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:02:14.844+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:02:14.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:02:14.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-15T08:02:45.248+0000] {processor.py:157} INFO - Started process (PID=47093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:02:45.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:02:45.252+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:02:45.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:02:45.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:02:45.279+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:02:45.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:02:45.290+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:02:45.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:02:45.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-15T08:03:15.632+0000] {processor.py:157} INFO - Started process (PID=47103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:03:15.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:03:15.638+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:03:15.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:03:15.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:03:15.675+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:03:15.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:03:15.690+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:03:15.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:03:15.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-15T08:03:45.992+0000] {processor.py:157} INFO - Started process (PID=47113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:03:45.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:03:46.003+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:03:46.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:03:46.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:03:46.032+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:03:46.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:03:46.043+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:03:46.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:03:46.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-15T08:04:25.632+0000] {processor.py:157} INFO - Started process (PID=47123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:04:25.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:04:25.636+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:04:25.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:04:25.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:04:25.664+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:04:25.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:04:25.677+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:04:25.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:04:25.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T08:04:55.998+0000] {processor.py:157} INFO - Started process (PID=47133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:04:56.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:04:56.003+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:04:56.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:04:56.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:04:56.030+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:04:56.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:04:56.040+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:04:56.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:04:56.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T08:05:26.336+0000] {processor.py:157} INFO - Started process (PID=47143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:05:26.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:05:26.339+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:05:26.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:05:26.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:05:26.364+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:05:26.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:05:26.374+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:05:26.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:05:26.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-15T08:05:56.651+0000] {processor.py:157} INFO - Started process (PID=47153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:05:56.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:05:56.654+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:05:56.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:05:56.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:05:56.680+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:05:56.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:05:56.690+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:05:56.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:05:56.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-15T08:06:27.016+0000] {processor.py:157} INFO - Started process (PID=47163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:06:27.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:06:27.018+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:06:27.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:06:27.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:06:27.041+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:06:27.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:06:27.051+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:06:27.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:06:27.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-15T08:22:19.238+0000] {processor.py:157} INFO - Started process (PID=47173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:22:19.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:22:19.247+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:22:19.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:22:19.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:22:19.344+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:22:19.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:22:19.385+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:22:19.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:22:19.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-15T08:22:49.650+0000] {processor.py:157} INFO - Started process (PID=47185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:22:49.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:22:49.658+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:22:49.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:22:49.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:22:49.720+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:22:49.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:22:49.737+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:22:49.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:22:49.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-15T08:23:19.878+0000] {processor.py:157} INFO - Started process (PID=47195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:23:19.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:23:19.884+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:23:19.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:23:19.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:23:19.922+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:23:19.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:23:19.936+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:23:19.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:23:19.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-15T08:23:50.197+0000] {processor.py:157} INFO - Started process (PID=47205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:23:50.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:23:50.201+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:23:50.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:23:50.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:23:50.239+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:23:50.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:23:50.249+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:23:50.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:23:50.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-15T08:24:20.529+0000] {processor.py:157} INFO - Started process (PID=47215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:24:20.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:24:20.532+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:24:20.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:24:20.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:24:20.559+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:24:20.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:24:20.572+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:24:20.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:24:20.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-15T08:24:50.848+0000] {processor.py:157} INFO - Started process (PID=47225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:24:50.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:24:50.851+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:24:50.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:24:50.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:24:50.878+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:24:50.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:24:50.892+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:24:50.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:24:50.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-15T08:25:21.203+0000] {processor.py:157} INFO - Started process (PID=47235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:25:21.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:25:21.205+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:25:21.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:25:21.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:25:21.232+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:25:21.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:25:21.243+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:25:21.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:25:21.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T08:42:51.009+0000] {processor.py:157} INFO - Started process (PID=47247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:42:51.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:42:51.021+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:42:51.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:42:51.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:42:51.100+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:42:51.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:42:51.121+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:42:51.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:42:51.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-15T08:43:21.288+0000] {processor.py:157} INFO - Started process (PID=47257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:43:21.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:43:21.294+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:43:21.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:43:21.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:43:21.330+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:43:21.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:43:21.342+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:43:21.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:43:21.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-15T08:43:51.599+0000] {processor.py:157} INFO - Started process (PID=47267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:43:51.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:43:51.602+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:43:51.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:43:51.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:43:51.635+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:43:51.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:43:51.647+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:43:51.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:43:51.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-15T08:44:21.910+0000] {processor.py:157} INFO - Started process (PID=47277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:44:21.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T08:44:21.912+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:44:21.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:44:21.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T08:44:21.943+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:44:21.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T08:44:21.954+0000] {logging_mixin.py:151} INFO - [2024-08-15T08:44:21.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T08:44:21.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-15T09:00:40.289+0000] {processor.py:157} INFO - Started process (PID=47287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:00:40.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:00:40.291+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:00:40.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:00:40.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:00:40.320+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:00:40.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:00:40.334+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:00:40.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:00:40.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-15T09:01:10.584+0000] {processor.py:157} INFO - Started process (PID=47299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:01:10.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:01:10.590+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:01:10.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:01:10.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:01:10.628+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:01:10.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:01:10.642+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:01:10.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:01:10.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-15T09:01:40.892+0000] {processor.py:157} INFO - Started process (PID=47309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:01:40.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:01:40.895+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:01:40.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:01:40.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:01:40.925+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:01:40.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:01:40.935+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:01:40.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:01:40.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-15T09:02:11.146+0000] {processor.py:157} INFO - Started process (PID=47319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:02:11.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:02:11.151+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:02:11.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:02:11.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:02:11.183+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:02:11.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:02:11.195+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:02:11.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:02:11.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-15T09:20:21.692+0000] {processor.py:157} INFO - Started process (PID=47331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:20:21.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:20:21.702+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:20:21.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:20:21.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:20:21.752+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:20:21.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:20:21.776+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:20:21.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:20:21.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-15T09:20:52.105+0000] {processor.py:157} INFO - Started process (PID=47341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:20:52.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:20:52.109+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:20:52.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:20:52.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:20:52.143+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:20:52.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:20:52.154+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:20:52.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:20:52.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-15T09:21:22.413+0000] {processor.py:157} INFO - Started process (PID=47351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:21:22.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:21:22.416+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:21:22.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:21:22.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:21:22.446+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:21:22.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:21:22.458+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:21:22.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:21:22.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-15T09:21:52.764+0000] {processor.py:157} INFO - Started process (PID=47361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:21:52.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:21:52.770+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:21:52.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:21:52.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:21:52.801+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:21:52.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:21:52.813+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:21:52.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:21:52.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-15T09:22:23.035+0000] {processor.py:157} INFO - Started process (PID=47371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:22:23.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:22:23.038+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:22:23.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:22:23.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:22:23.066+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:22:23.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:22:23.078+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:22:23.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:22:23.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-15T09:39:42.043+0000] {processor.py:157} INFO - Started process (PID=47381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:39:42.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:39:42.044+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:39:42.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:39:42.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:39:42.069+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:39:42.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:39:42.079+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:39:42.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:39:42.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-15T09:40:12.388+0000] {processor.py:157} INFO - Started process (PID=47391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:40:12.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:40:12.393+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:40:12.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:40:12.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:40:12.430+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:40:12.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:40:12.442+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:40:12.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:40:12.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-15T09:40:42.658+0000] {processor.py:157} INFO - Started process (PID=47401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:40:42.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:40:42.661+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:40:42.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:40:42.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:40:42.692+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:40:42.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:40:42.702+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:40:42.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:40:42.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-15T09:41:12.940+0000] {processor.py:157} INFO - Started process (PID=47411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:41:12.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:41:12.944+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:41:12.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:41:12.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:41:12.979+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:41:12.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:41:12.990+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:41:12.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:41:12.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-15T09:41:43.235+0000] {processor.py:157} INFO - Started process (PID=47421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:41:43.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:41:43.237+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:41:43.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:41:43.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:41:43.262+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:41:43.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:41:43.274+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:41:43.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:41:43.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T09:58:44.448+0000] {processor.py:157} INFO - Started process (PID=47431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:58:44.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:58:44.451+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:58:44.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:58:44.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:58:44.517+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:58:44.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:58:44.542+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:58:44.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:58:44.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-15T09:59:14.731+0000] {processor.py:157} INFO - Started process (PID=47441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:59:14.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:59:14.736+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:59:14.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:59:14.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:59:14.773+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:59:14.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:59:14.785+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:59:14.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:59:14.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-15T09:59:45.065+0000] {processor.py:157} INFO - Started process (PID=47451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:59:45.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T09:59:45.068+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:59:45.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:59:45.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T09:59:45.100+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:59:45.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T09:59:45.112+0000] {logging_mixin.py:151} INFO - [2024-08-15T09:59:45.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T09:59:45.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-15T10:00:15.425+0000] {processor.py:157} INFO - Started process (PID=47461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:00:15.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:00:15.427+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:00:15.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:00:15.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:00:15.457+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:00:15.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:00:15.468+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:00:15.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:00:15.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T10:00:45.744+0000] {processor.py:157} INFO - Started process (PID=47471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:00:45.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:00:45.747+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:00:45.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:00:45.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:00:45.774+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:00:45.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:00:45.784+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:00:45.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:00:45.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T10:10:23.657+0000] {processor.py:157} INFO - Started process (PID=47481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:10:23.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:10:23.663+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:10:23.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:10:23.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:10:23.707+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:10:23.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:10:23.721+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:10:23.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:10:23.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-15T10:10:53.990+0000] {processor.py:157} INFO - Started process (PID=47490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:10:53.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:10:53.998+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:10:53.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:10:54.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:10:54.042+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:10:54.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:10:54.061+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:10:54.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:10:54.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T10:11:24.256+0000] {processor.py:157} INFO - Started process (PID=47501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:11:24.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:11:24.259+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:11:24.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:11:24.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:11:24.285+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:11:24.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:11:24.294+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:11:24.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:11:24.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-15T10:11:54.593+0000] {processor.py:157} INFO - Started process (PID=47511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:11:54.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:11:54.596+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:11:54.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:11:54.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:11:54.633+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:11:54.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:11:54.646+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:11:54.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:11:54.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-15T10:12:24.874+0000] {processor.py:157} INFO - Started process (PID=47521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:12:24.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:12:24.877+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:12:24.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:12:24.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:12:24.902+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:12:24.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:12:24.912+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:12:24.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:12:24.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-15T10:24:05.726+0000] {processor.py:157} INFO - Started process (PID=47531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:24:05.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:24:05.728+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:24:05.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:24:05.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:24:05.777+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:24:05.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:24:05.798+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:24:05.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:24:05.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T10:24:36.116+0000] {processor.py:157} INFO - Started process (PID=47542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:24:36.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:24:36.122+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:24:36.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:24:36.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:24:36.172+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:24:36.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:24:36.185+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:24:36.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:24:36.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-15T10:29:13.401+0000] {processor.py:157} INFO - Started process (PID=47553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:29:13.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:29:13.412+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:29:13.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:29:13.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:29:13.473+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:29:13.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:29:13.496+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:29:13.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:29:13.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-15T10:29:43.864+0000] {processor.py:157} INFO - Started process (PID=47564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:29:43.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:29:43.872+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:29:43.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:29:43.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:29:43.908+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:29:43.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:29:43.926+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:29:43.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:29:43.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-15T10:30:14.219+0000] {processor.py:157} INFO - Started process (PID=47574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:30:14.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:30:14.226+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:30:14.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:30:14.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:30:14.259+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:30:14.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:30:14.271+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:30:14.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:30:14.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-15T10:30:44.480+0000] {processor.py:157} INFO - Started process (PID=47584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:30:44.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:30:44.483+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:30:44.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:30:44.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:30:44.509+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:30:44.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:30:44.519+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:30:44.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:30:44.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-15T10:46:48.654+0000] {processor.py:157} INFO - Started process (PID=47593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:46:48.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:46:48.658+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:46:48.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:46:48.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:46:48.700+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:46:48.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:46:48.714+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:46:48.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:46:48.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-15T10:47:19.104+0000] {processor.py:157} INFO - Started process (PID=47604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:47:19.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:47:19.109+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:47:19.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:47:19.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:47:19.177+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:47:19.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:47:19.192+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:47:19.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:47:19.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-15T10:47:49.407+0000] {processor.py:157} INFO - Started process (PID=47614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:47:49.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:47:49.410+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:47:49.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:47:49.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:47:49.438+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:47:49.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:47:49.447+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:47:49.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:47:49.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-15T10:48:19.738+0000] {processor.py:157} INFO - Started process (PID=47624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:48:19.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T10:48:19.742+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:48:19.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:48:19.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T10:48:19.782+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:48:19.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T10:48:19.796+0000] {logging_mixin.py:151} INFO - [2024-08-15T10:48:19.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T10:48:19.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-15T11:03:53.771+0000] {processor.py:157} INFO - Started process (PID=47633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:03:53.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:03:53.778+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:03:53.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:03:53.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:03:53.841+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:03:53.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:03:53.871+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:03:53.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:03:53.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-15T11:04:24.110+0000] {processor.py:157} INFO - Started process (PID=47644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:04:24.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:04:24.117+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:04:24.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:04:24.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:04:24.171+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:04:24.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:04:24.188+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:04:24.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:04:24.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-15T11:04:54.456+0000] {processor.py:157} INFO - Started process (PID=47654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:04:54.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:04:54.462+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:04:54.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:04:54.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:04:54.501+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:04:54.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:04:54.515+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:04:54.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:04:54.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-15T11:05:24.887+0000] {processor.py:157} INFO - Started process (PID=47664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:05:24.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:05:24.892+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:05:24.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:05:24.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:05:24.935+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:05:24.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:05:24.951+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:05:24.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:05:24.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-15T11:05:55.210+0000] {processor.py:157} INFO - Started process (PID=47674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:05:55.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:05:55.212+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:05:55.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:05:55.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:05:55.240+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:05:55.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:05:55.251+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:05:55.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:05:55.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-15T11:23:32.431+0000] {processor.py:157} INFO - Started process (PID=47685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:23:32.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:23:32.440+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:23:32.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:23:32.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:23:32.491+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:23:32.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:23:32.504+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:23:32.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:23:32.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-15T11:37:00.563+0000] {processor.py:157} INFO - Started process (PID=47695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:37:00.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:37:00.586+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:37:00.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:37:00.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:37:00.681+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:37:00.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:37:00.744+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:37:00.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:37:00.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-08-15T11:37:30.901+0000] {processor.py:157} INFO - Started process (PID=47705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:37:30.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T11:37:30.908+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:37:30.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:37:30.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T11:37:30.968+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:37:30.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T11:37:30.982+0000] {logging_mixin.py:151} INFO - [2024-08-15T11:37:30.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T11:37:30.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-15T12:05:42.791+0000] {processor.py:157} INFO - Started process (PID=47716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:05:42.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T12:05:42.800+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:05:42.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:05:42.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:05:42.881+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:05:42.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T12:05:42.911+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:05:42.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T12:05:42.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-15T12:06:13.299+0000] {processor.py:157} INFO - Started process (PID=47726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:06:13.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T12:06:13.307+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:06:13.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:06:13.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:06:13.360+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:06:13.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T12:06:13.383+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:06:13.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T12:06:13.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-15T12:25:11.336+0000] {processor.py:157} INFO - Started process (PID=47737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:25:11.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T12:25:11.346+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:25:11.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:25:11.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:25:11.407+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:25:11.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T12:25:11.423+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:25:11.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T12:25:11.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-15T12:25:41.810+0000] {processor.py:157} INFO - Started process (PID=47746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:25:41.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T12:25:41.817+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:25:41.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:25:41.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:25:41.872+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:25:41.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T12:25:41.887+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:25:41.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T12:25:41.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-15T12:35:10.466+0000] {processor.py:157} INFO - Started process (PID=47757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:35:10.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T12:35:10.468+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:35:10.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:35:10.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T12:35:10.495+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:35:10.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T12:35:10.504+0000] {logging_mixin.py:151} INFO - [2024-08-15T12:35:10.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T12:35:10.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-15T13:04:10.484+0000] {processor.py:157} INFO - Started process (PID=47767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:04:10.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T13:04:10.488+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:04:10.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:04:10.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:04:10.529+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:04:10.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T13:04:10.551+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:04:10.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T13:04:10.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-15T13:04:40.846+0000] {processor.py:157} INFO - Started process (PID=47777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:04:40.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T13:04:40.857+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:04:40.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:04:40.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:04:40.914+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:04:40.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T13:04:40.930+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:04:40.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T13:04:40.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-15T13:26:10.531+0000] {processor.py:157} INFO - Started process (PID=47788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:26:10.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T13:26:10.538+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:26:10.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:26:10.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:26:10.652+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:26:10.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T13:26:10.697+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:26:10.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T13:26:10.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-15T13:26:40.879+0000] {processor.py:157} INFO - Started process (PID=47799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:26:40.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T13:26:40.890+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:26:40.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:26:40.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T13:26:40.954+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:26:40.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T13:26:40.970+0000] {logging_mixin.py:151} INFO - [2024-08-15T13:26:40.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T13:26:40.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-15T14:27:08.271+0000] {processor.py:157} INFO - Started process (PID=47809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T14:27:08.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T14:27:08.278+0000] {logging_mixin.py:151} INFO - [2024-08-15T14:27:08.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T14:27:08.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T14:27:08.314+0000] {logging_mixin.py:151} INFO - [2024-08-15T14:27:08.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T14:27:08.326+0000] {logging_mixin.py:151} INFO - [2024-08-15T14:27:08.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T14:27:08.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-15T14:27:38.518+0000] {processor.py:157} INFO - Started process (PID=47819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T14:27:38.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T14:27:38.523+0000] {logging_mixin.py:151} INFO - [2024-08-15T14:27:38.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T14:27:38.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T14:27:38.562+0000] {logging_mixin.py:151} INFO - [2024-08-15T14:27:38.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T14:27:38.576+0000] {logging_mixin.py:151} INFO - [2024-08-15T14:27:38.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T14:27:38.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T15:28:05.990+0000] {processor.py:157} INFO - Started process (PID=47831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T15:28:05.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T15:28:06.002+0000] {logging_mixin.py:151} INFO - [2024-08-15T15:28:06.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T15:28:06.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T15:28:06.047+0000] {logging_mixin.py:151} INFO - [2024-08-15T15:28:06.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T15:28:06.063+0000] {logging_mixin.py:151} INFO - [2024-08-15T15:28:06.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T15:28:06.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-15T15:28:36.371+0000] {processor.py:157} INFO - Started process (PID=47841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T15:28:36.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T15:28:36.376+0000] {logging_mixin.py:151} INFO - [2024-08-15T15:28:36.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T15:28:36.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T15:28:36.418+0000] {logging_mixin.py:151} INFO - [2024-08-15T15:28:36.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T15:28:36.434+0000] {logging_mixin.py:151} INFO - [2024-08-15T15:28:36.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T15:28:36.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-15T16:29:03.860+0000] {processor.py:157} INFO - Started process (PID=47851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T16:29:03.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T16:29:03.865+0000] {logging_mixin.py:151} INFO - [2024-08-15T16:29:03.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T16:29:03.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T16:29:03.951+0000] {logging_mixin.py:151} INFO - [2024-08-15T16:29:03.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T16:29:03.978+0000] {logging_mixin.py:151} INFO - [2024-08-15T16:29:03.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T16:29:04.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-15T16:29:34.428+0000] {processor.py:157} INFO - Started process (PID=47861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T16:29:34.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T16:29:34.434+0000] {logging_mixin.py:151} INFO - [2024-08-15T16:29:34.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T16:29:34.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T16:29:34.489+0000] {logging_mixin.py:151} INFO - [2024-08-15T16:29:34.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T16:29:34.507+0000] {logging_mixin.py:151} INFO - [2024-08-15T16:29:34.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T16:29:34.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-15T17:30:02.085+0000] {processor.py:157} INFO - Started process (PID=47873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T17:30:02.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T17:30:02.102+0000] {logging_mixin.py:151} INFO - [2024-08-15T17:30:02.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T17:30:02.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T17:30:02.201+0000] {logging_mixin.py:151} INFO - [2024-08-15T17:30:02.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T17:30:02.221+0000] {logging_mixin.py:151} INFO - [2024-08-15T17:30:02.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T17:30:02.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-15T17:30:32.417+0000] {processor.py:157} INFO - Started process (PID=47883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T17:30:32.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T17:30:32.425+0000] {logging_mixin.py:151} INFO - [2024-08-15T17:30:32.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T17:30:32.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T17:30:32.473+0000] {logging_mixin.py:151} INFO - [2024-08-15T17:30:32.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T17:30:32.489+0000] {logging_mixin.py:151} INFO - [2024-08-15T17:30:32.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T17:30:32.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T18:30:59.945+0000] {processor.py:157} INFO - Started process (PID=47892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:30:59.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:30:59.949+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:30:59.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:30:59.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:30:59.999+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:30:59.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:31:00.014+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:31:00.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:31:00.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-15T18:31:30.358+0000] {processor.py:157} INFO - Started process (PID=47903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:31:30.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:31:30.363+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:31:30.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:31:30.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:31:30.410+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:31:30.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:31:30.427+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:31:30.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:31:30.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-15T18:38:40.740+0000] {processor.py:157} INFO - Started process (PID=47914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:38:40.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:38:40.747+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:38:40.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:38:40.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:38:40.857+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:38:40.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:38:40.885+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:38:40.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:38:40.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-15T18:39:11.126+0000] {processor.py:157} INFO - Started process (PID=47925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:39:11.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:39:11.135+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:39:11.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:39:11.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:39:11.210+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:39:11.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:39:11.232+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:39:11.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:39:11.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-15T18:39:41.450+0000] {processor.py:157} INFO - Started process (PID=47935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:39:41.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:39:41.457+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:39:41.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:39:41.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:39:41.500+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:39:41.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:39:41.517+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:39:41.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:39:41.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-15T18:40:11.811+0000] {processor.py:157} INFO - Started process (PID=47945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:40:11.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:40:11.814+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:40:11.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:40:11.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:40:11.855+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:40:11.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:40:11.871+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:40:11.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:40:11.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-15T18:40:42.076+0000] {processor.py:157} INFO - Started process (PID=47955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:40:42.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:40:42.083+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:40:42.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:40:42.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:40:42.125+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:40:42.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:40:42.139+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:40:42.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:40:42.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-15T18:41:12.460+0000] {processor.py:157} INFO - Started process (PID=47965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:41:12.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:41:12.464+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:41:12.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:41:12.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:41:12.506+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:41:12.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:41:12.521+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:41:12.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:41:12.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-15T18:41:42.748+0000] {processor.py:157} INFO - Started process (PID=47975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:41:42.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:41:42.755+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:41:42.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:41:42.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:41:42.792+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:41:42.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:41:42.805+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:41:42.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:41:42.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-15T18:42:13.151+0000] {processor.py:157} INFO - Started process (PID=47985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:42:13.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:42:13.164+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:42:13.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:42:13.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:42:13.258+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:42:13.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:42:13.287+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:42:13.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:42:13.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-15T18:42:43.481+0000] {processor.py:157} INFO - Started process (PID=47995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:42:43.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:42:43.488+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:42:43.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:42:43.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:42:43.535+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:42:43.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:42:43.552+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:42:43.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:42:43.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-15T18:43:13.896+0000] {processor.py:157} INFO - Started process (PID=48005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:43:13.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:43:13.907+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:43:13.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:43:13.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:43:13.990+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:43:13.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:43:14.023+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:43:14.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:43:14.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-15T18:43:44.271+0000] {processor.py:157} INFO - Started process (PID=48015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:43:44.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:43:44.279+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:43:44.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:43:44.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:43:44.341+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:43:44.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:43:44.357+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:43:44.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:43:44.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-15T18:44:14.608+0000] {processor.py:157} INFO - Started process (PID=48025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:44:14.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:44:14.618+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:44:14.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:44:14.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:44:14.692+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:44:14.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:44:14.712+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:44:14.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:44:14.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-15T18:44:44.940+0000] {processor.py:157} INFO - Started process (PID=48035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:44:44.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:44:44.947+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:44:44.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:44:44.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:44:45.002+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:44:45.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:44:45.016+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:44:45.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:44:45.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-15T18:45:15.451+0000] {processor.py:157} INFO - Started process (PID=48045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:45:15.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:45:15.463+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:45:15.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:45:15.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:45:15.554+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:45:15.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:45:15.572+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:45:15.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:45:15.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-15T18:45:45.926+0000] {processor.py:157} INFO - Started process (PID=48054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:45:45.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:45:45.933+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:45:45.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:45:45.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:45:45.986+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:45:45.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:45:46.007+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:45:46.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:45:46.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-15T18:46:16.214+0000] {processor.py:157} INFO - Started process (PID=48064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:46:16.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:46:16.220+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:46:16.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:46:16.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:46:16.272+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:46:16.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:46:16.290+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:46:16.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:46:16.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-15T18:46:46.667+0000] {processor.py:157} INFO - Started process (PID=48075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:46:46.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:46:46.675+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:46:46.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:46:46.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:46:46.738+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:46:46.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:46:46.757+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:46:46.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:46:46.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-15T18:47:16.982+0000] {processor.py:157} INFO - Started process (PID=48085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:47:16.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:47:16.989+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:47:16.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:47:17.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:47:17.036+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:47:17.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:47:17.052+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:47:17.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:47:17.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T18:47:47.420+0000] {processor.py:157} INFO - Started process (PID=48095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:47:47.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:47:47.426+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:47:47.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:47:47.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:47:47.520+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:47:47.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:47:47.542+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:47:47.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:47:47.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-15T18:48:17.732+0000] {processor.py:157} INFO - Started process (PID=48105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:48:17.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:48:17.741+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:48:17.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:48:17.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:48:17.816+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:48:17.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:48:17.863+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:48:17.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:48:17.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-15T18:48:48.183+0000] {processor.py:157} INFO - Started process (PID=48115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:48:48.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:48:48.193+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:48:48.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:48:48.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:48:48.270+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:48:48.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:48:48.295+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:48:48.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:48:48.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-15T18:49:18.561+0000] {processor.py:157} INFO - Started process (PID=48125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:49:18.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:49:18.570+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:49:18.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:49:18.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:49:18.640+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:49:18.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:49:18.657+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:49:18.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:49:18.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-15T18:49:48.903+0000] {processor.py:157} INFO - Started process (PID=48135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:49:48.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:49:48.929+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:49:48.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:49:48.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:49:48.977+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:49:48.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:49:48.994+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:49:48.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:49:49.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-15T18:50:19.416+0000] {processor.py:157} INFO - Started process (PID=48145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:50:19.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:50:19.423+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:50:19.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:50:19.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:50:19.471+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:50:19.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:50:19.485+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:50:19.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:50:19.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-15T18:50:49.691+0000] {processor.py:157} INFO - Started process (PID=48155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:50:49.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:50:49.696+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:50:49.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:50:49.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:50:49.731+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:50:49.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:50:49.747+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:50:49.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:50:49.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-15T18:51:19.944+0000] {processor.py:157} INFO - Started process (PID=48165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:51:19.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:51:19.955+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:51:19.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:51:19.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:51:20.023+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:51:20.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:51:20.039+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:51:20.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:51:20.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-15T18:51:50.439+0000] {processor.py:157} INFO - Started process (PID=48175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:51:50.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T18:51:50.446+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:51:50.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:51:50.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T18:51:50.508+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:51:50.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T18:51:50.524+0000] {logging_mixin.py:151} INFO - [2024-08-15T18:51:50.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T18:51:50.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-15T19:24:18.438+0000] {processor.py:157} INFO - Started process (PID=48185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:24:18.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T19:24:18.448+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:24:18.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:24:18.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:24:18.495+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:24:18.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T19:24:18.509+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:24:18.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T19:24:18.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-15T19:50:37.412+0000] {processor.py:157} INFO - Started process (PID=48195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:50:37.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T19:50:37.419+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:50:37.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:50:37.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:50:37.496+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:50:37.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T19:50:37.530+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:50:37.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T19:50:37.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-15T19:59:36.723+0000] {processor.py:157} INFO - Started process (PID=48207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:59:36.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T19:59:36.730+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:59:36.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:59:36.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T19:59:36.791+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:59:36.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T19:59:36.808+0000] {logging_mixin.py:151} INFO - [2024-08-15T19:59:36.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T19:59:36.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-15T20:00:07.011+0000] {processor.py:157} INFO - Started process (PID=48217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:00:07.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T20:00:07.017+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:00:07.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:00:07.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:00:07.072+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:00:07.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T20:00:07.087+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:00:07.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T20:00:07.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-15T20:14:10.953+0000] {processor.py:157} INFO - Started process (PID=48229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:14:10.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T20:14:10.962+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:14:10.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:14:10.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:14:11.029+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:14:11.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T20:14:11.055+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:14:11.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T20:14:11.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-15T20:18:35.501+0000] {processor.py:157} INFO - Started process (PID=48239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:18:35.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T20:18:35.506+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:18:35.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:18:35.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:18:35.563+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:18:35.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T20:18:35.580+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:18:35.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T20:18:35.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-15T20:19:05.800+0000] {processor.py:157} INFO - Started process (PID=48249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:19:05.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T20:19:05.806+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:19:05.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:19:05.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T20:19:05.852+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:19:05.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T20:19:05.868+0000] {logging_mixin.py:151} INFO - [2024-08-15T20:19:05.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T20:19:05.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-15T21:09:29.161+0000] {processor.py:157} INFO - Started process (PID=48259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:09:29.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T21:09:29.172+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:09:29.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:09:29.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:09:29.274+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:09:29.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T21:09:29.323+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:09:29.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T21:09:29.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-08-15T21:53:12.992+0000] {processor.py:157} INFO - Started process (PID=48269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:53:12.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T21:53:13.004+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:53:13.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:53:13.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:53:13.091+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:53:13.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T21:53:13.110+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:53:13.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T21:53:13.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-15T21:53:43.332+0000] {processor.py:157} INFO - Started process (PID=48279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:53:43.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T21:53:43.337+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:53:43.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:53:43.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T21:53:43.400+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:53:43.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T21:53:43.425+0000] {logging_mixin.py:151} INFO - [2024-08-15T21:53:43.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T21:53:43.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-15T22:54:23.215+0000] {processor.py:157} INFO - Started process (PID=48291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T22:54:23.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T22:54:23.221+0000] {logging_mixin.py:151} INFO - [2024-08-15T22:54:23.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T22:54:23.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T22:54:23.284+0000] {logging_mixin.py:151} INFO - [2024-08-15T22:54:23.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T22:54:23.311+0000] {logging_mixin.py:151} INFO - [2024-08-15T22:54:23.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T22:54:23.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-15T22:54:53.539+0000] {processor.py:157} INFO - Started process (PID=48299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-15T22:54:53.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-15T22:54:53.545+0000] {logging_mixin.py:151} INFO - [2024-08-15T22:54:53.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T22:54:53.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-15T22:54:53.596+0000] {logging_mixin.py:151} INFO - [2024-08-15T22:54:53.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-15T22:54:53.616+0000] {logging_mixin.py:151} INFO - [2024-08-15T22:54:53.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-14T01:00:00+00:00, run_after=2024-08-15T01:00:00+00:00
[2024-08-15T22:54:53.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
