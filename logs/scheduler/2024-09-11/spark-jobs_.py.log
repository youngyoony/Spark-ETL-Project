[2024-09-11T00:00:01.005+0000] {processor.py:157} INFO - Started process (PID=44991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:00:01.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:00:01.012+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:00:01.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:00:01.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:00:01.062+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:00:01.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:00:01.077+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:00:01.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:00:01.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T00:00:31.379+0000] {processor.py:157} INFO - Started process (PID=45001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:00:31.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:00:31.389+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:00:31.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:00:31.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:00:31.434+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:00:31.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:00:31.449+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:00:31.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:00:31.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T00:01:01.689+0000] {processor.py:157} INFO - Started process (PID=45011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:01:01.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:01:01.692+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:01:01.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:01:01.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:01:01.717+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:01:01.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:01:01.727+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:01:01.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:01:01.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T00:01:32.123+0000] {processor.py:157} INFO - Started process (PID=45020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:01:32.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:01:32.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:01:32.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:01:32.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:01:32.169+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:01:32.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:01:32.182+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:01:32.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:01:32.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T00:02:02.551+0000] {processor.py:157} INFO - Started process (PID=45031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:02:02.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:02:02.556+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:02:02.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:02:02.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:02:02.591+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:02:02.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:02:02.608+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:02:02.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:02:02.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T00:02:32.958+0000] {processor.py:157} INFO - Started process (PID=45041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:02:32.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:02:32.960+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:02:32.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:02:32.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:02:32.987+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:02:32.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:02:32.997+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:02:32.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:02:33.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T00:03:03.391+0000] {processor.py:157} INFO - Started process (PID=45051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:03:03.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:03:03.395+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:03:03.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:03:03.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:03:03.435+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:03:03.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:03:03.449+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:03:03.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:03:03.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T00:03:33.675+0000] {processor.py:157} INFO - Started process (PID=45061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:03:33.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:03:33.680+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:03:33.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:03:33.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:03:33.714+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:03:33.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:03:33.724+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:03:33.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:03:33.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T00:04:04.084+0000] {processor.py:157} INFO - Started process (PID=45071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:04:04.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:04:04.087+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:04:04.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:04:04.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:04:04.117+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:04:04.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:04:04.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:04:04.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:04:04.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T00:04:34.434+0000] {processor.py:157} INFO - Started process (PID=45081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:04:34.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:04:34.438+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:04:34.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:04:34.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:04:34.485+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:04:34.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:04:34.498+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:04:34.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:04:34.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T00:05:04.891+0000] {processor.py:157} INFO - Started process (PID=45091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:05:04.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:05:04.894+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:05:04.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:05:04.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:05:04.936+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:05:04.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:05:04.949+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:05:04.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:05:04.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T00:05:35.323+0000] {processor.py:157} INFO - Started process (PID=45101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:05:35.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:05:35.329+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:05:35.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:05:35.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:05:35.381+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:05:35.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:05:35.398+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:05:35.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:05:35.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T00:06:05.708+0000] {processor.py:157} INFO - Started process (PID=45110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:06:05.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:06:05.712+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:06:05.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:06:05.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:06:05.770+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:06:05.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:06:05.785+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:06:05.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:06:05.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-11T00:06:36.057+0000] {processor.py:157} INFO - Started process (PID=45121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:06:36.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:06:36.062+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:06:36.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:06:36.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:06:36.090+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:06:36.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:06:36.099+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:06:36.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:06:36.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T00:07:06.556+0000] {processor.py:157} INFO - Started process (PID=45131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:07:06.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:07:06.562+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:07:06.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:07:06.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:07:06.607+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:07:06.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:07:06.622+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:07:06.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:07:06.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T00:07:37.000+0000] {processor.py:157} INFO - Started process (PID=45141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:07:37.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:07:37.003+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:07:37.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:07:37.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:07:37.033+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:07:37.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:07:37.045+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:07:37.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:07:37.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T00:08:07.421+0000] {processor.py:157} INFO - Started process (PID=45151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:08:07.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:08:07.425+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:08:07.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:08:07.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:08:07.490+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:08:07.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:08:07.503+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:08:07.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:08:07.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T00:08:37.785+0000] {processor.py:157} INFO - Started process (PID=45161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:08:37.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:08:37.790+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:08:37.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:08:37.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:08:37.825+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:08:37.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:08:37.840+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:08:37.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:08:37.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T00:09:08.196+0000] {processor.py:157} INFO - Started process (PID=45171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:09:08.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:09:08.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:09:08.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:09:08.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:09:08.228+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:09:08.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:09:08.238+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:09:08.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:09:08.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T00:09:38.603+0000] {processor.py:157} INFO - Started process (PID=45181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:09:38.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:09:38.606+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:09:38.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:09:38.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:09:38.638+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:09:38.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:09:38.650+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:09:38.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:09:38.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T00:10:09.101+0000] {processor.py:157} INFO - Started process (PID=45191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:10:09.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:10:09.107+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:10:09.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:10:09.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:10:09.143+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:10:09.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:10:09.155+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:10:09.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:10:09.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T00:10:39.379+0000] {processor.py:157} INFO - Started process (PID=45201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:10:39.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:10:39.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:10:39.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:10:39.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:10:39.410+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:10:39.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:10:39.421+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:10:39.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:10:39.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T00:11:09.895+0000] {processor.py:157} INFO - Started process (PID=45211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:11:09.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:11:09.900+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:11:09.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:11:09.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:11:09.930+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:11:09.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:11:09.941+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:11:09.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:11:09.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T00:11:40.307+0000] {processor.py:157} INFO - Started process (PID=45221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:11:40.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:11:40.316+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:11:40.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:11:40.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:11:40.437+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:11:40.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:11:40.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:11:40.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:11:40.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-09-11T00:12:10.619+0000] {processor.py:157} INFO - Started process (PID=45231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:12:10.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:12:10.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:12:10.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:12:10.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:12:10.665+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:12:10.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:12:10.678+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:12:10.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:12:10.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T00:12:40.945+0000] {processor.py:157} INFO - Started process (PID=45241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:12:40.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:12:40.950+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:12:40.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:12:40.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:12:40.984+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:12:40.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:12:40.997+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:12:40.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:12:41.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T00:13:11.240+0000] {processor.py:157} INFO - Started process (PID=45251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:13:11.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:13:11.244+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:13:11.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:13:11.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:13:11.274+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:13:11.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:13:11.285+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:13:11.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:13:11.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T00:13:41.608+0000] {processor.py:157} INFO - Started process (PID=45261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:13:41.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:13:41.610+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:13:41.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:13:41.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:13:41.635+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:13:41.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:13:41.645+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:13:41.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:13:41.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-11T00:14:11.966+0000] {processor.py:157} INFO - Started process (PID=45271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:14:11.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:14:11.969+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:14:11.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:14:11.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:14:11.996+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:14:11.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:14:12.007+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:14:12.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:14:12.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T00:14:42.303+0000] {processor.py:157} INFO - Started process (PID=45281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:14:42.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:14:42.305+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:14:42.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:14:42.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:14:42.331+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:14:42.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:14:42.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:14:42.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:14:42.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T00:15:12.596+0000] {processor.py:157} INFO - Started process (PID=45291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:15:12.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:15:12.599+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:15:12.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:15:12.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:15:12.623+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:15:12.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:15:12.632+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:15:12.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:15:12.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-11T00:15:42.981+0000] {processor.py:157} INFO - Started process (PID=45301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:15:42.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:15:42.985+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:15:42.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:15:43.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:15:43.021+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:15:43.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:15:43.033+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:15:43.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:15:43.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T00:16:13.377+0000] {processor.py:157} INFO - Started process (PID=45310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:16:13.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:16:13.385+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:16:13.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:16:13.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:16:13.459+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:16:13.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:16:13.475+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:16:13.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:16:13.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T00:16:43.660+0000] {processor.py:157} INFO - Started process (PID=45321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:16:43.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:16:43.667+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:16:43.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:16:43.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:16:43.730+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:16:43.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:16:43.743+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:16:43.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:16:43.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T00:17:14.015+0000] {processor.py:157} INFO - Started process (PID=45331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:17:14.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:17:14.018+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:17:14.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:17:14.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:17:14.043+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:17:14.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:17:14.053+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:17:14.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:17:14.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T00:17:44.408+0000] {processor.py:157} INFO - Started process (PID=45341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:17:44.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:17:44.413+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:17:44.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:17:44.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:17:44.451+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:17:44.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:17:44.464+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:17:44.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:17:44.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T00:18:14.702+0000] {processor.py:157} INFO - Started process (PID=45350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:18:14.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:18:14.709+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:18:14.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:18:14.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:18:14.775+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:18:14.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:18:14.808+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:18:14.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:18:14.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T00:18:44.982+0000] {processor.py:157} INFO - Started process (PID=45361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:18:44.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:18:44.985+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:18:44.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:18:44.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:18:45.017+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:18:45.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:18:45.031+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:18:45.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:18:45.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T00:19:15.367+0000] {processor.py:157} INFO - Started process (PID=45369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:19:15.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:19:15.373+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:19:15.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:19:15.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:19:15.421+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:19:15.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:19:15.436+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:19:15.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:19:15.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T00:19:45.753+0000] {processor.py:157} INFO - Started process (PID=45381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:19:45.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:19:45.759+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:19:45.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:19:45.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:19:45.815+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:19:45.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:19:45.832+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:19:45.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:19:45.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T00:20:16.083+0000] {processor.py:157} INFO - Started process (PID=45391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:20:16.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:20:16.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:20:16.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:20:16.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:20:16.135+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:20:16.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:20:16.149+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:20:16.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:20:16.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T00:20:46.494+0000] {processor.py:157} INFO - Started process (PID=45401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:20:46.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:20:46.510+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:20:46.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:20:46.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:20:46.549+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:20:46.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:20:46.561+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:20:46.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:20:46.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T00:21:16.808+0000] {processor.py:157} INFO - Started process (PID=45411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:21:16.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:21:16.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:21:16.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:21:16.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:21:16.839+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:21:16.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:21:16.851+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:21:16.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:21:16.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T00:21:47.196+0000] {processor.py:157} INFO - Started process (PID=45420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:21:47.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:21:47.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:21:47.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:21:47.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:21:47.239+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:21:47.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:21:47.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:21:47.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:21:47.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T00:22:17.491+0000] {processor.py:157} INFO - Started process (PID=45431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:22:17.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:22:17.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:22:17.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:22:17.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:22:17.520+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:22:17.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:22:17.535+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:22:17.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:22:17.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T00:22:47.863+0000] {processor.py:157} INFO - Started process (PID=45441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:22:47.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:22:47.868+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:22:47.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:22:47.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:22:47.929+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:22:47.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:22:47.941+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:22:47.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:22:47.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-11T00:23:18.180+0000] {processor.py:157} INFO - Started process (PID=45451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:23:18.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:23:18.183+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:23:18.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:23:18.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:23:18.212+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:23:18.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:23:18.225+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:23:18.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:23:18.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T00:23:48.524+0000] {processor.py:157} INFO - Started process (PID=45461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:23:48.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:23:48.531+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:23:48.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:23:48.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:23:48.597+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:23:48.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:23:48.611+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:23:48.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:23:48.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T00:24:18.841+0000] {processor.py:157} INFO - Started process (PID=45471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:24:18.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:24:18.844+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:24:18.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:24:18.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:24:18.876+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:24:18.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:24:18.886+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:24:18.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:24:18.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T00:24:49.273+0000] {processor.py:157} INFO - Started process (PID=45481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:24:49.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:24:49.277+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:24:49.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:24:49.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:24:49.317+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:24:49.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:24:49.331+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:24:49.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:24:49.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T00:25:19.565+0000] {processor.py:157} INFO - Started process (PID=45491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:25:19.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:25:19.570+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:25:19.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:25:19.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:25:19.606+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:25:19.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:25:19.620+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:25:19.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:25:19.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T00:25:49.978+0000] {processor.py:157} INFO - Started process (PID=45501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:25:49.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:25:49.983+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:25:49.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:25:50.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:25:50.027+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:25:50.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:25:50.047+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:25:50.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:25:50.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T00:26:20.317+0000] {processor.py:157} INFO - Started process (PID=45511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:26:20.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:26:20.324+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:26:20.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:26:20.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:26:20.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:26:20.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:26:20.410+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:26:20.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:26:20.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T00:26:50.607+0000] {processor.py:157} INFO - Started process (PID=45521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:26:50.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:26:50.619+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:26:50.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:26:50.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:26:50.675+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:26:50.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:26:50.697+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:26:50.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:26:50.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T00:27:20.991+0000] {processor.py:157} INFO - Started process (PID=45530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:27:20.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:27:20.999+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:27:20.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:27:21.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:27:21.041+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:27:21.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:27:21.054+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:27:21.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:27:21.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T00:27:51.419+0000] {processor.py:157} INFO - Started process (PID=45541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:27:51.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:27:51.422+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:27:51.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:27:51.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:27:51.450+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:27:51.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:27:51.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:27:51.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:27:51.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T00:28:21.803+0000] {processor.py:157} INFO - Started process (PID=45551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:28:21.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:28:21.808+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:28:21.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:28:21.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:28:21.849+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:28:21.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:28:21.863+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:28:21.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:28:21.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T00:28:52.214+0000] {processor.py:157} INFO - Started process (PID=45561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:28:52.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:28:52.217+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:28:52.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:28:52.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:28:52.248+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:28:52.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:28:52.261+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:28:52.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:28:52.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T00:29:22.558+0000] {processor.py:157} INFO - Started process (PID=45571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:29:22.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:29:22.574+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:29:22.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:29:22.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:29:22.617+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:29:22.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:29:22.629+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:29:22.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:29:22.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T00:29:52.861+0000] {processor.py:157} INFO - Started process (PID=45581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:29:52.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:29:52.866+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:29:52.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:29:52.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:29:52.939+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:29:52.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:29:52.953+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:29:52.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:29:52.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T00:30:23.155+0000] {processor.py:157} INFO - Started process (PID=46162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:30:23.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:30:23.162+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:30:23.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:30:23.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:30:23.254+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:30:23.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:30:23.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:30:23.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:30:23.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T00:30:53.459+0000] {processor.py:157} INFO - Started process (PID=46172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:30:53.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:30:53.464+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:30:53.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:30:53.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:30:53.503+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:30:53.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:30:53.515+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:30:53.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:30:53.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T00:31:23.787+0000] {processor.py:157} INFO - Started process (PID=46182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:31:23.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:31:23.794+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:31:23.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:31:23.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:31:23.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:31:23.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:31:23.872+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:31:23.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:31:23.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T00:31:54.129+0000] {processor.py:157} INFO - Started process (PID=46192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:31:54.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:31:54.137+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:31:54.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:31:54.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:31:54.186+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:31:54.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:31:54.199+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:31:54.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:31:54.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T00:32:24.446+0000] {processor.py:157} INFO - Started process (PID=46370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:32:24.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:32:24.453+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:32:24.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:32:24.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:32:24.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:32:24.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:32:24.506+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:32:24.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:32:24.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T00:32:54.844+0000] {processor.py:157} INFO - Started process (PID=46380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:32:54.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:32:54.849+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:32:54.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:32:54.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:32:54.915+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:32:54.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:32:54.928+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:32:54.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:32:54.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T00:33:25.315+0000] {processor.py:157} INFO - Started process (PID=46390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:33:25.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:33:25.324+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:33:25.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:33:25.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:33:25.369+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:33:25.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:33:25.389+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:33:25.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:33:25.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T00:33:55.742+0000] {processor.py:157} INFO - Started process (PID=46400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:33:55.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:33:55.747+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:33:55.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:33:55.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:33:55.805+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:33:55.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:33:55.818+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:33:55.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:33:55.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T00:34:26.100+0000] {processor.py:157} INFO - Started process (PID=46409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:34:26.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:34:26.112+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:34:26.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:34:26.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:34:26.167+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:34:26.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:34:26.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:34:26.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:34:26.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T00:34:56.471+0000] {processor.py:157} INFO - Started process (PID=46419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:34:56.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:34:56.477+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:34:56.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:34:56.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:34:56.519+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:34:56.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:34:56.531+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:34:56.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:34:56.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T00:35:26.757+0000] {processor.py:157} INFO - Started process (PID=46430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:35:26.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:35:26.761+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:35:26.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:35:26.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:35:26.799+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:35:26.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:35:26.810+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:35:26.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:35:26.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T00:35:57.074+0000] {processor.py:157} INFO - Started process (PID=46440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:35:57.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:35:57.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:35:57.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:35:57.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:35:57.135+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:35:57.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:35:57.150+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:35:57.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:35:57.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T00:36:27.420+0000] {processor.py:157} INFO - Started process (PID=46450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:36:27.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:36:27.426+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:36:27.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:36:27.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:36:27.515+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:36:27.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:36:27.532+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:36:27.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:36:27.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T00:36:57.794+0000] {processor.py:157} INFO - Started process (PID=46460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:36:57.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:36:57.803+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:36:57.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:36:57.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:36:57.925+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:36:57.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:36:57.950+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:36:57.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:36:57.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-11T00:37:28.163+0000] {processor.py:157} INFO - Started process (PID=46470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:37:28.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:37:28.166+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:37:28.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:37:28.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:37:28.211+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:37:28.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:37:28.227+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:37:28.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:37:28.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T00:37:58.594+0000] {processor.py:157} INFO - Started process (PID=46479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:37:58.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:37:58.599+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:37:58.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:37:58.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:37:58.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:37:58.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:37:58.654+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:37:58.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:37:58.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T00:38:28.907+0000] {processor.py:157} INFO - Started process (PID=46490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:38:28.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:38:28.912+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:38:28.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:38:28.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:38:28.957+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:38:28.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:38:28.970+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:38:28.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:38:28.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T00:38:59.264+0000] {processor.py:157} INFO - Started process (PID=46500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:38:59.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:38:59.269+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:38:59.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:38:59.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:38:59.323+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:38:59.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:38:59.337+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:38:59.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:38:59.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T00:39:29.608+0000] {processor.py:157} INFO - Started process (PID=46510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:39:29.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:39:29.618+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:39:29.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:39:29.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:39:29.678+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:39:29.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:39:29.693+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:39:29.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:39:29.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T00:39:59.908+0000] {processor.py:157} INFO - Started process (PID=46520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:39:59.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:39:59.913+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:39:59.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:39:59.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:39:59.956+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:39:59.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:39:59.970+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:39:59.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:39:59.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T00:40:30.252+0000] {processor.py:157} INFO - Started process (PID=46529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:40:30.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:40:30.257+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:40:30.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:40:30.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:40:30.297+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:40:30.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:40:30.309+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:40:30.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:40:30.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T00:41:00.539+0000] {processor.py:157} INFO - Started process (PID=46539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:41:00.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:41:00.546+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:41:00.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:41:00.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:41:00.608+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:41:00.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:41:00.622+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:41:00.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:41:00.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T00:41:30.810+0000] {processor.py:157} INFO - Started process (PID=46549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:41:30.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:41:30.817+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:41:30.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:41:30.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:41:30.873+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:41:30.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:41:30.885+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:41:30.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:41:30.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T00:42:01.149+0000] {processor.py:157} INFO - Started process (PID=46560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:42:01.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:42:01.157+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:42:01.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:42:01.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:42:01.223+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:42:01.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:42:01.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:42:01.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:42:01.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-11T00:42:31.516+0000] {processor.py:157} INFO - Started process (PID=46570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:42:31.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:42:31.522+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:42:31.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:42:31.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:42:31.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:42:31.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:42:31.593+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:42:31.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:42:31.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T00:43:01.860+0000] {processor.py:157} INFO - Started process (PID=46580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:43:01.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:43:01.865+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:43:01.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:43:01.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:43:01.905+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:43:01.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:43:01.917+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:43:01.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:43:01.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T00:43:32.123+0000] {processor.py:157} INFO - Started process (PID=46590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:43:32.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:43:32.128+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:43:32.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:43:32.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:43:32.154+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:43:32.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:43:32.165+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:43:32.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:43:32.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T00:44:02.534+0000] {processor.py:157} INFO - Started process (PID=46599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:44:02.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:44:02.554+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:44:02.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:44:02.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:44:02.623+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:44:02.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:44:02.637+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:44:02.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:44:02.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T00:44:32.989+0000] {processor.py:157} INFO - Started process (PID=46610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:44:32.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:44:32.993+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:44:32.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:44:33.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:44:33.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:44:33.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:44:33.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:44:33.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:44:33.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T00:45:03.423+0000] {processor.py:157} INFO - Started process (PID=46619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:45:03.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:45:03.429+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:45:03.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:45:03.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:45:03.479+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:45:03.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:45:03.492+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:45:03.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:45:03.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T00:45:33.852+0000] {processor.py:157} INFO - Started process (PID=46628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:45:33.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:45:33.857+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:45:33.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:45:33.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:45:33.908+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:45:33.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:45:33.922+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:45:33.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:45:33.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T00:46:04.184+0000] {processor.py:157} INFO - Started process (PID=46640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:46:04.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:46:04.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:46:04.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:46:04.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:46:04.222+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:46:04.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:46:04.233+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:46:04.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:46:04.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T00:46:34.592+0000] {processor.py:157} INFO - Started process (PID=46650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:46:34.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:46:34.604+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:46:34.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:46:34.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:46:34.648+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:46:34.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:46:34.665+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:46:34.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:46:34.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T00:47:05.030+0000] {processor.py:157} INFO - Started process (PID=46660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:47:05.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:47:05.038+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:47:05.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:47:05.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:47:05.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:47:05.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:47:05.104+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:47:05.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:47:05.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T00:47:35.402+0000] {processor.py:157} INFO - Started process (PID=46670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:47:35.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:47:35.407+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:47:35.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:47:35.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:47:35.461+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:47:35.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:47:35.474+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:47:35.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:47:35.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T00:48:05.777+0000] {processor.py:157} INFO - Started process (PID=46680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:48:05.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:48:05.781+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:48:05.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:48:05.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:48:05.869+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:48:05.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:48:05.887+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:48:05.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:48:05.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-11T00:48:36.174+0000] {processor.py:157} INFO - Started process (PID=46688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:48:36.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:48:36.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:48:36.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:48:36.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:48:36.219+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:48:36.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:48:36.233+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:48:36.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:48:36.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T00:49:06.501+0000] {processor.py:157} INFO - Started process (PID=46699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:49:06.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:49:06.505+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:49:06.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:49:06.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:49:06.549+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:49:06.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:49:06.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:49:06.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:49:06.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T00:49:36.871+0000] {processor.py:157} INFO - Started process (PID=46709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:49:36.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:49:36.876+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:49:36.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:49:36.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:49:36.926+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:49:36.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:49:36.942+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:49:36.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:49:36.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T00:50:07.278+0000] {processor.py:157} INFO - Started process (PID=46720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:50:07.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:50:07.282+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:50:07.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:50:07.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:50:07.324+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:50:07.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:50:07.338+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:50:07.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:50:07.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T00:50:37.678+0000] {processor.py:157} INFO - Started process (PID=46730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:50:37.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:50:37.683+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:50:37.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:50:37.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:50:37.725+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:50:37.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:50:37.745+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:50:37.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:50:37.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T00:51:08.040+0000] {processor.py:157} INFO - Started process (PID=46740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:51:08.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:51:08.044+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:51:08.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:51:08.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:51:08.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:51:08.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:51:08.100+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:51:08.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:51:08.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T00:51:38.450+0000] {processor.py:157} INFO - Started process (PID=46749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:51:38.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:51:38.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:51:38.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:51:38.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:51:38.507+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:51:38.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:51:38.520+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:51:38.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:51:38.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T00:52:08.780+0000] {processor.py:157} INFO - Started process (PID=46759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:52:08.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:52:08.786+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:52:08.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:52:08.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:52:08.828+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:52:08.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:52:08.839+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:52:08.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:52:08.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T00:52:39.142+0000] {processor.py:157} INFO - Started process (PID=46770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:52:39.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:52:39.147+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:52:39.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:52:39.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:52:39.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:52:39.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:52:39.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:52:39.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:52:39.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T00:53:09.427+0000] {processor.py:157} INFO - Started process (PID=46780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:53:09.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:53:09.431+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:53:09.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:53:09.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:53:09.466+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:53:09.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:53:09.478+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:53:09.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:53:09.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-11T00:53:39.816+0000] {processor.py:157} INFO - Started process (PID=46790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:53:39.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:53:39.823+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:53:39.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:53:39.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:53:39.886+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:53:39.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:53:39.901+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:53:39.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:53:39.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T00:54:10.170+0000] {processor.py:157} INFO - Started process (PID=46800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:54:10.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:54:10.192+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:54:10.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:54:10.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:54:10.243+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:54:10.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:54:10.257+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:54:10.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:54:10.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T00:54:40.681+0000] {processor.py:157} INFO - Started process (PID=46810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:54:40.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:54:40.687+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:54:40.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:54:40.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:54:40.725+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:54:40.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:54:40.736+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:54:40.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:54:40.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T00:55:11.105+0000] {processor.py:157} INFO - Started process (PID=46820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:55:11.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:55:11.109+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:55:11.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:55:11.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:55:11.145+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:55:11.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:55:11.159+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:55:11.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:55:11.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T00:55:41.573+0000] {processor.py:157} INFO - Started process (PID=46830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:55:41.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:55:41.586+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:55:41.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:55:41.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:55:41.660+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:55:41.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:55:41.685+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:55:41.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:55:41.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-11T00:56:11.959+0000] {processor.py:157} INFO - Started process (PID=46839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:56:11.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:56:11.966+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:56:11.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:56:11.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:56:12.048+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:56:12.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:56:12.069+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:56:12.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:56:12.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-11T00:56:42.458+0000] {processor.py:157} INFO - Started process (PID=46850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:56:42.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:56:42.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:56:42.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:56:42.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:56:42.544+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:56:42.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:56:42.561+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:56:42.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:56:42.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-11T00:57:12.798+0000] {processor.py:157} INFO - Started process (PID=46860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:57:12.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:57:12.815+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:57:12.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:57:12.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:57:12.882+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:57:12.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:57:12.901+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:57:12.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:57:12.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-11T00:57:43.128+0000] {processor.py:157} INFO - Started process (PID=46870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:57:43.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:57:43.135+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:57:43.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:57:43.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:57:43.210+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:57:43.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:57:43.230+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:57:43.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:57:43.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T00:58:13.501+0000] {processor.py:157} INFO - Started process (PID=46880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:58:13.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:58:13.505+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:58:13.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:58:13.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:58:13.559+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:58:13.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:58:13.579+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:58:13.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:58:13.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T00:58:43.829+0000] {processor.py:157} INFO - Started process (PID=46890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:58:43.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:58:43.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:58:43.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:58:43.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:58:43.880+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:58:43.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:58:43.896+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:58:43.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:58:43.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T00:59:14.257+0000] {processor.py:157} INFO - Started process (PID=46900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:59:14.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:59:14.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:59:14.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:59:14.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:59:14.307+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:59:14.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:59:14.326+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:59:14.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:59:14.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T00:59:44.548+0000] {processor.py:157} INFO - Started process (PID=46910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:59:44.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T00:59:44.554+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:59:44.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:59:44.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T00:59:44.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:59:44.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T00:59:44.645+0000] {logging_mixin.py:151} INFO - [2024-09-11T00:59:44.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-11T00:59:44.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T01:00:15.125+0000] {processor.py:157} INFO - Started process (PID=46920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:00:15.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:00:15.129+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:00:15.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:00:15.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:00:15.162+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:00:15.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:00:15.175+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:00:15.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:00:15.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T01:00:45.520+0000] {processor.py:157} INFO - Started process (PID=46930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:00:45.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:00:45.524+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:00:45.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:00:45.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:00:45.562+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:00:45.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:00:45.577+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:00:45.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:00:45.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T01:01:15.882+0000] {processor.py:157} INFO - Started process (PID=46940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:01:15.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:01:15.884+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:01:15.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:01:15.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:01:15.919+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:01:15.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:01:15.930+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:01:15.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:01:15.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T01:01:46.269+0000] {processor.py:157} INFO - Started process (PID=46950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:01:46.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:01:46.272+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:01:46.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:01:46.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:01:46.306+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:01:46.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:01:46.318+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:01:46.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:01:46.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T01:02:16.616+0000] {processor.py:157} INFO - Started process (PID=46960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:02:16.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:02:16.620+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:02:16.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:02:16.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:02:16.654+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:02:16.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:02:16.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:02:16.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:02:16.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-11T01:02:47.010+0000] {processor.py:157} INFO - Started process (PID=46970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:02:47.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:02:47.015+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:02:47.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:02:47.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:02:47.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:02:47.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:02:47.071+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:02:47.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:02:47.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T01:03:17.433+0000] {processor.py:157} INFO - Started process (PID=46980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:03:17.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:03:17.438+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:03:17.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:03:17.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:03:17.485+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:03:17.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:03:17.498+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:03:17.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:03:17.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T01:03:47.818+0000] {processor.py:157} INFO - Started process (PID=46990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:03:47.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:03:47.826+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:03:47.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:03:47.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:03:47.875+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:03:47.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:03:47.887+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:03:47.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:03:47.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T01:04:18.126+0000] {processor.py:157} INFO - Started process (PID=47000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:04:18.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:04:18.131+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:04:18.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:04:18.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:04:18.166+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:04:18.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:04:18.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:04:18.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:04:18.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T01:04:48.464+0000] {processor.py:157} INFO - Started process (PID=47010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:04:48.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:04:48.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:04:48.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:04:48.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:04:48.494+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:04:48.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:04:48.505+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:04:48.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:04:48.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T01:05:18.826+0000] {processor.py:157} INFO - Started process (PID=47020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:05:18.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:05:18.831+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:05:18.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:05:18.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:05:18.886+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:05:18.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:05:18.896+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:05:18.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:05:18.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T01:05:49.278+0000] {processor.py:157} INFO - Started process (PID=47030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:05:49.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:05:49.280+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:05:49.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:05:49.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:05:49.308+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:05:49.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:05:49.319+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:05:49.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:05:49.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T01:06:19.645+0000] {processor.py:157} INFO - Started process (PID=47040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:06:19.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:06:19.649+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:06:19.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:06:19.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:06:19.706+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:06:19.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:06:19.719+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:06:19.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:06:19.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T01:06:49.931+0000] {processor.py:157} INFO - Started process (PID=47050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:06:49.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:06:49.934+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:06:49.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:06:49.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:06:49.973+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:06:49.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:06:49.986+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:06:49.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:06:49.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T01:07:20.328+0000] {processor.py:157} INFO - Started process (PID=47060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:07:20.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:07:20.330+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:07:20.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:07:20.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:07:20.359+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:07:20.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:07:20.368+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:07:20.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:07:20.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T01:07:50.780+0000] {processor.py:157} INFO - Started process (PID=47070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:07:50.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:07:50.785+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:07:50.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:07:50.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:07:50.821+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:07:50.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:07:50.834+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:07:50.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:07:50.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T01:08:21.038+0000] {processor.py:157} INFO - Started process (PID=47080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:08:21.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:08:21.040+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:08:21.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:08:21.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:08:21.068+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:08:21.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:08:21.077+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:08:21.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:08:21.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T01:08:51.487+0000] {processor.py:157} INFO - Started process (PID=47090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:08:51.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:08:51.492+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:08:51.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:08:51.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:08:51.529+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:08:51.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:08:51.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:08:51.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:08:51.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T01:09:21.894+0000] {processor.py:157} INFO - Started process (PID=47100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:09:21.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:09:21.896+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:09:21.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:09:21.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:09:21.921+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:09:21.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:09:21.932+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:09:21.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:09:21.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-11T01:09:52.312+0000] {processor.py:157} INFO - Started process (PID=47110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:09:52.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:09:52.316+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:09:52.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:09:52.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:09:52.357+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:09:52.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:09:52.368+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:09:52.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:09:52.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T01:10:22.665+0000] {processor.py:157} INFO - Started process (PID=47120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:10:22.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:10:22.669+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:10:22.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:10:22.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:10:22.704+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:10:22.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:10:22.716+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:10:22.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:10:22.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T01:10:53.052+0000] {processor.py:157} INFO - Started process (PID=47130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:10:53.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:10:53.056+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:10:53.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:10:53.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:10:53.081+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:10:53.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:10:53.091+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:10:53.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:10:53.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T01:11:23.598+0000] {processor.py:157} INFO - Started process (PID=47139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:11:23.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:11:23.603+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:11:23.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:11:23.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:11:23.641+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:11:23.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:11:23.653+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:11:23.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:11:23.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T01:11:54.005+0000] {processor.py:157} INFO - Started process (PID=47150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:11:54.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:11:54.008+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:11:54.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:11:54.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:11:54.035+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:11:54.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:11:54.046+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:11:54.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:11:54.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T01:12:24.466+0000] {processor.py:157} INFO - Started process (PID=47159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:12:24.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:12:24.478+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:12:24.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:12:24.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:12:24.525+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:12:24.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:12:24.537+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:12:24.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:12:24.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T01:12:54.882+0000] {processor.py:157} INFO - Started process (PID=47170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:12:54.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:12:54.884+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:12:54.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:12:54.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:12:54.912+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:12:54.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:12:54.921+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:12:54.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:12:54.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T01:13:25.225+0000] {processor.py:157} INFO - Started process (PID=47180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:13:25.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:13:25.238+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:13:25.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:13:25.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:13:25.283+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:13:25.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:13:25.295+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:13:25.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:13:25.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T01:13:55.611+0000] {processor.py:157} INFO - Started process (PID=47190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:13:55.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:13:55.615+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:13:55.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:13:55.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:13:55.650+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:13:55.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:13:55.665+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:13:55.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:13:55.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T01:14:26.031+0000] {processor.py:157} INFO - Started process (PID=47200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:14:26.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:14:26.034+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:14:26.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:14:26.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:14:26.062+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:14:26.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:14:26.072+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:14:26.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:14:26.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T01:14:56.334+0000] {processor.py:157} INFO - Started process (PID=47210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:14:56.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:14:56.337+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:14:56.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:14:56.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:14:56.370+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:14:56.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:14:56.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:14:56.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:14:56.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T01:15:26.645+0000] {processor.py:157} INFO - Started process (PID=47220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:15:26.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:15:26.648+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:15:26.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:15:26.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:15:26.680+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:15:26.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:15:26.695+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:15:26.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:15:26.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-11T01:15:56.978+0000] {processor.py:157} INFO - Started process (PID=47230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:15:56.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:15:56.981+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:15:56.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:15:56.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:15:57.015+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:15:57.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:15:57.025+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:15:57.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:15:57.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T01:16:27.416+0000] {processor.py:157} INFO - Started process (PID=47240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:16:27.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:16:27.420+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:16:27.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:16:27.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:16:27.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:16:27.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:16:27.480+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:16:27.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:16:27.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T01:16:57.755+0000] {processor.py:157} INFO - Started process (PID=47250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:16:57.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:16:57.758+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:16:57.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:16:57.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:16:57.786+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:16:57.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:16:57.797+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:16:57.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:16:57.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T01:17:28.183+0000] {processor.py:157} INFO - Started process (PID=47260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:17:28.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:17:28.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:17:28.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:17:28.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:17:28.224+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:17:28.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:17:28.240+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:17:28.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:17:28.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T01:17:58.488+0000] {processor.py:157} INFO - Started process (PID=47270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:17:58.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:17:58.490+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:17:58.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:17:58.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:17:58.514+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:17:58.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:17:58.524+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:17:58.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:17:58.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-11T01:18:28.861+0000] {processor.py:157} INFO - Started process (PID=47280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:18:28.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:18:28.865+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:18:28.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:18:28.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:18:28.905+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:18:28.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:18:28.917+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:18:28.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:18:28.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T01:18:59.268+0000] {processor.py:157} INFO - Started process (PID=47290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:18:59.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:18:59.270+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:18:59.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:18:59.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:18:59.298+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:18:59.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:18:59.307+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:18:59.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:18:59.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T01:19:29.724+0000] {processor.py:157} INFO - Started process (PID=47300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:19:29.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:19:29.733+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:19:29.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:19:29.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:19:29.783+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:19:29.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:19:29.795+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:19:29.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:19:29.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T01:20:00.153+0000] {processor.py:157} INFO - Started process (PID=47310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:20:00.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:20:00.159+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:20:00.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:20:00.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:20:00.198+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:20:00.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:20:00.211+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:20:00.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:20:00.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T01:20:30.567+0000] {processor.py:157} INFO - Started process (PID=47320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:20:30.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:20:30.569+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:20:30.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:20:30.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:20:30.602+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:20:30.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:20:30.614+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:20:30.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:20:30.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T01:21:01.071+0000] {processor.py:157} INFO - Started process (PID=47329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:21:01.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:21:01.080+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:21:01.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:21:01.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:21:01.125+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:21:01.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:21:01.137+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:21:01.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:21:01.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T01:21:31.435+0000] {processor.py:157} INFO - Started process (PID=47340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:21:31.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:21:31.439+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:21:31.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:21:31.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:21:31.465+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:21:31.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:21:31.475+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:21:31.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:21:31.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T01:22:01.819+0000] {processor.py:157} INFO - Started process (PID=47350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:22:01.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:22:01.828+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:22:01.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:22:01.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:22:01.869+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:22:01.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:22:01.881+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:22:01.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:22:01.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T01:22:32.219+0000] {processor.py:157} INFO - Started process (PID=47359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:22:32.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:22:32.223+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:22:32.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:22:32.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:22:32.249+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:22:32.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:22:32.259+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:22:32.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:22:32.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T01:23:02.610+0000] {processor.py:157} INFO - Started process (PID=47370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:23:02.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:23:02.616+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:23:02.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:23:02.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:23:02.658+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:23:02.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:23:02.670+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:23:02.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:23:02.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T01:23:33.007+0000] {processor.py:157} INFO - Started process (PID=47380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:23:33.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:23:33.009+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:23:33.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:23:33.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:23:33.036+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:23:33.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:23:33.046+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:23:33.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:23:33.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T01:24:03.450+0000] {processor.py:157} INFO - Started process (PID=47390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:24:03.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:24:03.456+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:24:03.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:24:03.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:24:03.501+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:24:03.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:24:03.514+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:24:03.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:24:03.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T01:24:33.840+0000] {processor.py:157} INFO - Started process (PID=47399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:24:33.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:24:33.842+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:24:33.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:24:33.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:24:33.868+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:24:33.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:24:33.878+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:24:33.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:24:33.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T01:25:04.333+0000] {processor.py:157} INFO - Started process (PID=47410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:25:04.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:25:04.337+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:25:04.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:25:04.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:25:04.376+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:25:04.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:25:04.389+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:25:04.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:25:04.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T01:25:34.689+0000] {processor.py:157} INFO - Started process (PID=47420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:25:34.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:25:34.691+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:25:34.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:25:34.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:25:34.714+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:25:34.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:25:34.724+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:25:34.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:25:34.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-11T01:26:05.131+0000] {processor.py:157} INFO - Started process (PID=47430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:26:05.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:26:05.136+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:26:05.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:26:05.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:26:05.177+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:26:05.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:26:05.189+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:26:05.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:26:05.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T01:26:35.457+0000] {processor.py:157} INFO - Started process (PID=47440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:26:35.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:26:35.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:26:35.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:26:35.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:26:35.487+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:26:35.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:26:35.497+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:26:35.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:26:35.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T01:27:05.853+0000] {processor.py:157} INFO - Started process (PID=47450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:27:05.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:27:05.858+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:27:05.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:27:05.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:27:05.893+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:27:05.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:27:05.910+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:27:05.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:27:05.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T01:27:36.281+0000] {processor.py:157} INFO - Started process (PID=47460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:27:36.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:27:36.284+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:27:36.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:27:36.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:27:36.321+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:27:36.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:27:36.332+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:27:36.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:27:36.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T01:28:06.700+0000] {processor.py:157} INFO - Started process (PID=47470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:28:06.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:28:06.704+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:28:06.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:28:06.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:28:06.741+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:28:06.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:28:06.753+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:28:06.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:28:06.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T01:28:37.040+0000] {processor.py:157} INFO - Started process (PID=47480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:28:37.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:28:37.044+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:28:37.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:28:37.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:28:37.067+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:28:37.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:28:37.076+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:28:37.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:28:37.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T01:29:07.445+0000] {processor.py:157} INFO - Started process (PID=47490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:29:07.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:29:07.449+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:29:07.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:29:07.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:29:07.487+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:29:07.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:29:07.499+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:29:07.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:29:07.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T01:29:37.806+0000] {processor.py:157} INFO - Started process (PID=47500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:29:37.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:29:37.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:29:37.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:29:37.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:29:37.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:29:37.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:29:37.849+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:29:37.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:29:37.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T01:30:08.191+0000] {processor.py:157} INFO - Started process (PID=47510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:30:08.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:30:08.196+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:30:08.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:30:08.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:30:08.235+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:30:08.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:30:08.247+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:30:08.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:30:08.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T01:30:38.526+0000] {processor.py:157} INFO - Started process (PID=47519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:30:38.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:30:38.529+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:30:38.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:30:38.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:30:38.562+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:30:38.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:30:38.572+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:30:38.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:30:38.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T01:31:08.996+0000] {processor.py:157} INFO - Started process (PID=47530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:31:09.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:31:09.002+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:31:09.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:31:09.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:31:09.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:31:09.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:31:09.053+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:31:09.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:31:09.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T01:31:39.360+0000] {processor.py:157} INFO - Started process (PID=47539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:31:39.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:31:39.363+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:31:39.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:31:39.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:31:39.388+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:31:39.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:31:39.398+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:31:39.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:31:39.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T01:32:09.849+0000] {processor.py:157} INFO - Started process (PID=47550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:32:09.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:32:09.857+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:32:09.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:32:09.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:32:09.903+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:32:09.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:32:09.918+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:32:09.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:32:09.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T01:32:40.206+0000] {processor.py:157} INFO - Started process (PID=47559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:32:40.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:32:40.209+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:32:40.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:32:40.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:32:40.234+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:32:40.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:32:40.245+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:32:40.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:32:40.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T01:33:10.653+0000] {processor.py:157} INFO - Started process (PID=47570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:33:10.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:33:10.658+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:33:10.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:33:10.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:33:10.701+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:33:10.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:33:10.713+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:33:10.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:33:10.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T01:33:40.951+0000] {processor.py:157} INFO - Started process (PID=47579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:33:40.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:33:40.954+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:33:40.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:33:40.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:33:40.980+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:33:40.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:33:40.990+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:33:40.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:33:40.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T01:34:11.271+0000] {processor.py:157} INFO - Started process (PID=47590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:34:11.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:34:11.276+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:34:11.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:34:11.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:34:11.319+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:34:11.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:34:11.332+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:34:11.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:34:11.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T01:34:41.737+0000] {processor.py:157} INFO - Started process (PID=47600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:34:41.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:34:41.741+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:34:41.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:34:41.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:34:41.777+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:34:41.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:34:41.789+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:34:41.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:34:41.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T01:35:12.208+0000] {processor.py:157} INFO - Started process (PID=47610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:35:12.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:35:12.210+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:35:12.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:35:12.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:35:12.235+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:35:12.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:35:12.246+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:35:12.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:35:12.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T01:35:42.539+0000] {processor.py:157} INFO - Started process (PID=47620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:35:42.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:35:42.544+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:35:42.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:35:42.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:35:42.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:35:42.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:35:42.602+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:35:42.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:35:42.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T01:36:12.964+0000] {processor.py:157} INFO - Started process (PID=47630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:36:12.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:36:12.968+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:36:12.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:36:12.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:36:13.004+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:36:13.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:36:13.017+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:36:13.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:36:13.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T01:36:43.334+0000] {processor.py:157} INFO - Started process (PID=47640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:36:43.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:36:43.336+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:36:43.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:36:43.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:36:43.369+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:36:43.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:36:43.379+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:36:43.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:36:43.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T01:37:13.772+0000] {processor.py:157} INFO - Started process (PID=47650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:37:13.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:37:13.776+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:37:13.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:37:13.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:37:13.811+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:37:13.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:37:13.824+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:37:13.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:37:13.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T01:37:44.250+0000] {processor.py:157} INFO - Started process (PID=47660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:37:44.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:37:44.257+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:37:44.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:37:44.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:37:44.292+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:37:44.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:37:44.308+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:37:44.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:37:44.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T01:38:14.616+0000] {processor.py:157} INFO - Started process (PID=47670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:38:14.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:38:14.619+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:38:14.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:38:14.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:38:14.643+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:38:14.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:38:14.652+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:38:14.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:38:14.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-11T01:38:45.078+0000] {processor.py:157} INFO - Started process (PID=47680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:38:45.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:38:45.084+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:38:45.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:38:45.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:38:45.129+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:38:45.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:38:45.143+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:38:45.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:38:45.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T01:39:15.404+0000] {processor.py:157} INFO - Started process (PID=47690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:39:15.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:39:15.408+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:39:15.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:39:15.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:39:15.439+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:39:15.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:39:15.449+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:39:15.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:39:15.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T01:39:45.800+0000] {processor.py:157} INFO - Started process (PID=47700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:39:45.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:39:45.803+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:39:45.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:39:45.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:39:45.833+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:39:45.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:39:45.845+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:39:45.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:39:45.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T01:40:16.186+0000] {processor.py:157} INFO - Started process (PID=47709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:40:16.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:40:16.192+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:40:16.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:40:16.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:40:16.226+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:40:16.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:40:16.237+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:40:16.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:40:16.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T01:40:46.508+0000] {processor.py:157} INFO - Started process (PID=47720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:40:46.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:40:46.511+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:40:46.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:40:46.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:40:46.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:40:46.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:40:46.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:40:46.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:40:46.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T01:41:16.935+0000] {processor.py:157} INFO - Started process (PID=47730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:41:16.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:41:16.942+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:41:16.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:41:16.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:41:16.984+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:41:16.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:41:16.996+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:41:16.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:41:17.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T01:41:47.341+0000] {processor.py:157} INFO - Started process (PID=47740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:41:47.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:41:47.344+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:41:47.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:41:47.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:41:47.376+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:41:47.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:41:47.388+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:41:47.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:41:47.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T01:42:17.659+0000] {processor.py:157} INFO - Started process (PID=47750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:42:17.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:42:17.664+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:42:17.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:42:17.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:42:17.741+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:42:17.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:42:17.755+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:42:17.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:42:17.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T01:42:48.181+0000] {processor.py:157} INFO - Started process (PID=47760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:42:48.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:42:48.196+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:42:48.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:42:48.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:42:48.245+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:42:48.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:42:48.262+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:42:48.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:42:48.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T01:43:18.571+0000] {processor.py:157} INFO - Started process (PID=47770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:43:18.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:43:18.575+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:43:18.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:43:18.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:43:18.610+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:43:18.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:43:18.622+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:43:18.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:43:18.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T01:43:48.988+0000] {processor.py:157} INFO - Started process (PID=47780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:43:48.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:43:48.993+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:43:48.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:43:49.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:43:49.023+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:43:49.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:43:49.033+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:43:49.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:43:49.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T01:44:19.431+0000] {processor.py:157} INFO - Started process (PID=47790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:44:19.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:44:19.433+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:44:19.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:44:19.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:44:19.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:44:19.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:44:19.480+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:44:19.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:44:19.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T01:44:49.874+0000] {processor.py:157} INFO - Started process (PID=47800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:44:49.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:44:49.877+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:44:49.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:44:49.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:44:49.906+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:44:49.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:44:49.918+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:44:49.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:44:49.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T01:45:20.301+0000] {processor.py:157} INFO - Started process (PID=47810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:45:20.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:45:20.304+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:45:20.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:45:20.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:45:20.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:45:20.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:45:20.356+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:45:20.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:45:20.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T01:45:50.678+0000] {processor.py:157} INFO - Started process (PID=47820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:45:50.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:45:50.686+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:45:50.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:45:50.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:45:50.716+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:45:50.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:45:50.727+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:45:50.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:45:50.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T01:46:21.091+0000] {processor.py:157} INFO - Started process (PID=47830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:46:21.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:46:21.095+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:46:21.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:46:21.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:46:21.133+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:46:21.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:46:21.146+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:46:21.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:46:21.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T01:46:51.458+0000] {processor.py:157} INFO - Started process (PID=47840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:46:51.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:46:51.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:46:51.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:46:51.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:46:51.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:46:51.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:46:51.502+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:46:51.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:46:51.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T01:47:21.845+0000] {processor.py:157} INFO - Started process (PID=47850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:47:21.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:47:21.848+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:47:21.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:47:21.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:47:21.895+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:47:21.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:47:21.910+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:47:21.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:47:22.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.734 seconds
[2024-09-11T01:47:52.956+0000] {processor.py:157} INFO - Started process (PID=47860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:47:52.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:47:52.959+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:47:52.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:47:52.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:47:53.026+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:47:53.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:47:53.040+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:47:53.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:47:53.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T01:48:23.266+0000] {processor.py:157} INFO - Started process (PID=47870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:48:23.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:48:23.273+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:48:23.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:48:23.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:48:23.301+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:48:23.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:48:23.312+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:48:23.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:48:23.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T01:48:53.680+0000] {processor.py:157} INFO - Started process (PID=47880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:48:53.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:48:53.701+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:48:53.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:48:53.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:48:53.748+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:48:53.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:48:53.760+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:48:53.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:48:53.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T01:49:24.062+0000] {processor.py:157} INFO - Started process (PID=47890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:49:24.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:49:24.067+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:49:24.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:49:24.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:49:24.095+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:49:24.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:49:24.105+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:49:24.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:49:24.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T01:49:54.478+0000] {processor.py:157} INFO - Started process (PID=47900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:49:54.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:49:54.484+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:49:54.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:49:54.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:49:54.521+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:49:54.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:49:54.535+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:49:54.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:49:54.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T01:50:24.768+0000] {processor.py:157} INFO - Started process (PID=47910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:50:24.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:50:24.772+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:50:24.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:50:24.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:50:24.798+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:50:24.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:50:24.811+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:50:24.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:50:24.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-11T01:50:55.356+0000] {processor.py:157} INFO - Started process (PID=47919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:50:55.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:50:55.363+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:50:55.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:50:55.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:50:55.422+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:50:55.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:50:55.437+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:50:55.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:50:55.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T01:51:25.769+0000] {processor.py:157} INFO - Started process (PID=47930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:51:25.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:51:25.781+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:51:25.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:51:25.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:51:25.823+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:51:25.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:51:25.836+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:51:25.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:51:25.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T01:51:56.080+0000] {processor.py:157} INFO - Started process (PID=47940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:51:56.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:51:56.087+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:51:56.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:51:56.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:51:56.129+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:51:56.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:51:56.142+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:51:56.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:51:56.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T01:52:26.490+0000] {processor.py:157} INFO - Started process (PID=47950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:52:26.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:52:26.505+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:52:26.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:52:26.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:52:26.547+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:52:26.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:52:26.564+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:52:26.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:52:26.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T01:52:56.844+0000] {processor.py:157} INFO - Started process (PID=47960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:52:56.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:52:56.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:52:56.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:52:56.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:52:56.873+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:52:56.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:52:56.883+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:52:56.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:52:56.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T01:53:27.282+0000] {processor.py:157} INFO - Started process (PID=47970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:53:27.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:53:27.291+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:53:27.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:53:27.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:53:27.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:53:27.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:53:27.400+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:53:27.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:53:27.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-09-11T01:53:57.890+0000] {processor.py:157} INFO - Started process (PID=47980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:53:57.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:53:57.895+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:53:57.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:53:57.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:53:57.952+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:53:57.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:53:57.966+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:53:57.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:53:57.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T01:54:28.197+0000] {processor.py:157} INFO - Started process (PID=47989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:54:28.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:54:28.202+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:54:28.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:54:28.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:54:28.240+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:54:28.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:54:28.252+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:54:28.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:54:28.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T01:54:58.605+0000] {processor.py:157} INFO - Started process (PID=48000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:54:58.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:54:58.607+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:54:58.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:54:58.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:54:58.633+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:54:58.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:54:58.642+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:54:58.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:54:58.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-11T01:55:28.936+0000] {processor.py:157} INFO - Started process (PID=48010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:55:28.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:55:28.941+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:55:28.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:55:28.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:55:29.000+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:55:28.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:55:29.013+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:55:29.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:55:29.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T01:55:59.281+0000] {processor.py:157} INFO - Started process (PID=48020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:55:59.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:55:59.291+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:55:59.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:55:59.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:55:59.340+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:55:59.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:55:59.353+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:55:59.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:55:59.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T01:56:29.650+0000] {processor.py:157} INFO - Started process (PID=48030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:56:29.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:56:29.661+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:56:29.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:56:29.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:56:29.707+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:56:29.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:56:29.722+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:56:29.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:56:29.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-09-11T01:56:59.947+0000] {processor.py:157} INFO - Started process (PID=48040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:56:59.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:56:59.953+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:56:59.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:56:59.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:57:00.010+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:57:00.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:57:00.027+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:57:00.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:57:00.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T01:57:30.228+0000] {processor.py:157} INFO - Started process (PID=48050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:57:30.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:57:30.234+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:57:30.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:57:30.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:57:30.275+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:57:30.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:57:30.288+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:57:30.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:57:30.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T01:58:00.524+0000] {processor.py:157} INFO - Started process (PID=48060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:58:00.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:58:00.528+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:58:00.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:58:00.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:58:00.564+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:58:00.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:58:00.577+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:58:00.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:58:00.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T01:58:30.894+0000] {processor.py:157} INFO - Started process (PID=48070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:58:30.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:58:30.898+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:58:30.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:58:30.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:58:30.961+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:58:30.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:58:30.976+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:58:30.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:58:30.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T01:59:01.326+0000] {processor.py:157} INFO - Started process (PID=48079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:59:01.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:59:01.331+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:59:01.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:59:01.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:59:01.364+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:59:01.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:59:01.374+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:59:01.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:59:01.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T01:59:31.642+0000] {processor.py:157} INFO - Started process (PID=48090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:59:31.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T01:59:31.647+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:59:31.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:59:31.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T01:59:31.702+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:59:31.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T01:59:31.715+0000] {logging_mixin.py:151} INFO - [2024-09-11T01:59:31.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T01:59:31.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.250 seconds
[2024-09-11T02:00:01.949+0000] {processor.py:157} INFO - Started process (PID=48100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:00:01.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:00:01.956+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:00:01.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:00:01.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:00:02.016+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:00:02.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:00:02.031+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:00:02.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:00:02.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-11T02:00:32.303+0000] {processor.py:157} INFO - Started process (PID=48110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:00:32.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:00:32.309+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:00:32.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:00:32.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:00:32.352+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:00:32.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:00:32.366+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:00:32.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:00:32.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T02:01:02.596+0000] {processor.py:157} INFO - Started process (PID=48120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:01:02.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:01:02.602+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:01:02.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:01:02.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:01:02.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:01:02.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:01:02.652+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:01:02.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:01:02.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T02:01:32.943+0000] {processor.py:157} INFO - Started process (PID=48130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:01:32.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:01:32.948+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:01:32.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:01:32.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:01:32.974+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:01:32.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:01:32.984+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:01:32.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:01:32.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T02:02:03.356+0000] {processor.py:157} INFO - Started process (PID=48140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:02:03.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:02:03.361+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:02:03.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:02:03.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:02:03.414+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:02:03.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:02:03.426+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:02:03.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:02:03.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T02:02:33.686+0000] {processor.py:157} INFO - Started process (PID=48150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:02:33.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:02:33.691+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:02:33.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:02:33.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:02:33.745+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:02:33.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:02:33.907+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:02:33.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:02:33.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-09-11T02:03:04.038+0000] {processor.py:157} INFO - Started process (PID=48160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:03:04.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:03:04.046+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:03:04.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:03:04.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:03:04.108+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:03:04.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:03:04.124+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:03:04.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:03:04.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T02:03:34.478+0000] {processor.py:157} INFO - Started process (PID=48170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:03:34.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:03:34.484+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:03:34.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:03:34.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:03:34.538+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:03:34.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:03:34.553+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:03:34.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:03:34.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T02:04:04.889+0000] {processor.py:157} INFO - Started process (PID=48179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:04:04.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:04:04.894+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:04:04.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:04:04.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:04:04.945+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:04:04.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:04:04.957+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:04:04.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:04:04.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T02:04:35.207+0000] {processor.py:157} INFO - Started process (PID=48190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:04:35.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:04:35.212+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:04:35.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:04:35.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:04:35.240+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:04:35.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:04:35.249+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:04:35.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:04:35.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T02:05:05.577+0000] {processor.py:157} INFO - Started process (PID=48200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:05:05.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:05:05.581+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:05:05.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:05:05.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:05:05.624+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:05:05.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:05:05.638+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:05:05.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:05:05.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T02:05:35.869+0000] {processor.py:157} INFO - Started process (PID=48210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:05:35.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:05:35.871+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:05:35.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:05:35.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:05:35.896+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:05:35.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:05:36.064+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:05:36.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:05:36.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-11T02:06:06.175+0000] {processor.py:157} INFO - Started process (PID=48220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:06:06.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:06:06.179+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:06:06.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:06:06.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:06:06.223+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:06:06.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:06:06.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:06:06.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:06:06.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T02:06:36.452+0000] {processor.py:157} INFO - Started process (PID=48230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:06:36.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:06:36.454+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:06:36.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:06:36.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:06:36.485+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:06:36.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:06:36.495+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:06:36.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:06:36.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T02:07:06.813+0000] {processor.py:157} INFO - Started process (PID=48240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:07:06.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:07:06.818+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:07:06.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:07:06.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:07:06.858+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:07:06.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:07:06.876+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:07:06.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:07:06.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T02:07:37.098+0000] {processor.py:157} INFO - Started process (PID=48250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:07:37.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:07:37.101+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:07:37.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:07:37.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:07:37.126+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:07:37.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:07:37.136+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:07:37.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:07:37.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T02:08:07.509+0000] {processor.py:157} INFO - Started process (PID=48260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:08:07.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:08:07.514+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:08:07.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:08:07.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:08:07.557+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:08:07.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:08:07.570+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:08:07.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:08:07.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T02:08:37.760+0000] {processor.py:157} INFO - Started process (PID=48270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:08:37.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:08:37.762+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:08:37.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:08:37.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:08:37.791+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:08:37.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:08:37.927+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:08:37.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:08:37.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-11T02:09:08.125+0000] {processor.py:157} INFO - Started process (PID=48280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:09:08.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:09:08.133+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:09:08.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:09:08.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:09:08.179+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:09:08.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:09:08.195+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:09:08.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:09:08.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T02:09:38.613+0000] {processor.py:157} INFO - Started process (PID=48290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:09:38.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:09:38.618+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:09:38.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:09:38.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:09:38.653+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:09:38.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:09:38.665+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:09:38.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:09:38.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T02:10:09.003+0000] {processor.py:157} INFO - Started process (PID=48300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:10:09.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:10:09.005+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:10:09.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:10:09.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:10:09.034+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:10:09.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:10:09.044+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:10:09.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:10:09.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T02:10:39.425+0000] {processor.py:157} INFO - Started process (PID=48310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:10:39.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:10:39.429+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:10:39.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:10:39.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:10:39.467+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:10:39.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:10:39.480+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:10:39.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:10:39.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T02:11:09.844+0000] {processor.py:157} INFO - Started process (PID=48320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:11:09.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:11:09.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:11:09.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:11:09.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:11:09.875+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:11:09.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:11:09.885+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:11:09.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:11:10.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.209 seconds
[2024-09-11T02:11:40.226+0000] {processor.py:157} INFO - Started process (PID=48330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:11:40.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:11:40.231+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:11:40.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:11:40.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:11:40.293+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:11:40.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:11:40.405+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:11:40.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:11:40.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-11T02:12:10.706+0000] {processor.py:157} INFO - Started process (PID=48340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:12:10.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:12:10.711+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:12:10.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:12:10.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:12:10.753+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:12:10.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:12:10.765+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:12:10.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:12:10.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T02:12:41.100+0000] {processor.py:157} INFO - Started process (PID=48350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:12:41.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:12:41.103+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:12:41.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:12:41.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:12:41.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:12:41.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:12:41.140+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:12:41.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:12:41.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T02:13:11.523+0000] {processor.py:157} INFO - Started process (PID=48360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:13:11.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:13:11.530+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:13:11.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:13:11.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:13:11.570+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:13:11.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:13:11.585+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:13:11.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:13:11.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T02:13:41.881+0000] {processor.py:157} INFO - Started process (PID=48370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:13:41.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:13:41.886+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:13:41.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:13:41.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:13:41.921+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:13:41.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:13:41.933+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:13:41.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:13:41.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T02:14:12.370+0000] {processor.py:157} INFO - Started process (PID=48380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:14:12.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:14:12.375+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:14:12.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:14:12.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:14:12.399+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:14:12.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:14:12.410+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:14:12.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:14:12.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-11T02:14:42.893+0000] {processor.py:157} INFO - Started process (PID=48389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:14:42.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:14:42.897+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:14:42.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:14:42.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:14:42.949+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:14:42.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:14:42.960+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:14:42.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:14:42.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T02:15:13.312+0000] {processor.py:157} INFO - Started process (PID=48400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:15:13.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:15:13.314+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:15:13.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:15:13.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:15:13.349+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:15:13.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:15:13.360+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:15:13.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:15:13.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T02:15:43.691+0000] {processor.py:157} INFO - Started process (PID=48409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:15:43.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:15:43.697+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:15:43.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:15:43.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:15:43.739+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:15:43.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:15:43.752+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:15:43.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:15:43.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T02:16:14.028+0000] {processor.py:157} INFO - Started process (PID=48420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:16:14.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:16:14.031+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:16:14.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:16:14.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:16:14.069+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:16:14.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:16:14.083+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:16:14.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:16:14.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T02:16:44.314+0000] {processor.py:157} INFO - Started process (PID=48430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:16:44.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:16:44.318+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:16:44.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:16:44.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:16:44.345+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:16:44.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:16:44.356+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:16:44.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:16:44.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T02:17:14.657+0000] {processor.py:157} INFO - Started process (PID=48440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:17:14.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:17:14.660+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:17:14.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:17:14.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:17:14.688+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:17:14.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:17:14.701+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:17:14.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:17:14.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-11T02:17:45.157+0000] {processor.py:157} INFO - Started process (PID=48450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:17:45.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:17:45.161+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:17:45.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:17:45.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:17:45.202+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:17:45.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:17:45.223+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:17:45.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:17:45.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T02:18:15.501+0000] {processor.py:157} INFO - Started process (PID=48460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:18:15.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:18:15.504+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:18:15.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:18:15.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:18:15.531+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:18:15.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:18:15.540+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:18:15.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:18:15.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T02:18:45.873+0000] {processor.py:157} INFO - Started process (PID=48470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:18:45.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:18:45.878+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:18:45.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:18:45.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:18:45.914+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:18:45.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:18:45.927+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:18:45.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:18:45.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T02:19:16.262+0000] {processor.py:157} INFO - Started process (PID=48480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:19:16.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:19:16.266+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:19:16.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:19:16.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:19:16.295+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:19:16.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:19:16.306+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:19:16.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:19:16.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T02:19:46.656+0000] {processor.py:157} INFO - Started process (PID=48489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:19:46.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:19:46.661+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:19:46.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:19:46.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:19:46.700+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:19:46.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:19:46.712+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:19:46.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:19:46.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T02:20:16.927+0000] {processor.py:157} INFO - Started process (PID=48500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:20:16.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:20:16.930+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:20:16.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:20:16.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:20:16.974+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:20:16.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:20:16.985+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:20:16.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:20:17.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-09-11T02:20:47.189+0000] {processor.py:157} INFO - Started process (PID=48510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:20:47.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:20:47.204+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:20:47.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:20:47.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:20:47.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:20:47.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:20:47.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:20:47.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:20:47.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T02:21:17.586+0000] {processor.py:157} INFO - Started process (PID=48520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:21:17.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:21:17.591+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:21:17.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:21:17.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:21:17.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:21:17.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:21:17.637+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:21:17.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:21:17.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T02:21:47.941+0000] {processor.py:157} INFO - Started process (PID=48530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:21:47.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:21:47.945+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:21:47.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:21:47.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:21:47.972+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:21:47.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:21:47.983+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:21:47.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:21:47.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T02:22:18.335+0000] {processor.py:157} INFO - Started process (PID=48540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:22:18.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:22:18.340+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:22:18.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:22:18.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:22:18.376+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:22:18.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:22:18.387+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:22:18.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:22:18.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T02:22:48.770+0000] {processor.py:157} INFO - Started process (PID=48550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:22:48.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:22:48.773+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:22:48.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:22:48.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:22:48.805+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:22:48.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:22:48.818+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:22:48.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:22:48.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T02:23:19.194+0000] {processor.py:157} INFO - Started process (PID=48560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:23:19.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:23:19.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:23:19.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:23:19.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:23:19.253+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:23:19.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:23:19.408+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:23:19.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:23:19.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-09-11T02:23:49.541+0000] {processor.py:157} INFO - Started process (PID=48570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:23:49.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:23:49.545+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:23:49.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:23:49.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:23:49.574+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:23:49.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:23:49.586+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:23:49.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:23:49.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T02:24:19.952+0000] {processor.py:157} INFO - Started process (PID=48580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:24:19.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:24:19.957+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:24:19.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:24:19.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:24:20.022+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:24:20.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:24:20.033+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:24:20.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:24:20.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T02:24:50.272+0000] {processor.py:157} INFO - Started process (PID=48590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:24:50.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:24:50.275+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:24:50.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:24:50.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:24:50.302+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:24:50.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:24:50.312+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:24:50.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:24:50.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T02:25:20.603+0000] {processor.py:157} INFO - Started process (PID=48600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:25:20.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:25:20.606+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:25:20.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:25:20.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:25:20.634+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:25:20.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:25:20.645+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:25:20.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:25:20.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T02:25:50.919+0000] {processor.py:157} INFO - Started process (PID=48610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:25:50.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:25:50.924+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:25:50.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:25:50.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:25:50.960+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:25:50.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:25:50.978+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:25:50.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:25:50.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T02:26:21.334+0000] {processor.py:157} INFO - Started process (PID=48620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:26:21.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:26:21.339+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:26:21.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:26:21.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:26:21.365+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:26:21.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:26:21.458+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:26:21.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:26:21.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-11T02:26:51.622+0000] {processor.py:157} INFO - Started process (PID=48630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:26:51.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:26:51.626+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:26:51.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:26:51.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:26:51.664+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:26:51.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:26:51.675+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:26:51.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:26:51.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T02:27:22.001+0000] {processor.py:157} INFO - Started process (PID=48640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:27:22.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:27:22.004+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:27:22.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:27:22.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:27:22.032+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:27:22.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:27:22.043+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:27:22.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:27:22.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T02:27:52.434+0000] {processor.py:157} INFO - Started process (PID=48650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:27:52.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:27:52.439+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:27:52.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:27:52.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:27:52.471+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:27:52.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:27:52.482+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:27:52.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:27:52.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T02:28:22.834+0000] {processor.py:157} INFO - Started process (PID=48660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:28:22.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:28:22.837+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:28:22.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:28:22.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:28:22.866+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:28:22.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:28:22.877+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:28:22.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:28:22.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T02:28:53.149+0000] {processor.py:157} INFO - Started process (PID=48670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:28:53.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:28:53.153+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:28:53.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:28:53.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:28:53.181+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:28:53.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:28:53.190+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:28:53.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:28:53.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-09-11T02:29:23.496+0000] {processor.py:157} INFO - Started process (PID=48680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:29:23.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:29:23.502+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:29:23.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:29:23.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:29:23.570+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:29:23.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:29:23.656+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:29:23.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:29:23.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-11T02:29:53.927+0000] {processor.py:157} INFO - Started process (PID=48690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:29:53.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:29:53.931+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:29:53.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:29:53.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:29:53.957+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:29:53.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:29:53.968+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:29:53.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:29:53.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T02:30:24.302+0000] {processor.py:157} INFO - Started process (PID=48700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:30:24.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:30:24.307+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:30:24.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:30:24.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:30:24.351+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:30:24.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:30:24.363+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:30:24.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:30:24.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T02:30:54.677+0000] {processor.py:157} INFO - Started process (PID=48710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:30:54.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:30:54.684+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:30:54.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:30:54.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:30:54.720+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:30:54.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:30:54.732+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:30:54.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:30:54.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T02:31:25.015+0000] {processor.py:157} INFO - Started process (PID=48720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:31:25.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:31:25.019+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:31:25.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:31:25.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:31:25.057+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:31:25.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:31:25.073+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:31:25.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:31:25.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T02:31:55.438+0000] {processor.py:157} INFO - Started process (PID=48730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:31:55.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:31:55.442+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:31:55.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:31:55.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:31:55.466+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:31:55.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:31:55.476+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:31:55.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:31:55.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-09-11T02:32:25.785+0000] {processor.py:157} INFO - Started process (PID=48740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:32:25.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:32:25.790+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:32:25.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:32:25.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:32:25.827+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:32:25.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:32:25.991+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:32:25.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:32:26.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.222 seconds
[2024-09-11T02:32:56.418+0000] {processor.py:157} INFO - Started process (PID=48750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:32:56.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:32:56.422+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:32:56.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:32:56.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:32:56.459+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:32:56.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:32:56.476+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:32:56.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:32:56.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T02:33:26.724+0000] {processor.py:157} INFO - Started process (PID=48760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:33:26.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:33:26.728+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:33:26.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:33:26.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:33:26.758+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:33:26.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:33:26.769+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:33:26.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:33:26.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T02:33:57.168+0000] {processor.py:157} INFO - Started process (PID=48770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:33:57.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:33:57.171+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:33:57.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:33:57.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:33:57.234+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:33:57.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:33:57.248+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:33:57.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:33:57.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T02:34:27.509+0000] {processor.py:157} INFO - Started process (PID=48780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:34:27.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:34:27.512+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:34:27.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:34:27.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:34:27.545+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:34:27.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:34:27.558+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:34:27.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:34:27.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T02:34:57.835+0000] {processor.py:157} INFO - Started process (PID=48790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:34:57.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:34:57.838+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:34:57.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:34:57.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:34:57.902+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:34:57.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:34:57.916+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:34:57.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:34:58.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.254 seconds
[2024-09-11T02:35:28.188+0000] {processor.py:157} INFO - Started process (PID=48800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:35:28.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:35:28.191+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:35:28.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:35:28.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:35:28.229+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:35:28.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:35:28.339+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:35:28.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:35:28.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-11T02:35:58.645+0000] {processor.py:157} INFO - Started process (PID=48810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:35:58.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:35:58.648+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:35:58.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:35:58.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:35:58.675+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:35:58.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:35:58.685+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:35:58.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:35:58.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T02:36:29.098+0000] {processor.py:157} INFO - Started process (PID=48819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:36:29.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:36:29.102+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:36:29.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:36:29.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:36:29.136+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:36:29.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:36:29.152+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:36:29.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:36:29.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T02:36:59.509+0000] {processor.py:157} INFO - Started process (PID=48830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:36:59.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:36:59.512+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:36:59.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:36:59.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:36:59.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:36:59.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:36:59.553+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:36:59.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:36:59.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T02:37:29.910+0000] {processor.py:157} INFO - Started process (PID=48840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:37:29.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:37:29.915+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:37:29.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:37:29.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:37:29.977+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:37:29.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:37:29.992+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:37:29.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:37:30.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T02:38:00.228+0000] {processor.py:157} INFO - Started process (PID=48850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:38:00.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:38:00.233+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:38:00.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:38:00.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:38:00.267+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:38:00.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:38:00.276+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:38:00.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:38:00.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-11T02:38:30.846+0000] {processor.py:157} INFO - Started process (PID=48860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:38:30.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:38:30.860+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:38:30.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:38:30.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:38:30.897+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:38:30.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:38:30.990+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:38:30.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:38:30.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-11T02:39:01.322+0000] {processor.py:157} INFO - Started process (PID=48870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:39:01.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:39:01.324+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:39:01.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:39:01.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:39:01.355+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:39:01.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:39:01.365+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:39:01.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:39:01.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T02:39:31.731+0000] {processor.py:157} INFO - Started process (PID=48880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:39:31.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:39:31.737+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:39:31.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:39:31.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:39:31.797+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:39:31.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:39:31.810+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:39:31.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:39:31.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T02:40:02.096+0000] {processor.py:157} INFO - Started process (PID=48890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:40:02.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:40:02.101+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:40:02.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:40:02.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:40:02.140+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:40:02.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:40:02.153+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:40:02.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:40:02.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T02:40:32.493+0000] {processor.py:157} INFO - Started process (PID=48899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:40:32.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:40:32.501+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:40:32.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:40:32.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:40:32.544+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:40:32.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:40:32.558+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:40:32.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:40:32.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T02:41:02.929+0000] {processor.py:157} INFO - Started process (PID=48910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:41:02.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:41:02.932+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:41:02.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:41:02.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:41:02.959+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:41:02.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:41:02.970+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:41:02.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:41:03.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-11T02:41:33.234+0000] {processor.py:157} INFO - Started process (PID=48920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:41:33.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:41:33.240+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:41:33.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:41:33.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:41:33.303+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:41:33.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:41:33.396+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:41:33.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:41:33.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-11T02:42:03.778+0000] {processor.py:157} INFO - Started process (PID=48930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:42:03.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:42:03.783+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:42:03.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:42:03.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:42:03.820+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:42:03.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:42:03.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:42:03.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:42:03.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T02:42:34.084+0000] {processor.py:157} INFO - Started process (PID=48940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:42:34.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:42:34.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:42:34.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:42:34.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:42:34.120+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:42:34.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:42:34.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:42:34.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:42:34.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T02:43:04.520+0000] {processor.py:157} INFO - Started process (PID=48950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:43:04.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:43:04.527+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:43:04.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:43:04.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:43:04.563+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:43:04.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:43:04.577+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:43:04.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:43:04.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T02:43:35.021+0000] {processor.py:157} INFO - Started process (PID=48960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:43:35.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:43:35.024+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:43:35.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:43:35.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:43:35.057+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:43:35.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:43:35.072+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:43:35.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:43:35.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T02:44:05.354+0000] {processor.py:157} INFO - Started process (PID=48970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:44:05.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:44:05.360+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:44:05.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:44:05.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:44:05.392+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:44:05.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:44:05.528+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:44:05.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:44:05.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-11T02:44:35.737+0000] {processor.py:157} INFO - Started process (PID=48980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:44:35.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:44:35.740+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:44:35.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:44:35.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:44:35.774+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:44:35.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:44:35.858+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:44:35.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:44:35.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T02:45:06.241+0000] {processor.py:157} INFO - Started process (PID=48990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:45:06.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:45:06.245+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:45:06.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:45:06.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:45:06.275+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:45:06.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:45:06.290+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:45:06.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:45:06.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T02:45:36.702+0000] {processor.py:157} INFO - Started process (PID=49000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:45:36.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:45:36.708+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:45:36.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:45:36.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:45:36.746+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:45:36.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:45:36.759+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:45:36.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:45:36.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T02:46:07.043+0000] {processor.py:157} INFO - Started process (PID=49010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:46:07.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:46:07.045+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:46:07.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:46:07.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:46:07.076+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:46:07.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:46:07.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:46:07.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:46:07.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T02:46:37.417+0000] {processor.py:157} INFO - Started process (PID=49020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:46:37.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:46:37.424+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:46:37.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:46:37.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:46:37.461+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:46:37.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:46:37.474+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:46:37.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:46:37.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T02:47:07.810+0000] {processor.py:157} INFO - Started process (PID=49030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:47:07.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:47:07.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:47:07.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:47:07.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:47:07.845+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:47:07.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:47:07.980+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:47:07.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:47:07.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-11T02:47:38.350+0000] {processor.py:157} INFO - Started process (PID=49040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:47:38.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:47:38.357+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:47:38.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:47:38.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:47:38.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:47:38.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:47:38.533+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:47:38.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:47:38.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-11T02:48:08.673+0000] {processor.py:157} INFO - Started process (PID=49050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:48:08.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:48:08.679+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:48:08.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:48:08.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:48:08.719+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:48:08.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:48:08.732+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:48:08.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:48:08.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T02:48:38.938+0000] {processor.py:157} INFO - Started process (PID=49060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:48:38.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:48:38.942+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:48:38.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:48:38.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:48:38.973+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:48:38.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:48:38.982+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:48:38.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:48:38.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T02:49:09.375+0000] {processor.py:157} INFO - Started process (PID=49070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:49:09.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:49:09.378+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:49:09.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:49:09.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:49:09.421+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:49:09.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:49:09.433+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:49:09.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:49:09.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T02:49:39.689+0000] {processor.py:157} INFO - Started process (PID=49079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:49:39.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:49:39.696+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:49:39.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:49:39.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:49:39.737+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:49:39.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:49:39.749+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:49:39.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:49:39.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-09-11T02:50:10.071+0000] {processor.py:157} INFO - Started process (PID=49090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:50:10.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:50:10.076+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:50:10.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:50:10.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:50:10.125+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:50:10.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:50:10.279+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:50:10.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:50:10.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.222 seconds
[2024-09-11T02:50:40.490+0000] {processor.py:157} INFO - Started process (PID=49100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:50:40.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:50:40.495+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:50:40.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:50:40.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:50:40.533+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:50:40.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:50:40.674+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:50:40.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:50:40.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-11T02:51:10.879+0000] {processor.py:157} INFO - Started process (PID=49110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:51:10.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:51:10.884+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:51:10.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:51:10.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:51:10.947+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:51:10.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:51:10.960+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:51:10.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:51:10.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T02:51:41.307+0000] {processor.py:157} INFO - Started process (PID=49120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:51:41.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:51:41.312+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:51:41.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:51:41.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:51:41.367+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:51:41.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:51:41.384+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:51:41.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:51:41.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T02:52:11.678+0000] {processor.py:157} INFO - Started process (PID=49130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:52:11.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:52:11.683+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:52:11.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:52:11.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:52:11.719+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:52:11.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:52:11.733+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:52:11.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:52:11.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T02:52:42.052+0000] {processor.py:157} INFO - Started process (PID=49140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:52:42.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:52:42.055+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:52:42.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:52:42.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:52:42.083+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:52:42.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:52:42.093+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:52:42.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:52:42.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-11T02:53:12.440+0000] {processor.py:157} INFO - Started process (PID=49149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:53:12.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:53:12.452+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:53:12.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:53:12.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:53:12.491+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:53:12.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:53:12.582+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:53:12.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:53:12.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-11T02:53:42.855+0000] {processor.py:157} INFO - Started process (PID=49160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:53:42.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:53:42.860+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:53:42.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:53:42.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:53:42.897+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:53:42.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:53:43.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:53:43.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:53:43.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-09-11T02:54:13.170+0000] {processor.py:157} INFO - Started process (PID=49170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:54:13.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:54:13.173+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:54:13.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:54:13.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:54:13.204+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:54:13.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:54:13.214+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:54:13.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:54:13.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T02:54:43.643+0000] {processor.py:157} INFO - Started process (PID=49180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:54:43.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:54:43.652+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:54:43.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:54:43.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:54:43.715+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:54:43.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:54:43.726+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:54:43.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:54:43.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T02:55:14.155+0000] {processor.py:157} INFO - Started process (PID=49190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:55:14.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:55:14.158+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:55:14.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:55:14.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:55:14.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:55:14.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:55:14.196+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:55:14.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:55:14.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T02:55:44.591+0000] {processor.py:157} INFO - Started process (PID=49200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:55:44.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:55:44.600+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:55:44.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:55:44.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:55:44.643+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:55:44.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:55:44.660+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:55:44.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:55:44.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-09-11T02:56:15.058+0000] {processor.py:157} INFO - Started process (PID=49212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:56:15.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:56:15.059+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:56:15.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:56:15.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:56:15.073+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:56:15.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:56:15.140+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:56:15.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:56:15.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T02:56:45.370+0000] {processor.py:157} INFO - Started process (PID=49220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:56:45.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:56:45.378+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:56:45.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:56:45.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:56:45.431+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:56:45.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:56:45.584+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:56:45.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:56:45.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-11T02:57:15.735+0000] {processor.py:157} INFO - Started process (PID=49230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:57:15.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:57:15.740+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:57:15.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:57:15.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:57:15.785+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:57:15.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:57:15.796+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:57:15.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:57:15.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T02:57:46.109+0000] {processor.py:157} INFO - Started process (PID=49240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:57:46.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:57:46.117+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:57:46.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:57:46.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:57:46.189+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:57:46.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:57:46.215+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:57:46.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:57:46.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T02:58:16.427+0000] {processor.py:157} INFO - Started process (PID=49250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:58:16.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:58:16.433+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:58:16.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:58:16.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:58:16.487+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:58:16.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:58:16.501+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:58:16.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:58:16.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T02:58:46.861+0000] {processor.py:157} INFO - Started process (PID=49260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:58:46.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:58:46.866+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:58:46.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:58:46.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:58:46.913+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:58:46.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:58:46.950+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:58:46.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:58:47.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-09-11T02:59:17.185+0000] {processor.py:157} INFO - Started process (PID=49270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:59:17.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:59:17.190+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:59:17.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:59:17.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:59:17.230+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:59:17.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:59:17.484+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:59:17.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:59:17.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.316 seconds
[2024-09-11T02:59:47.808+0000] {processor.py:157} INFO - Started process (PID=49280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:59:47.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T02:59:47.814+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:59:47.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:59:47.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T02:59:47.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:59:47.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T02:59:48.030+0000] {logging_mixin.py:151} INFO - [2024-09-11T02:59:48.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T02:59:48.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-09-11T03:00:18.150+0000] {processor.py:157} INFO - Started process (PID=49290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:00:18.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:00:18.154+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:00:18.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:00:18.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:00:18.199+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:00:18.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:00:18.211+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:00:18.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:00:18.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T03:00:48.480+0000] {processor.py:157} INFO - Started process (PID=49300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:00:48.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:00:48.482+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:00:48.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:00:48.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:00:48.511+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:00:48.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:00:48.522+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:00:48.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:00:48.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T03:01:18.930+0000] {processor.py:157} INFO - Started process (PID=49310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:01:18.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:01:18.937+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:01:18.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:01:18.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:01:18.993+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:01:18.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:01:19.026+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:01:19.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:01:19.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-11T03:01:49.263+0000] {processor.py:157} INFO - Started process (PID=49320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:01:49.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:01:49.278+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:01:49.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:01:49.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:01:49.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:01:49.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:01:49.358+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:01:49.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:01:49.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-09-11T03:02:19.643+0000] {processor.py:157} INFO - Started process (PID=49330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:02:19.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:02:19.649+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:02:19.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:02:19.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:02:19.703+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:02:19.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:02:19.869+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:02:19.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:02:19.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-11T03:02:50.118+0000] {processor.py:157} INFO - Started process (PID=49340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:02:50.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:02:50.122+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:02:50.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:02:50.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:02:50.223+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:02:50.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:02:50.231+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:02:50.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:02:50.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-11T03:03:20.594+0000] {processor.py:157} INFO - Started process (PID=49350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:03:20.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:03:20.611+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:03:20.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:03:20.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:03:20.651+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:03:20.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:03:20.662+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:03:20.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:03:20.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T03:03:50.888+0000] {processor.py:157} INFO - Started process (PID=49360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:03:50.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:03:50.891+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:03:50.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:03:50.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:03:50.917+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:03:50.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:03:50.929+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:03:50.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:03:50.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:04:21.210+0000] {processor.py:157} INFO - Started process (PID=49370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:04:21.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:04:21.215+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:04:21.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:04:21.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:04:21.246+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:04:21.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:04:21.259+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:04:21.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:04:21.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T03:04:51.547+0000] {processor.py:157} INFO - Started process (PID=49380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:04:51.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:04:51.551+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:04:51.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:04:51.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:04:51.578+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:04:51.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:04:51.735+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:04:51.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:04:51.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-09-11T03:05:22.139+0000] {processor.py:157} INFO - Started process (PID=49390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:05:22.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:05:22.144+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:05:22.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:05:22.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:05:22.179+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:05:22.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:05:22.281+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:05:22.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:05:22.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-11T03:05:52.442+0000] {processor.py:157} INFO - Started process (PID=49400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:05:52.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:05:52.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:05:52.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:05:52.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:05:52.570+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:05:52.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:05:52.578+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:05:52.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:05:52.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-11T03:06:22.828+0000] {processor.py:157} INFO - Started process (PID=49410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:06:22.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:06:22.833+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:06:22.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:06:22.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:06:22.868+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:06:22.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:06:22.880+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:06:22.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:06:22.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T03:06:53.157+0000] {processor.py:157} INFO - Started process (PID=49420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:06:53.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:06:53.165+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:06:53.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:06:53.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:06:53.190+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:06:53.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:06:53.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:06:53.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:06:53.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:07:23.529+0000] {processor.py:157} INFO - Started process (PID=49430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:07:23.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:07:23.538+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:07:23.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:07:23.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:07:23.559+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:07:23.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:07:23.570+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:07:23.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:07:23.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T03:07:53.923+0000] {processor.py:157} INFO - Started process (PID=49440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:07:53.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:07:53.927+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:07:53.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:07:53.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:07:53.964+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:07:53.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:07:54.100+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:07:54.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:07:54.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-11T03:08:24.202+0000] {processor.py:157} INFO - Started process (PID=49450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:08:24.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:08:24.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:08:24.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:08:24.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:08:24.244+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:08:24.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:08:24.363+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:08:24.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:08:24.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-11T03:08:54.697+0000] {processor.py:157} INFO - Started process (PID=49460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:08:54.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:08:54.701+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:08:54.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:08:54.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:08:54.839+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:08:54.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:08:54.847+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:08:54.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:08:54.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-11T03:09:25.034+0000] {processor.py:157} INFO - Started process (PID=49469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:09:25.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:09:25.045+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:09:25.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:09:25.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:09:25.098+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:09:25.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:09:25.111+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:09:25.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:09:25.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T03:09:55.354+0000] {processor.py:157} INFO - Started process (PID=49480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:09:55.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:09:55.357+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:09:55.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:09:55.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:09:55.395+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:09:55.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:09:55.407+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:09:55.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:09:55.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T03:10:25.707+0000] {processor.py:157} INFO - Started process (PID=49490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:10:25.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:10:25.709+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:10:25.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:10:25.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:10:25.736+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:10:25.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:10:25.749+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:10:25.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:10:25.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:10:56.104+0000] {processor.py:157} INFO - Started process (PID=49500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:10:56.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:10:56.108+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:10:56.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:10:56.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:10:56.145+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:10:56.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:10:56.281+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:10:56.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:10:56.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-11T03:11:26.631+0000] {processor.py:157} INFO - Started process (PID=49510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:11:26.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:11:26.634+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:11:26.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:11:26.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:11:26.674+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:11:26.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:11:26.791+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:11:26.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:11:26.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-11T03:11:57.003+0000] {processor.py:157} INFO - Started process (PID=49520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:11:57.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:11:57.007+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:11:57.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:11:57.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:11:57.147+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:11:57.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:11:57.155+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:11:57.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:11:57.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-11T03:12:27.376+0000] {processor.py:157} INFO - Started process (PID=49529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:12:27.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:12:27.378+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:12:27.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:12:27.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:12:27.418+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:12:27.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:12:27.430+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:12:27.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:12:27.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T03:12:57.722+0000] {processor.py:157} INFO - Started process (PID=49540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:12:57.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:12:57.725+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:12:57.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:12:57.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:12:57.760+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:12:57.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:12:57.771+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:12:57.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:12:57.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-11T03:13:28.104+0000] {processor.py:157} INFO - Started process (PID=49550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:13:28.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:13:28.123+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:13:28.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:13:28.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:13:28.165+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:13:28.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:13:28.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:13:28.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:13:28.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-09-11T03:13:58.666+0000] {processor.py:157} INFO - Started process (PID=49560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:13:58.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:13:58.670+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:13:58.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:13:58.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:13:58.711+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:13:58.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:13:58.823+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:13:58.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:13:58.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-11T03:14:28.991+0000] {processor.py:157} INFO - Started process (PID=49568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:14:28.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:14:28.996+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:14:28.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:14:29.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:14:29.038+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:14:29.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:14:29.219+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:14:29.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:14:29.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-09-11T03:14:59.408+0000] {processor.py:157} INFO - Started process (PID=49579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:14:59.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:14:59.413+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:14:59.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:14:59.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:14:59.519+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:14:59.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:14:59.526+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:14:59.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:14:59.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-11T03:15:29.723+0000] {processor.py:157} INFO - Started process (PID=49590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:15:29.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:15:29.733+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:15:29.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:15:29.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:15:29.773+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:15:29.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:15:29.796+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:15:29.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:15:29.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T03:16:00.141+0000] {processor.py:157} INFO - Started process (PID=49600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:16:00.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:16:00.150+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:16:00.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:16:00.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:16:00.172+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:16:00.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:16:00.183+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:16:00.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:16:00.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:16:30.474+0000] {processor.py:157} INFO - Started process (PID=49610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:16:30.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:16:30.479+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:16:30.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:16:30.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:16:30.527+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:16:30.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:16:30.540+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:16:30.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:16:30.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.216 seconds
[2024-09-11T03:17:00.791+0000] {processor.py:157} INFO - Started process (PID=49620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:17:00.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:17:00.797+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:17:00.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:17:00.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:17:00.831+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:17:00.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:17:00.923+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:17:00.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:17:00.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-11T03:17:31.261+0000] {processor.py:157} INFO - Started process (PID=49630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:17:31.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:17:31.264+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:17:31.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:17:31.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:17:31.292+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:17:31.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:17:31.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:17:31.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:17:31.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-11T03:18:01.627+0000] {processor.py:157} INFO - Started process (PID=49640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:18:01.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:18:01.631+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:18:01.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:18:01.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:18:01.825+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:18:01.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:18:01.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:18:01.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:18:01.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.219 seconds
[2024-09-11T03:18:32.179+0000] {processor.py:157} INFO - Started process (PID=49650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:18:32.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:18:32.182+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:18:32.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:18:32.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:18:32.208+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:18:32.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:18:32.220+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:18:32.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:18:32.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T03:19:02.584+0000] {processor.py:157} INFO - Started process (PID=49660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:19:02.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:19:02.599+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:19:02.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:19:02.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:19:02.644+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:19:02.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:19:02.657+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:19:02.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:19:02.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T03:19:32.983+0000] {processor.py:157} INFO - Started process (PID=49668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:19:32.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:19:32.987+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:19:32.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:19:33.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:19:33.034+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:19:33.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:19:33.048+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:19:33.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:19:33.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-09-11T03:20:03.305+0000] {processor.py:157} INFO - Started process (PID=49680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:20:03.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:20:03.308+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:20:03.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:20:03.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:20:03.336+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:20:03.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:20:03.416+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:20:03.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:20:03.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-11T03:20:33.777+0000] {processor.py:157} INFO - Started process (PID=49690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:20:33.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:20:33.787+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:20:33.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:20:33.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:20:33.839+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:20:33.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:20:34.001+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:20:34.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:20:34.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-11T03:21:04.339+0000] {processor.py:157} INFO - Started process (PID=49699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:21:04.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:21:04.360+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:21:04.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:21:04.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:21:04.535+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:21:04.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:21:04.546+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:21:04.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:21:04.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-09-11T03:21:34.659+0000] {processor.py:157} INFO - Started process (PID=49710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:21:34.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:21:34.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:21:34.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:21:34.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:21:34.719+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:21:34.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:21:34.731+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:21:34.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:21:34.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T03:22:05.016+0000] {processor.py:157} INFO - Started process (PID=49719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:22:05.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:22:05.021+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:22:05.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:22:05.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:22:05.060+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:22:05.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:22:05.073+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:22:05.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:22:05.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T03:22:35.343+0000] {processor.py:157} INFO - Started process (PID=49730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:22:35.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:22:35.347+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:22:35.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:22:35.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:22:35.399+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:22:35.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:22:35.411+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:22:35.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:22:35.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-09-11T03:23:05.628+0000] {processor.py:157} INFO - Started process (PID=49740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:23:05.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:23:05.631+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:23:05.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:23:05.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:23:05.661+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:23:05.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:23:05.740+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:23:05.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:23:05.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-11T03:23:36.084+0000] {processor.py:157} INFO - Started process (PID=49750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:23:36.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:23:36.089+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:23:36.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:23:36.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:23:36.127+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:23:36.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:23:36.306+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:23:36.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:23:36.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.234 seconds
[2024-09-11T03:24:06.481+0000] {processor.py:157} INFO - Started process (PID=49760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:24:06.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:24:06.486+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:24:06.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:24:06.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:24:06.676+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:24:06.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:24:06.687+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:24:06.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:24:06.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-11T03:24:36.975+0000] {processor.py:157} INFO - Started process (PID=49770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:24:36.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:24:36.979+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:24:36.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:24:36.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:24:37.007+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:24:37.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:24:37.017+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:24:37.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:24:37.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:25:07.398+0000] {processor.py:157} INFO - Started process (PID=49780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:25:07.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:25:07.414+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:25:07.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:25:07.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:25:07.451+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:25:07.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:25:07.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:25:07.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:25:07.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T03:25:37.688+0000] {processor.py:157} INFO - Started process (PID=49790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:25:37.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:25:37.691+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:25:37.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:25:37.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:25:37.717+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:25:37.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:25:37.727+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:25:37.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:25:37.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.211 seconds
[2024-09-11T03:26:07.973+0000] {processor.py:157} INFO - Started process (PID=49800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:26:07.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:26:07.979+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:26:07.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:26:07.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:26:08.011+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:26:08.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:26:08.090+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:26:08.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:26:08.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-11T03:26:38.264+0000] {processor.py:157} INFO - Started process (PID=49810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:26:38.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:26:38.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:26:38.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:26:38.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:26:38.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:26:38.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:26:38.401+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:26:38.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:26:38.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T03:27:08.616+0000] {processor.py:157} INFO - Started process (PID=49820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:27:08.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:27:08.619+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:27:08.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:27:08.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:27:08.767+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:27:08.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:27:08.776+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:27:08.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:27:08.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-11T03:27:39.129+0000] {processor.py:157} INFO - Started process (PID=49830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:27:39.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:27:39.136+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:27:39.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:27:39.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:27:39.184+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:27:39.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:27:39.199+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:27:39.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:27:39.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T03:28:09.515+0000] {processor.py:157} INFO - Started process (PID=49840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:28:09.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:28:09.521+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:28:09.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:28:09.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:28:09.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:28:09.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:28:09.577+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:28:09.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:28:09.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T03:28:39.779+0000] {processor.py:157} INFO - Started process (PID=49850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:28:39.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:28:39.781+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:28:39.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:28:39.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:28:39.805+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:28:39.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:28:39.967+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:28:39.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:28:39.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-09-11T03:29:10.288+0000] {processor.py:157} INFO - Started process (PID=49860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:29:10.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:29:10.293+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:29:10.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:29:10.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:29:10.330+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:29:10.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:29:10.412+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:29:10.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:29:10.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-11T03:29:40.599+0000] {processor.py:157} INFO - Started process (PID=49870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:29:40.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:29:40.601+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:29:40.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:29:40.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:29:40.729+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:29:40.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:29:40.738+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:29:40.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:29:40.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T03:30:11.108+0000] {processor.py:157} INFO - Started process (PID=49880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:30:11.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:30:11.113+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:30:11.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:30:11.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:30:11.265+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:30:11.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:30:11.273+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:30:11.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:30:11.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-11T03:30:41.629+0000] {processor.py:157} INFO - Started process (PID=49889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:30:41.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:30:41.633+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:30:41.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:30:41.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:30:41.710+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:30:41.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:30:41.731+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:30:41.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:30:41.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T03:31:11.942+0000] {processor.py:157} INFO - Started process (PID=49900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:31:11.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:31:11.945+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:31:11.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:31:11.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:31:11.977+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:31:11.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:31:11.989+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:31:11.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:31:11.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T03:31:42.379+0000] {processor.py:157} INFO - Started process (PID=49910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:31:42.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:31:42.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:31:42.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:31:42.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:31:42.425+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:31:42.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:31:42.582+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:31:42.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:31:42.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-09-11T03:32:12.679+0000] {processor.py:157} INFO - Started process (PID=49920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:32:12.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:32:12.686+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:32:12.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:32:12.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:32:12.746+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:32:12.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:32:13.002+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:32:13.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:32:13.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.338 seconds
[2024-09-11T03:32:43.067+0000] {processor.py:157} INFO - Started process (PID=49930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:32:43.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:32:43.071+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:32:43.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:32:43.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:32:43.170+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:32:43.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:32:43.178+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:32:43.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:32:43.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-11T03:33:13.544+0000] {processor.py:157} INFO - Started process (PID=49940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:33:13.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:33:13.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:33:13.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:33:13.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:33:13.746+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:33:13.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:33:13.758+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:33:13.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:33:13.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-09-11T03:33:44.111+0000] {processor.py:157} INFO - Started process (PID=49949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:33:44.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:33:44.118+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:33:44.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:33:44.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:33:44.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:33:44.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:33:44.212+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:33:44.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:33:44.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-11T03:34:14.413+0000] {processor.py:157} INFO - Started process (PID=49960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:34:14.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:34:14.415+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:34:14.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:34:14.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:34:14.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:34:14.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:34:14.457+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:34:14.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:34:14.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-11T03:34:44.990+0000] {processor.py:157} INFO - Started process (PID=49970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:34:44.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:34:45.008+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:34:45.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:34:45.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:34:45.087+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:34:45.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:34:45.302+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:34:45.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:34:45.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.329 seconds
[2024-09-11T03:35:15.628+0000] {processor.py:157} INFO - Started process (PID=49980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:35:15.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:35:15.635+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:35:15.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:35:15.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:35:15.705+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:35:15.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:35:15.870+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:35:15.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:35:15.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.255 seconds
[2024-09-11T03:35:45.992+0000] {processor.py:157} INFO - Started process (PID=49990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:35:45.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:35:46.001+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:35:46.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:35:46.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:35:46.121+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:35:46.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:35:46.128+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:35:46.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:35:46.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T03:36:16.456+0000] {processor.py:157} INFO - Started process (PID=50000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:36:16.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:36:16.461+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:36:16.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:36:16.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:36:16.632+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:36:16.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:36:16.642+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:36:16.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:36:16.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-11T03:36:46.944+0000] {processor.py:157} INFO - Started process (PID=50010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:36:46.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:36:46.951+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:36:46.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:36:46.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:36:46.988+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:36:46.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:36:47.002+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:36:47.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:36:47.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T03:37:17.200+0000] {processor.py:157} INFO - Started process (PID=50020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:37:17.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:37:17.204+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:37:17.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:37:17.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:37:17.231+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:37:17.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:37:17.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:37:17.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:37:17.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-09-11T03:37:47.643+0000] {processor.py:157} INFO - Started process (PID=50030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:37:47.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:37:47.649+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:37:47.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:37:47.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:37:47.710+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:37:47.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:37:47.858+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:37:47.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:37:47.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-09-11T03:38:18.039+0000] {processor.py:157} INFO - Started process (PID=50039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:38:18.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:38:18.046+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:38:18.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:38:18.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:38:18.094+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:38:18.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:38:18.210+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:38:18.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:38:18.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-11T03:38:48.361+0000] {processor.py:157} INFO - Started process (PID=50050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:38:48.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:38:48.365+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:38:48.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:38:48.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:38:48.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:38:48.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:38:48.471+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:38:48.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:38:48.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T03:39:18.800+0000] {processor.py:157} INFO - Started process (PID=50060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:39:18.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:39:18.806+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:39:18.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:39:18.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:39:18.908+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:39:18.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:39:18.915+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:39:18.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:39:18.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T03:39:49.251+0000] {processor.py:157} INFO - Started process (PID=50070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:39:49.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:39:49.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:39:49.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:39:49.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:39:49.301+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:39:49.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:39:49.313+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:39:49.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:39:49.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T03:40:19.608+0000] {processor.py:157} INFO - Started process (PID=50080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:40:19.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:40:19.611+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:40:19.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:40:19.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:40:19.637+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:40:19.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:40:19.647+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:40:19.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:40:19.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T03:40:49.999+0000] {processor.py:157} INFO - Started process (PID=50090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:40:50.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:40:50.002+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:40:50.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:40:50.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:40:50.027+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:40:50.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:40:50.037+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:40:50.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:40:50.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T03:41:20.342+0000] {processor.py:157} INFO - Started process (PID=50100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:41:20.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:41:20.347+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:41:20.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:41:20.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:41:20.389+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:41:20.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:41:20.401+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:41:20.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:41:20.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T03:41:50.631+0000] {processor.py:157} INFO - Started process (PID=50110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:41:50.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:41:50.634+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:41:50.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:41:50.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:41:50.663+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:41:50.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:41:50.673+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:41:50.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:41:50.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:42:21.058+0000] {processor.py:157} INFO - Started process (PID=50120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:42:21.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:42:21.063+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:42:21.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:42:21.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:42:21.098+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:42:21.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:42:21.110+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:42:21.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:42:21.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T03:42:51.446+0000] {processor.py:157} INFO - Started process (PID=50130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:42:51.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:42:51.450+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:42:51.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:42:51.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:42:51.480+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:42:51.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:42:51.490+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:42:51.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:42:51.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T03:43:21.766+0000] {processor.py:157} INFO - Started process (PID=50140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:43:21.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:43:21.769+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:43:21.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:43:21.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:43:21.813+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:43:21.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:43:21.827+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:43:21.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:43:21.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T03:43:52.237+0000] {processor.py:157} INFO - Started process (PID=50150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:43:52.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:43:52.244+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:43:52.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:43:52.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:43:52.284+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:43:52.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:43:52.300+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:43:52.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:43:52.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T03:44:22.517+0000] {processor.py:157} INFO - Started process (PID=50160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:44:22.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:44:22.520+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:44:22.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:44:22.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:44:22.547+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:44:22.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:44:22.558+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:44:22.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:44:22.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T03:44:52.841+0000] {processor.py:157} INFO - Started process (PID=50169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:44:52.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:44:52.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:44:52.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:44:52.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:44:52.903+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:44:52.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:44:52.967+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:44:52.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:44:53.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-11T03:45:23.160+0000] {processor.py:157} INFO - Started process (PID=50179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:45:23.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:45:23.165+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:45:23.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:45:23.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:45:23.219+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:45:23.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:45:23.231+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:45:23.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:45:23.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T03:45:53.431+0000] {processor.py:157} INFO - Started process (PID=50190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:45:53.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:45:53.434+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:45:53.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:45:53.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:45:53.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:45:53.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:45:53.471+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:45:53.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:45:53.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:46:23.732+0000] {processor.py:157} INFO - Started process (PID=50200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:46:23.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:46:23.737+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:46:23.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:46:23.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:46:23.775+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:46:23.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:46:23.788+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:46:23.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:46:23.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T03:46:54.021+0000] {processor.py:157} INFO - Started process (PID=50210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:46:54.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:46:54.023+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:46:54.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:46:54.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:46:54.048+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:46:54.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:46:54.059+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:46:54.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:46:54.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T03:47:24.408+0000] {processor.py:157} INFO - Started process (PID=50220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:47:24.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:47:24.412+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:47:24.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:47:24.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:47:24.449+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:47:24.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:47:24.462+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:47:24.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:47:24.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T03:47:54.865+0000] {processor.py:157} INFO - Started process (PID=50230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:47:54.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:47:54.872+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:47:54.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:47:54.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:47:54.943+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:47:54.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:47:54.962+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:47:54.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:47:54.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T03:48:25.249+0000] {processor.py:157} INFO - Started process (PID=50240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:48:25.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:48:25.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:48:25.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:48:25.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:48:25.319+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:48:25.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:48:25.334+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:48:25.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:48:25.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T03:48:55.698+0000] {processor.py:157} INFO - Started process (PID=50250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:48:55.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:48:55.706+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:48:55.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:48:55.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:48:55.752+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:48:55.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:48:55.772+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:48:55.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:48:55.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T03:49:26.048+0000] {processor.py:157} INFO - Started process (PID=50259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:49:26.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:49:26.053+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:49:26.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:49:26.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:49:26.117+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:49:26.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:49:26.131+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:49:26.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:49:26.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T03:49:56.348+0000] {processor.py:157} INFO - Started process (PID=50270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:49:56.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:49:56.360+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:49:56.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:49:56.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:49:56.423+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:49:56.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:49:56.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:49:56.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:49:56.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-11T03:50:26.678+0000] {processor.py:157} INFO - Started process (PID=50280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:50:26.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:50:26.686+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:50:26.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:50:26.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:50:26.741+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:50:26.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:50:26.758+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:50:26.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:50:26.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T03:50:57.020+0000] {processor.py:157} INFO - Started process (PID=50290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:50:57.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:50:57.024+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:50:57.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:50:57.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:50:57.093+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:50:57.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:50:57.109+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:50:57.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:50:57.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-11T03:51:27.351+0000] {processor.py:157} INFO - Started process (PID=50300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:51:27.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:51:27.357+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:51:27.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:51:27.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:51:27.405+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:51:27.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:51:27.417+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:51:27.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:51:27.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T03:51:57.765+0000] {processor.py:157} INFO - Started process (PID=50310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:51:57.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:51:57.772+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:51:57.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:51:57.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:51:57.824+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:51:57.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:51:57.837+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:51:57.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:51:57.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T03:52:28.015+0000] {processor.py:157} INFO - Started process (PID=50320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:52:28.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:52:28.018+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:52:28.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:52:28.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:52:28.050+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:52:28.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:52:28.065+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:52:28.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:52:28.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T03:52:58.463+0000] {processor.py:157} INFO - Started process (PID=50330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:52:58.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:52:58.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:52:58.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:52:58.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:52:58.510+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:52:58.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:52:58.523+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:52:58.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:52:58.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T03:53:28.764+0000] {processor.py:157} INFO - Started process (PID=50340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:53:28.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:53:28.766+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:53:28.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:53:28.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:53:28.792+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:53:28.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:53:28.802+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:53:28.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:53:28.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T03:53:59.168+0000] {processor.py:157} INFO - Started process (PID=50350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:53:59.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:53:59.173+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:53:59.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:53:59.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:53:59.208+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:53:59.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:53:59.220+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:53:59.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:53:59.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T03:54:29.555+0000] {processor.py:157} INFO - Started process (PID=50360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:54:29.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:54:29.557+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:54:29.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:54:29.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:54:29.583+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:54:29.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:54:29.595+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:54:29.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:54:29.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T03:54:59.864+0000] {processor.py:157} INFO - Started process (PID=50370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:54:59.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:54:59.867+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:54:59.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:54:59.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:54:59.893+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:54:59.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:54:59.903+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:54:59.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:54:59.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T03:55:30.231+0000] {processor.py:157} INFO - Started process (PID=50380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:55:30.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:55:30.239+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:55:30.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:55:30.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:55:30.280+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:55:30.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:55:30.295+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:55:30.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:55:30.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T03:56:00.615+0000] {processor.py:157} INFO - Started process (PID=50390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:56:00.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:56:00.626+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:56:00.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:56:00.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:56:00.688+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:56:00.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:56:00.711+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:56:00.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:56:00.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-11T03:56:30.929+0000] {processor.py:157} INFO - Started process (PID=50400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:56:30.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:56:30.934+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:56:30.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:56:30.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:56:30.969+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:56:30.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:56:30.978+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:56:30.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:56:30.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T03:57:01.329+0000] {processor.py:157} INFO - Started process (PID=50410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:57:01.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:57:01.332+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:57:01.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:57:01.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:57:01.371+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:57:01.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:57:01.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:57:01.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:57:01.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T03:57:31.740+0000] {processor.py:157} INFO - Started process (PID=50420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:57:31.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:57:31.750+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:57:31.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:57:31.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:57:31.803+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:57:31.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:57:31.816+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:57:31.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:57:31.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T03:58:02.043+0000] {processor.py:157} INFO - Started process (PID=50430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:58:02.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:58:02.046+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:58:02.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:58:02.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:58:02.075+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:58:02.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:58:02.085+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:58:02.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:58:02.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T03:58:32.396+0000] {processor.py:157} INFO - Started process (PID=50440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:58:32.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:58:32.402+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:58:32.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:58:32.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:58:32.436+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:58:32.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:58:32.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:58:32.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:58:32.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T03:59:02.739+0000] {processor.py:157} INFO - Started process (PID=50450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:59:02.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:59:02.742+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:59:02.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:59:02.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:59:02.779+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:59:02.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:59:02.794+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:59:02.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:59:02.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T03:59:33.027+0000] {processor.py:157} INFO - Started process (PID=50460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:59:33.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T03:59:33.033+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:59:33.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:59:33.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T03:59:33.078+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:59:33.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T03:59:33.090+0000] {logging_mixin.py:151} INFO - [2024-09-11T03:59:33.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T03:59:33.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T04:00:03.327+0000] {processor.py:157} INFO - Started process (PID=50470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:00:03.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:00:03.331+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:00:03.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:00:03.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:00:03.375+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:00:03.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:00:03.387+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:00:03.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:00:03.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T04:00:33.603+0000] {processor.py:157} INFO - Started process (PID=50480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:00:33.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:00:33.609+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:00:33.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:00:33.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:00:33.650+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:00:33.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:00:33.663+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:00:33.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:00:33.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T04:01:03.991+0000] {processor.py:157} INFO - Started process (PID=50490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:01:03.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:01:03.993+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:01:03.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:01:04.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:01:04.019+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:01:04.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:01:04.030+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:01:04.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:01:04.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T04:01:34.317+0000] {processor.py:157} INFO - Started process (PID=50500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:01:34.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:01:34.321+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:01:34.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:01:34.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:01:34.362+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:01:34.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:01:34.376+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:01:34.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:01:34.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T04:02:04.703+0000] {processor.py:157} INFO - Started process (PID=50510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:02:04.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:02:04.707+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:02:04.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:02:04.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:02:04.743+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:02:04.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:02:04.757+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:02:04.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:02:04.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T04:02:35.086+0000] {processor.py:157} INFO - Started process (PID=50520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:02:35.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:02:35.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:02:35.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:02:35.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:02:35.113+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:02:35.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:02:35.124+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:02:35.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:02:35.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T04:03:05.494+0000] {processor.py:157} INFO - Started process (PID=50530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:03:05.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:03:05.500+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:03:05.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:03:05.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:03:05.562+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:03:05.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:03:05.575+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:03:05.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:03:05.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T04:03:35.783+0000] {processor.py:157} INFO - Started process (PID=50540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:03:35.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:03:35.785+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:03:35.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:03:35.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:03:35.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:03:35.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:03:35.824+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:03:35.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:03:35.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T04:04:06.148+0000] {processor.py:157} INFO - Started process (PID=50550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:04:06.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:04:06.155+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:04:06.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:04:06.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:04:06.225+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:04:06.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:04:06.245+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:04:06.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:04:06.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T04:04:36.460+0000] {processor.py:157} INFO - Started process (PID=50560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:04:36.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:04:36.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:04:36.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:04:36.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:04:36.489+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:04:36.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:04:36.499+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:04:36.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:04:36.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T04:05:06.859+0000] {processor.py:157} INFO - Started process (PID=50570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:05:06.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:05:06.868+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:05:06.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:05:06.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:05:06.906+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:05:06.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:05:06.918+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:05:06.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:05:06.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T04:05:37.141+0000] {processor.py:157} INFO - Started process (PID=50580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:05:37.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:05:37.144+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:05:37.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:05:37.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:05:37.174+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:05:37.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:05:37.183+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:05:37.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:05:37.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T04:06:07.575+0000] {processor.py:157} INFO - Started process (PID=50590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:06:07.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:06:07.590+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:06:07.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:06:07.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:06:07.706+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:06:07.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:06:07.735+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:06:07.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:06:07.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-11T04:06:37.891+0000] {processor.py:157} INFO - Started process (PID=50600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:06:37.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:06:37.900+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:06:37.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:06:37.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:06:37.974+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:06:37.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:06:37.988+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:06:37.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:06:38.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T04:07:08.257+0000] {processor.py:157} INFO - Started process (PID=50610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:07:08.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:07:08.259+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:07:08.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:07:08.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:07:08.286+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:07:08.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:07:08.296+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:07:08.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:07:08.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T04:07:38.651+0000] {processor.py:157} INFO - Started process (PID=50620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:07:38.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:07:38.658+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:07:38.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:07:38.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:07:38.694+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:07:38.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:07:38.707+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:07:38.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:07:38.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T04:08:09.014+0000] {processor.py:157} INFO - Started process (PID=50630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:08:09.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:08:09.018+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:08:09.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:08:09.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:08:09.045+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:08:09.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:08:09.056+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:08:09.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:08:09.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T04:08:39.380+0000] {processor.py:157} INFO - Started process (PID=50640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:08:39.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:08:39.391+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:08:39.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:08:39.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:08:39.449+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:08:39.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:08:39.462+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:08:39.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:08:39.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T04:09:09.843+0000] {processor.py:157} INFO - Started process (PID=50650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:09:09.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:09:09.860+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:09:09.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:09:09.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:09:09.934+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:09:09.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:09:09.953+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:09:09.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:09:09.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T04:09:40.098+0000] {processor.py:157} INFO - Started process (PID=50660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:09:40.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:09:40.103+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:09:40.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:09:40.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:09:40.129+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:09:40.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:09:40.141+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:09:40.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:09:40.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T04:10:10.456+0000] {processor.py:157} INFO - Started process (PID=50669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:10:10.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:10:10.461+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:10:10.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:10:10.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:10:10.502+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:10:10.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:10:10.516+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:10:10.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:10:10.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T04:10:40.750+0000] {processor.py:157} INFO - Started process (PID=50680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:10:40.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:10:40.754+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:10:40.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:10:40.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:10:40.780+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:10:40.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:10:40.791+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:10:40.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:10:40.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T04:11:11.137+0000] {processor.py:157} INFO - Started process (PID=50690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:11:11.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:11:11.142+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:11:11.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:11:11.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:11:11.197+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:11:11.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:11:11.211+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:11:11.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:11:11.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T04:11:41.554+0000] {processor.py:157} INFO - Started process (PID=50700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:11:41.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:11:41.559+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:11:41.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:11:41.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:11:41.591+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:11:41.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:11:41.600+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:11:41.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:11:41.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T04:12:12.007+0000] {processor.py:157} INFO - Started process (PID=50710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:12:12.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:12:12.028+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:12:12.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:12:12.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:12:12.104+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:12:12.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:12:12.132+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:12:12.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:12:12.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-11T04:12:42.327+0000] {processor.py:157} INFO - Started process (PID=50720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:12:42.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:12:42.335+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:12:42.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:12:42.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:12:42.377+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:12:42.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:12:42.390+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:12:42.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:12:42.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T04:13:12.673+0000] {processor.py:157} INFO - Started process (PID=50730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:13:12.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:13:12.676+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:13:12.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:13:12.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:13:12.701+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:13:12.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:13:12.711+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:13:12.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:13:12.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T04:13:43.075+0000] {processor.py:157} INFO - Started process (PID=50739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:13:43.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:13:43.090+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:13:43.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:13:43.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:13:43.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:13:43.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:13:43.143+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:13:43.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:13:43.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T04:14:13.347+0000] {processor.py:157} INFO - Started process (PID=50750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:14:13.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:14:13.350+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:14:13.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:14:13.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:14:13.376+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:14:13.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:14:13.386+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:14:13.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:14:13.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T04:14:43.650+0000] {processor.py:157} INFO - Started process (PID=50760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:14:43.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:14:43.656+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:14:43.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:14:43.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:14:43.698+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:14:43.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:14:43.713+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:14:43.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:14:43.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T04:15:14.044+0000] {processor.py:157} INFO - Started process (PID=50770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:15:14.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:15:14.047+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:15:14.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:15:14.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:15:14.074+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:15:14.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:15:14.084+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:15:14.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:15:14.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T04:15:44.393+0000] {processor.py:157} INFO - Started process (PID=50780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:15:44.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:15:44.398+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:15:44.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:15:44.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:15:44.436+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:15:44.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:15:44.450+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:15:44.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:15:44.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T04:16:14.750+0000] {processor.py:157} INFO - Started process (PID=50790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:16:14.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:16:14.755+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:16:14.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:16:14.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:16:14.793+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:16:14.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:16:14.806+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:16:14.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:16:14.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T04:16:45.088+0000] {processor.py:157} INFO - Started process (PID=50800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:16:45.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:16:45.118+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:16:45.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:16:45.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:16:45.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:16:45.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:16:45.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:16:45.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:16:45.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-11T04:17:15.456+0000] {processor.py:157} INFO - Started process (PID=50810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:17:15.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:17:15.467+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:17:15.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:17:15.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:17:15.523+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:17:15.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:17:15.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:17:15.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:17:15.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T04:17:45.765+0000] {processor.py:157} INFO - Started process (PID=50820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:17:45.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:17:45.771+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:17:45.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:17:45.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:17:45.822+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:17:45.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:17:45.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:17:45.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:17:45.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T04:18:16.184+0000] {processor.py:157} INFO - Started process (PID=50829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:18:16.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:18:16.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:18:16.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:18:16.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:18:16.266+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:18:16.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:18:16.284+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:18:16.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:18:16.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-11T04:18:46.523+0000] {processor.py:157} INFO - Started process (PID=50839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:18:46.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:18:46.530+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:18:46.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:18:46.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:18:46.572+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:18:46.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:18:46.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:18:46.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:18:46.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T04:19:16.876+0000] {processor.py:157} INFO - Started process (PID=50850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:19:16.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:19:16.879+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:19:16.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:19:16.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:19:16.907+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:19:16.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:19:16.918+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:19:16.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:19:16.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T04:19:47.133+0000] {processor.py:157} INFO - Started process (PID=50860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:19:47.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:19:47.138+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:19:47.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:19:47.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:19:47.189+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:19:47.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:19:47.204+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:19:47.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:19:47.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T04:20:17.377+0000] {processor.py:157} INFO - Started process (PID=50870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:20:17.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:20:17.384+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:20:17.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:20:17.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:20:17.426+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:20:17.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:20:17.438+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:20:17.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:20:17.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T04:20:47.677+0000] {processor.py:157} INFO - Started process (PID=50880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:20:47.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:20:47.684+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:20:47.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:20:47.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:20:47.721+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:20:47.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:20:47.736+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:20:47.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:20:47.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T04:21:18.017+0000] {processor.py:157} INFO - Started process (PID=50890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:21:18.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:21:18.022+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:21:18.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:21:18.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:21:18.100+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:21:18.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:21:18.125+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:21:18.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:21:18.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-11T04:21:48.484+0000] {processor.py:157} INFO - Started process (PID=50900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:21:48.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:21:48.490+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:21:48.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:21:48.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:21:48.556+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:21:48.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:21:48.582+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:21:48.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:21:48.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T04:22:19.112+0000] {processor.py:157} INFO - Started process (PID=50910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:22:19.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:22:19.121+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:22:19.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:22:19.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:22:19.160+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:22:19.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:22:19.174+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:22:19.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:22:19.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T04:22:49.489+0000] {processor.py:157} INFO - Started process (PID=50920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:22:49.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:22:49.494+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:22:49.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:22:49.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:22:49.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:22:49.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:22:49.554+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:22:49.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:22:49.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T04:23:19.796+0000] {processor.py:157} INFO - Started process (PID=50930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:23:19.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:23:19.801+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:23:19.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:23:19.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:23:19.839+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:23:19.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:23:19.853+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:23:19.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:23:19.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T04:23:50.178+0000] {processor.py:157} INFO - Started process (PID=50939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:23:50.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:23:50.186+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:23:50.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:23:50.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:23:50.247+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:23:50.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:23:50.265+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:23:50.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:23:50.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T04:24:20.721+0000] {processor.py:157} INFO - Started process (PID=50950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:24:20.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:24:20.732+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:24:20.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:24:20.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:24:20.793+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:24:20.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:24:20.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:24:20.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:24:20.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T04:24:51.325+0000] {processor.py:157} INFO - Started process (PID=50960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:24:51.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:24:51.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:24:51.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:24:51.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:24:51.423+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:24:51.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:24:51.465+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:24:51.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:24:51.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-11T04:25:21.734+0000] {processor.py:157} INFO - Started process (PID=50970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:25:21.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:25:21.740+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:25:21.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:25:21.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:25:21.787+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:25:21.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:25:21.800+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:25:21.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:25:21.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T04:25:52.115+0000] {processor.py:157} INFO - Started process (PID=50980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:25:52.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:25:52.118+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:25:52.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:25:52.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:25:52.144+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:25:52.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:25:52.154+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:25:52.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:25:52.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T04:26:22.509+0000] {processor.py:157} INFO - Started process (PID=50990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:26:22.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:26:22.515+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:26:22.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:26:22.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:26:22.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:26:22.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:26:22.606+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:26:22.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:26:22.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T04:26:52.780+0000] {processor.py:157} INFO - Started process (PID=51000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:26:52.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:26:52.783+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:26:52.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:26:52.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:26:52.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:26:52.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:26:52.821+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:26:52.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:26:52.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T04:27:23.128+0000] {processor.py:157} INFO - Started process (PID=51010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:27:23.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:27:23.133+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:27:23.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:27:23.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:27:23.172+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:27:23.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:27:23.186+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:27:23.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:27:23.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T04:27:53.465+0000] {processor.py:157} INFO - Started process (PID=51020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:27:53.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:27:53.479+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:27:53.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:27:53.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:27:53.546+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:27:53.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:27:53.582+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:27:53.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:27:53.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-11T04:28:23.826+0000] {processor.py:157} INFO - Started process (PID=51029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:28:23.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:28:23.832+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:28:23.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:28:23.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:28:23.880+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:28:23.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:28:23.894+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:28:23.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:28:23.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T04:28:54.268+0000] {processor.py:157} INFO - Started process (PID=51038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:28:54.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:28:54.274+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:28:54.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:28:54.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:28:54.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:28:54.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:28:54.359+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:28:54.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:28:54.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-11T04:29:24.646+0000] {processor.py:157} INFO - Started process (PID=51050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:29:24.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:29:24.661+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:29:24.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:29:24.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:29:24.710+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:29:24.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:29:24.726+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:29:24.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:29:24.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T04:29:54.983+0000] {processor.py:157} INFO - Started process (PID=51059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:29:54.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:29:54.988+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:29:54.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:29:55.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:29:55.037+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:29:55.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:29:55.049+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:29:55.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:29:55.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T04:30:25.337+0000] {processor.py:157} INFO - Started process (PID=51070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:30:25.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:30:25.352+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:30:25.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:30:25.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:30:25.412+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:30:25.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:30:25.424+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:30:25.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:30:25.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T04:30:56.102+0000] {processor.py:157} INFO - Started process (PID=51080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:30:56.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:30:56.120+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:30:56.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:30:56.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:30:56.196+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:30:56.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:30:56.224+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:30:56.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:30:56.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-11T04:31:26.339+0000] {processor.py:157} INFO - Started process (PID=51090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:31:26.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:31:26.342+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:31:26.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:31:26.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:31:26.371+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:31:26.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:31:26.379+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:31:26.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:31:26.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T04:32:46.055+0000] {processor.py:157} INFO - Started process (PID=51100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:32:46.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:32:46.068+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:32:46.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:32:46.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:32:46.119+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:32:46.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:32:46.135+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:32:46.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:32:46.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T04:37:05.631+0000] {processor.py:157} INFO - Started process (PID=51111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:37:05.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:37:05.638+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:37:05.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:37:05.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:37:05.693+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:37:05.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:37:05.710+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:37:05.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:37:05.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T04:37:35.992+0000] {processor.py:157} INFO - Started process (PID=51124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:37:35.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:37:36.000+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:37:36.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:37:36.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:37:36.074+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:37:36.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:37:36.097+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:37:36.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:37:36.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T04:38:06.397+0000] {processor.py:157} INFO - Started process (PID=51134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:38:06.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:38:06.402+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:38:06.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:38:06.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:38:06.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:38:06.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:38:06.461+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:38:06.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:38:06.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T04:38:39.397+0000] {processor.py:157} INFO - Started process (PID=51144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:38:39.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T04:38:39.400+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:38:39.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:38:39.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T04:38:39.432+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:38:39.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T04:38:39.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T04:38:39.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T04:38:39.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T05:35:03.342+0000] {processor.py:157} INFO - Started process (PID=51153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T05:35:03.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T05:35:03.362+0000] {logging_mixin.py:151} INFO - [2024-09-11T05:35:03.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T05:35:03.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T05:35:03.514+0000] {logging_mixin.py:151} INFO - [2024-09-11T05:35:03.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T05:35:03.567+0000] {logging_mixin.py:151} INFO - [2024-09-11T05:35:03.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T05:35:03.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.276 seconds
[2024-09-11T06:39:09.414+0000] {processor.py:157} INFO - Started process (PID=51164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:39:09.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T06:39:09.421+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:39:09.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:39:09.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:39:09.472+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:39:09.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T06:39:09.487+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:39:09.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T06:39:09.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T06:39:39.709+0000] {processor.py:157} INFO - Started process (PID=51174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:39:39.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T06:39:39.717+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:39:39.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:39:39.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:39:39.760+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:39:39.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T06:39:39.778+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:39:39.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T06:39:39.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T06:45:50.094+0000] {processor.py:157} INFO - Started process (PID=51185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:45:50.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T06:45:50.113+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:45:50.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:45:50.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T06:45:50.233+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:45:50.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T06:45:50.249+0000] {logging_mixin.py:151} INFO - [2024-09-11T06:45:50.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T06:45:50.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-11T07:12:03.573+0000] {processor.py:157} INFO - Started process (PID=51197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T07:12:03.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T07:12:03.592+0000] {logging_mixin.py:151} INFO - [2024-09-11T07:12:03.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T07:12:03.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T07:12:03.707+0000] {logging_mixin.py:151} INFO - [2024-09-11T07:12:03.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T07:12:03.754+0000] {logging_mixin.py:151} INFO - [2024-09-11T07:12:03.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T07:12:03.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-11T07:12:34.077+0000] {processor.py:157} INFO - Started process (PID=51207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T07:12:34.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T07:12:34.082+0000] {logging_mixin.py:151} INFO - [2024-09-11T07:12:34.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T07:12:34.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T07:12:34.122+0000] {logging_mixin.py:151} INFO - [2024-09-11T07:12:34.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T07:12:34.136+0000] {logging_mixin.py:151} INFO - [2024-09-11T07:12:34.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T07:12:34.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T08:03:41.986+0000] {processor.py:157} INFO - Started process (PID=51216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T08:03:41.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T08:03:41.993+0000] {logging_mixin.py:151} INFO - [2024-09-11T08:03:41.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T08:03:42.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T08:03:42.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T08:03:42.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T08:03:42.058+0000] {logging_mixin.py:151} INFO - [2024-09-11T08:03:42.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T08:03:42.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T09:22:42.977+0000] {processor.py:157} INFO - Started process (PID=51227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T09:22:42.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T09:22:42.991+0000] {logging_mixin.py:151} INFO - [2024-09-11T09:22:42.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T09:22:43.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T09:22:43.094+0000] {logging_mixin.py:151} INFO - [2024-09-11T09:22:43.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T09:22:43.138+0000] {logging_mixin.py:151} INFO - [2024-09-11T09:22:43.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T09:22:43.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-09-11T09:23:13.507+0000] {processor.py:157} INFO - Started process (PID=51237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T09:23:13.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T09:23:13.513+0000] {logging_mixin.py:151} INFO - [2024-09-11T09:23:13.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T09:23:13.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T09:23:13.565+0000] {logging_mixin.py:151} INFO - [2024-09-11T09:23:13.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T09:23:13.579+0000] {logging_mixin.py:151} INFO - [2024-09-11T09:23:13.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T09:23:13.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T10:15:16.265+0000] {processor.py:157} INFO - Started process (PID=51246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T10:15:16.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T10:15:16.279+0000] {logging_mixin.py:151} INFO - [2024-09-11T10:15:16.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T10:15:16.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T10:15:16.323+0000] {logging_mixin.py:151} INFO - [2024-09-11T10:15:16.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T10:15:16.345+0000] {logging_mixin.py:151} INFO - [2024-09-11T10:15:16.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T10:15:16.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T10:31:07.236+0000] {processor.py:157} INFO - Started process (PID=51256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T10:31:07.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T10:31:07.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T10:31:07.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T10:31:07.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T10:31:07.305+0000] {logging_mixin.py:151} INFO - [2024-09-11T10:31:07.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T10:31:07.338+0000] {logging_mixin.py:151} INFO - [2024-09-11T10:31:07.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T10:31:07.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-11T11:03:27.286+0000] {processor.py:157} INFO - Started process (PID=51267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:03:27.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T11:03:27.293+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:03:27.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:03:27.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:03:27.334+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:03:27.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T11:03:27.347+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:03:27.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T11:03:27.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T11:31:30.914+0000] {processor.py:157} INFO - Started process (PID=51278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:31:30.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T11:31:30.919+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:31:30.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:31:30.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:31:30.955+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:31:30.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T11:31:30.967+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:31:30.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T11:31:30.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T11:32:18.590+0000] {processor.py:157} INFO - Started process (PID=51288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:32:18.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T11:32:18.594+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:32:18.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:32:18.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:32:18.636+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:32:18.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T11:32:18.649+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:32:18.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T11:32:18.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T11:32:48.900+0000] {processor.py:157} INFO - Started process (PID=51298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:32:48.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T11:32:48.902+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:32:48.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:32:48.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:32:48.929+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:32:48.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T11:32:48.938+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:32:48.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T11:32:48.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T11:33:20.165+0000] {processor.py:157} INFO - Started process (PID=51308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:33:20.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T11:33:20.170+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:33:20.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:33:20.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:33:20.211+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:33:20.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T11:33:20.223+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:33:20.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T11:33:20.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T11:49:55.389+0000] {processor.py:157} INFO - Started process (PID=51319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:49:55.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T11:49:55.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:49:55.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:49:55.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T11:49:55.426+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:49:55.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T11:49:55.438+0000] {logging_mixin.py:151} INFO - [2024-09-11T11:49:55.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T11:49:55.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T12:09:06.691+0000] {processor.py:157} INFO - Started process (PID=51329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:09:06.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:09:06.702+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:09:06.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:09:06.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:09:06.778+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:09:06.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:09:06.808+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:09:06.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:09:06.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-11T12:10:19.568+0000] {processor.py:157} INFO - Started process (PID=51340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:10:19.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:10:19.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:10:19.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:10:19.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:10:19.651+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:10:19.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:10:19.691+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:10:19.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:10:19.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-11T12:10:50.035+0000] {processor.py:157} INFO - Started process (PID=51350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:10:50.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:10:50.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:10:50.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:10:50.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:10:50.074+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:10:50.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:10:50.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:10:50.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:10:50.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T12:11:33.498+0000] {processor.py:157} INFO - Started process (PID=51360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:11:33.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:11:33.512+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:11:33.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:11:33.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:11:33.550+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:11:33.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:11:33.562+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:11:33.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:11:33.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T12:12:22.508+0000] {processor.py:157} INFO - Started process (PID=51370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:12:22.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:12:22.513+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:12:22.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:12:22.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:12:22.571+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:12:22.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:12:22.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:12:22.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:12:22.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T12:12:52.916+0000] {processor.py:157} INFO - Started process (PID=51379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:12:52.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:12:52.920+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:12:52.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:12:52.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:12:52.955+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:12:52.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:12:52.968+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:12:52.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:12:52.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T12:13:34.873+0000] {processor.py:157} INFO - Started process (PID=51390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:13:34.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:13:34.879+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:13:34.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:13:34.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:13:34.919+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:13:34.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:13:34.934+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:13:34.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:13:34.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T12:14:05.149+0000] {processor.py:157} INFO - Started process (PID=51400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:14:05.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:14:05.151+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:14:05.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:14:05.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:14:05.177+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:14:05.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:14:05.187+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:14:05.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:14:05.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T12:14:49.875+0000] {processor.py:157} INFO - Started process (PID=51410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:14:49.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:14:49.881+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:14:49.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:14:49.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:14:49.930+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:14:49.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:14:49.944+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:14:49.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:14:49.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T12:16:45.304+0000] {processor.py:157} INFO - Started process (PID=51421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:16:45.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:16:45.310+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:16:45.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:16:45.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:16:45.356+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:16:45.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:16:45.378+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:16:45.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:16:45.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T12:17:15.554+0000] {processor.py:157} INFO - Started process (PID=51431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:17:15.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:17:15.561+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:17:15.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:17:15.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:17:15.619+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:17:15.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:17:15.632+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:17:15.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:17:15.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T12:18:19.211+0000] {processor.py:157} INFO - Started process (PID=51442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:18:19.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:18:19.213+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:18:19.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:18:19.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:18:19.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:18:19.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:18:19.254+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:18:19.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:18:19.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T12:18:58.237+0000] {processor.py:157} INFO - Started process (PID=51452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:18:58.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:18:58.240+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:18:58.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:18:58.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:18:58.276+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:18:58.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:18:58.288+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:18:58.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:18:58.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T12:19:28.556+0000] {processor.py:157} INFO - Started process (PID=51462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:19:28.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:19:28.558+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:19:28.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:19:28.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:19:28.586+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:19:28.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:19:28.596+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:19:28.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:19:28.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T12:31:58.315+0000] {processor.py:157} INFO - Started process (PID=51471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:31:58.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:31:58.319+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:31:58.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:31:58.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:31:58.354+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:31:58.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:31:58.369+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:31:58.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:31:58.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T12:49:17.695+0000] {processor.py:157} INFO - Started process (PID=51484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:49:17.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:49:17.703+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:49:17.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:49:17.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:49:17.784+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:49:17.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:49:17.813+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:49:17.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:49:17.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-11T12:53:33.535+0000] {processor.py:157} INFO - Started process (PID=51494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:53:33.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T12:53:33.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:53:33.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:53:33.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T12:53:33.579+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:53:33.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T12:53:33.592+0000] {logging_mixin.py:151} INFO - [2024-09-11T12:53:33.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T12:53:33.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T13:08:47.310+0000] {processor.py:157} INFO - Started process (PID=51505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:08:47.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:08:47.317+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:08:47.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:08:47.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:08:47.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:08:47.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:08:47.430+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:08:47.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:08:47.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-11T13:09:17.614+0000] {processor.py:157} INFO - Started process (PID=51515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:09:17.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:09:17.621+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:09:17.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:09:17.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:09:17.677+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:09:17.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:09:17.692+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:09:17.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:09:17.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T13:27:21.502+0000] {processor.py:157} INFO - Started process (PID=51525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:27:21.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:27:21.506+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:27:21.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:27:21.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:27:21.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:27:21.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:27:21.559+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:27:21.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:27:21.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T13:27:51.910+0000] {processor.py:157} INFO - Started process (PID=51536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:27:51.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:27:51.923+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:27:51.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:27:51.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:27:51.971+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:27:51.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:27:52.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:27:52.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:27:52.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.261 seconds
[2024-09-11T13:29:08.483+0000] {processor.py:157} INFO - Started process (PID=51546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:29:08.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:29:08.491+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:29:08.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:29:08.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:29:08.536+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:29:08.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:29:08.550+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:29:08.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:29:08.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T13:29:50.658+0000] {processor.py:157} INFO - Started process (PID=51555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:29:50.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:29:50.665+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:29:50.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:29:50.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:29:50.714+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:29:50.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:29:50.728+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:29:50.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:29:50.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T13:30:20.959+0000] {processor.py:157} INFO - Started process (PID=51566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:30:20.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:30:20.961+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:30:20.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:30:20.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:30:20.988+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:30:20.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:30:20.999+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:30:20.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:30:21.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T13:31:00.685+0000] {processor.py:157} INFO - Started process (PID=51576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:31:00.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:31:00.690+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:31:00.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:31:00.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:31:00.731+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:31:00.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:31:00.746+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:31:00.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:31:00.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T13:31:57.689+0000] {processor.py:157} INFO - Started process (PID=51585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:31:57.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:31:57.699+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:31:57.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:31:57.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:31:57.751+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:31:57.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:31:57.776+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:31:57.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:31:57.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-11T13:32:28.036+0000] {processor.py:157} INFO - Started process (PID=51596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:32:28.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:32:28.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:32:28.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:32:28.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:32:28.067+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:32:28.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:32:28.078+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:32:28.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:32:28.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T13:33:57.948+0000] {processor.py:157} INFO - Started process (PID=51605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:33:57.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:33:57.954+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:33:57.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:33:57.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:33:57.997+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:33:57.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:33:58.013+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:33:58.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:33:58.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T13:35:11.527+0000] {processor.py:157} INFO - Started process (PID=51618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:35:11.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:35:11.530+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:35:11.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:35:11.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:35:11.564+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:35:11.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:35:11.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:35:11.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:35:11.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T13:35:41.971+0000] {processor.py:157} INFO - Started process (PID=51628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:35:41.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:35:41.973+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:35:41.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:35:41.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:35:41.999+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:35:41.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:35:42.009+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:35:42.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:35:42.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-11T13:52:04.370+0000] {processor.py:157} INFO - Started process (PID=51637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:52:04.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T13:52:04.383+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:52:04.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:52:04.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T13:52:04.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:52:04.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T13:52:04.507+0000] {logging_mixin.py:151} INFO - [2024-09-11T13:52:04.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T13:52:04.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-11T14:09:38.247+0000] {processor.py:157} INFO - Started process (PID=51648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:09:38.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:09:38.308+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:09:38.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:09:38.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:09:38.463+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:09:38.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:09:38.497+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:09:38.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:09:38.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.297 seconds
[2024-09-11T14:10:12.515+0000] {processor.py:157} INFO - Started process (PID=51658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:10:12.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:10:12.520+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:10:12.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:10:12.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:10:12.563+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:10:12.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:10:12.575+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:10:12.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:10:12.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T14:22:16.023+0000] {processor.py:157} INFO - Started process (PID=51670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:22:16.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:22:16.029+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:22:16.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:22:16.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:22:16.106+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:22:16.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:22:16.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:22:16.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:22:16.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-11T14:22:46.472+0000] {processor.py:157} INFO - Started process (PID=51680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:22:46.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:22:46.477+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:22:46.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:22:46.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:22:46.521+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:22:46.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:22:46.536+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:22:46.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:22:46.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T14:33:10.430+0000] {processor.py:157} INFO - Started process (PID=51690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:33:10.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:33:10.435+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:33:10.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:33:10.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:33:10.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:33:10.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:33:10.525+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:33:10.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:33:10.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-11T14:51:14.883+0000] {processor.py:157} INFO - Started process (PID=51700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:51:14.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:51:14.889+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:51:14.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:51:14.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:51:14.946+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:51:14.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:51:14.959+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:51:14.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:51:14.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T14:53:51.386+0000] {processor.py:157} INFO - Started process (PID=51711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:53:51.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:53:51.398+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:53:51.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:53:51.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:53:51.503+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:53:51.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:53:51.538+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:53:51.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:53:51.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-11T14:55:42.046+0000] {processor.py:157} INFO - Started process (PID=51721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:55:42.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:55:42.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:55:42.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:55:42.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:55:42.104+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:55:42.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:55:42.124+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:55:42.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:55:42.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T14:56:12.497+0000] {processor.py:157} INFO - Started process (PID=51731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:56:12.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:56:12.503+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:56:12.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:56:12.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:56:12.563+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:56:12.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:56:12.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:56:12.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:56:12.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T14:58:51.616+0000] {processor.py:157} INFO - Started process (PID=51742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:58:51.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T14:58:51.628+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:58:51.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:58:51.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T14:58:51.706+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:58:51.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T14:58:51.731+0000] {logging_mixin.py:151} INFO - [2024-09-11T14:58:51.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T14:58:51.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-11T15:01:33.143+0000] {processor.py:157} INFO - Started process (PID=51752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:01:33.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:01:33.153+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:01:33.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:01:33.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:01:33.263+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:01:33.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:01:33.309+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:01:33.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:01:33.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-09-11T15:02:03.701+0000] {processor.py:157} INFO - Started process (PID=51764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:02:03.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:02:03.720+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:02:03.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:02:03.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:02:03.760+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:02:03.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:02:03.774+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:02:03.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:02:03.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T15:04:53.644+0000] {processor.py:157} INFO - Started process (PID=51773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:04:53.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:04:53.650+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:04:53.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:04:53.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:04:53.701+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:04:53.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:04:53.717+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:04:53.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:04:53.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T15:18:29.868+0000] {processor.py:157} INFO - Started process (PID=51784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:18:29.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:18:29.875+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:18:29.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:18:29.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:18:29.927+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:18:29.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:18:29.950+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:18:29.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:18:29.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T15:19:00.401+0000] {processor.py:157} INFO - Started process (PID=51792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:19:00.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:19:00.407+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:19:00.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:19:00.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:19:00.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:19:00.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:19:00.477+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:19:00.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:19:00.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T15:26:45.277+0000] {processor.py:157} INFO - Started process (PID=51806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:26:45.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:26:45.281+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:26:45.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:26:45.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:26:45.333+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:26:45.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:26:45.359+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:26:45.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:26:45.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T15:27:16.036+0000] {processor.py:157} INFO - Started process (PID=51816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:27:16.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:27:16.043+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:27:16.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:27:16.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:27:16.083+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:27:16.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:27:16.096+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:27:16.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:27:16.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T15:28:39.346+0000] {processor.py:157} INFO - Started process (PID=51826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:28:39.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:28:39.351+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:28:39.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:28:39.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:28:39.397+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:28:39.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:28:39.411+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:28:39.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:28:39.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T15:29:48.814+0000] {processor.py:157} INFO - Started process (PID=51836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:29:48.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:29:48.825+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:29:48.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:29:48.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:29:48.937+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:29:48.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:29:48.954+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:29:48.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:29:48.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-11T15:30:19.097+0000] {processor.py:157} INFO - Started process (PID=51846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:30:19.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:30:19.101+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:30:19.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:30:19.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:30:19.131+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:30:19.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:30:19.141+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:30:19.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:30:19.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T15:31:16.524+0000] {processor.py:157} INFO - Started process (PID=51858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:31:16.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:31:16.530+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:31:16.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:31:16.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:31:16.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:31:16.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:31:16.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:31:16.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:31:16.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T15:31:58.179+0000] {processor.py:157} INFO - Started process (PID=51868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:31:58.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:31:58.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:31:58.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:31:58.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:31:58.245+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:31:58.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:31:58.260+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:31:58.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:31:58.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T15:32:28.475+0000] {processor.py:157} INFO - Started process (PID=51878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:32:28.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:32:28.482+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:32:28.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:32:28.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:32:28.529+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:32:28.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:32:28.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:32:28.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:32:28.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T15:33:07.117+0000] {processor.py:157} INFO - Started process (PID=51888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:33:07.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:33:07.123+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:33:07.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:33:07.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:33:07.169+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:33:07.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:33:07.181+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:33:07.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:33:07.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T15:36:59.241+0000] {processor.py:157} INFO - Started process (PID=51899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:36:59.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:36:59.244+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:36:59.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:36:59.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:36:59.297+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:36:59.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:36:59.309+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:36:59.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:36:59.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T15:37:29.601+0000] {processor.py:157} INFO - Started process (PID=51910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:37:29.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:37:29.605+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:37:29.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:37:29.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:37:29.654+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:37:29.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:37:29.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:37:29.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:37:29.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T15:38:12.981+0000] {processor.py:157} INFO - Started process (PID=51920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:38:12.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:38:12.986+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:38:12.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:38:13.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:38:13.044+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:38:13.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:38:13.056+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:38:13.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:38:13.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T15:38:43.490+0000] {processor.py:157} INFO - Started process (PID=51930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:38:43.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:38:43.499+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:38:43.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:38:43.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:38:43.592+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:38:43.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:38:43.614+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:38:43.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:38:43.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T15:39:13.796+0000] {processor.py:157} INFO - Started process (PID=51940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:39:13.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:39:13.801+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:39:13.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:39:13.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:39:13.849+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:39:13.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:39:13.868+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:39:13.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:39:13.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T15:39:44.140+0000] {processor.py:157} INFO - Started process (PID=51950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:39:44.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:39:44.143+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:39:44.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:39:44.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:39:44.177+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:39:44.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:39:44.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:39:44.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:39:44.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T15:40:14.546+0000] {processor.py:157} INFO - Started process (PID=51960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:40:14.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:40:14.561+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:40:14.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:40:14.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:40:14.603+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:40:14.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:40:14.632+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:40:14.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:40:14.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T15:40:44.982+0000] {processor.py:157} INFO - Started process (PID=51970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:40:44.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:40:44.992+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:40:44.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:40:45.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:40:45.043+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:40:45.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:40:45.068+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:40:45.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:40:45.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T15:41:15.325+0000] {processor.py:157} INFO - Started process (PID=51980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:41:15.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:41:15.330+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:41:15.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:41:15.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:41:15.370+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:41:15.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:41:15.391+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:41:15.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:41:15.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T15:41:45.776+0000] {processor.py:157} INFO - Started process (PID=51988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:41:45.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:41:45.814+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:41:45.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:41:45.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:41:45.952+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:41:45.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:41:45.979+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:41:45.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:41:45.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-11T15:42:16.069+0000] {processor.py:157} INFO - Started process (PID=52000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:42:16.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:42:16.074+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:42:16.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:42:16.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:42:16.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:42:16.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:42:16.148+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:42:16.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:42:16.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T15:42:46.489+0000] {processor.py:157} INFO - Started process (PID=52010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:42:46.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:42:46.496+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:42:46.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:42:46.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:42:46.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:42:46.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:42:46.565+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:42:46.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:42:46.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T15:43:16.824+0000] {processor.py:157} INFO - Started process (PID=52020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:43:16.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:43:16.830+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:43:16.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:43:16.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:43:16.870+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:43:16.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:43:16.884+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:43:16.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:43:16.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T15:43:47.150+0000] {processor.py:157} INFO - Started process (PID=52030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:43:47.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:43:47.156+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:43:47.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:43:47.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:43:47.218+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:43:47.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:43:47.232+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:43:47.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:43:47.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T15:44:17.657+0000] {processor.py:157} INFO - Started process (PID=52040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:44:17.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:44:17.663+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:44:17.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:44:17.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:44:17.712+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:44:17.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:44:17.730+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:44:17.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:44:17.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T15:44:48.005+0000] {processor.py:157} INFO - Started process (PID=52050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:44:48.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:44:48.010+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:44:48.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:44:48.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:44:48.068+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:44:48.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:44:48.083+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:44:48.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:44:48.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T15:45:18.317+0000] {processor.py:157} INFO - Started process (PID=52059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:45:18.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:45:18.323+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:45:18.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:45:18.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:45:18.366+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:45:18.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:45:18.379+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:45:18.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:45:18.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T15:45:48.676+0000] {processor.py:157} INFO - Started process (PID=52070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:45:48.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:45:48.679+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:45:48.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:45:48.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:45:48.722+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:45:48.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:45:48.741+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:45:48.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:45:48.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T15:46:19.085+0000] {processor.py:157} INFO - Started process (PID=52080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:46:19.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:46:19.093+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:46:19.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:46:19.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:46:19.164+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:46:19.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:46:19.184+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:46:19.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:46:19.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T15:46:49.364+0000] {processor.py:157} INFO - Started process (PID=52090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:46:49.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:46:49.367+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:46:49.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:46:49.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:46:49.407+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:46:49.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:46:49.420+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:46:49.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:46:49.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T15:47:19.746+0000] {processor.py:157} INFO - Started process (PID=52100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:47:19.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:47:19.754+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:47:19.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:47:19.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:47:19.802+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:47:19.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:47:19.816+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:47:19.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:47:19.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T15:47:50.084+0000] {processor.py:157} INFO - Started process (PID=52110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:47:50.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:47:50.091+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:47:50.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:47:50.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:47:50.164+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:47:50.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:47:50.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:47:50.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:47:50.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-11T15:48:20.420+0000] {processor.py:157} INFO - Started process (PID=52120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:48:20.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:48:20.430+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:48:20.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:48:20.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:48:20.497+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:48:20.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:48:20.512+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:48:20.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:48:20.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-11T15:48:50.891+0000] {processor.py:157} INFO - Started process (PID=52130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:48:50.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:48:50.900+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:48:50.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:48:50.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:48:51.008+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:48:51.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:48:51.033+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:48:51.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:48:51.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-11T15:49:21.235+0000] {processor.py:157} INFO - Started process (PID=52140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:49:21.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:49:21.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:49:21.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:49:21.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:49:21.310+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:49:21.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:49:21.325+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:49:21.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:49:21.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T15:49:51.585+0000] {processor.py:157} INFO - Started process (PID=52149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:49:51.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:49:51.590+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:49:51.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:49:51.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:49:51.636+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:49:51.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:49:51.651+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:49:51.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:49:51.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T15:50:21.878+0000] {processor.py:157} INFO - Started process (PID=52160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:50:21.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:50:21.881+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:50:21.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:50:21.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:50:21.910+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:50:21.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:50:21.920+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:50:21.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:50:21.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T15:50:52.206+0000] {processor.py:157} INFO - Started process (PID=52169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:50:52.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:50:52.209+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:50:52.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:50:52.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:50:52.244+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:50:52.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:50:52.258+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:50:52.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:50:52.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T15:51:22.512+0000] {processor.py:157} INFO - Started process (PID=52180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:51:22.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:51:22.518+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:51:22.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:51:22.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:51:22.573+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:51:22.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:51:22.586+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:51:22.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:51:22.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T15:51:52.852+0000] {processor.py:157} INFO - Started process (PID=52190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:51:52.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:51:52.862+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:51:52.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:51:52.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:51:52.915+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:51:52.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:51:52.928+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:51:52.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:51:52.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-11T15:52:23.265+0000] {processor.py:157} INFO - Started process (PID=52200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:52:23.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:52:23.273+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:52:23.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:52:23.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:52:23.335+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:52:23.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:52:23.349+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:52:23.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:52:23.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T15:52:53.559+0000] {processor.py:157} INFO - Started process (PID=52210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:52:53.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:52:53.563+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:52:53.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:52:53.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:52:53.600+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:52:53.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:52:53.614+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:52:53.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:52:53.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T15:53:24.038+0000] {processor.py:157} INFO - Started process (PID=52220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:53:24.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:53:24.058+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:53:24.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:53:24.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:53:24.135+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:53:24.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:53:24.154+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:53:24.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:53:24.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-11T15:53:54.399+0000] {processor.py:157} INFO - Started process (PID=52230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:53:54.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:53:54.406+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:53:54.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:53:54.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:53:54.462+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:53:54.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:53:54.476+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:53:54.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:53:54.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T15:54:24.755+0000] {processor.py:157} INFO - Started process (PID=52240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:54:24.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:54:24.759+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:54:24.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:54:24.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:54:24.814+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:54:24.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:54:24.827+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:54:24.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:54:24.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T15:54:55.068+0000] {processor.py:157} INFO - Started process (PID=52250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:54:55.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:54:55.074+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:54:55.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:54:55.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:54:55.139+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:54:55.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:54:55.152+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:54:55.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:54:55.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T15:55:25.436+0000] {processor.py:157} INFO - Started process (PID=52259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:55:25.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:55:25.455+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:55:25.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:55:25.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:55:25.498+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:55:25.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:55:25.522+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:55:25.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:55:25.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-11T15:55:55.773+0000] {processor.py:157} INFO - Started process (PID=52270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:55:55.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:55:55.778+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:55:55.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:55:55.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:55:55.833+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:55:55.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:55:55.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:55:55.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:55:55.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T15:56:26.070+0000] {processor.py:157} INFO - Started process (PID=52280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:56:26.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:56:26.073+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:56:26.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:56:26.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:56:26.096+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:56:26.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:56:26.107+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:56:26.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:56:26.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-11T15:56:56.438+0000] {processor.py:157} INFO - Started process (PID=52289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:56:56.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:56:56.444+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:56:56.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:56:56.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:56:56.487+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:56:56.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:56:56.502+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:56:56.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:56:56.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T15:57:26.749+0000] {processor.py:157} INFO - Started process (PID=52300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:57:26.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:57:26.754+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:57:26.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:57:26.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:57:26.824+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:57:26.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:57:26.837+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:57:26.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:57:26.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T15:57:57.036+0000] {processor.py:157} INFO - Started process (PID=52310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:57:57.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:57:57.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:57:57.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:57:57.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:57:57.067+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:57:57.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:57:57.077+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:57:57.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:57:57.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T15:58:27.399+0000] {processor.py:157} INFO - Started process (PID=52320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:58:27.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:58:27.405+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:58:27.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:58:27.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:58:27.458+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:58:27.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:58:27.472+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:58:27.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:58:27.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T15:58:57.652+0000] {processor.py:157} INFO - Started process (PID=52329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:58:57.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:58:57.659+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:58:57.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:58:57.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:58:57.698+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:58:57.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:58:57.711+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:58:57.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:58:57.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T15:59:28.214+0000] {processor.py:157} INFO - Started process (PID=52340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:59:28.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T15:59:28.219+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:59:28.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:59:28.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T15:59:28.275+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:59:28.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T15:59:28.294+0000] {logging_mixin.py:151} INFO - [2024-09-11T15:59:28.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T15:59:28.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T16:08:52.958+0000] {processor.py:157} INFO - Started process (PID=52350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:08:52.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:08:52.959+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:08:52.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:08:52.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:08:52.992+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:08:52.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:08:53.006+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:08:53.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:08:53.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T16:09:23.302+0000] {processor.py:157} INFO - Started process (PID=52362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:09:23.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:09:23.308+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:09:23.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:09:23.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:09:23.360+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:09:23.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:09:23.376+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:09:23.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:09:23.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T16:09:53.793+0000] {processor.py:157} INFO - Started process (PID=52372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:09:53.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:09:53.803+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:09:53.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:09:53.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:09:53.878+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:09:53.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:09:53.896+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:09:53.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:09:53.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-11T16:10:24.239+0000] {processor.py:157} INFO - Started process (PID=52382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:10:24.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:10:24.243+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:10:24.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:10:24.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:10:24.282+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:10:24.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:10:24.303+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:10:24.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:10:24.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T16:10:54.579+0000] {processor.py:157} INFO - Started process (PID=52391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:10:54.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:10:54.585+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:10:54.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:10:54.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:10:54.627+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:10:54.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:10:54.652+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:10:54.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:10:54.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T16:11:24.932+0000] {processor.py:157} INFO - Started process (PID=52401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:11:24.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:11:24.938+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:11:24.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:11:24.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:11:25.000+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:11:25.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:11:25.017+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:11:25.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:11:25.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T16:11:55.251+0000] {processor.py:157} INFO - Started process (PID=52412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:11:55.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:11:55.257+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:11:55.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:11:55.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:11:55.314+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:11:55.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:11:55.328+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:11:55.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:11:55.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T16:12:25.603+0000] {processor.py:157} INFO - Started process (PID=52422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:12:25.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:12:25.614+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:12:25.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:12:25.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:12:25.680+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:12:25.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:12:25.695+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:12:25.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:12:25.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T16:12:55.952+0000] {processor.py:157} INFO - Started process (PID=52432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:12:55.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:12:55.962+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:12:55.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:12:55.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:12:56.009+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:12:56.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:12:56.031+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:12:56.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:12:56.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T16:13:26.333+0000] {processor.py:157} INFO - Started process (PID=52442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:13:26.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:13:26.338+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:13:26.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:13:26.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:13:26.411+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:13:26.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:13:26.427+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:13:26.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:13:26.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-11T16:13:56.880+0000] {processor.py:157} INFO - Started process (PID=52452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:13:56.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:13:56.896+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:13:56.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:13:56.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:13:56.938+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:13:56.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:13:56.956+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:13:56.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:13:56.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T16:14:27.326+0000] {processor.py:157} INFO - Started process (PID=52462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:14:27.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:14:27.332+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:14:27.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:14:27.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:14:27.372+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:14:27.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:14:27.387+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:14:27.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:14:27.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T16:14:57.611+0000] {processor.py:157} INFO - Started process (PID=52472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:14:57.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:14:57.621+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:14:57.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:14:57.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:14:57.672+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:14:57.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:14:57.685+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:14:57.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:14:57.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T16:15:28.113+0000] {processor.py:157} INFO - Started process (PID=52482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:15:28.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:15:28.129+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:15:28.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:15:28.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:15:28.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:15:28.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:15:28.202+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:15:28.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:15:28.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T16:15:58.604+0000] {processor.py:157} INFO - Started process (PID=52492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:15:58.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:15:58.607+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:15:58.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:15:58.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:15:58.660+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:15:58.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:15:58.673+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:15:58.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:15:58.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T16:16:28.983+0000] {processor.py:157} INFO - Started process (PID=52502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:16:28.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:16:28.988+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:16:28.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:16:29.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:16:29.026+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:16:29.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:16:29.049+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:16:29.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:16:29.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T16:16:59.358+0000] {processor.py:157} INFO - Started process (PID=52512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:16:59.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:16:59.363+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:16:59.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:16:59.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:16:59.402+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:16:59.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:16:59.416+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:16:59.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:16:59.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T16:17:29.667+0000] {processor.py:157} INFO - Started process (PID=52522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:17:29.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:17:29.672+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:17:29.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:17:29.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:17:29.719+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:17:29.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:17:29.737+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:17:29.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:17:29.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T16:18:00.027+0000] {processor.py:157} INFO - Started process (PID=52532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:18:00.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:18:00.037+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:18:00.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:18:00.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:18:00.089+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:18:00.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:18:00.103+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:18:00.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:18:00.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T16:18:30.409+0000] {processor.py:157} INFO - Started process (PID=52542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:18:30.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:18:30.415+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:18:30.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:18:30.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:18:30.466+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:18:30.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:18:30.479+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:18:30.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:18:30.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T16:19:00.765+0000] {processor.py:157} INFO - Started process (PID=52552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:19:00.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:19:00.780+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:19:00.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:19:00.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:19:00.834+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:19:00.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:19:00.849+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:19:00.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:19:00.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T16:19:31.082+0000] {processor.py:157} INFO - Started process (PID=52562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:19:31.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:19:31.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:19:31.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:19:31.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:19:31.124+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:19:31.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:19:31.140+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:19:31.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:19:31.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T16:20:01.391+0000] {processor.py:157} INFO - Started process (PID=52572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:20:01.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:20:01.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:20:01.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:20:01.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:20:01.434+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:20:01.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:20:01.447+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:20:01.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:20:01.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T16:20:31.726+0000] {processor.py:157} INFO - Started process (PID=52582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:20:31.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:20:31.730+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:20:31.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:20:31.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:20:31.763+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:20:31.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:20:31.775+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:20:31.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:20:31.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T16:21:02.117+0000] {processor.py:157} INFO - Started process (PID=52591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:21:02.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:21:02.121+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:21:02.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:21:02.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:21:02.163+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:21:02.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:21:02.177+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:21:02.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:21:02.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T16:21:32.418+0000] {processor.py:157} INFO - Started process (PID=52602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:21:32.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:21:32.423+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:21:32.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:21:32.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:21:32.455+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:21:32.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:21:32.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:21:32.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:21:32.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T16:22:02.738+0000] {processor.py:157} INFO - Started process (PID=52612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:22:02.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:22:02.744+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:22:02.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:22:02.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:22:02.793+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:22:02.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:22:02.807+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:22:02.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:22:02.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T16:22:33.090+0000] {processor.py:157} INFO - Started process (PID=52622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:22:33.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:22:33.096+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:22:33.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:22:33.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:22:33.149+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:22:33.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:22:33.163+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:22:33.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:22:33.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T16:23:03.381+0000] {processor.py:157} INFO - Started process (PID=52632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:23:03.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:23:03.384+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:23:03.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:23:03.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:23:03.408+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:23:03.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:23:03.421+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:23:03.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:23:03.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T16:23:33.701+0000] {processor.py:157} INFO - Started process (PID=52642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:23:33.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:23:33.713+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:23:33.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:23:33.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:23:33.775+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:23:33.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:23:33.789+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:23:33.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:23:33.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T16:24:04.032+0000] {processor.py:157} INFO - Started process (PID=52652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:24:04.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:24:04.038+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:24:04.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:24:04.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:24:04.073+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:24:04.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:24:04.084+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:24:04.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:24:04.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T16:24:34.510+0000] {processor.py:157} INFO - Started process (PID=52662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:24:34.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:24:34.522+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:24:34.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:24:34.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:24:34.596+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:24:34.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:24:34.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:24:34.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:24:34.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-11T16:25:05.022+0000] {processor.py:157} INFO - Started process (PID=52672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:25:05.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:25:05.029+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:25:05.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:25:05.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:25:05.071+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:25:05.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:25:05.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:25:05.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:25:05.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T16:25:35.451+0000] {processor.py:157} INFO - Started process (PID=52682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:25:35.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:25:35.457+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:25:35.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:25:35.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:25:35.516+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:25:35.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:25:35.530+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:25:35.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:25:35.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T16:26:05.767+0000] {processor.py:157} INFO - Started process (PID=52692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:26:05.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:26:05.771+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:26:05.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:26:05.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:26:05.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:26:05.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:26:05.825+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:26:05.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:26:05.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T16:26:36.073+0000] {processor.py:157} INFO - Started process (PID=52701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:26:36.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:26:36.078+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:26:36.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:26:36.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:26:36.117+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:26:36.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:26:36.150+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:26:36.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:26:36.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T16:27:06.494+0000] {processor.py:157} INFO - Started process (PID=52712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:27:06.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:27:06.501+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:27:06.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:27:06.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:27:06.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:27:06.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:27:06.564+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:27:06.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:27:06.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T16:27:36.816+0000] {processor.py:157} INFO - Started process (PID=52722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:27:36.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:27:36.821+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:27:36.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:27:36.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:27:36.881+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:27:36.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:27:36.895+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:27:36.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:27:36.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T16:28:07.167+0000] {processor.py:157} INFO - Started process (PID=52731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:28:07.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:28:07.177+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:28:07.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:28:07.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:28:07.226+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:28:07.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:28:07.242+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:28:07.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:28:07.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T16:28:37.498+0000] {processor.py:157} INFO - Started process (PID=52741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:28:37.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:28:37.504+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:28:37.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:28:37.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:28:37.557+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:28:37.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:28:37.571+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:28:37.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:28:37.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T16:29:07.865+0000] {processor.py:157} INFO - Started process (PID=52752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:29:07.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:29:07.867+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:29:07.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:29:07.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:29:07.891+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:29:07.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:29:07.902+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:29:07.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:29:07.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-11T16:29:38.199+0000] {processor.py:157} INFO - Started process (PID=52762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:29:38.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:29:38.205+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:29:38.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:29:38.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:29:38.263+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:29:38.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:29:38.278+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:29:38.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:29:38.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T16:30:08.543+0000] {processor.py:157} INFO - Started process (PID=52771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:30:08.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:30:08.549+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:30:08.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:30:08.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:30:08.612+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:30:08.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:30:08.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:30:08.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:30:08.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T16:30:38.889+0000] {processor.py:157} INFO - Started process (PID=52782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:30:38.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:30:38.894+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:30:38.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:30:38.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:30:38.932+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:30:38.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:30:38.944+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:30:38.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:30:38.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T16:31:09.187+0000] {processor.py:157} INFO - Started process (PID=52792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:31:09.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:31:09.192+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:31:09.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:31:09.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:31:09.262+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:31:09.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:31:09.275+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:31:09.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:31:09.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T16:31:39.518+0000] {processor.py:157} INFO - Started process (PID=52801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:31:39.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:31:39.541+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:31:39.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:31:39.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:31:39.582+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:31:39.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:31:39.594+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:31:39.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:31:39.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T16:32:09.910+0000] {processor.py:157} INFO - Started process (PID=52812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:32:09.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:32:09.912+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:32:09.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:32:09.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:32:09.938+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:32:09.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:32:09.949+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:32:09.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:32:09.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T16:32:40.277+0000] {processor.py:157} INFO - Started process (PID=52821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:32:40.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:32:40.282+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:32:40.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:32:40.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:32:40.334+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:32:40.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:32:40.347+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:32:40.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:32:40.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T16:33:10.582+0000] {processor.py:157} INFO - Started process (PID=52832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:33:10.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:33:10.585+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:33:10.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:33:10.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:33:10.614+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:33:10.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:33:10.626+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:33:10.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:33:10.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T16:33:40.970+0000] {processor.py:157} INFO - Started process (PID=52842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:33:40.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:33:40.974+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:33:40.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:33:40.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:33:41.022+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:33:41.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:33:41.047+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:33:41.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:33:41.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T16:34:11.335+0000] {processor.py:157} INFO - Started process (PID=52852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:34:11.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:34:11.338+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:34:11.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:34:11.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:34:11.400+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:34:11.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:34:11.413+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:34:11.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:34:11.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T16:34:41.684+0000] {processor.py:157} INFO - Started process (PID=52862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:34:41.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:34:41.688+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:34:41.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:34:41.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:34:41.748+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:34:41.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:34:41.762+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:34:41.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:34:41.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T16:35:12.013+0000] {processor.py:157} INFO - Started process (PID=52872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:35:12.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:35:12.026+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:35:12.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:35:12.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:35:12.081+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:35:12.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:35:12.094+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:35:12.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:35:12.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T16:35:42.483+0000] {processor.py:157} INFO - Started process (PID=52882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:35:42.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:35:42.487+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:35:42.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:35:42.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:35:42.528+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:35:42.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:35:42.541+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:35:42.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:35:42.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T16:36:12.836+0000] {processor.py:157} INFO - Started process (PID=52892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:36:12.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:36:12.842+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:36:12.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:36:12.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:36:12.890+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:36:12.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:36:12.905+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:36:12.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:36:12.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T16:36:43.200+0000] {processor.py:157} INFO - Started process (PID=52902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:36:43.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:36:43.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:36:43.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:36:43.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:36:43.245+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:36:43.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:36:43.258+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:36:43.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:36:43.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T16:37:13.599+0000] {processor.py:157} INFO - Started process (PID=52912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:37:13.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:37:13.604+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:37:13.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:37:13.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:37:13.649+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:37:13.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:37:13.669+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:37:13.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:37:13.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T16:37:43.946+0000] {processor.py:157} INFO - Started process (PID=52922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:37:43.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:37:43.951+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:37:43.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:37:43.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:37:43.994+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:37:43.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:37:44.007+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:37:44.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:37:44.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T16:38:14.297+0000] {processor.py:157} INFO - Started process (PID=52932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:38:14.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:38:14.302+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:38:14.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:38:14.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:38:14.345+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:38:14.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:38:14.373+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:38:14.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:38:14.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T16:38:44.634+0000] {processor.py:157} INFO - Started process (PID=52942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:38:44.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:38:44.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:38:44.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:38:44.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:38:44.679+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:38:44.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:38:44.710+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:38:44.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:38:44.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T16:39:14.971+0000] {processor.py:157} INFO - Started process (PID=52952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:39:14.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:39:14.975+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:39:14.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:39:14.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:39:15.012+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:39:15.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:39:15.026+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:39:15.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:39:15.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T16:39:45.333+0000] {processor.py:157} INFO - Started process (PID=52962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:39:45.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:39:45.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:39:45.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:39:45.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:39:45.386+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:39:45.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:39:45.400+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:39:45.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:39:45.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T16:40:15.752+0000] {processor.py:157} INFO - Started process (PID=52972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:40:15.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:40:15.755+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:40:15.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:40:15.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:40:15.781+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:40:15.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:40:15.791+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:40:15.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:40:15.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T16:40:46.098+0000] {processor.py:157} INFO - Started process (PID=52981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:40:46.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:40:46.103+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:40:46.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:40:46.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:40:46.145+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:40:46.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:40:46.172+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:40:46.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:40:46.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T16:41:16.380+0000] {processor.py:157} INFO - Started process (PID=52992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:41:16.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:41:16.385+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:41:16.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:41:16.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:41:16.454+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:41:16.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:41:16.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:41:16.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:41:16.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T16:41:46.660+0000] {processor.py:157} INFO - Started process (PID=53002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:41:46.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:41:46.665+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:41:46.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:41:46.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:41:46.703+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:41:46.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:41:46.716+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:41:46.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:41:46.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T16:42:17.018+0000] {processor.py:157} INFO - Started process (PID=53012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:42:17.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:42:17.022+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:42:17.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:42:17.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:42:17.054+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:42:17.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:42:17.066+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:42:17.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:42:17.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T16:42:47.383+0000] {processor.py:157} INFO - Started process (PID=53022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:42:47.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:42:47.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:42:47.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:42:47.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:42:47.432+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:42:47.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:42:47.444+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:42:47.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:42:47.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T16:43:17.851+0000] {processor.py:157} INFO - Started process (PID=53032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:43:17.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:43:17.855+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:43:17.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:43:17.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:43:17.917+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:43:17.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:43:17.931+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:43:17.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:43:17.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T16:43:48.309+0000] {processor.py:157} INFO - Started process (PID=53042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:43:48.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:43:48.312+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:43:48.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:43:48.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:43:48.377+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:43:48.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:43:48.391+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:43:48.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:43:48.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T16:44:18.665+0000] {processor.py:157} INFO - Started process (PID=53052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:44:18.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:44:18.671+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:44:18.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:44:18.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:44:18.709+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:44:18.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:44:18.723+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:44:18.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:44:18.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T16:44:49.123+0000] {processor.py:157} INFO - Started process (PID=53062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:44:49.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:44:49.129+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:44:49.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:44:49.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:44:49.169+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:44:49.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:44:49.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:44:49.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:44:49.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T16:45:19.393+0000] {processor.py:157} INFO - Started process (PID=53072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:45:19.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:45:19.397+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:45:19.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:45:19.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:45:19.439+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:45:19.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:45:19.453+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:45:19.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:45:19.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T16:45:49.783+0000] {processor.py:157} INFO - Started process (PID=53082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:45:49.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:45:49.789+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:45:49.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:45:49.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:45:49.828+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:45:49.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:45:49.840+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:45:49.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:45:49.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T16:46:20.205+0000] {processor.py:157} INFO - Started process (PID=53091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:46:20.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:46:20.211+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:46:20.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:46:20.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:46:20.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:46:20.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:46:20.290+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:46:20.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:46:20.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T16:46:50.660+0000] {processor.py:157} INFO - Started process (PID=53102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:46:50.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:46:50.671+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:46:50.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:46:50.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:46:50.715+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:46:50.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:46:50.728+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:46:50.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:46:50.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T16:47:21.105+0000] {processor.py:157} INFO - Started process (PID=53112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:47:21.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:47:21.111+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:47:21.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:47:21.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:47:21.167+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:47:21.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:47:21.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:47:21.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:47:21.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T16:47:51.571+0000] {processor.py:157} INFO - Started process (PID=53122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:47:51.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:47:51.587+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:47:51.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:47:51.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:47:51.645+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:47:51.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:47:51.658+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:47:51.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:47:51.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T16:48:21.919+0000] {processor.py:157} INFO - Started process (PID=53132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:48:21.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:48:21.927+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:48:21.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:48:21.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:48:21.971+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:48:21.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:48:21.984+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:48:21.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:48:21.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T16:48:52.293+0000] {processor.py:157} INFO - Started process (PID=53142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:48:52.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:48:52.297+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:48:52.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:48:52.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:48:52.334+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:48:52.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:48:52.348+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:48:52.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:48:52.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T16:49:22.618+0000] {processor.py:157} INFO - Started process (PID=53152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:49:22.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:49:22.620+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:49:22.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:49:22.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:49:22.663+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:49:22.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:49:22.681+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:49:22.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:49:22.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T16:49:52.954+0000] {processor.py:157} INFO - Started process (PID=53162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:49:52.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:49:52.963+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:49:52.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:49:52.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:49:53.028+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:49:53.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:49:53.042+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:49:53.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:49:53.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T16:50:23.399+0000] {processor.py:157} INFO - Started process (PID=53171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:50:23.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:50:23.405+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:50:23.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:50:23.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:50:23.487+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:50:23.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:50:23.505+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:50:23.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:50:23.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-11T16:50:54.348+0000] {processor.py:157} INFO - Started process (PID=53182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:50:54.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:50:54.357+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:50:54.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:50:54.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:50:54.523+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:50:54.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:50:54.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:50:54.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:50:54.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-09-11T16:52:35.336+0000] {processor.py:157} INFO - Started process (PID=53194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:52:35.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:52:35.342+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:52:35.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:52:35.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:52:35.397+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:52:35.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:52:35.412+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:52:35.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:52:35.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T16:53:19.337+0000] {processor.py:157} INFO - Started process (PID=53203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:53:19.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:53:19.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:53:19.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:53:19.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:53:19.404+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:53:19.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:53:19.419+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:53:19.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:53:19.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T16:53:49.662+0000] {processor.py:157} INFO - Started process (PID=53214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:53:49.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:53:49.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:53:49.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:53:49.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:53:49.706+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:53:49.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:53:49.721+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:53:49.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:53:49.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T16:54:38.227+0000] {processor.py:157} INFO - Started process (PID=53226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:54:38.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:54:38.228+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:54:38.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:54:38.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:54:38.258+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:54:38.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:54:38.272+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:54:38.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:54:38.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T16:55:25.619+0000] {processor.py:157} INFO - Started process (PID=53236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:55:25.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:55:25.627+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:55:25.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:55:25.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:55:25.696+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:55:25.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:55:25.726+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:55:25.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:55:25.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-11T16:55:56.045+0000] {processor.py:157} INFO - Started process (PID=53246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:55:56.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:55:56.047+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:55:56.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:55:56.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:55:56.074+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:55:56.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:55:56.084+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:55:56.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:55:56.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T16:56:30.109+0000] {processor.py:157} INFO - Started process (PID=53256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:56:30.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:56:30.116+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:56:30.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:56:30.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:56:30.168+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:56:30.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:56:30.181+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:56:30.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:56:30.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T16:57:29.766+0000] {processor.py:157} INFO - Started process (PID=53267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:57:29.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:57:29.773+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:57:29.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:57:29.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:57:29.802+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:57:29.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:57:29.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:57:29.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:57:29.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T16:58:00.161+0000] {processor.py:157} INFO - Started process (PID=53278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:58:00.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:58:00.164+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:58:00.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:58:00.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:58:00.202+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:58:00.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:58:00.216+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:58:00.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:58:00.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T16:58:44.609+0000] {processor.py:157} INFO - Started process (PID=53288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:58:44.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:58:44.615+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:58:44.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:58:44.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:58:44.687+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:58:44.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:58:44.702+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:58:44.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:58:44.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T16:59:14.979+0000] {processor.py:157} INFO - Started process (PID=53298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:59:14.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T16:59:14.984+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:59:14.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:59:15.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T16:59:15.029+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:59:15.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T16:59:15.042+0000] {logging_mixin.py:151} INFO - [2024-09-11T16:59:15.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T16:59:15.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T17:00:09.282+0000] {processor.py:157} INFO - Started process (PID=53308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:00:09.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:00:09.284+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:00:09.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:00:09.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:00:09.304+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:00:09.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:00:09.312+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:00:09.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:00:09.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-09-11T17:01:05.429+0000] {processor.py:157} INFO - Started process (PID=53320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:01:05.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:01:05.434+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:01:05.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:01:05.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:01:05.496+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:01:05.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:01:05.509+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:01:05.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:01:05.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T17:01:35.853+0000] {processor.py:157} INFO - Started process (PID=53330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:01:35.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:01:35.859+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:01:35.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:01:35.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:01:35.888+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:01:35.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:01:35.898+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:01:35.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:01:35.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T17:02:14.093+0000] {processor.py:157} INFO - Started process (PID=53340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:02:14.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:02:14.098+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:02:14.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:02:14.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:02:14.161+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:02:14.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:02:14.176+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:02:14.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:02:14.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T17:02:55.171+0000] {processor.py:157} INFO - Started process (PID=53350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:02:55.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:02:55.178+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:02:55.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:02:55.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:02:55.242+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:02:55.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:02:55.258+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:02:55.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:02:55.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T17:03:25.529+0000] {processor.py:157} INFO - Started process (PID=53360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:03:25.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:03:25.535+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:03:25.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:03:25.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:03:25.571+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:03:25.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:03:25.584+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:03:25.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:03:25.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T17:04:04.375+0000] {processor.py:157} INFO - Started process (PID=53370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:04:04.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:04:04.381+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:04:04.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:04:04.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:04:04.422+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:04:04.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:04:04.436+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:04:04.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:04:04.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T17:05:00.460+0000] {processor.py:157} INFO - Started process (PID=53380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:05:00.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:05:00.471+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:05:00.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:05:00.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:05:00.518+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:05:00.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:05:00.533+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:05:00.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:05:00.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T17:05:30.851+0000] {processor.py:157} INFO - Started process (PID=53392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:05:30.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:05:30.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:05:30.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:05:30.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:05:30.886+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:05:30.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:05:30.898+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:05:30.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:05:30.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T17:06:12.641+0000] {processor.py:157} INFO - Started process (PID=53401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:06:12.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:06:12.647+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:06:12.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:06:12.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:06:12.693+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:06:12.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:06:12.707+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:06:12.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:06:12.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T17:11:23.027+0000] {processor.py:157} INFO - Started process (PID=53414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:11:23.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:11:23.048+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:11:23.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:11:23.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:11:23.096+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:11:23.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:11:23.108+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:11:23.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:11:23.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-11T17:11:53.375+0000] {processor.py:157} INFO - Started process (PID=53424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:11:53.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:11:53.379+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:11:53.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:11:53.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:11:53.406+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:11:53.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:11:53.417+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:11:53.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:11:53.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T17:12:30.464+0000] {processor.py:157} INFO - Started process (PID=53433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:12:30.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:12:30.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:12:30.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:12:30.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:12:30.511+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:12:30.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:12:30.525+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:12:30.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:12:30.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T17:13:00.761+0000] {processor.py:157} INFO - Started process (PID=53444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:13:00.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:13:00.763+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:13:00.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:13:00.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:13:00.786+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:13:00.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:13:00.795+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:13:00.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:13:00.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-09-11T17:16:51.887+0000] {processor.py:157} INFO - Started process (PID=53456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:16:51.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:16:51.892+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:16:51.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:16:51.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:16:51.953+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:16:51.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:16:51.978+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:16:51.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:16:51.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T17:20:34.472+0000] {processor.py:157} INFO - Started process (PID=53466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:20:34.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:20:34.477+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:20:34.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:20:34.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:20:34.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:20:34.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:20:34.559+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:20:34.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:20:34.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-11T17:21:04.959+0000] {processor.py:157} INFO - Started process (PID=53476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:21:04.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:21:04.966+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:21:04.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:21:04.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:21:04.994+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:21:04.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:21:05.006+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:21:05.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:21:05.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T17:22:55.949+0000] {processor.py:157} INFO - Started process (PID=53486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:22:55.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:22:55.954+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:22:55.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:22:55.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:22:56.006+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:22:56.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:22:56.020+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:22:56.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:22:56.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T17:23:53.284+0000] {processor.py:157} INFO - Started process (PID=53497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:23:53.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:23:53.290+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:23:53.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:23:53.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:23:53.392+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:23:53.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:23:53.433+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:23:53.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:23:53.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-11T17:24:23.798+0000] {processor.py:157} INFO - Started process (PID=53508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:24:23.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:24:23.816+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:24:23.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:24:23.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:24:23.887+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:24:23.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:24:23.915+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:24:23.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:24:23.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T17:27:17.343+0000] {processor.py:157} INFO - Started process (PID=53516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:27:17.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:27:17.348+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:27:17.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:27:17.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:27:17.397+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:27:17.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:27:17.412+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:27:17.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:27:17.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T17:27:47.747+0000] {processor.py:157} INFO - Started process (PID=53528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:27:47.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:27:47.752+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:27:47.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:27:47.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:27:47.795+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:27:47.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:27:47.808+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:27:47.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:27:47.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T17:28:18.059+0000] {processor.py:157} INFO - Started process (PID=53538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:28:18.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:28:18.064+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:28:18.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:28:18.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:28:18.107+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:28:18.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:28:18.122+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:28:18.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:28:18.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T17:28:48.391+0000] {processor.py:157} INFO - Started process (PID=53548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:28:48.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:28:48.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:28:48.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:28:48.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:28:48.421+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:28:48.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:28:48.434+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:28:48.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:28:48.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T17:29:18.806+0000] {processor.py:157} INFO - Started process (PID=53558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:29:18.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:29:18.810+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:29:18.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:29:18.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:29:18.864+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:29:18.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:29:18.877+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:29:18.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:29:18.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T17:29:49.132+0000] {processor.py:157} INFO - Started process (PID=53568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:29:49.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:29:49.135+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:29:49.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:29:49.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:29:49.164+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:29:49.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:29:49.175+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:29:49.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:29:49.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T17:30:39.356+0000] {processor.py:157} INFO - Started process (PID=53578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:30:39.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:30:39.367+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:30:39.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:30:39.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:30:39.433+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:30:39.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:30:39.459+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:30:39.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:30:39.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-11T17:31:09.738+0000] {processor.py:157} INFO - Started process (PID=53589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:31:09.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:31:09.750+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:31:09.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:31:09.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:31:09.794+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:31:09.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:31:09.817+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:31:09.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:31:09.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T17:31:40.046+0000] {processor.py:157} INFO - Started process (PID=53599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:31:40.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:31:40.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:31:40.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:31:40.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:31:40.090+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:31:40.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:31:40.106+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:31:40.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:31:40.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T17:32:10.427+0000] {processor.py:157} INFO - Started process (PID=53609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:32:10.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:32:10.431+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:32:10.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:32:10.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:32:10.467+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:32:10.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:32:10.485+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:32:10.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:32:10.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T17:32:40.700+0000] {processor.py:157} INFO - Started process (PID=53619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:32:40.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:32:40.704+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:32:40.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:32:40.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:32:40.731+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:32:40.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:32:40.740+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:32:40.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:32:40.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T17:33:11.085+0000] {processor.py:157} INFO - Started process (PID=53629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:33:11.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:33:11.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:33:11.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:33:11.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:33:11.123+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:33:11.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:33:11.134+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:33:11.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:33:11.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T17:42:37.503+0000] {processor.py:157} INFO - Started process (PID=53640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:42:37.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:42:37.520+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:42:37.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:42:37.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:42:37.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:42:37.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:42:37.595+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:42:37.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:42:37.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T17:43:07.780+0000] {processor.py:157} INFO - Started process (PID=53650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:43:07.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:43:07.788+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:43:07.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:43:07.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:43:07.832+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:43:07.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:43:07.850+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:43:07.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:43:07.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T17:43:38.154+0000] {processor.py:157} INFO - Started process (PID=53660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:43:38.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:43:38.157+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:43:38.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:43:38.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:43:38.191+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:43:38.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:43:38.203+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:43:38.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:43:38.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T17:44:08.508+0000] {processor.py:157} INFO - Started process (PID=53670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:44:08.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:44:08.510+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:44:08.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:44:08.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:44:08.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:44:08.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:44:08.549+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:44:08.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:44:08.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T17:44:38.878+0000] {processor.py:157} INFO - Started process (PID=53679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:44:38.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:44:38.882+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:44:38.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:44:38.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:44:38.918+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:44:38.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:44:38.932+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:44:38.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:44:38.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T17:45:09.195+0000] {processor.py:157} INFO - Started process (PID=53690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:45:09.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:45:09.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:45:09.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:45:09.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:45:09.233+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:45:09.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:45:09.243+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:45:09.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:45:09.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T17:45:39.508+0000] {processor.py:157} INFO - Started process (PID=53700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:45:39.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:45:39.511+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:45:39.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:45:39.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:45:39.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:45:39.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:45:39.549+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:45:39.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:45:39.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T17:46:09.838+0000] {processor.py:157} INFO - Started process (PID=53710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:46:09.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:46:09.860+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:46:09.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:46:09.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:46:09.900+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:46:09.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:46:09.914+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:46:09.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:46:09.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T17:46:40.151+0000] {processor.py:157} INFO - Started process (PID=53720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:46:40.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:46:40.156+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:46:40.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:46:40.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:46:40.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:46:40.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:46:40.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:46:40.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:46:40.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T17:47:10.532+0000] {processor.py:157} INFO - Started process (PID=53730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:47:10.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:47:10.534+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:47:10.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:47:10.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:47:10.563+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:47:10.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:47:10.572+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:47:10.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:47:10.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T17:47:40.942+0000] {processor.py:157} INFO - Started process (PID=53740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:47:40.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:47:40.947+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:47:40.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:47:40.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:47:40.983+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:47:40.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:47:40.995+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:47:40.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:47:41.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T17:48:11.279+0000] {processor.py:157} INFO - Started process (PID=53750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:48:11.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:48:11.283+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:48:11.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:48:11.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:48:11.316+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:48:11.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:48:11.326+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:48:11.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:48:11.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T17:48:41.702+0000] {processor.py:157} INFO - Started process (PID=53759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:48:41.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:48:41.723+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:48:41.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:48:41.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:48:41.777+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:48:41.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:48:41.791+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:48:41.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:48:41.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T17:49:12.014+0000] {processor.py:157} INFO - Started process (PID=53770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:49:12.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:49:12.017+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:49:12.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:49:12.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:49:12.042+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:49:12.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:49:12.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:49:12.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:49:12.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T17:49:42.371+0000] {processor.py:157} INFO - Started process (PID=53780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:49:42.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:49:42.384+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:49:42.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:49:42.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:49:42.427+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:49:42.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:49:42.445+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:49:42.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:49:42.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T17:50:12.678+0000] {processor.py:157} INFO - Started process (PID=53790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:50:12.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:50:12.682+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:50:12.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:50:12.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:50:12.709+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:50:12.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:50:12.721+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:50:12.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:50:12.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T17:50:43.081+0000] {processor.py:157} INFO - Started process (PID=53800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:50:43.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:50:43.087+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:50:43.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:50:43.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:50:43.128+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:50:43.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:50:43.141+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:50:43.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:50:43.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T17:51:13.365+0000] {processor.py:157} INFO - Started process (PID=53810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:51:13.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:51:13.370+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:51:13.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:51:13.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:51:13.406+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:51:13.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:51:13.419+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:51:13.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:51:13.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T17:51:43.794+0000] {processor.py:157} INFO - Started process (PID=53820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:51:43.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:51:43.798+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:51:43.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:51:43.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:51:43.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:51:43.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:51:43.862+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:51:43.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:51:43.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T17:52:14.103+0000] {processor.py:157} INFO - Started process (PID=53830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:52:14.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:52:14.107+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:52:14.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:52:14.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:52:14.133+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:52:14.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:52:14.144+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:52:14.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:52:14.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T17:52:44.490+0000] {processor.py:157} INFO - Started process (PID=53840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:52:44.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:52:44.495+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:52:44.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:52:44.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:52:44.549+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:52:44.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:52:44.574+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:52:44.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:52:44.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T17:53:14.807+0000] {processor.py:157} INFO - Started process (PID=53850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:53:14.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:53:14.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:53:14.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:53:14.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:53:14.852+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:53:14.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:53:14.864+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:53:14.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:53:14.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T17:53:45.081+0000] {processor.py:157} INFO - Started process (PID=53860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:53:45.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:53:45.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:53:45.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:53:45.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:53:45.123+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:53:45.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:53:45.137+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:53:45.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:53:45.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T17:54:15.394+0000] {processor.py:157} INFO - Started process (PID=53869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:54:15.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:54:15.400+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:54:15.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:54:15.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:54:15.447+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:54:15.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:54:15.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:54:15.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:54:15.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T17:54:45.711+0000] {processor.py:157} INFO - Started process (PID=53880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:54:45.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:54:45.715+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:54:45.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:54:45.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:54:45.749+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:54:45.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:54:45.758+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:54:45.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:54:45.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T17:55:16.050+0000] {processor.py:157} INFO - Started process (PID=53890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:55:16.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:55:16.060+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:55:16.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:55:16.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:55:16.109+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:55:16.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:55:16.122+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:55:16.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:55:16.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T17:55:46.445+0000] {processor.py:157} INFO - Started process (PID=53900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:55:46.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:55:46.450+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:55:46.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:55:46.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:55:46.490+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:55:46.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:55:46.502+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:55:46.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:55:46.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T17:56:16.753+0000] {processor.py:157} INFO - Started process (PID=53910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:56:16.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:56:16.757+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:56:16.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:56:16.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:56:16.803+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:56:16.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:56:16.821+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:56:16.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:56:16.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T17:56:47.120+0000] {processor.py:157} INFO - Started process (PID=53920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:56:47.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:56:47.123+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:56:47.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:56:47.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:56:47.151+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:56:47.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:56:47.161+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:56:47.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:56:47.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T17:57:17.486+0000] {processor.py:157} INFO - Started process (PID=53930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:57:17.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:57:17.505+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:57:17.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:57:17.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:57:17.544+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:57:17.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:57:17.556+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:57:17.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:57:17.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T17:57:47.810+0000] {processor.py:157} INFO - Started process (PID=53940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:57:47.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:57:47.818+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:57:47.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:57:47.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:57:47.857+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:57:47.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:57:47.871+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:57:47.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:57:47.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T17:58:18.151+0000] {processor.py:157} INFO - Started process (PID=53950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:58:18.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:58:18.154+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:58:18.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:58:18.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:58:18.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:58:18.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:58:18.194+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:58:18.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:58:18.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T17:58:48.486+0000] {processor.py:157} INFO - Started process (PID=53959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:58:48.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:58:48.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:58:48.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:58:48.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:58:48.551+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:58:48.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:58:48.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:58:48.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:58:48.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T17:59:18.831+0000] {processor.py:157} INFO - Started process (PID=53970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:59:18.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:59:18.837+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:59:18.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:59:18.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:59:18.884+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:59:18.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:59:18.914+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:59:18.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:59:18.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T17:59:49.119+0000] {processor.py:157} INFO - Started process (PID=53980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:59:49.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T17:59:49.124+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:59:49.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:59:49.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T17:59:49.166+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:59:49.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T17:59:49.182+0000] {logging_mixin.py:151} INFO - [2024-09-11T17:59:49.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T17:59:49.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T18:00:19.451+0000] {processor.py:157} INFO - Started process (PID=53989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:00:19.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:00:19.459+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:00:19.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:00:19.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:00:19.518+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:00:19.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:00:19.532+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:00:19.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:00:19.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T18:00:49.835+0000] {processor.py:157} INFO - Started process (PID=54000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:00:49.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:00:49.841+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:00:49.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:00:49.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:00:49.881+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:00:49.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:00:49.893+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:00:49.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:00:49.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T18:01:20.180+0000] {processor.py:157} INFO - Started process (PID=54009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:01:20.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:01:20.187+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:01:20.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:01:20.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:01:20.248+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:01:20.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:01:20.267+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:01:20.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:01:20.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T18:01:50.681+0000] {processor.py:157} INFO - Started process (PID=54020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:01:50.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:01:50.689+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:01:50.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:01:50.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:01:50.763+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:01:50.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:01:50.781+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:01:50.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:01:50.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T18:02:21.002+0000] {processor.py:157} INFO - Started process (PID=54030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:02:21.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:02:21.015+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:02:21.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:02:21.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:02:21.071+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:02:21.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:02:21.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:02:21.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:02:21.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T18:02:51.385+0000] {processor.py:157} INFO - Started process (PID=54040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:02:51.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:02:51.391+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:02:51.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:02:51.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:02:51.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:02:51.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:02:51.476+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:02:51.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:02:51.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T18:03:21.726+0000] {processor.py:157} INFO - Started process (PID=54050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:03:21.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:03:21.733+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:03:21.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:03:21.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:03:21.793+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:03:21.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:03:21.806+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:03:21.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:03:21.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T18:03:52.094+0000] {processor.py:157} INFO - Started process (PID=54059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:03:52.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:03:52.100+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:03:52.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:03:52.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:03:52.156+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:03:52.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:03:52.179+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:03:52.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:03:52.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-11T18:04:22.423+0000] {processor.py:157} INFO - Started process (PID=54070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:04:22.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:04:22.428+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:04:22.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:04:22.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:04:22.485+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:04:22.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:04:22.498+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:04:22.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:04:22.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T18:04:52.784+0000] {processor.py:157} INFO - Started process (PID=54080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:04:52.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:04:52.790+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:04:52.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:04:52.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:04:52.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:04:52.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:04:52.870+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:04:52.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:04:52.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T18:05:23.094+0000] {processor.py:157} INFO - Started process (PID=54089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:05:23.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:05:23.101+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:05:23.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:05:23.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:05:23.158+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:05:23.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:05:23.172+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:05:23.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:05:23.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T18:05:53.430+0000] {processor.py:157} INFO - Started process (PID=54098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:05:53.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:05:53.437+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:05:53.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:05:53.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:05:53.499+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:05:53.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:05:53.514+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:05:53.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:05:53.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T18:06:23.710+0000] {processor.py:157} INFO - Started process (PID=54109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:06:23.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:06:23.719+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:06:23.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:06:23.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:06:23.768+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:06:23.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:06:23.782+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:06:23.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:06:23.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T18:06:54.079+0000] {processor.py:157} INFO - Started process (PID=54120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:06:54.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:06:54.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:06:54.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:06:54.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:06:54.151+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:06:54.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:06:54.167+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:06:54.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:06:54.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T18:07:24.428+0000] {processor.py:157} INFO - Started process (PID=54130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:07:24.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:07:24.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:07:24.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:07:24.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:07:24.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:07:24.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:07:24.568+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:07:24.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:07:24.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-11T18:07:54.767+0000] {processor.py:157} INFO - Started process (PID=54139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:07:54.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:07:54.774+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:07:54.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:07:54.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:07:54.840+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:07:54.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:07:54.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:07:54.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:07:54.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T18:08:25.090+0000] {processor.py:157} INFO - Started process (PID=54150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:08:25.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:08:25.095+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:08:25.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:08:25.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:08:25.125+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:08:25.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:08:25.136+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:08:25.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:08:25.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T18:08:55.487+0000] {processor.py:157} INFO - Started process (PID=54160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:08:55.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:08:55.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:08:55.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:08:55.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:08:55.553+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:08:55.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:08:55.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:08:55.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:08:55.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T18:09:25.852+0000] {processor.py:157} INFO - Started process (PID=54170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:09:25.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:09:25.859+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:09:25.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:09:25.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:09:25.961+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:09:25.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:09:25.982+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:09:25.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:09:25.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T18:09:56.162+0000] {processor.py:157} INFO - Started process (PID=54179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:09:56.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:09:56.177+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:09:56.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:09:56.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:09:56.237+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:09:56.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:09:56.259+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:09:56.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:09:56.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-11T18:10:26.566+0000] {processor.py:157} INFO - Started process (PID=54190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:10:26.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:10:26.572+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:10:26.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:10:26.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:10:26.618+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:10:26.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:10:26.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:10:26.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:10:26.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T18:10:56.901+0000] {processor.py:157} INFO - Started process (PID=54200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:10:56.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:10:56.908+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:10:56.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:10:56.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:10:56.973+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:10:56.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:10:56.998+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:10:56.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:10:57.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-11T18:11:27.170+0000] {processor.py:157} INFO - Started process (PID=54210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:11:27.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:11:27.176+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:11:27.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:11:27.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:11:27.238+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:11:27.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:11:27.252+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:11:27.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:11:27.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T18:11:57.693+0000] {processor.py:157} INFO - Started process (PID=54220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:11:57.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:11:57.703+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:11:57.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:11:57.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:11:57.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:11:57.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:11:57.860+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:11:57.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:11:57.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-11T18:12:28.086+0000] {processor.py:157} INFO - Started process (PID=54230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:12:28.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:12:28.108+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:12:28.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:12:28.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:12:28.170+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:12:28.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:12:28.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:12:28.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:12:28.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T18:12:58.565+0000] {processor.py:157} INFO - Started process (PID=54240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:12:58.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:12:58.579+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:12:58.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:12:58.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:12:58.643+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:12:58.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:12:58.678+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:12:58.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:12:58.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-11T18:13:28.951+0000] {processor.py:157} INFO - Started process (PID=54249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:13:28.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:13:28.962+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:13:28.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:13:28.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:13:29.035+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:13:29.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:13:29.056+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:13:29.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:13:29.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-11T18:13:59.238+0000] {processor.py:157} INFO - Started process (PID=54260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:13:59.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:13:59.248+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:13:59.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:13:59.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:13:59.337+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:13:59.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:13:59.361+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:13:59.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:13:59.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-11T18:14:29.643+0000] {processor.py:157} INFO - Started process (PID=54269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:14:29.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:14:29.657+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:14:29.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:14:29.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:14:29.729+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:14:29.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:14:29.745+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:14:29.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:14:29.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T18:15:00.048+0000] {processor.py:157} INFO - Started process (PID=54280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:15:00.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:15:00.056+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:15:00.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:15:00.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:15:00.169+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:15:00.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:15:00.187+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:15:00.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:15:00.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-11T18:15:30.353+0000] {processor.py:157} INFO - Started process (PID=54290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:15:30.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:15:30.361+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:15:30.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:15:30.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:15:30.415+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:15:30.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:15:30.429+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:15:30.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:15:30.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T18:16:00.793+0000] {processor.py:157} INFO - Started process (PID=54300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:16:00.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:16:00.800+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:16:00.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:16:00.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:16:00.862+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:16:00.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:16:00.879+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:16:00.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:16:00.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T18:16:31.111+0000] {processor.py:157} INFO - Started process (PID=54310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:16:31.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:16:31.118+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:16:31.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:16:31.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:16:31.163+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:16:31.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:16:31.176+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:16:31.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:16:31.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T18:17:01.410+0000] {processor.py:157} INFO - Started process (PID=54320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:17:01.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:17:01.419+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:17:01.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:17:01.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:17:01.458+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:17:01.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:17:01.473+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:17:01.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:17:01.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T18:17:31.810+0000] {processor.py:157} INFO - Started process (PID=54330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:17:31.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:17:31.815+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:17:31.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:17:31.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:17:31.841+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:17:31.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:17:31.855+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:17:31.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:17:31.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T18:18:02.181+0000] {processor.py:157} INFO - Started process (PID=54340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:18:02.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:18:02.184+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:18:02.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:18:02.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:18:02.220+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:18:02.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:18:02.233+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:18:02.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:18:02.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T18:18:32.452+0000] {processor.py:157} INFO - Started process (PID=54350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:18:32.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:18:32.455+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:18:32.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:18:32.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:18:32.482+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:18:32.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:18:32.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:18:32.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:18:32.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T18:19:02.838+0000] {processor.py:157} INFO - Started process (PID=54360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:19:02.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:19:02.844+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:19:02.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:19:02.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:19:02.889+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:19:02.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:19:02.903+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:19:02.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:19:02.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T18:19:33.140+0000] {processor.py:157} INFO - Started process (PID=54370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:19:33.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:19:33.144+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:19:33.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:19:33.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:19:33.170+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:19:33.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:19:33.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:19:33.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:19:33.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T18:20:03.536+0000] {processor.py:157} INFO - Started process (PID=54380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:20:03.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:20:03.542+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:20:03.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:20:03.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:20:03.605+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:20:03.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:20:03.618+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:20:03.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:20:03.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T18:20:33.879+0000] {processor.py:157} INFO - Started process (PID=54390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:20:33.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:20:33.886+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:20:33.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:20:33.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:20:33.946+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:20:33.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:20:33.960+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:20:33.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:20:33.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T18:21:04.150+0000] {processor.py:157} INFO - Started process (PID=54400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:21:04.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:21:04.160+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:21:04.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:21:04.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:21:04.181+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:21:04.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:21:04.191+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:21:04.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:21:04.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T18:21:34.537+0000] {processor.py:157} INFO - Started process (PID=54409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:21:34.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:21:34.543+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:21:34.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:21:34.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:21:34.590+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:21:34.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:21:34.602+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:21:34.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:21:34.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T18:22:05.214+0000] {processor.py:157} INFO - Started process (PID=54422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:22:05.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:22:05.217+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:22:05.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:22:05.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:22:05.242+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:22:05.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:22:05.252+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:22:05.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:22:05.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T18:22:40.593+0000] {processor.py:157} INFO - Started process (PID=54432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:22:40.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:22:40.594+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:22:40.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:22:40.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:22:40.614+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:22:40.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:22:40.622+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:22:40.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:22:40.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.038 seconds
[2024-09-11T18:23:10.945+0000] {processor.py:157} INFO - Started process (PID=54443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:23:10.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:23:10.951+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:23:10.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:23:10.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:23:11.001+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:23:11.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:23:11.012+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:23:11.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:23:11.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T18:35:47.193+0000] {processor.py:157} INFO - Started process (PID=54454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:35:47.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:35:47.199+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:35:47.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:35:47.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:35:47.254+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:35:47.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:35:47.276+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:35:47.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:35:47.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T18:36:17.635+0000] {processor.py:157} INFO - Started process (PID=54464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:36:17.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:36:17.643+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:36:17.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:36:17.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:36:17.683+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:36:17.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:36:17.695+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:36:17.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:36:17.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T18:36:52.019+0000] {processor.py:157} INFO - Started process (PID=54474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:36:52.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:36:52.024+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:36:52.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:36:52.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:36:52.063+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:36:52.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:36:52.081+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:36:52.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:36:52.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T18:37:55.447+0000] {processor.py:157} INFO - Started process (PID=54483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:37:55.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:37:55.453+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:37:55.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:37:55.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:37:55.500+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:37:55.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:37:55.516+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:37:55.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:37:55.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T18:38:25.772+0000] {processor.py:157} INFO - Started process (PID=54496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:38:25.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:38:25.775+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:38:25.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:38:25.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:38:25.800+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:38:25.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:38:25.810+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:38:25.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:38:25.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T18:39:22.464+0000] {processor.py:157} INFO - Started process (PID=54506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:39:22.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:39:22.478+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:39:22.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:39:22.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:39:22.533+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:39:22.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:39:22.546+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:39:22.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:39:22.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-11T18:40:23.480+0000] {processor.py:157} INFO - Started process (PID=54518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:40:23.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:40:23.502+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:40:23.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:40:23.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:40:23.548+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:40:23.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:40:23.562+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:40:23.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:40:23.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T18:40:53.836+0000] {processor.py:157} INFO - Started process (PID=54528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:40:53.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:40:53.839+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:40:53.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:40:53.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:40:53.878+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:40:53.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:40:53.893+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:40:53.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:40:53.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T18:46:23.003+0000] {processor.py:157} INFO - Started process (PID=54538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:46:23.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:46:23.009+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:46:23.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:46:23.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:46:23.106+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:46:23.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:46:23.142+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:46:23.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:46:23.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-11T18:46:53.551+0000] {processor.py:157} INFO - Started process (PID=54548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:46:53.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:46:53.581+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:46:53.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:46:53.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:46:53.679+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:46:53.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:46:53.716+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:46:53.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:46:53.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-11T18:47:24.185+0000] {processor.py:157} INFO - Started process (PID=54558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:47:24.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:47:24.190+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:47:24.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:47:24.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:47:24.278+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:47:24.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:47:24.300+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:47:24.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:47:24.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-11T18:47:54.465+0000] {processor.py:157} INFO - Started process (PID=54568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:47:54.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:47:54.481+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:47:54.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:47:54.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:47:54.568+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:47:54.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:47:54.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:47:54.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:47:54.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-11T18:48:25.159+0000] {processor.py:157} INFO - Started process (PID=54578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:48:25.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:48:25.168+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:48:25.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:48:25.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:48:25.245+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:48:25.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:48:25.273+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:48:25.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:48:25.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-11T18:48:55.451+0000] {processor.py:157} INFO - Started process (PID=54588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:48:55.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:48:55.461+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:48:55.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:48:55.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:48:55.546+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:48:55.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:48:55.572+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:48:55.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:48:55.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-11T18:49:25.792+0000] {processor.py:157} INFO - Started process (PID=54598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:49:25.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:49:25.794+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:49:25.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:49:25.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:49:25.826+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:49:25.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:49:25.840+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:49:25.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:49:25.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T18:49:56.110+0000] {processor.py:157} INFO - Started process (PID=54608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:49:56.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:49:56.117+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:49:56.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:49:56.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:49:56.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:49:56.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:49:56.215+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:49:56.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:49:56.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T18:50:26.545+0000] {processor.py:157} INFO - Started process (PID=54618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:50:26.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:50:26.547+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:50:26.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:50:26.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:50:26.586+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:50:26.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:50:26.600+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:50:26.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:50:26.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T18:50:56.851+0000] {processor.py:157} INFO - Started process (PID=54628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:50:56.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:50:56.857+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:50:56.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:50:56.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:50:56.942+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:50:56.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:50:56.964+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:50:56.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:50:56.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-11T18:51:27.157+0000] {processor.py:157} INFO - Started process (PID=54638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:51:27.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:51:27.164+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:51:27.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:51:27.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:51:27.198+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:51:27.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:51:27.212+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:51:27.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:51:27.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T18:51:57.546+0000] {processor.py:157} INFO - Started process (PID=54648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:51:57.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:51:57.555+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:51:57.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:51:57.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:51:57.621+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:51:57.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:51:57.642+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:51:57.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:51:57.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T18:52:27.867+0000] {processor.py:157} INFO - Started process (PID=54657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:52:27.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:52:27.885+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:52:27.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:52:27.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:52:27.957+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:52:27.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:52:27.978+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:52:27.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:52:27.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-11T18:52:58.314+0000] {processor.py:157} INFO - Started process (PID=54668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:52:58.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:52:58.323+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:52:58.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:52:58.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:52:58.411+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:52:58.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:52:58.430+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:52:58.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:52:58.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-11T18:53:28.615+0000] {processor.py:157} INFO - Started process (PID=54678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:53:28.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:53:28.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:53:28.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:53:28.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:53:28.706+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:53:28.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:53:28.730+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:53:28.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:53:28.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-11T18:53:58.979+0000] {processor.py:157} INFO - Started process (PID=54688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:53:58.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:53:58.998+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:53:58.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:53:59.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:53:59.064+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:53:59.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:53:59.093+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:53:59.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:53:59.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-11T18:54:29.295+0000] {processor.py:157} INFO - Started process (PID=54696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:54:29.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:54:29.306+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:54:29.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:54:29.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:54:29.399+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:54:29.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:54:29.419+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:54:29.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:54:29.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-11T18:54:59.742+0000] {processor.py:157} INFO - Started process (PID=54708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:54:59.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:54:59.748+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:54:59.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:54:59.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:54:59.788+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:54:59.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:54:59.803+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:54:59.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:54:59.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T18:55:30.088+0000] {processor.py:157} INFO - Started process (PID=54718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:55:30.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:55:30.099+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:55:30.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:55:30.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:55:30.155+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:55:30.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:55:30.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:55:30.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:55:30.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-11T18:56:00.414+0000] {processor.py:157} INFO - Started process (PID=54727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:56:00.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:56:00.438+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:56:00.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:56:00.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:56:00.521+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:56:00.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:56:00.544+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:56:00.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:56:00.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-11T18:56:30.886+0000] {processor.py:157} INFO - Started process (PID=54738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:56:30.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:56:30.892+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:56:30.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:56:30.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:56:30.979+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:56:30.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:56:30.999+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:56:30.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:56:31.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T18:57:01.178+0000] {processor.py:157} INFO - Started process (PID=54748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:57:01.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:57:01.187+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:57:01.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:57:01.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:57:01.248+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:57:01.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:57:01.272+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:57:01.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:57:01.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T18:57:31.567+0000] {processor.py:157} INFO - Started process (PID=54758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:57:31.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:57:31.586+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:57:31.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:57:31.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:57:31.647+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:57:31.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:57:31.678+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:57:31.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:57:31.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-11T18:58:01.888+0000] {processor.py:157} INFO - Started process (PID=54768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:58:01.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:58:01.905+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:58:01.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:58:01.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:58:02.042+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:58:02.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:58:02.073+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:58:02.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:58:02.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-09-11T18:58:32.218+0000] {processor.py:157} INFO - Started process (PID=54778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:58:32.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:58:32.225+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:58:32.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:58:32.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:58:32.294+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:58:32.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:58:32.316+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:58:32.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:58:32.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-11T18:59:02.614+0000] {processor.py:157} INFO - Started process (PID=54788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:59:02.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:59:02.622+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:59:02.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:59:02.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:59:02.678+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:59:02.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:59:02.696+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:59:02.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:59:02.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T18:59:33.005+0000] {processor.py:157} INFO - Started process (PID=54798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:59:33.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T18:59:33.010+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:59:33.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:59:33.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T18:59:33.045+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:59:33.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T18:59:33.059+0000] {logging_mixin.py:151} INFO - [2024-09-11T18:59:33.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T18:59:33.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T19:00:03.386+0000] {processor.py:157} INFO - Started process (PID=54808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:00:03.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:00:03.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:00:03.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:00:03.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:00:03.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:00:03.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:00:03.482+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:00:03.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:00:03.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-11T19:00:33.699+0000] {processor.py:157} INFO - Started process (PID=54818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:00:33.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:00:33.705+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:00:33.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:00:33.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:00:33.779+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:00:33.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:00:33.797+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:00:33.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:00:33.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T19:01:04.006+0000] {processor.py:157} INFO - Started process (PID=54828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:01:04.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:01:04.032+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:01:04.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:01:04.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:01:04.106+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:01:04.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:01:04.131+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:01:04.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:01:04.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-11T19:01:34.390+0000] {processor.py:157} INFO - Started process (PID=54838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:01:34.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:01:34.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:01:34.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:01:34.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:01:34.434+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:01:34.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:01:34.448+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:01:34.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:01:34.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T19:02:04.742+0000] {processor.py:157} INFO - Started process (PID=54848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:02:04.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:02:04.746+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:02:04.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:02:04.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:02:04.803+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:02:04.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:02:04.827+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:02:04.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:02:04.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T19:02:35.060+0000] {processor.py:157} INFO - Started process (PID=54858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:02:35.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:02:35.071+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:02:35.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:02:35.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:02:35.122+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:02:35.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:02:35.138+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:02:35.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:02:35.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T19:03:05.328+0000] {processor.py:157} INFO - Started process (PID=54868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:03:05.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:03:05.333+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:03:05.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:03:05.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:03:05.371+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:03:05.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:03:05.385+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:03:05.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:03:05.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T19:03:35.711+0000] {processor.py:157} INFO - Started process (PID=54876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:03:35.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:03:35.719+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:03:35.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:03:35.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:03:35.801+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:03:35.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:03:35.819+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:03:35.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:03:35.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T19:04:05.999+0000] {processor.py:157} INFO - Started process (PID=54888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:04:06.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:04:06.003+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:04:06.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:04:06.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:04:06.038+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:04:06.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:04:06.053+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:04:06.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:04:06.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T19:04:36.428+0000] {processor.py:157} INFO - Started process (PID=54898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:04:36.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:04:36.440+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:04:36.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:04:36.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:04:36.510+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:04:36.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:04:36.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:04:36.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:04:36.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-11T19:05:06.694+0000] {processor.py:157} INFO - Started process (PID=54908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:05:06.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:05:06.702+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:05:06.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:05:06.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:05:06.781+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:05:06.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:05:06.801+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:05:06.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:05:06.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T19:05:37.061+0000] {processor.py:157} INFO - Started process (PID=54916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:05:37.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:05:37.079+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:05:37.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:05:37.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:05:37.182+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:05:37.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:05:37.203+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:05:37.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:05:37.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-11T19:06:07.643+0000] {processor.py:157} INFO - Started process (PID=54927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:06:07.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:06:07.651+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:06:07.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:06:07.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:06:07.712+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:06:07.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:06:07.731+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:06:07.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:06:07.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-11T19:06:37.955+0000] {processor.py:157} INFO - Started process (PID=54938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:06:37.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:06:37.963+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:06:37.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:06:37.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:06:38.010+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:06:38.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:06:38.045+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:06:38.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:06:38.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-11T19:07:08.250+0000] {processor.py:157} INFO - Started process (PID=54948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:07:08.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:07:08.258+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:07:08.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:07:08.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:07:08.318+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:07:08.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:07:08.334+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:07:08.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:07:08.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T19:07:38.609+0000] {processor.py:157} INFO - Started process (PID=54958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:07:38.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:07:38.611+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:07:38.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:07:38.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:07:38.634+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:07:38.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:07:38.645+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:07:38.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:07:38.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-11T19:08:08.896+0000] {processor.py:157} INFO - Started process (PID=54968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:08:08.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:08:08.900+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:08:08.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:08:08.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:08:08.946+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:08:08.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:08:08.965+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:08:08.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:08:08.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T19:08:39.188+0000] {processor.py:157} INFO - Started process (PID=54978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:08:39.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:08:39.192+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:08:39.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:08:39.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:08:39.225+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:08:39.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:08:39.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:08:39.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:08:39.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T19:09:09.564+0000] {processor.py:157} INFO - Started process (PID=54988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:09:09.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:09:09.569+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:09:09.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:09:09.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:09:09.610+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:09:09.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:09:09.624+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:09:09.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:09:09.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T19:09:39.816+0000] {processor.py:157} INFO - Started process (PID=54998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:09:39.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:09:39.819+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:09:39.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:09:39.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:09:39.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:09:39.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:09:39.868+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:09:39.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:09:39.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T19:10:10.110+0000] {processor.py:157} INFO - Started process (PID=55008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:10:10.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:10:10.115+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:10:10.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:10:10.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:10:10.159+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:10:10.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:10:10.178+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:10:10.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:10:10.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T19:10:40.380+0000] {processor.py:157} INFO - Started process (PID=55018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:10:40.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:10:40.384+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:10:40.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:10:40.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:10:40.428+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:10:40.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:10:40.443+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:10:40.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:10:40.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T19:11:10.682+0000] {processor.py:157} INFO - Started process (PID=55028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:11:10.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:11:10.685+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:11:10.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:11:10.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:11:10.713+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:11:10.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:11:10.724+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:11:10.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:11:10.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T19:11:40.986+0000] {processor.py:157} INFO - Started process (PID=55037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:11:40.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:11:40.992+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:11:40.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:11:41.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:11:41.040+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:11:41.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:11:41.059+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:11:41.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:11:41.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T19:12:11.401+0000] {processor.py:157} INFO - Started process (PID=55048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:12:11.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:12:11.403+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:12:11.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:12:11.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:12:11.435+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:12:11.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:12:11.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:12:11.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:12:11.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T19:12:41.799+0000] {processor.py:157} INFO - Started process (PID=55057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:12:41.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:12:41.804+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:12:41.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:12:41.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:12:41.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:12:41.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:12:41.860+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:12:41.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:12:41.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T19:13:12.178+0000] {processor.py:157} INFO - Started process (PID=55068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:13:12.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:13:12.181+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:13:12.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:13:12.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:13:12.213+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:13:12.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:13:12.224+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:13:12.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:13:12.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-11T19:13:42.560+0000] {processor.py:157} INFO - Started process (PID=55078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:13:42.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:13:42.568+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:13:42.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:13:42.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:13:42.657+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:13:42.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:13:42.675+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:13:42.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:13:42.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-11T19:14:12.832+0000] {processor.py:157} INFO - Started process (PID=55088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:14:12.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:14:12.836+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:14:12.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:14:12.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:14:12.868+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:14:12.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:14:12.880+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:14:12.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:14:12.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T19:14:43.132+0000] {processor.py:157} INFO - Started process (PID=55098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:14:43.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:14:43.137+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:14:43.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:14:43.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:14:43.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:14:43.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:14:43.207+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:14:43.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:14:43.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T19:15:13.390+0000] {processor.py:157} INFO - Started process (PID=55108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:15:13.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:15:13.397+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:15:13.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:15:13.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:15:13.427+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:15:13.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:15:13.440+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:15:13.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:15:13.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T19:15:43.755+0000] {processor.py:157} INFO - Started process (PID=55118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:15:43.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:15:43.771+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:15:43.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:15:43.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:15:43.819+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:15:43.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:15:43.853+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:15:43.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:15:43.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-11T19:16:13.987+0000] {processor.py:157} INFO - Started process (PID=55128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:16:13.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:16:13.990+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:16:13.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:16:14.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:16:14.026+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:16:14.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:16:14.045+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:16:14.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:16:14.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T19:16:44.357+0000] {processor.py:157} INFO - Started process (PID=55138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:16:44.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:16:44.362+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:16:44.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:16:44.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:16:44.427+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:16:44.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:16:44.442+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:16:44.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:16:44.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T19:17:14.754+0000] {processor.py:157} INFO - Started process (PID=55148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:17:14.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:17:14.758+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:17:14.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:17:14.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:17:14.788+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:17:14.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:17:14.801+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:17:14.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:17:14.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T19:17:45.098+0000] {processor.py:157} INFO - Started process (PID=55158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:17:45.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:17:45.103+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:17:45.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:17:45.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:17:45.187+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:17:45.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:17:45.208+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:17:45.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:17:45.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T19:18:15.386+0000] {processor.py:157} INFO - Started process (PID=55168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:18:15.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:18:15.392+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:18:15.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:18:15.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:18:15.493+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:18:15.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:18:15.519+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:18:15.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:18:15.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-11T19:18:45.839+0000] {processor.py:157} INFO - Started process (PID=55178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:18:45.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:18:45.851+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:18:45.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:18:45.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:18:45.913+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:18:45.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:18:45.934+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:18:45.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:18:45.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-11T19:19:16.188+0000] {processor.py:157} INFO - Started process (PID=55188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:19:16.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:19:16.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:19:16.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:19:16.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:19:16.287+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:19:16.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:19:16.307+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:19:16.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:19:16.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-11T19:19:46.536+0000] {processor.py:157} INFO - Started process (PID=55198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:19:46.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:19:46.550+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:19:46.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:19:46.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:19:46.627+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:19:46.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:19:46.655+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:19:46.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:19:46.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-11T19:20:16.859+0000] {processor.py:157} INFO - Started process (PID=55208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:20:16.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:20:16.864+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:20:16.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:20:16.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:20:16.907+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:20:16.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:20:16.922+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:20:16.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:20:16.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T19:20:47.221+0000] {processor.py:157} INFO - Started process (PID=55218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:20:47.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:20:47.229+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:20:47.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:20:47.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:20:47.309+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:20:47.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:20:47.326+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:20:47.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:20:47.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-11T19:21:17.526+0000] {processor.py:157} INFO - Started process (PID=55228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:21:17.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:21:17.533+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:21:17.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:21:17.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:21:17.609+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:21:17.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:21:17.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:21:17.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:21:17.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-11T19:21:47.839+0000] {processor.py:157} INFO - Started process (PID=55238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:21:47.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:21:47.843+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:21:47.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:21:47.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:21:47.878+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:21:47.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:21:47.893+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:21:47.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:21:47.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T19:22:18.174+0000] {processor.py:157} INFO - Started process (PID=55248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:22:18.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:22:18.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:22:18.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:22:18.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:22:18.232+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:22:18.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:22:18.248+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:22:18.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:22:18.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T19:22:48.425+0000] {processor.py:157} INFO - Started process (PID=55258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:22:48.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:22:48.429+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:22:48.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:22:48.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:22:48.456+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:22:48.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:22:48.468+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:22:48.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:22:48.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T19:23:18.715+0000] {processor.py:157} INFO - Started process (PID=55268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:23:18.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:23:18.720+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:23:18.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:23:18.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:23:18.791+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:23:18.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:23:18.805+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:23:18.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:23:18.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T19:23:48.987+0000] {processor.py:157} INFO - Started process (PID=55278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:23:48.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:23:48.995+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:23:48.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:23:49.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:23:49.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:23:49.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:23:49.066+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:23:49.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:23:49.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T19:24:19.348+0000] {processor.py:157} INFO - Started process (PID=55288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:24:19.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:24:19.352+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:24:19.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:24:19.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:24:19.406+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:24:19.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:24:19.423+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:24:19.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:24:19.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T19:24:49.627+0000] {processor.py:157} INFO - Started process (PID=55298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:24:49.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:24:49.630+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:24:49.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:24:49.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:24:49.663+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:24:49.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:24:49.675+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:24:49.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:24:49.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T19:25:19.928+0000] {processor.py:157} INFO - Started process (PID=55308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:25:19.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:25:19.935+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:25:19.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:25:19.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:25:19.994+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:25:19.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:25:20.009+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:25:20.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:25:20.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T19:25:50.249+0000] {processor.py:157} INFO - Started process (PID=55318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:25:50.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:25:50.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:25:50.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:25:50.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:25:50.299+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:25:50.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:25:50.315+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:25:50.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:25:50.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T19:26:20.581+0000] {processor.py:157} INFO - Started process (PID=55328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:26:20.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:26:20.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:26:20.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:26:20.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:26:20.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:26:20.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:26:20.683+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:26:20.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:26:20.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T19:26:50.927+0000] {processor.py:157} INFO - Started process (PID=55338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:26:50.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:26:50.943+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:26:50.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:26:50.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:26:50.995+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:26:50.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:26:51.022+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:26:51.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:26:51.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-11T19:27:21.262+0000] {processor.py:157} INFO - Started process (PID=55348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:27:21.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:27:21.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:27:21.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:27:21.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:27:21.316+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:27:21.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:27:21.329+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:27:21.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:27:21.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T19:27:51.539+0000] {processor.py:157} INFO - Started process (PID=55358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:27:51.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:27:51.543+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:27:51.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:27:51.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:27:51.583+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:27:51.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:27:51.597+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:27:51.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:27:51.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T19:28:21.806+0000] {processor.py:157} INFO - Started process (PID=55368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:28:21.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:28:21.810+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:28:21.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:28:21.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:28:21.871+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:28:21.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:28:21.889+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:28:21.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:28:21.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-11T19:28:52.134+0000] {processor.py:157} INFO - Started process (PID=55378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:28:52.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:28:52.140+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:28:52.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:28:52.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:28:52.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:28:52.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:28:52.219+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:28:52.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:28:52.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T19:29:22.437+0000] {processor.py:157} INFO - Started process (PID=55388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:29:22.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:29:22.441+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:29:22.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:29:22.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:29:22.479+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:29:22.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:29:22.494+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:29:22.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:29:22.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T19:29:52.695+0000] {processor.py:157} INFO - Started process (PID=55398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:29:52.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:29:52.698+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:29:52.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:29:52.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:29:52.743+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:29:52.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:29:52.763+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:29:52.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:29:52.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T19:30:23.003+0000] {processor.py:157} INFO - Started process (PID=55408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:30:23.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:30:23.012+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:30:23.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:30:23.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:30:23.049+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:30:23.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:30:23.061+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:30:23.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:30:23.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T19:30:53.351+0000] {processor.py:157} INFO - Started process (PID=55418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:30:53.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:30:53.355+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:30:53.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:30:53.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:30:53.392+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:30:53.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:30:53.409+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:30:53.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:30:53.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-11T19:31:23.609+0000] {processor.py:157} INFO - Started process (PID=55427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:31:23.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:31:23.614+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:31:23.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:31:23.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:31:23.657+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:31:23.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:31:23.672+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:31:23.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:31:23.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T19:31:53.993+0000] {processor.py:157} INFO - Started process (PID=55438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:31:53.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:31:53.995+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:31:53.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:31:54.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:31:54.025+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:31:54.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:31:54.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:31:54.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:31:54.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T19:32:24.371+0000] {processor.py:157} INFO - Started process (PID=55448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:32:24.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:32:24.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:32:24.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:32:24.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:32:24.425+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:32:24.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:32:24.438+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:32:24.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:32:24.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T19:32:54.636+0000] {processor.py:157} INFO - Started process (PID=55458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:32:54.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:32:54.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:32:54.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:32:54.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:32:54.668+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:32:54.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:32:54.680+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:32:54.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:32:54.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T19:33:25.048+0000] {processor.py:157} INFO - Started process (PID=55468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:33:25.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:33:25.063+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:33:25.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:33:25.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:33:25.133+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:33:25.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:33:25.155+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:33:25.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:33:25.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-11T19:33:55.347+0000] {processor.py:157} INFO - Started process (PID=55478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:33:55.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:33:55.353+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:33:55.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:33:55.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:33:55.442+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:33:55.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:33:55.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:33:55.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:33:55.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-11T19:34:25.710+0000] {processor.py:157} INFO - Started process (PID=55488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:34:25.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:34:25.718+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:34:25.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:34:25.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:34:25.792+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:34:25.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:34:25.815+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:34:25.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:34:25.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T19:34:56.035+0000] {processor.py:157} INFO - Started process (PID=55498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:34:56.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:34:56.040+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:34:56.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:34:56.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:34:56.092+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:34:56.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:34:56.114+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:34:56.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:34:56.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T19:35:26.489+0000] {processor.py:157} INFO - Started process (PID=55507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:35:26.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:35:26.524+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:35:26.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:35:26.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:35:26.583+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:35:26.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:35:26.622+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:35:26.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:35:26.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-11T19:35:56.854+0000] {processor.py:157} INFO - Started process (PID=55518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:35:56.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:35:56.859+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:35:56.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:35:56.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:35:56.903+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:35:56.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:35:56.919+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:35:56.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:35:56.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T19:36:27.298+0000] {processor.py:157} INFO - Started process (PID=55528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:36:27.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:36:27.304+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:36:27.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:36:27.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:36:27.344+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:36:27.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:36:27.359+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:36:27.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:36:27.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T19:36:57.636+0000] {processor.py:157} INFO - Started process (PID=55538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:36:57.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:36:57.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:36:57.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:36:57.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:36:57.665+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:36:57.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:36:57.676+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:36:57.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:36:57.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T19:37:28.028+0000] {processor.py:157} INFO - Started process (PID=55548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:37:28.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:37:28.036+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:37:28.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:37:28.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:37:28.114+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:37:28.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:37:28.143+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:37:28.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:37:28.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-11T19:37:58.320+0000] {processor.py:157} INFO - Started process (PID=55558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:37:58.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:37:58.327+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:37:58.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:37:58.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:37:58.371+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:37:58.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:37:58.389+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:37:58.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:37:58.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T19:38:28.583+0000] {processor.py:157} INFO - Started process (PID=55568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:38:28.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:38:28.586+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:38:28.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:38:28.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:38:28.612+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:38:28.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:38:28.621+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:38:28.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:38:28.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-11T19:38:58.910+0000] {processor.py:157} INFO - Started process (PID=55577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:38:58.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:38:58.919+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:38:58.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:38:58.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:38:58.973+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:38:58.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:38:58.993+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:38:58.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:38:59.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-11T19:39:29.189+0000] {processor.py:157} INFO - Started process (PID=55587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:39:29.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:39:29.199+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:39:29.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:39:29.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:39:29.260+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:39:29.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:39:29.293+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:39:29.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:39:29.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-11T19:39:59.559+0000] {processor.py:157} INFO - Started process (PID=55598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:39:59.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:39:59.565+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:39:59.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:39:59.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:39:59.654+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:39:59.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:39:59.698+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:39:59.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:39:59.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-11T19:40:29.876+0000] {processor.py:157} INFO - Started process (PID=55608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:40:29.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:40:29.885+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:40:29.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:40:29.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:40:29.959+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:40:29.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:40:29.979+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:40:29.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:40:29.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T19:41:00.214+0000] {processor.py:157} INFO - Started process (PID=55618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:41:00.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:41:00.218+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:41:00.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:41:00.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:41:00.248+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:41:00.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:41:00.259+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:41:00.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:41:00.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T19:41:30.659+0000] {processor.py:157} INFO - Started process (PID=55627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:41:30.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:41:30.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:41:30.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:41:30.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:41:30.726+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:41:30.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:41:30.769+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:41:30.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:41:30.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T19:42:01.097+0000] {processor.py:157} INFO - Started process (PID=55638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:42:01.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:42:01.102+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:42:01.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:42:01.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:42:01.136+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:42:01.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:42:01.147+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:42:01.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:42:01.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T19:42:31.461+0000] {processor.py:157} INFO - Started process (PID=55648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:42:31.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:42:31.465+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:42:31.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:42:31.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:42:31.540+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:42:31.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:42:31.559+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:42:31.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:42:31.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-11T19:43:01.792+0000] {processor.py:157} INFO - Started process (PID=55658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:43:01.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:43:01.796+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:43:01.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:43:01.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:43:01.829+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:43:01.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:43:01.841+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:43:01.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:43:01.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T19:43:32.047+0000] {processor.py:157} INFO - Started process (PID=55668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:43:32.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:43:32.051+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:43:32.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:43:32.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:43:32.128+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:43:32.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:43:32.149+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:43:32.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:43:32.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T19:44:02.336+0000] {processor.py:157} INFO - Started process (PID=55677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:44:02.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:44:02.343+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:44:02.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:44:02.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:44:02.387+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:44:02.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:44:02.398+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:44:02.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:44:02.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T19:44:32.675+0000] {processor.py:157} INFO - Started process (PID=55688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:44:32.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:44:32.679+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:44:32.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:44:32.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:44:32.709+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:44:32.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:44:32.724+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:44:32.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:44:32.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T19:45:03.064+0000] {processor.py:157} INFO - Started process (PID=55698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:45:03.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:45:03.087+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:45:03.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:45:03.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:45:03.139+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:45:03.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:45:03.151+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:45:03.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:45:03.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T19:45:33.351+0000] {processor.py:157} INFO - Started process (PID=55708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:45:33.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:45:33.355+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:45:33.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:45:33.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:45:33.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:45:33.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:45:33.406+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:45:33.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:45:33.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T19:46:03.652+0000] {processor.py:157} INFO - Started process (PID=55718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:46:03.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:46:03.656+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:46:03.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:46:03.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:46:03.705+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:46:03.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:46:03.723+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:46:03.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:46:03.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T19:46:33.944+0000] {processor.py:157} INFO - Started process (PID=55728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:46:33.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:46:33.948+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:46:33.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:46:33.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:46:33.980+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:46:33.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:46:33.991+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:46:33.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:46:34.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T19:47:04.283+0000] {processor.py:157} INFO - Started process (PID=55738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:47:04.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:47:04.288+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:47:04.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:47:04.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:47:04.330+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:47:04.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:47:04.348+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:47:04.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:47:04.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T19:47:34.618+0000] {processor.py:157} INFO - Started process (PID=55748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:47:34.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:47:34.624+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:47:34.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:47:34.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:47:34.698+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:47:34.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:47:34.716+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:47:34.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:47:34.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-11T19:48:04.895+0000] {processor.py:157} INFO - Started process (PID=55758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:48:04.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:48:04.900+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:48:04.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:48:04.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:48:04.935+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:48:04.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:48:04.949+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:48:04.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:48:04.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T19:48:35.196+0000] {processor.py:157} INFO - Started process (PID=55768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:48:35.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:48:35.203+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:48:35.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:48:35.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:48:35.275+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:48:35.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:48:35.289+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:48:35.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:48:35.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T19:49:05.639+0000] {processor.py:157} INFO - Started process (PID=55778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:49:05.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:49:05.644+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:49:05.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:49:05.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:49:05.687+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:49:05.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:49:05.702+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:49:05.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:49:05.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T19:49:35.921+0000] {processor.py:157} INFO - Started process (PID=55788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:49:35.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:49:35.926+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:49:35.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:49:35.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:49:35.965+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:49:35.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:49:35.980+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:49:35.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:49:35.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T19:50:06.263+0000] {processor.py:157} INFO - Started process (PID=55797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:50:06.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:50:06.269+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:50:06.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:50:06.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:50:06.319+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:50:06.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:50:06.333+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:50:06.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:50:06.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T19:50:36.569+0000] {processor.py:157} INFO - Started process (PID=55808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:50:36.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:50:36.575+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:50:36.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:50:36.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:50:36.621+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:50:36.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:50:36.648+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:50:36.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:50:36.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-11T19:51:06.884+0000] {processor.py:157} INFO - Started process (PID=55818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:51:06.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:51:06.889+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:51:06.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:51:06.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:51:06.918+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:51:06.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:51:06.931+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:51:06.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:51:06.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T19:51:37.254+0000] {processor.py:157} INFO - Started process (PID=55827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:51:37.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:51:37.258+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:51:37.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:51:37.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:51:37.291+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:51:37.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:51:37.305+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:51:37.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:51:37.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T19:52:07.525+0000] {processor.py:157} INFO - Started process (PID=55838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:52:07.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:52:07.530+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:52:07.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:52:07.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:52:07.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:52:07.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:52:07.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:52:07.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:52:07.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T19:52:37.830+0000] {processor.py:157} INFO - Started process (PID=55848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:52:37.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:52:37.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:52:37.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:52:37.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:52:37.912+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:52:37.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:52:37.940+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:52:37.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:52:37.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T19:53:08.230+0000] {processor.py:157} INFO - Started process (PID=55858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:53:08.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:53:08.233+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:53:08.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:53:08.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:53:08.265+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:53:08.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:53:08.276+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:53:08.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:53:08.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T19:53:38.585+0000] {processor.py:157} INFO - Started process (PID=55868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:53:38.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:53:38.591+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:53:38.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:53:38.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:53:38.656+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:53:38.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:53:38.692+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:53:38.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:53:38.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-11T19:54:08.870+0000] {processor.py:157} INFO - Started process (PID=55878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:54:08.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:54:08.873+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:54:08.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:54:08.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:54:08.914+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:54:08.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:54:08.928+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:54:08.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:54:08.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T19:54:39.149+0000] {processor.py:157} INFO - Started process (PID=55888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:54:39.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:54:39.152+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:54:39.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:54:39.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:54:39.189+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:54:39.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:54:39.201+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:54:39.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:54:39.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T19:55:09.491+0000] {processor.py:157} INFO - Started process (PID=55898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:55:09.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:55:09.495+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:55:09.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:55:09.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:55:09.535+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:55:09.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:55:09.550+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:55:09.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:55:09.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T19:55:39.781+0000] {processor.py:157} INFO - Started process (PID=55908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:55:39.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:55:39.785+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:55:39.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:55:39.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:55:39.824+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:55:39.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:55:39.837+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:55:39.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:55:39.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T19:56:10.123+0000] {processor.py:157} INFO - Started process (PID=55917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:56:10.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:56:10.128+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:56:10.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:56:10.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:56:10.186+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:56:10.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:56:10.207+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:56:10.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:56:10.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T19:56:40.622+0000] {processor.py:157} INFO - Started process (PID=55928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:56:40.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:56:40.628+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:56:40.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:56:40.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:56:40.703+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:56:40.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:56:40.721+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:56:40.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:56:40.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-11T19:57:11.035+0000] {processor.py:157} INFO - Started process (PID=55938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:57:11.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:57:11.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:57:11.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:57:11.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:57:11.072+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:57:11.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:57:11.086+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:57:11.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:57:11.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T19:57:41.362+0000] {processor.py:157} INFO - Started process (PID=55948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:57:41.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:57:41.367+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:57:41.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:57:41.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:57:41.416+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:57:41.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:57:41.435+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:57:41.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:57:41.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T19:58:11.635+0000] {processor.py:157} INFO - Started process (PID=55958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:58:11.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:58:11.639+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:58:11.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:58:11.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:58:11.675+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:58:11.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:58:11.689+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:58:11.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:58:11.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T19:58:41.930+0000] {processor.py:157} INFO - Started process (PID=55968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:58:41.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:58:41.935+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:58:41.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:58:41.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:58:41.986+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:58:41.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:58:42.005+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:58:42.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:58:42.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T19:59:12.214+0000] {processor.py:157} INFO - Started process (PID=55978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:59:12.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:59:12.222+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:59:12.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:59:12.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:59:12.267+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:59:12.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:59:12.285+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:59:12.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:59:12.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T19:59:42.479+0000] {processor.py:157} INFO - Started process (PID=55988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:59:42.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T19:59:42.484+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:59:42.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:59:42.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T19:59:42.519+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:59:42.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T19:59:42.534+0000] {logging_mixin.py:151} INFO - [2024-09-11T19:59:42.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T19:59:42.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T20:00:12.761+0000] {processor.py:157} INFO - Started process (PID=55998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:00:12.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:00:12.765+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:00:12.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:00:12.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:00:12.815+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:00:12.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:00:12.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:00:12.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:00:12.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T20:00:43.027+0000] {processor.py:157} INFO - Started process (PID=56008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:00:43.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:00:43.037+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:00:43.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:00:43.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:00:43.069+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:00:43.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:00:43.084+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:00:43.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:00:43.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T20:01:13.331+0000] {processor.py:157} INFO - Started process (PID=56018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:01:13.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:01:13.335+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:01:13.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:01:13.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:01:13.375+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:01:13.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:01:13.391+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:01:13.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:01:13.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T20:01:43.600+0000] {processor.py:157} INFO - Started process (PID=56028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:01:43.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:01:43.607+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:01:43.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:01:43.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:01:43.652+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:01:43.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:01:43.671+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:01:43.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:01:43.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T20:02:13.874+0000] {processor.py:157} INFO - Started process (PID=56038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:02:13.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:02:13.877+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:02:13.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:02:13.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:02:13.917+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:02:13.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:02:13.933+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:02:13.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:02:13.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T20:02:44.221+0000] {processor.py:157} INFO - Started process (PID=56048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:02:44.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:02:44.225+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:02:44.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:02:44.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:02:44.264+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:02:44.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:02:44.279+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:02:44.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:02:44.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T20:03:14.513+0000] {processor.py:157} INFO - Started process (PID=56058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:03:14.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:03:14.519+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:03:14.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:03:14.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:03:14.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:03:14.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:03:14.585+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:03:14.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:03:14.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T20:03:44.797+0000] {processor.py:157} INFO - Started process (PID=56068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:03:44.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:03:44.802+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:03:44.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:03:44.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:03:44.848+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:03:44.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:03:44.864+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:03:44.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:03:44.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T20:04:15.106+0000] {processor.py:157} INFO - Started process (PID=56078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:04:15.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:04:15.114+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:04:15.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:04:15.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:04:15.169+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:04:15.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:04:15.188+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:04:15.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:04:15.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T20:04:45.399+0000] {processor.py:157} INFO - Started process (PID=56088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:04:45.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:04:45.404+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:04:45.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:04:45.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:04:45.442+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:04:45.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:04:45.456+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:04:45.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:04:45.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T20:05:15.720+0000] {processor.py:157} INFO - Started process (PID=56098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:05:15.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:05:15.723+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:05:15.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:05:15.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:05:15.788+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:05:15.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:05:15.804+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:05:15.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:05:15.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T20:05:46.005+0000] {processor.py:157} INFO - Started process (PID=56108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:05:46.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:05:46.011+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:05:46.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:05:46.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:05:46.066+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:05:46.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:05:46.087+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:05:46.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:05:46.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-11T20:06:16.339+0000] {processor.py:157} INFO - Started process (PID=56118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:06:16.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:06:16.342+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:06:16.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:06:16.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:06:16.380+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:06:16.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:06:16.397+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:06:16.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:06:16.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T20:06:46.720+0000] {processor.py:157} INFO - Started process (PID=56128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:06:46.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:06:46.724+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:06:46.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:06:46.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:06:46.770+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:06:46.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:06:46.789+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:06:46.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:06:46.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T20:07:16.971+0000] {processor.py:157} INFO - Started process (PID=56138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:07:16.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:07:16.975+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:07:16.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:07:16.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:07:17.009+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:07:17.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:07:17.024+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:07:17.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:07:17.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T20:07:47.295+0000] {processor.py:157} INFO - Started process (PID=56148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:07:47.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:07:47.298+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:07:47.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:07:47.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:07:47.336+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:07:47.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:07:47.350+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:07:47.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:07:47.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T20:08:17.583+0000] {processor.py:157} INFO - Started process (PID=56158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:08:17.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:08:17.588+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:08:17.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:08:17.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:08:17.631+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:08:17.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:08:17.648+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:08:17.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:08:17.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T20:08:47.908+0000] {processor.py:157} INFO - Started process (PID=56168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:08:47.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:08:47.911+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:08:47.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:08:47.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:08:47.947+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:08:47.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:08:47.964+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:08:47.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:08:47.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T20:09:18.265+0000] {processor.py:157} INFO - Started process (PID=56178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:09:18.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:09:18.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:09:18.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:09:18.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:09:18.303+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:09:18.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:09:18.321+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:09:18.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:09:18.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T20:09:48.535+0000] {processor.py:157} INFO - Started process (PID=56188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:09:48.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:09:48.541+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:09:48.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:09:48.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:09:48.603+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:09:48.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:09:48.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:09:48.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:09:48.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-11T20:10:18.807+0000] {processor.py:157} INFO - Started process (PID=56198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:10:18.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:10:18.810+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:10:18.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:10:18.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:10:18.849+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:10:18.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:10:18.866+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:10:18.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:10:18.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T20:10:49.091+0000] {processor.py:157} INFO - Started process (PID=56208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:10:49.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:10:49.097+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:10:49.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:10:49.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:10:49.132+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:10:49.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:10:49.145+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:10:49.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:10:49.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T20:11:19.376+0000] {processor.py:157} INFO - Started process (PID=56218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:11:19.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:11:19.381+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:11:19.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:11:19.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:11:19.415+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:11:19.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:11:19.429+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:11:19.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:11:19.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T20:11:49.762+0000] {processor.py:157} INFO - Started process (PID=56228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:11:49.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:11:49.770+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:11:49.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:11:49.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:11:49.825+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:11:49.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:11:49.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:11:49.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:11:49.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T20:12:20.176+0000] {processor.py:157} INFO - Started process (PID=56238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:12:20.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:12:20.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:12:20.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:12:20.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:12:20.252+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:12:20.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:12:20.287+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:12:20.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:12:20.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-11T20:12:50.498+0000] {processor.py:157} INFO - Started process (PID=56248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:12:50.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:12:50.507+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:12:50.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:12:50.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:12:50.564+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:12:50.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:12:50.584+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:12:50.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:12:50.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-11T20:13:20.815+0000] {processor.py:157} INFO - Started process (PID=56258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:13:20.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:13:20.820+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:13:20.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:13:20.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:13:20.852+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:13:20.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:13:20.867+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:13:20.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:13:20.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T20:13:51.148+0000] {processor.py:157} INFO - Started process (PID=56268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:13:51.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:13:51.152+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:13:51.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:13:51.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:13:51.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:13:51.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:13:51.218+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:13:51.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:13:51.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T20:14:21.431+0000] {processor.py:157} INFO - Started process (PID=56278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:14:21.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:14:21.437+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:14:21.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:14:21.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:14:21.475+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:14:21.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:14:21.488+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:14:21.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:14:21.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T20:14:51.771+0000] {processor.py:157} INFO - Started process (PID=56288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:14:51.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:14:51.775+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:14:51.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:14:51.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:14:51.810+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:14:51.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:14:51.820+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:14:51.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:14:51.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T20:15:22.180+0000] {processor.py:157} INFO - Started process (PID=56297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:15:22.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:15:22.187+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:15:22.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:15:22.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:15:22.276+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:15:22.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:15:22.300+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:15:22.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:15:22.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-11T20:15:52.499+0000] {processor.py:157} INFO - Started process (PID=56308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:15:52.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:15:52.506+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:15:52.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:15:52.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:15:52.592+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:15:52.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:15:52.613+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:15:52.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:15:52.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-11T20:16:22.779+0000] {processor.py:157} INFO - Started process (PID=56318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:16:22.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:16:22.782+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:16:22.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:16:22.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:16:22.820+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:16:22.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:16:22.836+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:16:22.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:16:22.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T20:16:53.162+0000] {processor.py:157} INFO - Started process (PID=56326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:16:53.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:16:53.168+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:16:53.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:16:53.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:16:53.215+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:16:53.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:16:53.231+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:16:53.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:16:53.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T20:17:23.414+0000] {processor.py:157} INFO - Started process (PID=56338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:17:23.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:17:23.418+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:17:23.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:17:23.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:17:23.453+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:17:23.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:17:23.466+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:17:23.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:17:23.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T20:17:53.794+0000] {processor.py:157} INFO - Started process (PID=56348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:17:53.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:17:53.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:17:53.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:17:53.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:17:53.875+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:17:53.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:17:53.903+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:17:53.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:17:53.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-11T20:18:24.113+0000] {processor.py:157} INFO - Started process (PID=56358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:18:24.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:18:24.118+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:18:24.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:18:24.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:18:24.172+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:18:24.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:18:24.189+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:18:24.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:18:24.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T20:18:54.486+0000] {processor.py:157} INFO - Started process (PID=56368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:18:54.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:18:54.488+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:18:54.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:18:54.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:18:54.524+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:18:54.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:18:54.539+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:18:54.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:18:54.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T20:19:24.801+0000] {processor.py:157} INFO - Started process (PID=56378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:19:24.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:19:24.805+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:19:24.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:19:24.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:19:24.850+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:19:24.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:19:24.864+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:19:24.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:19:24.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T20:19:55.055+0000] {processor.py:157} INFO - Started process (PID=56388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:19:55.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:19:55.057+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:19:55.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:19:55.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:19:55.094+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:19:55.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:19:55.112+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:19:55.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:19:55.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T20:20:25.428+0000] {processor.py:157} INFO - Started process (PID=56398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:20:25.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:20:25.437+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:20:25.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:20:25.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:20:25.529+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:20:25.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:20:25.549+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:20:25.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:20:25.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-11T20:20:55.844+0000] {processor.py:157} INFO - Started process (PID=56408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:20:55.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:20:55.853+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:20:55.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:20:55.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:20:55.930+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:20:55.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:20:55.975+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:20:55.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:20:55.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-11T20:21:26.172+0000] {processor.py:157} INFO - Started process (PID=56418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:21:26.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:21:26.182+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:21:26.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:21:26.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:21:26.249+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:21:26.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:21:26.278+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:21:26.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:21:26.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-11T20:21:56.457+0000] {processor.py:157} INFO - Started process (PID=56428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:21:56.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:21:56.466+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:21:56.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:21:56.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:21:56.503+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:21:56.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:21:56.518+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:21:56.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:21:56.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T20:22:26.789+0000] {processor.py:157} INFO - Started process (PID=56438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:22:26.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:22:26.792+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:22:26.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:22:26.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:22:26.829+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:22:26.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:22:26.848+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:22:26.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:22:26.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T20:22:57.155+0000] {processor.py:157} INFO - Started process (PID=56448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:22:57.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:22:57.163+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:22:57.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:22:57.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:22:57.238+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:22:57.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:22:57.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:22:57.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:22:57.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T20:23:27.393+0000] {processor.py:157} INFO - Started process (PID=56458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:23:27.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:23:27.397+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:23:27.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:23:27.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:23:27.435+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:23:27.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:23:27.450+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:23:27.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:23:27.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T20:23:57.729+0000] {processor.py:157} INFO - Started process (PID=56468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:23:57.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:23:57.733+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:23:57.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:23:57.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:23:57.769+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:23:57.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:23:57.785+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:23:57.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:23:57.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T20:24:28.002+0000] {processor.py:157} INFO - Started process (PID=56478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:24:28.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:24:28.008+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:24:28.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:24:28.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:24:28.093+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:24:28.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:24:28.113+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:24:28.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:24:28.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-11T20:24:58.226+0000] {processor.py:157} INFO - Started process (PID=56488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:24:58.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:24:58.228+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:24:58.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:24:58.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:24:58.259+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:24:58.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:24:58.269+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:24:58.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:24:58.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T20:25:28.595+0000] {processor.py:157} INFO - Started process (PID=56498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:25:28.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:25:28.603+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:25:28.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:25:28.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:25:28.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:25:28.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:25:28.683+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:25:28.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:25:28.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T20:25:58.903+0000] {processor.py:157} INFO - Started process (PID=56508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:25:58.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:25:58.910+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:25:58.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:25:58.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:25:58.992+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:25:58.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:25:59.010+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:25:59.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:25:59.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T20:26:29.198+0000] {processor.py:157} INFO - Started process (PID=56518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:26:29.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:26:29.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:26:29.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:26:29.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:26:29.237+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:26:29.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:26:29.252+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:26:29.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:26:29.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T20:26:59.527+0000] {processor.py:157} INFO - Started process (PID=56528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:26:59.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:26:59.531+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:26:59.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:26:59.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:26:59.578+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:26:59.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:26:59.597+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:26:59.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:26:59.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T20:27:29.905+0000] {processor.py:157} INFO - Started process (PID=56538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:27:29.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:27:29.910+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:27:29.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:27:29.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:27:29.943+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:27:29.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:27:29.962+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:27:29.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:27:29.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T20:28:00.254+0000] {processor.py:157} INFO - Started process (PID=56548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:28:00.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:28:00.257+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:28:00.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:28:00.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:28:00.291+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:28:00.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:28:00.308+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:28:00.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:28:00.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T20:28:30.547+0000] {processor.py:157} INFO - Started process (PID=56558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:28:30.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:28:30.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:28:30.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:28:30.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:28:30.608+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:28:30.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:28:30.627+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:28:30.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:28:30.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-11T20:29:00.828+0000] {processor.py:157} INFO - Started process (PID=56568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:29:00.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:29:00.831+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:29:00.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:29:00.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:29:00.862+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:29:00.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:29:00.879+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:29:00.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:29:00.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T20:29:31.174+0000] {processor.py:157} INFO - Started process (PID=56578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:29:31.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:29:31.178+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:29:31.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:29:31.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:29:31.219+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:29:31.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:29:31.235+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:29:31.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:29:31.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T20:30:01.455+0000] {processor.py:157} INFO - Started process (PID=56587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:30:01.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:30:01.458+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:30:01.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:30:01.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:30:01.498+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:30:01.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:30:01.518+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:30:01.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:30:01.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T20:30:31.747+0000] {processor.py:157} INFO - Started process (PID=56598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:30:31.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:30:31.751+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:30:31.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:30:31.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:30:31.796+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:30:31.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:30:31.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:30:31.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:30:31.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T20:31:02.117+0000] {processor.py:157} INFO - Started process (PID=56608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:31:02.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:31:02.122+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:31:02.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:31:02.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:31:02.176+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:31:02.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:31:02.198+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:31:02.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:31:02.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T20:31:32.415+0000] {processor.py:157} INFO - Started process (PID=56618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:31:32.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:31:32.421+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:31:32.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:31:32.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:31:32.455+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:31:32.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:31:32.471+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:31:32.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:31:32.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T20:32:02.800+0000] {processor.py:157} INFO - Started process (PID=56628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:32:02.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:32:02.808+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:32:02.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:32:02.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:32:02.872+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:32:02.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:32:02.893+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:32:02.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:32:02.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-11T20:32:33.113+0000] {processor.py:157} INFO - Started process (PID=56638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:32:33.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:32:33.127+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:32:33.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:32:33.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:32:33.229+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:32:33.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:32:33.278+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:32:33.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:32:33.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-11T20:33:03.426+0000] {processor.py:157} INFO - Started process (PID=56648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:33:03.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:33:03.435+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:33:03.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:33:03.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:33:03.500+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:33:03.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:33:03.516+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:33:03.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:33:03.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T20:33:33.821+0000] {processor.py:157} INFO - Started process (PID=56658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:33:33.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:33:33.828+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:33:33.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:33:33.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:33:33.908+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:33:33.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:33:33.930+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:33:33.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:33:33.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-11T20:34:04.279+0000] {processor.py:157} INFO - Started process (PID=56668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:34:04.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:34:04.287+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:34:04.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:34:04.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:34:04.352+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:34:04.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:34:04.376+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:34:04.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:34:04.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-11T20:34:34.590+0000] {processor.py:157} INFO - Started process (PID=56677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:34:34.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:34:34.622+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:34:34.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:34:34.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:34:34.683+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:34:34.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:34:34.707+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:34:34.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:34:34.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T20:35:04.945+0000] {processor.py:157} INFO - Started process (PID=56688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:35:04.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:35:04.952+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:35:04.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:35:04.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:35:05.016+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:35:05.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:35:05.035+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:35:05.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:35:05.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T20:35:35.237+0000] {processor.py:157} INFO - Started process (PID=56698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:35:35.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:35:35.243+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:35:35.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:35:35.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:35:35.298+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:35:35.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:35:35.330+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:35:35.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:35:35.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T20:36:05.597+0000] {processor.py:157} INFO - Started process (PID=56707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:36:05.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:36:05.615+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:36:05.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:36:05.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:36:05.682+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:36:05.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:36:05.718+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:36:05.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:36:05.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-11T20:36:35.906+0000] {processor.py:157} INFO - Started process (PID=56718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:36:35.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:36:35.913+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:36:35.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:36:35.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:36:35.978+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:36:35.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:36:36.015+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:36:36.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:36:36.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-11T20:37:06.286+0000] {processor.py:157} INFO - Started process (PID=56728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:37:06.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:37:06.296+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:37:06.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:37:06.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:37:06.363+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:37:06.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:37:06.385+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:37:06.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:37:06.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T20:37:36.608+0000] {processor.py:157} INFO - Started process (PID=56738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:37:36.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:37:36.616+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:37:36.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:37:36.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:37:36.666+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:37:36.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:37:36.697+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:37:36.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:37:36.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-11T20:38:06.891+0000] {processor.py:157} INFO - Started process (PID=56748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:38:06.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:38:06.898+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:38:06.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:38:06.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:38:06.961+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:38:06.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:38:06.985+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:38:06.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:38:06.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-11T20:38:37.222+0000] {processor.py:157} INFO - Started process (PID=56758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:38:37.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:38:37.235+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:38:37.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:38:37.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:38:37.293+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:38:37.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:38:37.315+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:38:37.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:38:37.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T20:39:07.681+0000] {processor.py:157} INFO - Started process (PID=56768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:39:07.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:39:07.688+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:39:07.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:39:07.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:39:07.785+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:39:07.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:39:07.807+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:39:07.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:39:07.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-11T20:39:38.070+0000] {processor.py:157} INFO - Started process (PID=56778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:39:38.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:39:38.084+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:39:38.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:39:38.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:39:38.175+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:39:38.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:39:38.212+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:39:38.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:39:38.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-11T20:40:08.584+0000] {processor.py:157} INFO - Started process (PID=56788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:40:08.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:40:08.592+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:40:08.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:40:08.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:40:08.682+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:40:08.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:40:08.721+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:40:08.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:40:08.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-11T20:40:38.880+0000] {processor.py:157} INFO - Started process (PID=56798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:40:38.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:40:38.888+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:40:38.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:40:38.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:40:38.984+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:40:38.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:40:39.006+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:40:39.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:40:39.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-11T20:41:09.311+0000] {processor.py:157} INFO - Started process (PID=56808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:41:09.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:41:09.320+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:41:09.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:41:09.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:41:09.416+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:41:09.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:41:09.441+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:41:09.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:41:09.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-11T20:41:39.699+0000] {processor.py:157} INFO - Started process (PID=56818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:41:39.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:41:39.704+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:41:39.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:41:39.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:41:39.778+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:41:39.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:41:39.797+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:41:39.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:41:39.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-11T20:42:10.000+0000] {processor.py:157} INFO - Started process (PID=56828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:42:10.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:42:10.006+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:42:10.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:42:10.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:42:10.089+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:42:10.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:42:10.109+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:42:10.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:42:10.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T20:42:40.674+0000] {processor.py:157} INFO - Started process (PID=56838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:42:40.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:42:40.711+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:42:40.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:42:40.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:42:40.789+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:42:40.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:42:40.822+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:42:40.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:42:40.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-11T20:43:11.033+0000] {processor.py:157} INFO - Started process (PID=56847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:43:11.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:43:11.049+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:43:11.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:43:11.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:43:11.112+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:43:11.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:43:11.139+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:43:11.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:43:11.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-11T20:43:41.456+0000] {processor.py:157} INFO - Started process (PID=56858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:43:41.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:43:41.460+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:43:41.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:43:41.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:43:41.497+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:43:41.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:43:41.511+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:43:41.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:43:41.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T20:44:11.803+0000] {processor.py:157} INFO - Started process (PID=56868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:44:11.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:44:11.809+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:44:11.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:44:11.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:44:11.882+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:44:11.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:44:11.905+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:44:11.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:44:11.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-11T20:44:42.053+0000] {processor.py:157} INFO - Started process (PID=56878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:44:42.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:44:42.058+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:44:42.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:44:42.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:44:42.095+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:44:42.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:44:42.109+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:44:42.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:44:42.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T20:45:12.380+0000] {processor.py:157} INFO - Started process (PID=56888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:45:12.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:45:12.385+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:45:12.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:45:12.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:45:12.433+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:45:12.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:45:12.456+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:45:12.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:45:12.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T20:45:42.689+0000] {processor.py:157} INFO - Started process (PID=56898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:45:42.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:45:42.696+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:45:42.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:45:42.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:45:42.770+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:45:42.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:45:42.788+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:45:42.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:45:42.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-11T20:46:12.984+0000] {processor.py:157} INFO - Started process (PID=56908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:46:12.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:46:12.990+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:46:12.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:46:13.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:46:13.031+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:46:13.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:46:13.047+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:46:13.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:46:13.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T20:46:43.384+0000] {processor.py:157} INFO - Started process (PID=56918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:46:43.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:46:43.389+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:46:43.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:46:43.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:46:43.452+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:46:43.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:46:43.471+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:46:43.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:46:43.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T20:47:13.636+0000] {processor.py:157} INFO - Started process (PID=56928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:47:13.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:47:13.645+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:47:13.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:47:13.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:47:13.675+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:47:13.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:47:13.686+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:47:13.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:47:13.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T20:47:43.993+0000] {processor.py:157} INFO - Started process (PID=56938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:47:43.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:47:44.000+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:47:44.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:47:44.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:47:44.065+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:47:44.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:47:44.084+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:47:44.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:47:44.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-11T20:48:14.238+0000] {processor.py:157} INFO - Started process (PID=56948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:48:14.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:48:14.241+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:48:14.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:48:14.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:48:14.276+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:48:14.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:48:14.289+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:48:14.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:48:14.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T20:48:44.607+0000] {processor.py:157} INFO - Started process (PID=56958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:48:44.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:48:44.611+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:48:44.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:48:44.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:48:44.652+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:48:44.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:48:44.671+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:48:44.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:48:44.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T20:49:14.963+0000] {processor.py:157} INFO - Started process (PID=56968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:49:14.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:49:14.968+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:49:14.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:49:14.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:49:15.026+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:49:15.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:49:15.043+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:49:15.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:49:15.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-11T20:49:45.256+0000] {processor.py:157} INFO - Started process (PID=56978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:49:45.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:49:45.259+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:49:45.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:49:45.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:49:45.295+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:49:45.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:49:45.317+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:49:45.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:49:45.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T20:50:15.520+0000] {processor.py:157} INFO - Started process (PID=56988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:50:15.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:50:15.526+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:50:15.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:50:15.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:50:15.603+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:50:15.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:50:15.619+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:50:15.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:50:15.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-11T20:50:45.866+0000] {processor.py:157} INFO - Started process (PID=56998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:50:45.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:50:45.879+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:50:45.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:50:45.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:50:45.938+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:50:45.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:50:45.953+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:50:45.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:50:45.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-11T20:51:16.170+0000] {processor.py:157} INFO - Started process (PID=57008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:51:16.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:51:16.181+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:51:16.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:51:16.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:51:16.264+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:51:16.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:51:16.283+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:51:16.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:51:16.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T20:51:46.484+0000] {processor.py:157} INFO - Started process (PID=57018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:51:46.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:51:46.494+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:51:46.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:51:46.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:51:46.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:51:46.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:51:46.601+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:51:46.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:51:46.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-11T20:52:16.851+0000] {processor.py:157} INFO - Started process (PID=57027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:52:16.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:52:16.861+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:52:16.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:52:16.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:52:16.944+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:52:16.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:52:16.966+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:52:16.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:52:16.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-11T20:52:47.188+0000] {processor.py:157} INFO - Started process (PID=57038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:52:47.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:52:47.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:52:47.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:52:47.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:52:47.285+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:52:47.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:52:47.316+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:52:47.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:52:47.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-11T20:53:17.478+0000] {processor.py:157} INFO - Started process (PID=57048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:53:17.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:53:17.484+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:53:17.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:53:17.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:53:17.537+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:53:17.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:53:17.554+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:53:17.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:53:17.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-11T20:53:47.818+0000] {processor.py:157} INFO - Started process (PID=57058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:53:47.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:53:47.824+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:53:47.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:53:47.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:53:47.881+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:53:47.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:53:47.901+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:53:47.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:53:47.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-11T20:54:18.123+0000] {processor.py:157} INFO - Started process (PID=57068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:54:18.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:54:18.131+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:54:18.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:54:18.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:54:18.165+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:54:18.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:54:18.180+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:54:18.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:54:18.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T20:54:48.448+0000] {processor.py:157} INFO - Started process (PID=57078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:54:48.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:54:48.454+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:54:48.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:54:48.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:54:48.495+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:54:48.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:54:48.516+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:54:48.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:54:48.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T20:55:18.716+0000] {processor.py:157} INFO - Started process (PID=57088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:55:18.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:55:18.720+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:55:18.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:55:18.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:55:18.753+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:55:18.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:55:18.769+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:55:18.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:55:18.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T20:55:49.047+0000] {processor.py:157} INFO - Started process (PID=57097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:55:49.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:55:49.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:55:49.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:55:49.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:55:49.095+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:55:49.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:55:49.112+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:55:49.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:55:49.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T20:56:19.319+0000] {processor.py:157} INFO - Started process (PID=57108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:56:19.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:56:19.327+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:56:19.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:56:19.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:56:19.369+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:56:19.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:56:19.381+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:56:19.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:56:19.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T20:56:49.589+0000] {processor.py:157} INFO - Started process (PID=57118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:56:49.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:56:49.592+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:56:49.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:56:49.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:56:49.638+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:56:49.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:56:49.656+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:56:49.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:56:49.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T20:57:19.887+0000] {processor.py:157} INFO - Started process (PID=57128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:57:19.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:57:19.892+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:57:19.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:57:19.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:57:19.927+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:57:19.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:57:19.941+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:57:19.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:57:19.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T20:57:50.259+0000] {processor.py:157} INFO - Started process (PID=57138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:57:50.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:57:50.267+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:57:50.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:57:50.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:57:50.355+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:57:50.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:57:50.374+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:57:50.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:57:50.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T20:58:20.529+0000] {processor.py:157} INFO - Started process (PID=57148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:58:20.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:58:20.532+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:58:20.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:58:20.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:58:20.579+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:58:20.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:58:20.595+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:58:20.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:58:20.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-11T20:58:51.419+0000] {processor.py:157} INFO - Started process (PID=57158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:58:51.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:58:51.427+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:58:51.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:58:51.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:58:51.511+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:58:51.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:58:51.546+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:58:51.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:58:51.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-11T20:59:36.826+0000] {processor.py:157} INFO - Started process (PID=57168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:59:36.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T20:59:36.836+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:59:36.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:59:36.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T20:59:36.872+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:59:36.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T20:59:36.888+0000] {logging_mixin.py:151} INFO - [2024-09-11T20:59:36.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T20:59:36.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T21:00:07.150+0000] {processor.py:157} INFO - Started process (PID=57180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:00:07.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:00:07.153+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:00:07.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:00:07.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:00:07.193+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:00:07.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:00:07.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:00:07.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:00:07.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T21:00:37.507+0000] {processor.py:157} INFO - Started process (PID=57190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:00:37.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:00:37.513+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:00:37.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:00:37.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:00:37.555+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:00:37.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:00:37.572+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:00:37.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:00:37.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T21:01:07.772+0000] {processor.py:157} INFO - Started process (PID=57200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:01:07.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:01:07.775+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:01:07.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:01:07.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:01:07.814+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:01:07.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:01:07.831+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:01:07.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:01:07.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T21:01:38.106+0000] {processor.py:157} INFO - Started process (PID=57210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:01:38.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:01:38.111+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:01:38.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:01:38.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:01:38.154+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:01:38.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:01:38.167+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:01:38.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:01:38.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T21:03:56.097+0000] {processor.py:157} INFO - Started process (PID=57219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:03:56.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:03:56.119+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:03:56.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:03:56.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:03:56.205+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:03:56.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:03:56.244+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:03:56.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:03:56.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-09-11T21:04:26.568+0000] {processor.py:157} INFO - Started process (PID=57232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:04:26.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:04:26.574+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:04:26.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:04:26.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:04:26.633+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:04:26.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:04:26.652+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:04:26.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:04:26.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-11T21:04:56.938+0000] {processor.py:157} INFO - Started process (PID=57242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:04:56.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:04:56.944+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:04:56.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:04:56.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:04:57.027+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:04:57.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:04:57.050+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:04:57.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:04:57.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-11T21:05:27.408+0000] {processor.py:157} INFO - Started process (PID=57252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:05:27.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:05:27.424+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:05:27.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:05:27.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:05:27.482+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:05:27.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:05:27.505+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:05:27.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:05:27.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-11T21:05:57.906+0000] {processor.py:157} INFO - Started process (PID=57262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:05:57.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:05:57.915+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:05:57.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:05:57.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:05:57.977+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:05:57.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:05:57.994+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:05:57.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:05:58.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T21:06:28.379+0000] {processor.py:157} INFO - Started process (PID=57272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:06:28.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:06:28.385+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:06:28.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:06:28.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:06:28.466+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:06:28.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:06:28.484+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:06:28.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:06:28.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-11T21:06:58.706+0000] {processor.py:157} INFO - Started process (PID=57282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:06:58.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:06:58.717+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:06:58.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:06:58.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:06:58.788+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:06:58.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:06:58.835+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:06:58.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:06:58.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-11T21:07:29.343+0000] {processor.py:157} INFO - Started process (PID=57292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:07:29.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:07:29.349+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:07:29.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:07:29.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:07:29.422+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:07:29.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:07:29.447+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:07:29.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:07:29.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-11T21:07:59.886+0000] {processor.py:157} INFO - Started process (PID=57302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:07:59.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:07:59.892+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:07:59.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:07:59.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:07:59.948+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:07:59.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:07:59.962+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:07:59.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:07:59.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T21:09:42.437+0000] {processor.py:157} INFO - Started process (PID=57314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:09:42.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:09:42.443+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:09:42.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:09:42.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:09:42.492+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:09:42.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:09:42.507+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:09:42.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:09:42.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T21:10:53.090+0000] {processor.py:157} INFO - Started process (PID=57324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:10:53.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:10:53.100+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:10:53.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:10:53.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:10:53.222+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:10:53.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:10:53.253+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:10:53.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:10:53.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-11T21:11:23.621+0000] {processor.py:157} INFO - Started process (PID=57334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:11:23.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:11:23.628+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:11:23.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:11:23.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:11:23.656+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:11:23.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:11:23.667+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:11:23.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:11:23.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T21:12:22.803+0000] {processor.py:157} INFO - Started process (PID=57344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:12:22.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:12:22.817+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:12:22.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:12:22.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:12:22.862+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:12:22.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:12:22.879+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:12:22.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:12:22.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T21:13:34.959+0000] {processor.py:157} INFO - Started process (PID=57354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:13:34.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:13:34.962+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:13:34.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:13:34.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:13:34.989+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:13:34.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:13:34.998+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:13:34.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:13:35.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T21:14:05.345+0000] {processor.py:157} INFO - Started process (PID=57364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:14:05.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:14:05.351+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:14:05.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:14:05.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:14:05.392+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:14:05.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:14:05.415+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:14:05.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:14:05.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T21:14:38.001+0000] {processor.py:157} INFO - Started process (PID=57373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:14:38.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:14:38.006+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:14:38.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:14:38.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:14:38.061+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:14:38.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:14:38.076+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:14:38.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:14:38.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-11T21:15:08.351+0000] {processor.py:157} INFO - Started process (PID=57384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:15:08.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:15:08.354+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:15:08.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:15:08.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:15:08.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:15:08.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:15:08.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:15:08.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:15:08.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T21:16:01.237+0000] {processor.py:157} INFO - Started process (PID=57394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:16:01.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:16:01.252+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:16:01.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:16:01.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:16:01.292+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:16:01.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:16:01.305+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:16:01.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:16:01.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-11T21:16:52.147+0000] {processor.py:157} INFO - Started process (PID=57404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:16:52.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:16:52.153+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:16:52.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:16:52.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:16:52.200+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:16:52.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:16:52.218+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:16:52.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:16:52.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T21:17:22.577+0000] {processor.py:157} INFO - Started process (PID=57414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:17:22.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:17:22.579+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:17:22.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:17:22.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:17:22.608+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:17:22.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:17:22.618+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:17:22.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:17:22.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T21:18:11.094+0000] {processor.py:157} INFO - Started process (PID=57423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:18:11.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:18:11.099+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:18:11.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:18:11.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:18:11.155+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:18:11.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:18:11.167+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:18:11.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:18:11.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T21:18:56.722+0000] {processor.py:157} INFO - Started process (PID=57434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:18:56.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:18:56.726+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:18:56.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:18:56.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:18:56.770+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:18:56.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:18:56.787+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:18:56.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:18:56.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T21:19:27.087+0000] {processor.py:157} INFO - Started process (PID=57444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:19:27.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:19:27.094+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:19:27.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:19:27.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:19:27.150+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:19:27.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:19:27.164+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:19:27.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:19:27.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-11T21:21:41.259+0000] {processor.py:157} INFO - Started process (PID=57455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:21:41.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:21:41.270+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:21:41.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:21:41.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:21:41.346+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:21:41.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:21:41.370+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:21:41.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:21:41.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-11T21:23:02.057+0000] {processor.py:157} INFO - Started process (PID=57466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:23:02.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:23:02.066+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:23:02.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:23:02.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:23:02.120+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:23:02.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:23:02.139+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:23:02.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:23:02.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-11T21:23:32.546+0000] {processor.py:157} INFO - Started process (PID=57476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:23:32.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:23:32.554+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:23:32.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:23:32.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:23:32.602+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:23:32.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:23:32.615+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:23:32.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:23:32.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-11T21:24:02.993+0000] {processor.py:157} INFO - Started process (PID=57486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:24:02.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:24:03.003+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:24:03.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:24:03.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:24:03.071+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:24:03.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:24:03.088+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:24:03.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:24:03.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-11T21:24:33.341+0000] {processor.py:157} INFO - Started process (PID=57496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:24:33.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:24:33.348+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:24:33.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:24:33.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:24:33.378+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:24:33.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:24:33.390+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:24:33.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:24:33.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T21:25:03.628+0000] {processor.py:157} INFO - Started process (PID=57506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:25:03.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:25:03.632+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:25:03.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:25:03.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:25:03.677+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:25:03.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:25:03.696+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:25:03.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:25:03.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T21:25:33.860+0000] {processor.py:157} INFO - Started process (PID=57516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:25:33.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:25:33.863+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:25:33.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:25:33.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:25:33.900+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:25:33.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:25:33.912+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:25:33.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:25:33.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-11T21:26:04.244+0000] {processor.py:157} INFO - Started process (PID=57526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:26:04.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:26:04.246+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:26:04.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:26:04.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:26:04.280+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:26:04.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:26:04.293+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:26:04.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:26:04.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-11T21:26:34.543+0000] {processor.py:157} INFO - Started process (PID=57536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:26:34.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:26:34.546+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:26:34.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:26:34.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:26:34.573+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:26:34.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:26:34.584+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:26:34.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:26:34.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T21:27:04.858+0000] {processor.py:157} INFO - Started process (PID=57545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:27:04.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:27:04.864+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:27:04.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:27:04.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:27:04.912+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:27:04.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:27:04.932+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:27:04.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:27:04.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T21:27:35.150+0000] {processor.py:157} INFO - Started process (PID=57556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:27:35.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:27:35.154+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:27:35.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:27:35.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:27:35.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:27:35.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:27:35.197+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:27:35.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:27:35.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T21:28:05.570+0000] {processor.py:157} INFO - Started process (PID=57566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:28:05.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:28:05.584+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:28:05.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:28:05.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:28:05.659+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:28:05.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:28:05.679+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:28:05.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:28:05.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-11T21:28:35.794+0000] {processor.py:157} INFO - Started process (PID=57576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:28:35.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:28:35.798+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:28:35.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:28:35.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:28:35.839+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:28:35.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:28:35.851+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:28:35.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:28:35.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-11T21:29:06.236+0000] {processor.py:157} INFO - Started process (PID=57586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:29:06.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:29:06.247+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:29:06.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:29:06.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:29:06.318+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:29:06.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:29:06.337+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:29:06.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:29:06.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-11T21:29:36.519+0000] {processor.py:157} INFO - Started process (PID=57596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:29:36.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:29:36.524+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:29:36.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:29:36.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:29:36.559+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:29:36.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:29:36.575+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:29:36.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:29:36.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-11T21:30:06.900+0000] {processor.py:157} INFO - Started process (PID=57606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:30:06.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:30:06.907+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:30:06.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:30:06.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:30:06.977+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:30:06.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:30:07.011+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:30:07.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:30:07.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-11T21:30:37.200+0000] {processor.py:157} INFO - Started process (PID=57616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:30:37.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:30:37.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:30:37.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:30:37.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:30:37.252+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:30:37.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:30:37.270+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:30:37.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:30:37.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-11T21:31:07.585+0000] {processor.py:157} INFO - Started process (PID=57626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:31:07.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:31:07.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:31:07.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:31:07.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:31:07.615+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:31:07.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:31:07.628+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:31:07.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:31:07.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T21:31:37.960+0000] {processor.py:157} INFO - Started process (PID=57636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:31:37.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:31:37.966+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:31:37.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:31:37.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:31:38.003+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:31:38.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:31:38.015+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:31:38.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:31:38.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T21:32:08.376+0000] {processor.py:157} INFO - Started process (PID=57646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:32:08.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:32:08.383+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:32:08.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:32:08.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:32:08.446+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:32:08.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:32:08.466+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:32:08.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:32:08.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-11T21:32:38.605+0000] {processor.py:157} INFO - Started process (PID=57656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:32:38.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:32:38.608+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:32:38.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:32:38.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:32:38.640+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:32:38.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:32:38.651+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:32:38.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:32:38.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T21:33:08.878+0000] {processor.py:157} INFO - Started process (PID=57666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:33:08.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:33:08.884+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:33:08.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:33:08.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:33:08.928+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:33:08.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:33:08.940+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:33:08.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:33:08.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T21:33:39.118+0000] {processor.py:157} INFO - Started process (PID=57676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:33:39.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:33:39.123+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:33:39.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:33:39.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:33:39.147+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:33:39.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:33:39.158+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:33:39.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:33:39.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T21:34:09.479+0000] {processor.py:157} INFO - Started process (PID=57686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:34:09.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:34:09.483+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:34:09.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:34:09.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:34:09.511+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:34:09.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:34:09.521+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:34:09.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:34:09.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T21:34:39.813+0000] {processor.py:157} INFO - Started process (PID=57696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:34:39.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:34:39.818+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:34:39.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:34:39.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:34:39.854+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:34:39.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:34:39.867+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:34:39.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:34:39.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T21:35:10.095+0000] {processor.py:157} INFO - Started process (PID=57706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:35:10.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:35:10.098+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:35:10.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:35:10.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:35:10.128+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:35:10.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:35:10.141+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:35:10.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:35:10.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T21:35:40.450+0000] {processor.py:157} INFO - Started process (PID=57716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:35:40.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:35:40.455+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:35:40.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:35:40.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:35:40.497+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:35:40.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:35:40.507+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:35:40.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:35:40.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-11T21:36:10.822+0000] {processor.py:157} INFO - Started process (PID=57726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:36:10.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:36:10.824+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:36:10.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:36:10.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:36:10.858+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:36:10.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:36:10.873+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:36:10.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:36:10.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T21:36:41.196+0000] {processor.py:157} INFO - Started process (PID=57735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:36:41.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:36:41.199+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:36:41.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:36:41.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:36:41.223+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:36:41.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:36:41.232+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:36:41.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:36:41.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-11T21:37:11.587+0000] {processor.py:157} INFO - Started process (PID=57746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:37:11.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:37:11.589+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:37:11.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:37:11.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:37:11.617+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:37:11.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:37:11.629+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:37:11.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:37:11.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T21:37:41.944+0000] {processor.py:157} INFO - Started process (PID=57756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:37:41.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:37:41.950+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:37:41.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:37:41.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:37:41.981+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:37:41.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:37:41.991+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:37:41.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:37:42.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-11T21:38:12.274+0000] {processor.py:157} INFO - Started process (PID=57766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:38:12.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:38:12.277+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:38:12.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:38:12.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:38:12.305+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:38:12.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:38:12.317+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:38:12.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:38:12.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T21:38:42.692+0000] {processor.py:157} INFO - Started process (PID=57776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:38:42.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:38:42.695+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:38:42.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:38:42.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:38:42.727+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:38:42.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:38:42.737+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:38:42.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:38:42.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T21:39:13.064+0000] {processor.py:157} INFO - Started process (PID=57786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:39:13.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:39:13.069+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:39:13.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:39:13.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:39:13.101+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:39:13.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:39:13.114+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:39:13.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:39:13.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T21:39:43.444+0000] {processor.py:157} INFO - Started process (PID=57796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:39:43.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:39:43.448+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:39:43.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:39:43.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:39:43.475+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:39:43.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:39:43.486+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:39:43.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:39:43.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T21:40:13.890+0000] {processor.py:157} INFO - Started process (PID=57806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:40:13.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:40:13.894+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:40:13.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:40:13.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:40:13.922+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:40:13.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:40:13.934+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:40:13.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:40:13.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T21:40:44.262+0000] {processor.py:157} INFO - Started process (PID=57816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:40:44.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:40:44.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:40:44.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:40:44.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:40:44.300+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:40:44.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:40:44.311+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:40:44.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:40:44.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-11T21:41:14.591+0000] {processor.py:157} INFO - Started process (PID=57826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:41:14.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:41:14.595+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:41:14.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:41:14.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:41:14.625+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:41:14.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:41:14.634+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:41:14.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:41:14.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T21:41:44.988+0000] {processor.py:157} INFO - Started process (PID=57836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:41:44.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:41:44.993+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:41:44.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:41:45.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:41:45.019+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:41:45.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:41:45.031+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:41:45.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:41:45.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T21:42:15.367+0000] {processor.py:157} INFO - Started process (PID=57846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:42:15.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:42:15.371+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:42:15.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:42:15.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:42:15.403+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:42:15.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:42:15.419+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:42:15.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:42:15.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T21:42:45.815+0000] {processor.py:157} INFO - Started process (PID=57856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:42:45.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:42:45.819+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:42:45.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:42:45.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:42:45.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:42:45.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:42:45.856+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:42:45.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:42:45.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T21:43:16.254+0000] {processor.py:157} INFO - Started process (PID=57866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:43:16.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:43:16.256+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:43:16.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:43:16.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:43:16.291+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:43:16.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:43:16.304+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:43:16.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:43:16.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T21:43:46.628+0000] {processor.py:157} INFO - Started process (PID=57876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:43:46.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:43:46.630+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:43:46.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:43:46.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:43:46.658+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:43:46.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:43:46.668+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:43:46.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:43:46.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T21:44:17.021+0000] {processor.py:157} INFO - Started process (PID=57886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:44:17.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:44:17.028+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:44:17.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:44:17.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:44:17.091+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:44:17.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:44:17.105+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:44:17.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:44:17.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T21:44:47.351+0000] {processor.py:157} INFO - Started process (PID=57896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:44:47.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:44:47.355+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:44:47.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:44:47.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:44:47.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:44:47.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:44:47.407+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:44:47.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:44:47.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T21:45:17.621+0000] {processor.py:157} INFO - Started process (PID=57906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:45:17.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:45:17.624+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:45:17.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:45:17.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:45:17.690+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:45:17.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:45:17.705+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:45:17.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:45:17.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-11T21:45:47.938+0000] {processor.py:157} INFO - Started process (PID=57916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:45:47.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:45:47.948+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:45:47.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:45:47.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:45:47.972+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:45:47.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:45:47.982+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:45:47.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:45:47.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-11T21:46:18.307+0000] {processor.py:157} INFO - Started process (PID=57926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:46:18.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:46:18.311+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:46:18.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:46:18.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:46:18.353+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:46:18.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:46:18.379+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:46:18.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:46:18.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-11T21:46:48.551+0000] {processor.py:157} INFO - Started process (PID=57936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:46:48.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:46:48.553+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:46:48.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:46:48.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:46:48.583+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:46:48.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:46:48.594+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:46:48.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:46:48.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T21:47:18.842+0000] {processor.py:157} INFO - Started process (PID=57946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:47:18.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:47:18.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:47:18.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:47:18.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:47:18.875+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:47:18.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:47:18.887+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:47:18.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:47:18.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T21:47:49.116+0000] {processor.py:157} INFO - Started process (PID=57956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:47:49.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:47:49.121+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:47:49.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:47:49.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:47:49.162+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:47:49.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:47:49.176+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:47:49.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:47:49.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T21:48:19.378+0000] {processor.py:157} INFO - Started process (PID=57966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:48:19.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:48:19.383+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:48:19.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:48:19.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:48:19.416+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:48:19.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:48:19.429+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:48:19.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:48:19.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T21:48:49.689+0000] {processor.py:157} INFO - Started process (PID=57976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:48:49.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:48:49.694+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:48:49.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:48:49.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:48:49.720+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:48:49.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:48:49.731+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:48:49.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:48:49.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T21:49:20.017+0000] {processor.py:157} INFO - Started process (PID=57986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:49:20.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:49:20.021+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:49:20.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:49:20.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:49:20.046+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:49:20.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:49:20.059+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:49:20.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:49:20.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T21:49:50.354+0000] {processor.py:157} INFO - Started process (PID=57996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:49:50.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:49:50.357+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:49:50.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:49:50.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:49:50.383+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:49:50.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:49:50.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:49:50.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:49:50.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T21:50:20.664+0000] {processor.py:157} INFO - Started process (PID=58006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:50:20.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:50:20.669+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:50:20.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:50:20.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:50:20.713+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:50:20.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:50:20.728+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:50:20.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:50:20.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T21:50:50.873+0000] {processor.py:157} INFO - Started process (PID=58016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:50:50.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:50:50.876+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:50:50.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:50:50.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:50:50.903+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:50:50.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:50:50.915+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:50:50.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:50:50.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T21:51:21.233+0000] {processor.py:157} INFO - Started process (PID=58026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:51:21.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:51:21.237+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:51:21.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:51:21.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:51:21.270+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:51:21.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:51:21.283+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:51:21.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:51:21.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T21:51:51.625+0000] {processor.py:157} INFO - Started process (PID=58035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:51:51.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:51:51.649+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:51:51.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:51:51.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:51:51.710+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:51:51.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:51:51.734+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:51:51.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:51:51.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-11T21:52:21.900+0000] {processor.py:157} INFO - Started process (PID=58046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:52:21.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:52:21.905+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:52:21.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:52:21.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:52:21.950+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:52:21.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:52:21.965+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:52:21.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:52:21.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T21:52:52.301+0000] {processor.py:157} INFO - Started process (PID=58056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:52:52.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:52:52.308+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:52:52.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:52:52.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:52:52.367+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:52:52.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:52:52.394+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:52:52.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:52:52.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-11T21:53:22.626+0000] {processor.py:157} INFO - Started process (PID=58066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:53:22.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:53:22.638+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:53:22.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:53:22.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:53:22.691+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:53:22.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:53:22.713+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:53:22.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:53:22.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-11T21:53:52.924+0000] {processor.py:157} INFO - Started process (PID=58076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:53:52.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:53:52.930+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:53:52.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:53:52.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:53:52.978+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:53:52.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:53:52.999+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:53:52.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:53:53.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T21:54:23.338+0000] {processor.py:157} INFO - Started process (PID=58086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:54:23.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:54:23.341+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:54:23.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:54:23.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:54:23.369+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:54:23.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:54:23.382+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:54:23.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:54:23.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T21:54:53.690+0000] {processor.py:157} INFO - Started process (PID=58096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:54:53.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:54:53.693+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:54:53.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:54:53.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:54:53.721+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:54:53.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:54:53.734+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:54:53.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:54:53.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T21:55:23.998+0000] {processor.py:157} INFO - Started process (PID=58106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:55:23.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:55:24.001+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:55:24.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:55:24.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:55:24.027+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:55:24.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:55:24.037+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:55:24.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:55:24.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T21:55:54.356+0000] {processor.py:157} INFO - Started process (PID=58116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:55:54.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:55:54.361+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:55:54.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:55:54.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:55:54.396+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:55:54.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:55:54.410+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:55:54.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:55:54.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T21:56:24.699+0000] {processor.py:157} INFO - Started process (PID=58126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:56:24.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:56:24.702+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:56:24.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:56:24.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:56:24.727+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:56:24.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:56:24.736+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:56:24.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:56:24.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-11T21:56:55.034+0000] {processor.py:157} INFO - Started process (PID=58136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:56:55.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:56:55.037+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:56:55.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:56:55.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:56:55.067+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:56:55.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:56:55.080+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:56:55.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:56:55.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T21:57:25.390+0000] {processor.py:157} INFO - Started process (PID=58146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:57:25.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:57:25.393+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:57:25.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:57:25.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:57:25.418+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:57:25.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:57:25.428+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:57:25.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:57:25.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T21:57:55.688+0000] {processor.py:157} INFO - Started process (PID=58156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:57:55.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:57:55.693+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:57:55.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:57:55.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:57:55.730+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:57:55.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:57:55.743+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:57:55.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:57:55.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-11T21:58:26.045+0000] {processor.py:157} INFO - Started process (PID=58166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:58:26.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:58:26.048+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:58:26.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:58:26.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:58:26.075+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:58:26.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:58:26.085+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:58:26.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:58:26.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-11T21:58:56.400+0000] {processor.py:157} INFO - Started process (PID=58176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:58:56.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:58:56.404+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:58:56.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:58:56.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:58:56.431+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:58:56.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:58:56.442+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:58:56.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:58:56.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T21:59:26.784+0000] {processor.py:157} INFO - Started process (PID=58186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:59:26.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:59:26.789+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:59:26.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:59:26.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:59:26.816+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:59:26.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:59:26.826+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:59:26.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:59:26.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T21:59:57.144+0000] {processor.py:157} INFO - Started process (PID=58196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:59:57.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T21:59:57.148+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:59:57.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:59:57.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T21:59:57.175+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:59:57.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T21:59:57.187+0000] {logging_mixin.py:151} INFO - [2024-09-11T21:59:57.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T21:59:57.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T22:00:27.530+0000] {processor.py:157} INFO - Started process (PID=58206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:00:27.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:00:27.534+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:00:27.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:00:27.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:00:27.561+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:00:27.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:00:27.571+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:00:27.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:00:27.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-11T22:00:57.896+0000] {processor.py:157} INFO - Started process (PID=58216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:00:57.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:00:57.899+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:00:57.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:00:57.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:00:57.926+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:00:57.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:00:57.936+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:00:57.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:00:57.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T22:01:28.294+0000] {processor.py:157} INFO - Started process (PID=58226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:01:28.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:01:28.297+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:01:28.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:01:28.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:01:28.334+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:01:28.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:01:28.346+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:01:28.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:01:28.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-11T22:01:58.646+0000] {processor.py:157} INFO - Started process (PID=58236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:01:58.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:01:58.654+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:01:58.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:01:58.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:01:58.716+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:01:58.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:01:58.729+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:01:58.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:01:58.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-11T22:02:28.928+0000] {processor.py:157} INFO - Started process (PID=58246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:02:28.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:02:28.931+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:02:28.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:02:28.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:02:28.963+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:02:28.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:02:28.974+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:02:28.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:02:28.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T22:02:59.222+0000] {processor.py:157} INFO - Started process (PID=58254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:02:59.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:02:59.228+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:02:59.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:02:59.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:02:59.302+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:02:59.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:02:59.319+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:02:59.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:02:59.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-11T22:03:29.505+0000] {processor.py:157} INFO - Started process (PID=58266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:03:29.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:03:29.512+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:03:29.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:03:29.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:03:29.550+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:03:29.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:03:29.566+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:03:29.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:03:29.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-11T22:03:59.790+0000] {processor.py:157} INFO - Started process (PID=58276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:03:59.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:03:59.795+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:03:59.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:03:59.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:03:59.830+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:03:59.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:03:59.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:03:59.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:03:59.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T22:04:30.150+0000] {processor.py:157} INFO - Started process (PID=58285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:04:30.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:04:30.156+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:04:30.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:04:30.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:04:30.237+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:04:30.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:04:30.255+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:04:30.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:04:30.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T22:05:00.499+0000] {processor.py:157} INFO - Started process (PID=58296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:05:00.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:05:00.504+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:05:00.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:05:00.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:05:00.568+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:05:00.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:05:00.587+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:05:00.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:05:00.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-11T22:05:30.796+0000] {processor.py:157} INFO - Started process (PID=58306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:05:30.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:05:30.799+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:05:30.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:05:30.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:05:30.833+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:05:30.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:05:30.846+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:05:30.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:05:30.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T22:06:01.175+0000] {processor.py:157} INFO - Started process (PID=58316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:06:01.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:06:01.181+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:06:01.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:06:01.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:06:01.251+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:06:01.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:06:01.272+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:06:01.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:06:01.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-11T22:06:31.449+0000] {processor.py:157} INFO - Started process (PID=58326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:06:31.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:06:31.452+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:06:31.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:06:31.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:06:31.491+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:06:31.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:06:31.504+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:06:31.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:06:31.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-11T22:07:01.822+0000] {processor.py:157} INFO - Started process (PID=58336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:07:01.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:07:01.831+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:07:01.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:07:01.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:07:01.901+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:07:01.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:07:01.920+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:07:01.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:07:01.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-11T22:07:32.092+0000] {processor.py:157} INFO - Started process (PID=58346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:07:32.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:07:32.097+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:07:32.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:07:32.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:07:32.130+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:07:32.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:07:32.141+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:07:32.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:07:32.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-11T22:08:02.429+0000] {processor.py:157} INFO - Started process (PID=58355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:08:02.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:08:02.444+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:08:02.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:08:02.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:08:02.490+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:08:02.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:08:02.504+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:08:02.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:08:02.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-11T22:08:32.765+0000] {processor.py:157} INFO - Started process (PID=58366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:08:32.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:08:32.769+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:08:32.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:08:32.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:08:32.800+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:08:32.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:08:32.812+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:08:32.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:08:32.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-11T22:09:03.049+0000] {processor.py:157} INFO - Started process (PID=58376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:09:03.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:09:03.052+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:09:03.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:09:03.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:09:03.083+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:09:03.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:09:03.096+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:09:03.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:09:03.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T22:09:33.387+0000] {processor.py:157} INFO - Started process (PID=58386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:09:33.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:09:33.391+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:09:33.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:09:33.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:09:33.428+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:09:33.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:09:33.444+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:09:33.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:09:33.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T22:10:03.775+0000] {processor.py:157} INFO - Started process (PID=58396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:10:03.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:10:03.778+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:10:03.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:10:03.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:10:03.806+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:10:03.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:10:03.816+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:10:03.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:10:03.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T22:10:34.096+0000] {processor.py:157} INFO - Started process (PID=58406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:10:34.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:10:34.106+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:10:34.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:10:34.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:10:34.127+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:10:34.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:10:34.137+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:10:34.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:10:34.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T22:11:04.423+0000] {processor.py:157} INFO - Started process (PID=58416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:11:04.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:11:04.427+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:11:04.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:11:04.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:11:04.453+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:11:04.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:11:04.465+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:11:04.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:11:04.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-11T22:11:34.703+0000] {processor.py:157} INFO - Started process (PID=58426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:11:34.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:11:34.714+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:11:34.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:11:34.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:11:34.752+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:11:34.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:11:34.765+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:11:34.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:11:34.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T22:12:05.009+0000] {processor.py:157} INFO - Started process (PID=58436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:12:05.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:12:05.012+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:12:05.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:12:05.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:12:05.039+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:12:05.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:12:05.050+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:12:05.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:12:05.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-11T22:12:35.357+0000] {processor.py:157} INFO - Started process (PID=58446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:12:35.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:12:35.360+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:12:35.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:12:35.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:12:35.399+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:12:35.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:12:35.414+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:12:35.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:12:35.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-11T22:13:11.577+0000] {processor.py:157} INFO - Started process (PID=58456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:13:11.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:13:11.580+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:13:11.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:13:11.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:13:11.606+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:13:11.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:13:11.617+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:13:11.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:13:11.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T22:15:00.087+0000] {processor.py:157} INFO - Started process (PID=58468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:15:00.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:15:00.093+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:15:00.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:15:00.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:15:00.160+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:15:00.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:15:00.185+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:15:00.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:15:00.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-11T22:15:30.546+0000] {processor.py:157} INFO - Started process (PID=58478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:15:30.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:15:30.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:15:30.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:15:30.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:15:30.593+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:15:30.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:15:30.603+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:15:30.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:15:30.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T22:16:06.905+0000] {processor.py:157} INFO - Started process (PID=58488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:16:06.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:16:06.909+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:16:06.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:16:06.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:16:06.950+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:16:06.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:16:06.962+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:16:06.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:16:06.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T22:17:08.307+0000] {processor.py:157} INFO - Started process (PID=58498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:17:08.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:17:08.311+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:17:08.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:17:08.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:17:08.354+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:17:08.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:17:08.370+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:17:08.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:17:08.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-11T22:17:38.645+0000] {processor.py:157} INFO - Started process (PID=58508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:17:38.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:17:38.651+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:17:38.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:17:38.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:17:38.689+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:17:38.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:17:38.702+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:17:38.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:17:38.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T22:18:58.591+0000] {processor.py:157} INFO - Started process (PID=58520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:18:58.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:18:58.597+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:18:58.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:18:58.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:18:58.646+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:18:58.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:18:58.661+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:18:58.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:18:58.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-11T22:21:10.650+0000] {processor.py:157} INFO - Started process (PID=58530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:21:10.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:21:10.655+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:21:10.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:21:10.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:21:10.757+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:21:10.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:21:10.784+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:21:10.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:21:10.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-11T22:21:41.004+0000] {processor.py:157} INFO - Started process (PID=58540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:21:41.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:21:41.008+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:21:41.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:21:41.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:21:41.068+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:21:41.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:21:41.080+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:21:41.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:21:41.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T22:23:15.793+0000] {processor.py:157} INFO - Started process (PID=58552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:23:15.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:23:15.804+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:23:15.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:23:15.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:23:15.847+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:23:15.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:23:15.860+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:23:15.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:23:15.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-11T22:23:46.226+0000] {processor.py:157} INFO - Started process (PID=58562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:23:46.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:23:46.230+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:23:46.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:23:46.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:23:46.268+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:23:46.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:23:46.282+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:23:46.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:23:46.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-11T22:26:10.174+0000] {processor.py:157} INFO - Started process (PID=58572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:26:10.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:26:10.176+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:26:10.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:26:10.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:26:10.210+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:26:10.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:26:10.221+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:26:10.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:26:10.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-11T22:27:46.066+0000] {processor.py:157} INFO - Started process (PID=58581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:27:46.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:27:46.079+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:27:46.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:27:46.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:27:46.120+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:27:46.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:27:46.132+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:27:46.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:27:46.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T22:28:16.380+0000] {processor.py:157} INFO - Started process (PID=58592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:28:16.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:28:16.385+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:28:16.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:28:16.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:28:16.404+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:28:16.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:28:16.416+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:28:16.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:28:16.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-11T22:42:26.027+0000] {processor.py:157} INFO - Started process (PID=58602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:42:26.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:42:26.033+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:42:26.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:42:26.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:42:26.079+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:42:26.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:42:26.095+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:42:26.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:42:26.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-11T22:56:52.365+0000] {processor.py:157} INFO - Started process (PID=58611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:56:52.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:56:52.371+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:56:52.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:56:52.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:56:52.410+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:56:52.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:56:52.443+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:56:52.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:56:52.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T22:57:22.896+0000] {processor.py:157} INFO - Started process (PID=58621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:57:22.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:57:22.901+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:57:22.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:57:22.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:57:22.952+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:57:22.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:57:22.967+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:57:22.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:57:22.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-11T22:57:53.326+0000] {processor.py:157} INFO - Started process (PID=58632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:57:53.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:57:53.330+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:57:53.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:57:53.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:57:53.358+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:57:53.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:57:53.378+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:57:53.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:57:53.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-11T22:58:38.454+0000] {processor.py:157} INFO - Started process (PID=58644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:58:38.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:58:38.457+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:58:38.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:58:38.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:58:38.491+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:58:38.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:58:38.503+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:58:38.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:58:38.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-11T22:59:08.791+0000] {processor.py:157} INFO - Started process (PID=58654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:59:08.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:59:08.794+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:59:08.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:59:08.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:59:08.827+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:59:08.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:59:08.838+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:59:08.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:59:08.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-11T22:59:52.157+0000] {processor.py:157} INFO - Started process (PID=58664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:59:52.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T22:59:52.160+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:59:52.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:59:52.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T22:59:52.206+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:59:52.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T22:59:52.222+0000] {logging_mixin.py:151} INFO - [2024-09-11T22:59:52.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T22:59:52.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-11T23:00:22.548+0000] {processor.py:157} INFO - Started process (PID=58674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:00:22.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:00:22.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:00:22.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:00:22.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:00:22.584+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:00:22.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:00:22.594+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:00:22.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:00:22.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-11T23:02:03.159+0000] {processor.py:157} INFO - Started process (PID=58683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:02:03.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:02:03.164+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:02:03.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:02:03.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:02:03.203+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:02:03.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:02:03.215+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:02:03.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:02:03.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-11T23:02:45.480+0000] {processor.py:157} INFO - Started process (PID=58693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:02:45.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:02:45.485+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:02:45.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:02:45.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:02:45.522+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:02:45.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:02:45.551+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:02:45.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:02:45.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-11T23:03:15.832+0000] {processor.py:157} INFO - Started process (PID=58704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:03:15.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:03:15.849+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:03:15.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:03:15.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:03:15.957+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:03:15.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:03:16.006+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:03:16.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:03:16.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-09-11T23:03:53.227+0000] {processor.py:157} INFO - Started process (PID=58714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:03:53.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:03:53.253+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:03:53.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:03:53.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:03:53.313+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:03:53.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:03:53.327+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:03:53.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:03:53.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-11T23:04:23.548+0000] {processor.py:157} INFO - Started process (PID=58724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:04:23.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:04:23.552+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:04:23.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:04:23.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:04:23.613+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:04:23.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:04:23.629+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:04:23.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:04:23.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-11T23:04:56.633+0000] {processor.py:157} INFO - Started process (PID=58734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:04:56.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:04:56.653+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:04:56.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:04:56.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:04:56.694+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:04:56.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:04:56.707+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:04:56.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:04:56.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-11T23:11:40.524+0000] {processor.py:157} INFO - Started process (PID=58744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:11:40.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:11:40.527+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:11:40.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:11:40.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:11:40.554+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:11:40.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:11:40.564+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:11:40.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:11:40.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-11T23:12:10.850+0000] {processor.py:157} INFO - Started process (PID=58754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:12:10.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-11T23:12:10.854+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:12:10.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:12:10.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-11T23:12:10.887+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:12:10.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-11T23:12:10.899+0000] {logging_mixin.py:151} INFO - [2024-09-11T23:12:10.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-11T23:12:10.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
