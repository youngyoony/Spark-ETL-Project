[2024-07-20T00:00:16.308+0000] {processor.py:157} INFO - Started process (PID=85060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:00:16.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:00:16.312+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:16.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:00:16.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:00:16.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:16.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:00:16.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:16.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:00:16.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T00:00:46.882+0000] {processor.py:157} INFO - Started process (PID=85085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:00:46.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:00:46.886+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:46.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:00:46.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:00:46.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:46.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:00:46.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:46.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:00:46.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T00:01:17.334+0000] {processor.py:157} INFO - Started process (PID=85110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:01:17.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:01:17.337+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:17.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:01:17.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:01:17.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:17.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:01:17.377+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:17.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:01:17.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T00:01:47.804+0000] {processor.py:157} INFO - Started process (PID=85135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:01:47.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:01:47.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:47.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:01:47.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:01:47.835+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:47.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:01:47.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:47.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:01:47.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T00:02:18.255+0000] {processor.py:157} INFO - Started process (PID=85160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:02:18.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:02:18.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:18.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:02:18.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:02:18.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:18.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:02:18.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:18.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:02:18.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T00:02:48.670+0000] {processor.py:157} INFO - Started process (PID=85185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:02:48.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:02:48.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:48.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:02:48.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:02:48.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:48.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:02:48.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:48.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:02:48.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T00:03:19.118+0000] {processor.py:157} INFO - Started process (PID=85210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:03:19.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:03:19.121+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:19.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:03:19.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:03:19.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:19.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:03:19.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:19.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:03:19.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T00:03:49.605+0000] {processor.py:157} INFO - Started process (PID=85235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:03:49.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:03:49.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:49.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:03:49.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:03:49.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:49.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:03:49.653+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:49.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:03:49.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T00:04:20.080+0000] {processor.py:157} INFO - Started process (PID=85260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:04:20.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:04:20.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:20.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:04:20.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:04:20.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:20.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:04:20.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:20.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:04:20.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T00:04:50.540+0000] {processor.py:157} INFO - Started process (PID=85285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:04:50.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:04:50.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:50.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:04:50.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:04:50.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:50.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:04:50.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:50.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:04:50.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T00:05:21.088+0000] {processor.py:157} INFO - Started process (PID=85310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:05:21.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:05:21.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:21.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:05:21.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:05:21.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:21.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:05:21.131+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:21.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:05:21.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T00:05:51.562+0000] {processor.py:157} INFO - Started process (PID=85335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:05:51.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:05:51.564+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:51.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:05:51.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:05:51.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:51.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:05:51.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:51.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:05:51.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T00:06:22.005+0000] {processor.py:157} INFO - Started process (PID=85360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:06:22.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:06:22.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:22.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:06:22.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:06:22.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:22.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:06:22.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:22.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:06:22.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T00:06:52.436+0000] {processor.py:157} INFO - Started process (PID=85385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:06:52.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:06:52.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:52.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:06:52.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:06:52.466+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:52.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:06:52.477+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:52.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:06:52.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T00:07:22.925+0000] {processor.py:157} INFO - Started process (PID=85410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:07:22.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:07:22.928+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:22.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:07:22.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:07:22.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:22.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:07:22.967+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:22.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:07:22.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T00:07:53.690+0000] {processor.py:157} INFO - Started process (PID=85435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:07:53.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:07:53.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:53.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:07:53.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:07:53.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:53.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:07:53.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:53.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:07:53.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T00:23:47.842+0000] {processor.py:157} INFO - Started process (PID=85460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:23:47.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:23:47.848+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:23:47.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:23:47.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:23:47.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:23:47.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:23:47.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:23:47.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:23:47.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-20T00:24:18.416+0000] {processor.py:157} INFO - Started process (PID=85487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:24:18.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:24:18.423+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:24:18.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:24:18.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:24:18.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:24:18.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:24:18.469+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:24:18.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:24:18.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T00:40:32.894+0000] {processor.py:157} INFO - Started process (PID=85512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:40:32.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:40:32.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:40:32.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:40:32.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:40:32.926+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:40:32.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:40:32.940+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:40:32.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:40:32.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T00:41:03.339+0000] {processor.py:157} INFO - Started process (PID=85932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:41:03.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:41:03.346+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:03.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:41:03.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:41:03.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:03.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:41:03.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:03.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:41:03.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T00:41:33.816+0000] {processor.py:157} INFO - Started process (PID=85957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:41:33.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:41:33.821+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:33.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:41:33.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:41:33.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:33.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:41:33.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:33.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:41:33.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T00:42:04.210+0000] {processor.py:157} INFO - Started process (PID=85982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:42:04.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:42:04.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:04.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:42:04.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:42:04.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:04.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:42:04.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:04.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:42:04.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T00:42:34.578+0000] {processor.py:157} INFO - Started process (PID=86007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:42:34.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:42:34.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:34.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:42:34.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:42:34.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:34.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:42:34.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:34.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:42:34.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T00:43:04.966+0000] {processor.py:157} INFO - Started process (PID=86035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:43:04.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:43:04.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:43:04.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:43:04.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:43:05.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:43:05.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:43:05.017+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:43:05.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:43:05.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T00:59:29.761+0000] {processor.py:157} INFO - Started process (PID=86061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:59:29.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T00:59:29.766+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:59:29.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:59:29.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T00:59:29.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:59:29.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:59:29.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:59:29.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-20T00:59:29.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-20T01:07:59.218+0000] {processor.py:157} INFO - Started process (PID=86087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:07:59.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:07:59.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:07:59.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:07:59.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:07:59.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:07:59.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:07:59.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:07:59.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:07:59.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T01:08:29.694+0000] {processor.py:157} INFO - Started process (PID=86503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:08:29.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:08:29.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:08:29.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:08:29.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:08:29.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:08:29.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:08:29.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:08:29.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:08:29.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-20T01:24:23.427+0000] {processor.py:157} INFO - Started process (PID=86530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:24:23.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:24:23.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:23.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:24:23.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:24:23.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:23.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:24:23.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:23.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:24:23.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T01:24:53.867+0000] {processor.py:157} INFO - Started process (PID=86555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:24:53.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:24:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:53.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:24:53.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:24:53.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:53.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:24:53.928+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:53.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:24:53.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T01:25:24.380+0000] {processor.py:157} INFO - Started process (PID=86580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:25:24.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:25:24.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:24.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:25:24.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:25:24.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:24.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:25:24.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:24.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:25:24.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T01:25:54.855+0000] {processor.py:157} INFO - Started process (PID=86605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:25:54.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:25:54.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:54.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:25:54.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:25:54.893+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:54.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:25:54.903+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:54.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:25:54.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T01:26:25.291+0000] {processor.py:157} INFO - Started process (PID=86630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:26:25.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:26:25.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:26:25.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:26:25.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:26:25.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:26:25.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:26:25.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:26:25.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:26:25.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T01:43:02.854+0000] {processor.py:157} INFO - Started process (PID=86657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:43:02.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:43:02.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:02.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:43:02.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:43:02.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:02.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:43:02.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:02.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:43:02.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-20T01:43:33.509+0000] {processor.py:157} INFO - Started process (PID=86682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:43:33.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:43:33.511+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:33.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:43:33.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:43:33.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:33.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:43:33.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:33.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:43:33.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T01:44:03.927+0000] {processor.py:157} INFO - Started process (PID=86707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:44:03.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:44:03.930+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:03.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:44:03.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:44:03.963+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:03.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:44:03.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:03.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:44:03.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T01:44:34.409+0000] {processor.py:157} INFO - Started process (PID=86732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:44:34.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:44:34.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:34.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:44:34.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:44:34.448+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:34.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:44:34.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:34.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:44:34.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T01:45:04.934+0000] {processor.py:157} INFO - Started process (PID=86757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:45:04.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:45:04.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:45:04.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:45:04.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:45:04.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:45:04.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:45:04.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:45:04.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:45:05.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-20T01:59:14.212+0000] {processor.py:157} INFO - Started process (PID=86783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:59:14.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:59:14.215+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:14.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:59:14.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:59:14.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:14.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:59:14.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:14.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:59:14.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T01:59:44.679+0000] {processor.py:157} INFO - Started process (PID=86808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:59:44.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T01:59:44.683+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:44.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:59:44.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T01:59:44.731+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:44.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:59:44.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:44.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T01:59:44.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-20T02:00:15.226+0000] {processor.py:157} INFO - Started process (PID=86834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:00:15.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:00:15.228+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:15.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:00:15.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:00:15.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:15.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:00:15.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:15.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:00:15.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T02:00:45.637+0000] {processor.py:157} INFO - Started process (PID=86859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:00:45.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:00:45.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:45.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:00:45.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:00:45.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:45.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:00:45.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:45.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:00:45.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T02:01:16.142+0000] {processor.py:157} INFO - Started process (PID=86884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:01:16.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:01:16.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:16.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:01:16.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:01:16.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:16.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:01:16.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:16.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:01:16.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T02:01:46.690+0000] {processor.py:157} INFO - Started process (PID=86909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:01:46.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:01:46.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:46.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:01:46.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:01:46.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:46.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:01:46.739+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:46.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:01:46.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T02:02:17.151+0000] {processor.py:157} INFO - Started process (PID=86934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:02:17.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:02:17.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:02:17.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:02:17.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:02:17.183+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:02:17.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:02:17.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:02:17.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:02:17.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T02:08:55.510+0000] {processor.py:157} INFO - Started process (PID=86959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:08:55.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:08:55.513+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:08:55.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:08:55.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:08:55.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:08:55.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:08:55.559+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:08:55.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:08:55.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T02:09:26.049+0000] {processor.py:157} INFO - Started process (PID=86984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:09:26.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:09:26.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:26.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:09:26.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:09:26.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:26.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:09:26.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:26.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:09:26.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T02:09:56.608+0000] {processor.py:157} INFO - Started process (PID=87009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:09:56.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:09:56.610+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:56.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:09:56.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:09:56.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:56.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:09:56.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:56.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:09:56.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T02:10:27.029+0000] {processor.py:157} INFO - Started process (PID=87034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:10:27.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:10:27.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:27.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:10:27.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:10:27.065+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:27.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:10:27.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:27.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:10:27.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T02:10:57.494+0000] {processor.py:157} INFO - Started process (PID=87059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:10:57.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:10:57.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:57.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:10:57.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:10:57.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:57.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:10:57.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:57.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:10:57.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T02:11:27.970+0000] {processor.py:157} INFO - Started process (PID=87084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:11:27.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:11:27.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:27.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:11:27.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:11:28.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:28.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:11:28.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:28.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:11:28.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T02:11:58.464+0000] {processor.py:157} INFO - Started process (PID=87109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:11:58.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:11:58.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:58.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:11:58.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:11:58.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:58.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:11:58.504+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:58.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:11:58.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T02:12:28.870+0000] {processor.py:157} INFO - Started process (PID=87134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:12:28.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:12:28.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:12:28.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:12:28.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:12:28.900+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:12:28.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:12:28.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:12:28.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:12:28.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T02:29:53.960+0000] {processor.py:157} INFO - Started process (PID=87161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:29:53.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:29:53.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:29:53.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:29:53.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:29:53.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:29:53.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:29:54.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:29:54.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:29:54.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T02:30:24.440+0000] {processor.py:157} INFO - Started process (PID=87186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:30:24.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:30:24.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:24.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:30:24.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:30:24.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:24.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:30:24.482+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:24.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:30:24.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T02:30:54.862+0000] {processor.py:157} INFO - Started process (PID=87211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:30:54.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:30:54.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:54.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:30:54.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:30:54.893+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:54.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:30:54.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:54.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:30:54.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T02:31:25.356+0000] {processor.py:157} INFO - Started process (PID=87236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:31:25.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:31:25.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:25.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:31:25.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:31:25.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:25.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:31:25.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:25.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:31:25.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T02:31:55.764+0000] {processor.py:157} INFO - Started process (PID=87261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:31:55.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:31:55.766+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:55.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:31:55.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:31:55.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:55.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:31:55.804+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:55.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:31:55.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T02:32:26.249+0000] {processor.py:157} INFO - Started process (PID=87286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:32:26.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:32:26.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:26.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:32:26.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:32:26.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:26.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:32:26.287+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:26.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:32:26.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T02:32:56.701+0000] {processor.py:157} INFO - Started process (PID=87311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:32:56.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:32:56.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:56.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:32:56.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:32:56.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:56.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:32:56.746+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:56.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:32:56.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T02:33:27.156+0000] {processor.py:157} INFO - Started process (PID=87336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:33:27.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:33:27.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:27.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:33:27.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:33:27.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:27.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:33:27.201+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:27.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:33:27.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T02:33:57.619+0000] {processor.py:157} INFO - Started process (PID=87361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:33:57.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:33:57.622+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:57.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:33:57.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:33:57.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:57.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:33:57.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:57.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:33:57.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T02:34:28.056+0000] {processor.py:157} INFO - Started process (PID=87386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:34:28.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:34:28.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:28.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:34:28.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:34:28.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:28.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:34:28.097+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:28.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:34:28.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T02:34:58.560+0000] {processor.py:157} INFO - Started process (PID=87411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:34:58.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:34:58.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:58.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:34:58.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:34:58.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:58.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:34:58.599+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:58.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:34:58.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T02:35:29.011+0000] {processor.py:157} INFO - Started process (PID=87436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:35:29.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:35:29.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:29.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:35:29.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:35:29.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:29.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:35:29.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:29.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:35:29.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T02:35:59.493+0000] {processor.py:157} INFO - Started process (PID=87461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:35:59.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:35:59.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:59.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:35:59.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:35:59.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:59.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:35:59.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:59.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:35:59.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T02:36:29.909+0000] {processor.py:157} INFO - Started process (PID=87486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:36:29.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:36:29.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:36:29.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:36:29.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:36:29.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:36:29.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:36:29.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:36:29.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:36:29.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T02:37:00.341+0000] {processor.py:157} INFO - Started process (PID=87511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:37:00.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:37:00.346+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:00.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:37:00.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:37:00.375+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:00.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:37:00.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:00.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:37:00.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T02:37:30.754+0000] {processor.py:157} INFO - Started process (PID=87536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:37:30.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:37:30.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:30.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:37:30.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:37:30.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:30.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:37:30.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:30.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:37:30.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T02:43:52.398+0000] {processor.py:157} INFO - Started process (PID=87563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:43:52.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:43:52.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:43:52.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:43:52.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:43:52.448+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:43:52.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:43:52.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:43:52.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:43:52.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T02:44:23.083+0000] {processor.py:157} INFO - Started process (PID=87588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:44:23.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:44:23.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:44:23.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:44:23.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:44:23.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:44:23.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:44:23.126+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:44:23.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:44:23.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T02:51:04.592+0000] {processor.py:157} INFO - Started process (PID=87613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:51:04.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:51:04.594+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:04.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:51:04.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:51:04.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:04.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:51:04.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:04.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:51:04.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T02:51:35.078+0000] {processor.py:157} INFO - Started process (PID=87638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:51:35.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T02:51:35.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:35.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:51:35.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T02:51:35.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:35.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:51:35.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:35.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T02:51:35.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-20T03:08:30.706+0000] {processor.py:157} INFO - Started process (PID=87665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:08:30.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:08:30.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:08:30.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:08:30.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:08:30.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:08:30.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:08:30.744+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:08:30.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:08:30.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T03:09:01.114+0000] {processor.py:157} INFO - Started process (PID=87689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:09:01.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:09:01.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:09:01.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:09:01.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:09:01.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:09:01.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:09:01.181+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:09:01.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:09:01.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-20T03:10:28.882+0000] {processor.py:157} INFO - Started process (PID=87715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:10:28.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:10:28.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:10:28.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:10:28.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:10:28.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:10:28.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:10:28.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:10:28.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:10:28.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T03:25:56.866+0000] {processor.py:157} INFO - Started process (PID=87739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:25:56.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:25:56.870+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:25:56.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:25:56.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:25:56.928+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:25:56.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:25:56.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:25:56.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:25:56.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T03:26:27.564+0000] {processor.py:157} INFO - Started process (PID=87765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:26:27.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:26:27.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:26:27.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:26:27.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:26:27.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:26:27.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:26:27.610+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:26:27.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:26:27.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T03:27:25.786+0000] {processor.py:157} INFO - Started process (PID=87792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:27:25.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:27:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:27:25.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:27:25.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:27:25.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:27:25.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:27:25.843+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:27:25.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:27:25.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T03:42:54.522+0000] {processor.py:157} INFO - Started process (PID=87817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:42:54.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:42:54.533+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:42:54.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:42:54.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:42:54.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:42:54.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:42:54.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:42:54.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:42:54.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-20T03:43:25.139+0000] {processor.py:157} INFO - Started process (PID=87841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:43:25.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:43:25.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:25.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:43:25.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:43:25.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:25.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:43:25.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:25.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:43:25.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-20T03:43:55.651+0000] {processor.py:157} INFO - Started process (PID=87867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:43:55.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:43:55.653+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:55.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:43:55.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:43:55.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:55.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:43:55.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:55.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:43:55.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T03:44:26.142+0000] {processor.py:157} INFO - Started process (PID=87892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:44:26.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:44:26.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:26.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:44:26.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:44:26.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:26.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:44:26.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:26.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:44:26.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T03:44:56.629+0000] {processor.py:157} INFO - Started process (PID=87917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:44:56.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:44:56.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:56.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:44:56.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:44:56.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:56.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:44:56.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:56.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:44:56.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T03:45:27.075+0000] {processor.py:157} INFO - Started process (PID=87942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:45:27.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:45:27.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:45:27.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:45:27.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:45:27.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:45:27.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:45:27.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:45:27.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:45:27.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T03:53:25.184+0000] {processor.py:157} INFO - Started process (PID=87969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:53:25.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:53:25.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:25.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:53:25.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:53:25.252+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:25.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:53:25.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:25.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:53:25.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-20T03:53:55.766+0000] {processor.py:157} INFO - Started process (PID=87994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:53:55.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:53:55.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:55.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:53:55.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:53:55.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:55.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:53:55.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:55.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:53:55.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T03:54:26.292+0000] {processor.py:157} INFO - Started process (PID=88019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:54:26.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:54:26.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:26.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:54:26.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:54:26.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:26.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:54:26.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:26.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:54:26.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T03:54:56.779+0000] {processor.py:157} INFO - Started process (PID=88044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:54:56.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:54:56.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:56.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:54:56.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:54:56.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:56.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:54:56.820+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:56.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:54:56.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T03:55:27.184+0000] {processor.py:157} INFO - Started process (PID=88069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:55:27.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:55:27.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:27.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:55:27.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:55:27.214+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:27.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:55:27.224+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:27.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:55:27.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T03:55:57.643+0000] {processor.py:157} INFO - Started process (PID=88094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:55:57.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:55:57.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:57.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:55:57.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:55:57.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:57.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:55:57.682+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:57.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:55:57.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T03:56:28.115+0000] {processor.py:157} INFO - Started process (PID=88119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:56:28.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:56:28.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:28.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:56:28.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:56:28.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:28.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:56:28.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:28.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:56:28.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T03:56:58.583+0000] {processor.py:157} INFO - Started process (PID=88144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:56:58.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:56:58.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:58.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:56:58.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:56:58.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:58.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:56:58.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:58.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:56:58.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T03:57:29.088+0000] {processor.py:157} INFO - Started process (PID=88169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:57:29.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:57:29.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:29.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:57:29.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:57:29.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:29.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:57:29.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:29.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:57:29.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T03:57:59.535+0000] {processor.py:157} INFO - Started process (PID=88194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:57:59.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:57:59.538+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:59.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:57:59.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:57:59.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:59.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:57:59.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:59.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:57:59.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T03:58:30.041+0000] {processor.py:157} INFO - Started process (PID=88219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:58:30.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:58:30.044+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:58:30.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:58:30.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:58:30.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:58:30.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:58:30.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:58:30.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:58:30.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T03:59:00.577+0000] {processor.py:157} INFO - Started process (PID=88244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:59:00.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:59:00.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:00.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:59:00.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:59:00.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:00.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:59:00.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:00.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:59:00.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T03:59:31.065+0000] {processor.py:157} INFO - Started process (PID=88269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:59:31.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T03:59:31.069+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:31.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:59:31.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T03:59:31.105+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:31.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:59:31.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:31.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T03:59:31.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T04:00:01.575+0000] {processor.py:157} INFO - Started process (PID=88294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:00:01.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:00:01.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:01.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:00:01.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:00:01.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:01.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:00:01.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:01.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:00:01.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:00:31.966+0000] {processor.py:157} INFO - Started process (PID=88319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:00:31.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:00:31.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:31.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:00:31.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:00:31.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:31.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:00:32.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:32.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:00:32.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:01:02.388+0000] {processor.py:157} INFO - Started process (PID=88344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:01:02.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:01:02.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:02.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:01:02.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:01:02.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:02.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:01:02.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:02.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:01:02.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:01:32.880+0000] {processor.py:157} INFO - Started process (PID=88369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:01:32.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:01:32.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:32.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:01:32.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:01:32.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:32.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:01:32.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:32.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:01:32.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:02:03.287+0000] {processor.py:157} INFO - Started process (PID=88394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:02:03.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:02:03.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:03.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:02:03.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:02:03.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:03.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:02:03.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:03.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:02:03.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:02:33.739+0000] {processor.py:157} INFO - Started process (PID=88419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:02:33.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:02:33.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:33.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:02:33.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:02:33.773+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:33.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:02:33.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:33.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:02:33.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:03:04.178+0000] {processor.py:157} INFO - Started process (PID=88444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:03:04.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:03:04.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:04.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:03:04.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:03:04.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:04.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:03:04.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:04.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:03:04.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T04:03:34.620+0000] {processor.py:157} INFO - Started process (PID=88469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:03:34.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:03:34.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:34.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:03:34.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:03:34.650+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:34.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:03:34.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:34.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:03:34.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T04:04:05.066+0000] {processor.py:157} INFO - Started process (PID=88494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:04:05.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:04:05.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:05.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:04:05.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:04:05.097+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:05.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:04:05.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:05.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:04:05.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:04:35.528+0000] {processor.py:157} INFO - Started process (PID=88519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:04:35.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:04:35.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:35.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:04:35.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:04:35.561+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:35.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:04:35.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:35.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:04:35.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:05:06.042+0000] {processor.py:157} INFO - Started process (PID=88544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:05:06.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:05:06.046+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:06.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:05:06.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:05:06.074+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:06.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:05:06.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:06.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:05:06.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:05:36.491+0000] {processor.py:157} INFO - Started process (PID=88569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:05:36.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:05:36.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:36.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:05:36.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:05:36.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:36.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:05:36.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:36.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:05:36.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T04:06:06.897+0000] {processor.py:157} INFO - Started process (PID=88594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:06:06.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:06:06.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:06.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:06:06.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:06:06.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:06.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:06:06.936+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:06.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:06:06.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T04:06:37.395+0000] {processor.py:157} INFO - Started process (PID=88619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:06:37.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:06:37.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:37.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:06:37.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:06:37.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:37.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:06:37.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:37.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:06:37.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:07:07.904+0000] {processor.py:157} INFO - Started process (PID=88644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:07:07.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:07:07.906+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:07.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:07:07.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:07:07.938+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:07.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:07:07.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:07.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:07:07.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:07:38.324+0000] {processor.py:157} INFO - Started process (PID=88669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:07:38.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:07:38.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:38.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:07:38.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:07:38.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:38.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:07:38.362+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:38.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:07:38.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T04:08:08.797+0000] {processor.py:157} INFO - Started process (PID=88694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:08:08.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:08:08.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:08.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:08:08.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:08:08.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:08.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:08:08.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:08.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:08:08.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:08:39.306+0000] {processor.py:157} INFO - Started process (PID=88719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:08:39.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:08:39.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:39.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:08:39.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:08:39.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:39.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:08:39.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:39.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:08:39.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:09:09.799+0000] {processor.py:157} INFO - Started process (PID=88744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:09:09.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:09:09.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:09:09.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:09:09.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:09:09.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:09:09.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:09:09.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:09:09.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:09:09.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:16:17.797+0000] {processor.py:157} INFO - Started process (PID=88768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:16:17.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:16:17.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:17.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:16:17.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:16:17.870+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:17.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:16:17.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:17.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:16:17.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-20T04:16:48.489+0000] {processor.py:157} INFO - Started process (PID=88796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:16:48.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:16:48.495+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:48.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:16:48.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:16:48.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:48.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:16:48.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:48.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:16:48.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-20T04:17:18.993+0000] {processor.py:157} INFO - Started process (PID=88821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:17:18.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:17:18.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:18.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:17:19.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:17:19.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:19.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:17:19.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:19.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:17:19.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:17:49.396+0000] {processor.py:157} INFO - Started process (PID=88846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:17:49.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:17:49.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:49.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:17:49.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:17:49.435+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:49.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:17:49.447+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:49.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:17:49.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T04:18:19.868+0000] {processor.py:157} INFO - Started process (PID=88871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:18:19.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:18:19.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:19.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:18:19.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:18:19.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:19.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:18:19.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:19.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:18:19.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:18:50.312+0000] {processor.py:157} INFO - Started process (PID=88896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:18:50.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:18:50.316+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:50.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:18:50.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:18:50.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:50.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:18:50.357+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:50.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:18:50.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T04:19:20.687+0000] {processor.py:157} INFO - Started process (PID=88921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:19:20.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:19:20.689+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:20.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:19:20.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:19:20.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:20.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:19:20.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:20.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:19:20.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T04:19:51.087+0000] {processor.py:157} INFO - Started process (PID=88946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:19:51.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:19:51.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:51.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:19:51.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:19:51.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:51.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:19:51.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:51.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:19:51.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:20:21.511+0000] {processor.py:157} INFO - Started process (PID=88971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:20:21.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:20:21.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:21.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:20:21.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:20:21.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:21.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:20:21.549+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:21.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:20:21.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:20:51.972+0000] {processor.py:157} INFO - Started process (PID=88996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:20:51.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:20:51.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:51.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:20:51.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:20:52.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:52.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:20:52.018+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:52.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:20:52.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T04:21:22.410+0000] {processor.py:157} INFO - Started process (PID=89021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:21:22.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:21:22.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:22.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:21:22.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:21:22.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:22.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:21:22.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:22.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:21:22.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T04:21:52.822+0000] {processor.py:157} INFO - Started process (PID=89046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:21:52.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:21:52.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:52.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:21:52.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:21:52.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:52.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:21:52.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:52.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:21:52.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T04:22:23.185+0000] {processor.py:157} INFO - Started process (PID=89071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:22:23.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:22:23.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:23.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:22:23.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:22:23.211+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:23.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:22:23.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:23.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:22:23.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T04:22:53.539+0000] {processor.py:157} INFO - Started process (PID=89096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:22:53.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:22:53.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:53.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:22:53.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:22:53.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:53.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:22:53.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:53.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:22:53.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:23:23.939+0000] {processor.py:157} INFO - Started process (PID=89121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:23:23.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:23:23.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:23.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:23:23.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:23:23.971+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:23.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:23:23.984+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:23.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:23:23.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T04:23:54.327+0000] {processor.py:157} INFO - Started process (PID=89146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:23:54.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:23:54.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:54.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:23:54.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:23:54.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:54.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:23:54.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:54.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:23:54.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:24:24.748+0000] {processor.py:157} INFO - Started process (PID=89171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:24:24.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:24:24.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:24.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:24:24.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:24:24.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:24.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:24:24.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:24.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:24:24.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:24:55.182+0000] {processor.py:157} INFO - Started process (PID=89196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:24:55.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:24:55.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:55.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:24:55.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:24:55.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:55.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:24:55.224+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:55.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:24:55.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:25:25.567+0000] {processor.py:157} INFO - Started process (PID=89221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:25:25.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:25:25.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:25.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:25:25.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:25:25.596+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:25.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:25:25.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:25.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:25:25.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T04:25:55.988+0000] {processor.py:157} INFO - Started process (PID=89246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:25:55.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:25:55.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:55.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:25:56.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:25:56.018+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:56.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:25:56.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:56.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:25:56.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:26:26.454+0000] {processor.py:157} INFO - Started process (PID=89271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:26:26.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:26:26.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:26.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:26:26.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:26:26.482+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:26.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:26:26.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:26.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:26:26.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T04:26:56.859+0000] {processor.py:157} INFO - Started process (PID=89296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:26:56.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:26:56.862+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:56.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:26:56.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:26:56.891+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:56.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:26:56.903+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:56.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:26:56.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:27:27.318+0000] {processor.py:157} INFO - Started process (PID=89321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:27:27.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:27:27.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:27.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:27:27.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:27:27.348+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:27.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:27:27.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:27.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:27:27.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:27:57.747+0000] {processor.py:157} INFO - Started process (PID=89346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:27:57.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:27:57.751+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:57.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:27:57.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:27:57.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:57.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:27:57.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:57.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:27:57.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T04:28:28.217+0000] {processor.py:157} INFO - Started process (PID=89371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:28:28.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:28:28.220+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:28.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:28:28.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:28:28.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:28.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:28:28.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:28.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:28:28.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T04:28:58.662+0000] {processor.py:157} INFO - Started process (PID=89396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:28:58.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:28:58.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:58.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:28:58.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:28:58.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:58.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:28:58.702+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:58.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:28:58.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:29:29.070+0000] {processor.py:157} INFO - Started process (PID=89421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:29:29.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:29:29.074+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:29.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:29:29.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:29:29.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:29.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:29:29.111+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:29.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:29:29.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:29:59.469+0000] {processor.py:157} INFO - Started process (PID=89446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:29:59.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:29:59.473+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:59.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:29:59.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:29:59.504+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:59.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:29:59.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:59.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:29:59.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:30:29.934+0000] {processor.py:157} INFO - Started process (PID=89471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:30:29.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:30:29.937+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:30:29.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:30:29.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:30:29.967+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:30:29.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:30:29.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:30:29.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:30:29.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:31:00.377+0000] {processor.py:157} INFO - Started process (PID=89496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:31:00.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:31:00.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:00.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:31:00.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:31:00.412+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:00.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:31:00.423+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:00.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:31:00.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T04:31:30.787+0000] {processor.py:157} INFO - Started process (PID=89521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:31:30.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:31:30.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:30.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:31:30.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:31:30.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:30.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:31:30.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:30.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:31:30.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:32:01.214+0000] {processor.py:157} INFO - Started process (PID=89546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:32:01.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:32:01.219+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:01.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:32:01.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:32:01.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:01.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:32:01.261+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:01.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:32:01.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:32:31.682+0000] {processor.py:157} INFO - Started process (PID=89571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:32:31.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:32:31.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:31.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:32:31.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:32:31.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:31.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:32:31.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:31.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:32:31.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:33:02.129+0000] {processor.py:157} INFO - Started process (PID=89596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:33:02.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:33:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:02.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:33:02.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:33:02.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:02.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:33:02.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:02.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:33:02.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:33:32.571+0000] {processor.py:157} INFO - Started process (PID=89621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:33:32.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:33:32.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:32.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:33:32.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:33:32.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:32.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:33:32.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:32.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:33:32.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:34:02.983+0000] {processor.py:157} INFO - Started process (PID=89646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:34:02.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:34:02.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:02.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:34:02.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:34:03.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:03.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:34:03.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:03.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:34:03.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:34:33.388+0000] {processor.py:157} INFO - Started process (PID=89671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:34:33.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:34:33.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:33.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:34:33.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:34:33.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:33.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:34:33.425+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:33.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:34:33.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T04:35:03.809+0000] {processor.py:157} INFO - Started process (PID=89696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:35:03.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:35:03.812+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:03.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:35:03.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:35:03.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:03.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:35:03.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:03.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:35:03.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:35:34.237+0000] {processor.py:157} INFO - Started process (PID=89721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:35:34.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:35:34.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:34.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:35:34.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:35:34.267+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:34.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:35:34.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:34.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:35:34.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:36:04.688+0000] {processor.py:157} INFO - Started process (PID=89746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:36:04.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:36:04.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:04.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:36:04.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:36:04.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:04.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:36:04.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:04.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:36:04.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T04:36:35.170+0000] {processor.py:157} INFO - Started process (PID=89771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:36:35.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:36:35.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:35.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:36:35.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:36:35.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:35.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:36:35.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:35.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:36:35.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:37:05.586+0000] {processor.py:157} INFO - Started process (PID=89796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:37:05.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:37:05.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:05.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:37:05.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:37:05.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:05.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:37:05.626+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:05.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:37:05.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:37:36.351+0000] {processor.py:157} INFO - Started process (PID=89821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:37:36.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:37:36.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:36.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:37:36.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:37:36.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:36.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:37:36.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:36.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:37:36.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-20T04:38:06.854+0000] {processor.py:157} INFO - Started process (PID=89846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:38:06.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:38:06.857+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:06.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:38:06.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:38:06.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:06.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:38:06.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:06.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:38:06.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:38:37.298+0000] {processor.py:157} INFO - Started process (PID=89871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:38:37.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:38:37.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:37.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:38:37.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:38:37.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:37.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:38:37.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:37.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:38:37.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:39:07.720+0000] {processor.py:157} INFO - Started process (PID=89896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:39:07.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:39:07.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:07.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:39:07.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:39:07.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:07.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:39:07.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:07.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:39:07.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T04:39:38.130+0000] {processor.py:157} INFO - Started process (PID=89921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:39:38.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:39:38.133+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:38.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:39:38.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:39:38.162+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:38.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:39:38.172+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:38.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:39:38.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:40:08.549+0000] {processor.py:157} INFO - Started process (PID=89946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:40:08.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:40:08.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:08.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:40:08.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:40:08.629+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:08.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:40:08.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:08.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:40:08.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-20T04:40:39.085+0000] {processor.py:157} INFO - Started process (PID=89971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:40:39.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:40:39.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:39.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:40:39.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:40:39.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:39.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:40:39.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:39.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:40:39.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:41:09.527+0000] {processor.py:157} INFO - Started process (PID=89996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:41:09.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:41:09.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:09.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:41:09.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:41:09.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:09.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:41:09.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:09.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:41:09.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:41:39.992+0000] {processor.py:157} INFO - Started process (PID=90021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:41:39.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:41:39.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:39.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:41:40.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:41:40.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:40.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:41:40.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:40.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:41:40.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:42:10.358+0000] {processor.py:157} INFO - Started process (PID=90046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:42:10.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:42:10.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:10.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:42:10.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:42:10.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:10.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:42:10.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:10.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:42:10.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:42:40.813+0000] {processor.py:157} INFO - Started process (PID=90071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:42:40.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:42:40.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:40.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:42:40.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:42:40.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:40.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:42:40.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:40.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:42:40.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T04:43:11.263+0000] {processor.py:157} INFO - Started process (PID=90096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:43:11.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:43:11.267+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:11.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:43:11.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:43:11.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:11.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:43:11.306+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:11.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:43:11.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:43:41.646+0000] {processor.py:157} INFO - Started process (PID=90121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:43:41.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:43:41.650+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:41.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:43:41.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:43:41.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:41.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:43:41.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:41.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:43:41.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T04:44:12.160+0000] {processor.py:157} INFO - Started process (PID=90146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:44:12.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:44:12.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:12.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:44:12.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:44:12.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:12.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:44:12.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:12.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:44:12.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T04:44:42.703+0000] {processor.py:157} INFO - Started process (PID=90171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:44:42.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:44:42.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:42.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:44:42.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:44:42.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:42.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:44:42.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:42.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:44:42.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-20T04:45:13.243+0000] {processor.py:157} INFO - Started process (PID=90196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:45:13.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:45:13.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:13.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:45:13.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:45:13.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:13.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:45:13.312+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:13.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:45:13.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-20T04:45:43.735+0000] {processor.py:157} INFO - Started process (PID=90221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:45:43.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:45:43.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:43.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:45:43.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:45:43.786+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:43.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:45:43.804+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:43.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:45:43.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-20T04:46:14.215+0000] {processor.py:157} INFO - Started process (PID=90246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:46:14.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:46:14.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:14.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:46:14.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:46:14.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:14.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:46:14.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:14.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:46:14.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:46:44.656+0000] {processor.py:157} INFO - Started process (PID=90271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:46:44.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:46:44.658+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:44.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:46:44.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:46:44.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:44.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:46:44.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:44.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:46:44.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:47:15.048+0000] {processor.py:157} INFO - Started process (PID=90296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:47:15.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:47:15.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:15.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:47:15.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:47:15.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:15.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:47:15.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:15.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:47:15.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T04:47:45.463+0000] {processor.py:157} INFO - Started process (PID=90321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:47:45.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:47:45.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:45.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:47:45.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:47:45.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:45.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:47:45.522+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:45.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:47:45.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T04:48:15.859+0000] {processor.py:157} INFO - Started process (PID=90346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:48:15.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:48:15.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:15.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:48:15.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:48:15.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:15.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:48:15.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:15.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:48:15.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T04:48:46.307+0000] {processor.py:157} INFO - Started process (PID=90371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:48:46.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:48:46.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:46.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:48:46.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:48:46.338+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:46.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:48:46.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:46.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:48:46.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:49:16.726+0000] {processor.py:157} INFO - Started process (PID=90396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:49:16.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:49:16.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:16.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:49:16.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:49:16.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:16.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:49:16.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:16.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:49:16.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:49:47.173+0000] {processor.py:157} INFO - Started process (PID=90421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:49:47.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:49:47.177+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:47.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:49:47.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:49:47.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:47.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:49:47.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:47.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:49:47.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T04:50:17.615+0000] {processor.py:157} INFO - Started process (PID=90446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:50:17.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:50:17.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:17.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:50:17.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:50:17.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:17.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:50:17.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:17.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:50:17.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:50:47.927+0000] {processor.py:157} INFO - Started process (PID=90471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:50:47.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:50:47.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:47.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:50:47.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:50:47.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:47.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:50:47.971+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:47.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:50:47.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T04:51:18.369+0000] {processor.py:157} INFO - Started process (PID=90496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:51:18.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:51:18.373+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:18.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:51:18.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:51:18.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:18.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:51:18.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:18.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:51:18.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:51:48.798+0000] {processor.py:157} INFO - Started process (PID=90520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:51:48.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:51:48.804+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:48.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:51:48.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:51:48.850+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:48.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:51:48.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:48.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:51:48.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T04:52:19.216+0000] {processor.py:157} INFO - Started process (PID=90546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:52:19.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:52:19.219+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:19.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:52:19.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:52:19.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:19.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:52:19.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:19.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:52:19.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:52:49.644+0000] {processor.py:157} INFO - Started process (PID=90571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:52:49.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:52:49.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:49.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:52:49.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:52:49.677+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:49.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:52:49.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:49.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:52:49.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T04:53:20.084+0000] {processor.py:157} INFO - Started process (PID=90596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:53:20.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:53:20.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:20.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:53:20.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:53:20.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:20.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:53:20.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:20.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:53:20.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:53:50.524+0000] {processor.py:157} INFO - Started process (PID=90621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:53:50.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:53:50.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:50.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:53:50.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:53:50.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:50.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:53:50.568+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:50.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:53:50.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T04:54:20.921+0000] {processor.py:157} INFO - Started process (PID=90646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:54:20.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:54:20.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:20.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:54:20.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:54:20.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:20.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:54:20.965+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:20.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:54:20.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T04:54:51.336+0000] {processor.py:157} INFO - Started process (PID=90671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:54:51.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:54:51.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:51.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:54:51.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:54:51.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:51.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:54:51.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:51.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:54:51.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T04:55:21.776+0000] {processor.py:157} INFO - Started process (PID=90696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:55:21.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:55:21.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:21.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:55:21.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:55:21.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:21.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:55:21.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:21.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:55:21.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:55:52.218+0000] {processor.py:157} INFO - Started process (PID=90721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:55:52.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:55:52.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:52.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:55:52.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:55:52.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:52.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:55:52.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:52.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:55:52.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T04:56:22.633+0000] {processor.py:157} INFO - Started process (PID=90746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:56:22.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:56:22.637+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:22.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:56:22.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:56:22.666+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:22.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:56:22.677+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:22.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:56:22.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:56:53.020+0000] {processor.py:157} INFO - Started process (PID=90771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:56:53.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:56:53.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:53.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:56:53.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:56:53.049+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:53.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:56:53.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:53.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:56:53.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:57:23.469+0000] {processor.py:157} INFO - Started process (PID=90796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:57:23.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:57:23.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:23.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:57:23.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:57:23.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:23.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:57:23.510+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:23.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:57:23.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:57:53.839+0000] {processor.py:157} INFO - Started process (PID=90821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:57:53.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:57:53.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:53.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:57:53.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:57:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:53.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:57:53.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:53.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:57:53.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T04:58:24.282+0000] {processor.py:157} INFO - Started process (PID=90846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:58:24.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:58:24.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:24.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:58:24.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:58:24.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:24.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:58:24.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:24.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:58:24.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:58:54.717+0000] {processor.py:157} INFO - Started process (PID=90871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:58:54.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:58:54.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:54.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:58:54.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:58:54.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:54.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:58:54.759+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:54.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:58:54.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T04:59:25.111+0000] {processor.py:157} INFO - Started process (PID=90896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:59:25.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:59:25.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:25.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:59:25.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:59:25.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:25.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:59:25.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:25.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:59:25.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T04:59:55.563+0000] {processor.py:157} INFO - Started process (PID=90921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:59:55.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T04:59:55.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:55.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:59:55.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T04:59:55.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:55.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:59:55.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:55.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T04:59:55.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:00:25.972+0000] {processor.py:157} INFO - Started process (PID=90946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:00:25.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:00:25.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:25.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:00:25.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:00:26.014+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:26.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:00:26.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:26.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:00:26.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T05:00:56.408+0000] {processor.py:157} INFO - Started process (PID=90971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:00:56.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:00:56.411+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:56.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:00:56.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:00:56.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:56.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:00:56.455+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:56.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:00:56.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T05:01:26.825+0000] {processor.py:157} INFO - Started process (PID=90996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:01:26.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:01:26.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:26.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:01:26.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:01:26.857+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:26.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:01:26.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:26.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:01:26.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:01:57.258+0000] {processor.py:157} INFO - Started process (PID=91021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:01:57.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:01:57.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:57.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:01:57.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:01:57.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:57.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:01:57.313+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:57.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:01:57.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-20T05:02:27.735+0000] {processor.py:157} INFO - Started process (PID=91046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:02:27.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:02:27.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:27.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:02:27.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:02:27.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:27.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:02:27.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:27.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:02:27.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:02:58.150+0000] {processor.py:157} INFO - Started process (PID=91071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:02:58.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:02:58.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:58.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:02:58.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:02:58.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:58.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:02:58.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:58.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:02:58.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:03:28.586+0000] {processor.py:157} INFO - Started process (PID=91096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:03:28.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:03:28.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:28.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:03:28.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:03:28.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:28.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:03:28.625+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:28.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:03:28.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T05:03:59.000+0000] {processor.py:157} INFO - Started process (PID=91121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:03:59.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:03:59.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:59.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:03:59.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:03:59.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:59.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:03:59.039+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:59.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:03:59.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:04:29.437+0000] {processor.py:157} INFO - Started process (PID=91146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:04:29.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:04:29.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:29.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:04:29.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:04:29.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:29.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:04:29.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:29.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:04:29.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:04:59.875+0000] {processor.py:157} INFO - Started process (PID=91171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:04:59.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:04:59.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:59.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:04:59.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:04:59.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:59.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:04:59.915+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:59.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:04:59.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:05:30.300+0000] {processor.py:157} INFO - Started process (PID=91196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:05:30.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:05:30.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:05:30.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:05:30.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:05:30.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:05:30.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:05:30.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:05:30.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:05:30.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:06:00.738+0000] {processor.py:157} INFO - Started process (PID=91221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:06:00.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:06:00.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:00.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:06:00.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:06:00.766+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:00.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:06:00.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:00.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:06:00.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T05:06:31.138+0000] {processor.py:157} INFO - Started process (PID=91246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:06:31.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:06:31.142+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:31.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:06:31.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:06:31.168+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:31.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:06:31.177+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:31.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:06:31.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T05:07:01.581+0000] {processor.py:157} INFO - Started process (PID=91271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:07:01.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:07:01.584+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:01.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:07:01.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:07:01.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:01.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:07:01.623+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:01.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:07:01.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:07:31.991+0000] {processor.py:157} INFO - Started process (PID=91296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:07:31.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:07:31.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:31.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:07:32.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:07:32.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:32.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:07:32.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:32.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:07:32.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:08:02.368+0000] {processor.py:157} INFO - Started process (PID=91321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:08:02.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:08:02.372+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:02.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:08:02.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:08:02.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:02.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:08:02.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:02.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:08:02.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:08:32.823+0000] {processor.py:157} INFO - Started process (PID=91346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:08:32.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:08:32.827+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:32.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:08:32.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:08:32.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:32.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:08:32.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:32.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:08:32.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T05:09:03.228+0000] {processor.py:157} INFO - Started process (PID=91371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:09:03.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:09:03.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:03.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:09:03.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:09:03.253+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:03.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:09:03.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:03.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:09:03.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-20T05:09:33.682+0000] {processor.py:157} INFO - Started process (PID=91396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:09:33.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:09:33.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:33.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:09:33.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:09:33.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:33.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:09:33.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:33.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:09:33.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T05:10:04.139+0000] {processor.py:157} INFO - Started process (PID=91421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:10:04.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:10:04.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:04.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:10:04.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:10:04.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:04.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:10:04.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:04.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:10:04.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T05:10:34.590+0000] {processor.py:157} INFO - Started process (PID=91446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:10:34.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:10:34.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:34.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:10:34.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:10:34.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:34.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:10:34.632+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:34.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:10:34.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:11:05.023+0000] {processor.py:157} INFO - Started process (PID=91471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:11:05.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:11:05.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:05.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:11:05.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:11:05.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:05.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:11:05.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:05.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:11:05.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:11:35.457+0000] {processor.py:157} INFO - Started process (PID=91496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:11:35.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:11:35.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:35.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:11:35.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:11:35.488+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:35.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:11:35.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:35.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:11:35.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:12:05.921+0000] {processor.py:157} INFO - Started process (PID=91521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:12:05.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:12:05.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:05.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:12:05.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:12:05.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:05.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:12:05.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:05.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:12:05.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:12:36.299+0000] {processor.py:157} INFO - Started process (PID=91546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:12:36.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:12:36.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:36.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:12:36.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:12:36.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:36.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:12:36.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:36.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:12:36.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T05:13:06.730+0000] {processor.py:157} INFO - Started process (PID=91571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:13:06.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:13:06.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:06.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:13:06.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:13:06.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:06.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:13:06.771+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:06.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:13:06.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:13:37.151+0000] {processor.py:157} INFO - Started process (PID=91596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:13:37.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:13:37.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:37.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:13:37.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:13:37.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:37.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:13:37.192+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:37.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:13:37.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:14:07.548+0000] {processor.py:157} INFO - Started process (PID=91621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:14:07.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:14:07.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:07.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:14:07.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:14:07.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:07.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:14:07.594+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:07.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:14:07.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T05:14:37.993+0000] {processor.py:157} INFO - Started process (PID=91646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:14:37.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:14:37.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:37.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:14:38.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:14:38.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:38.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:14:38.035+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:38.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:14:38.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:15:08.441+0000] {processor.py:157} INFO - Started process (PID=91671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:15:08.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:15:08.444+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:08.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:15:08.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:15:08.470+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:08.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:15:08.481+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:08.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:15:08.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:15:38.843+0000] {processor.py:157} INFO - Started process (PID=91696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:15:38.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:15:38.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:38.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:15:38.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:15:38.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:38.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:15:38.886+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:38.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:15:38.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T05:16:09.318+0000] {processor.py:157} INFO - Started process (PID=91721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:16:09.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:16:09.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:09.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:16:09.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:16:09.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:09.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:16:09.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:09.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:16:09.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:16:39.723+0000] {processor.py:157} INFO - Started process (PID=91746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:16:39.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:16:39.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:39.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:16:39.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:16:39.754+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:39.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:16:39.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:39.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:16:39.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:17:10.114+0000] {processor.py:157} INFO - Started process (PID=91771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:17:10.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:17:10.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:10.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:17:10.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:17:10.146+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:10.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:17:10.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:10.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:17:10.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T05:17:40.544+0000] {processor.py:157} INFO - Started process (PID=91796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:17:40.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:17:40.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:40.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:17:40.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:17:40.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:40.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:17:40.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:40.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:17:40.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T05:18:10.929+0000] {processor.py:157} INFO - Started process (PID=91821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:18:10.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:18:10.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:10.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:18:10.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:18:10.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:10.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:18:10.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:10.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:18:10.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:18:41.302+0000] {processor.py:157} INFO - Started process (PID=91846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:18:41.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:18:41.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:41.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:18:41.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:18:41.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:41.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:18:41.346+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:41.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:18:41.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T05:19:11.699+0000] {processor.py:157} INFO - Started process (PID=91871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:19:11.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:19:11.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:11.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:19:11.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:19:11.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:11.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:19:11.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:11.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:19:11.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-20T05:19:42.134+0000] {processor.py:157} INFO - Started process (PID=91896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:19:42.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:19:42.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:42.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:19:42.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:19:42.162+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:42.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:19:42.172+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:42.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:19:42.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T05:20:12.580+0000] {processor.py:157} INFO - Started process (PID=91921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:20:12.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:20:12.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:12.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:20:12.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:20:12.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:12.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:20:12.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:12.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:20:12.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:20:42.954+0000] {processor.py:157} INFO - Started process (PID=91946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:20:42.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:20:42.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:42.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:20:42.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:20:42.987+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:42.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:20:42.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:42.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:20:43.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:21:13.400+0000] {processor.py:157} INFO - Started process (PID=91971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:21:13.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:21:13.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:13.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:21:13.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:21:13.430+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:13.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:21:13.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:13.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:21:13.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:21:43.786+0000] {processor.py:157} INFO - Started process (PID=91996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:21:43.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:21:43.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:43.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:21:43.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:21:43.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:43.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:21:43.824+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:43.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:21:43.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T05:22:14.192+0000] {processor.py:157} INFO - Started process (PID=92021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:22:14.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:22:14.195+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:14.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:22:14.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:22:14.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:14.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:22:14.234+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:14.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:22:14.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:22:44.598+0000] {processor.py:157} INFO - Started process (PID=92046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:22:44.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:22:44.600+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:44.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:22:44.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:22:44.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:44.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:22:44.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:44.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:22:44.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T05:23:15.001+0000] {processor.py:157} INFO - Started process (PID=92071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:23:15.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:23:15.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:15.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:23:15.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:23:15.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:15.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:23:15.047+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:15.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:23:15.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T05:23:45.407+0000] {processor.py:157} INFO - Started process (PID=92096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:23:45.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:23:45.411+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:45.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:23:45.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:23:45.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:45.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:23:45.450+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:45.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:23:45.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:24:15.818+0000] {processor.py:157} INFO - Started process (PID=92121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:24:15.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:24:15.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:15.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:24:15.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:24:15.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:15.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:24:15.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:15.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:24:15.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:24:46.199+0000] {processor.py:157} INFO - Started process (PID=92146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:24:46.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:24:46.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:46.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:24:46.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:24:46.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:46.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:24:46.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:46.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:24:46.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T05:25:16.670+0000] {processor.py:157} INFO - Started process (PID=92171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:25:16.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:25:16.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:16.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:25:16.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:25:16.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:16.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:25:16.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:16.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:25:16.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T05:25:47.091+0000] {processor.py:157} INFO - Started process (PID=92196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:25:47.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:25:47.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:47.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:25:47.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:25:47.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:47.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:25:47.132+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:47.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:25:47.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T05:26:17.493+0000] {processor.py:157} INFO - Started process (PID=92221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:26:17.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:26:17.495+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:17.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:26:17.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:26:17.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:17.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:26:17.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:17.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:26:17.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T05:26:47.932+0000] {processor.py:157} INFO - Started process (PID=92246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:26:47.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:26:47.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:47.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:26:47.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:26:47.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:47.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:26:47.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:47.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:26:47.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T05:27:18.338+0000] {processor.py:157} INFO - Started process (PID=92271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:27:18.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:27:18.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:18.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:27:18.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:27:18.372+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:18.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:27:18.384+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:18.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:27:18.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T05:27:48.708+0000] {processor.py:157} INFO - Started process (PID=92296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:27:48.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:27:48.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:48.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:27:48.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:27:48.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:48.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:27:48.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:48.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:27:48.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:28:19.085+0000] {processor.py:157} INFO - Started process (PID=92321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:28:19.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:28:19.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:19.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:28:19.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:28:19.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:19.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:28:19.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:19.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:28:19.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T05:28:49.547+0000] {processor.py:157} INFO - Started process (PID=92346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:28:49.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:28:49.551+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:49.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:28:49.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:28:49.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:49.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:28:49.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:49.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:28:49.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:29:19.999+0000] {processor.py:157} INFO - Started process (PID=92371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:29:20.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:29:20.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:20.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:29:20.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:29:20.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:20.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:29:20.044+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:20.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:29:20.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T05:29:50.469+0000] {processor.py:157} INFO - Started process (PID=92396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:29:50.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:29:50.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:50.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:29:50.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:29:50.500+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:50.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:29:50.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:50.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:29:50.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:30:20.876+0000] {processor.py:157} INFO - Started process (PID=92421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:30:20.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:30:20.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:20.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:30:20.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:30:20.907+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:20.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:30:20.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:20.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:30:20.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:30:51.260+0000] {processor.py:157} INFO - Started process (PID=92445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:30:51.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:30:51.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:51.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:30:51.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:30:51.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:51.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:30:51.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:51.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:30:51.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T05:31:21.709+0000] {processor.py:157} INFO - Started process (PID=92471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:31:21.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:31:21.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:21.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:31:21.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:31:21.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:21.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:31:21.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:21.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:31:21.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T05:31:52.086+0000] {processor.py:157} INFO - Started process (PID=92496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:31:52.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:31:52.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:52.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:31:52.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:31:52.115+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:52.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:31:52.126+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:52.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:31:52.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:32:22.481+0000] {processor.py:157} INFO - Started process (PID=92521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:32:22.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:32:22.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:22.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:32:22.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:32:22.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:22.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:32:22.526+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:22.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:32:22.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T05:32:52.933+0000] {processor.py:157} INFO - Started process (PID=92546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:32:52.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:32:52.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:52.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:32:52.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:32:53.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:53.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:32:53.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:53.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:32:53.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T05:33:23.521+0000] {processor.py:157} INFO - Started process (PID=92571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:33:23.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:33:23.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:23.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:33:23.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:33:23.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:23.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:33:23.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:23.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:33:23.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-20T05:33:54.096+0000] {processor.py:157} INFO - Started process (PID=92595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:33:54.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:33:54.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:54.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:33:54.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:33:54.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:54.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:33:54.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:54.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:33:54.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-20T05:34:24.613+0000] {processor.py:157} INFO - Started process (PID=92621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:34:24.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:34:24.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:24.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:34:24.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:34:24.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:24.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:34:24.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:24.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:34:24.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:34:55.089+0000] {processor.py:157} INFO - Started process (PID=92646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:34:55.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:34:55.095+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:55.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:34:55.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:34:55.142+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:55.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:34:55.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:55.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:34:55.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-20T05:35:25.646+0000] {processor.py:157} INFO - Started process (PID=92671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:35:25.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:35:25.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:25.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:35:25.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:35:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:25.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:35:25.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:25.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:35:25.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-20T05:35:56.229+0000] {processor.py:157} INFO - Started process (PID=92696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:35:56.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:35:56.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:56.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:35:56.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:35:56.289+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:56.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:35:56.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:56.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:35:56.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-20T05:36:26.748+0000] {processor.py:157} INFO - Started process (PID=92721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:36:26.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:36:26.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:26.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:36:26.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:36:26.778+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:26.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:36:26.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:26.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:36:26.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T05:36:57.178+0000] {processor.py:157} INFO - Started process (PID=92746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:36:57.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:36:57.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:57.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:36:57.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:36:57.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:57.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:36:57.252+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:57.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:36:57.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-20T05:37:27.683+0000] {processor.py:157} INFO - Started process (PID=92771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:37:27.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:37:27.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:27.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:37:27.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:37:27.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:27.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:37:27.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:27.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:37:27.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T05:37:58.165+0000] {processor.py:157} INFO - Started process (PID=92796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:37:58.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:37:58.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:58.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:37:58.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:37:58.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:58.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:37:58.292+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:58.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:37:58.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-20T05:38:28.714+0000] {processor.py:157} INFO - Started process (PID=92821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:38:28.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:38:28.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:28.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:38:28.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:38:28.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:28.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:38:28.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:28.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:38:28.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T05:38:59.154+0000] {processor.py:157} INFO - Started process (PID=92846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:38:59.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:38:59.160+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:59.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:38:59.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:38:59.197+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:59.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:38:59.214+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:59.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:38:59.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T05:39:29.578+0000] {processor.py:157} INFO - Started process (PID=92871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:39:29.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:39:29.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:29.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:39:29.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:39:29.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:29.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:39:29.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:29.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:39:29.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T05:39:59.979+0000] {processor.py:157} INFO - Started process (PID=92896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:39:59.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:39:59.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:59.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:39:59.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:40:00.009+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:00.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:40:00.020+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:00.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:40:00.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:40:30.377+0000] {processor.py:157} INFO - Started process (PID=92920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:40:30.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:40:30.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:30.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:40:30.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:40:30.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:30.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:40:30.423+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:30.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:40:30.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T05:41:00.785+0000] {processor.py:157} INFO - Started process (PID=92946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:41:00.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:41:00.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:00.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:41:00.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:41:00.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:00.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:41:00.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:00.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:41:00.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-20T05:41:31.266+0000] {processor.py:157} INFO - Started process (PID=92971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:41:31.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:41:31.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:31.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:41:31.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:41:31.299+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:31.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:41:31.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:31.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:41:31.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T05:42:01.642+0000] {processor.py:157} INFO - Started process (PID=92996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:42:01.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:42:01.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:01.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:42:01.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:42:01.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:01.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:42:01.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:01.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:42:01.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:42:32.089+0000] {processor.py:157} INFO - Started process (PID=93021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:42:32.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:42:32.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:32.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:42:32.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:42:32.133+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:32.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:42:32.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:32.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:42:32.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-20T05:43:02.533+0000] {processor.py:157} INFO - Started process (PID=93046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:43:02.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:43:02.535+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:02.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:43:02.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:43:02.561+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:02.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:43:02.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:02.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:43:02.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:43:32.991+0000] {processor.py:157} INFO - Started process (PID=93071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:43:32.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:43:32.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:32.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:43:33.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:43:33.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:33.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:43:33.035+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:33.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:43:33.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T05:44:03.441+0000] {processor.py:157} INFO - Started process (PID=93096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:44:03.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:44:03.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:03.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:44:03.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:44:03.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:03.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:44:03.482+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:03.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:44:03.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T05:44:33.880+0000] {processor.py:157} INFO - Started process (PID=93121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:44:33.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:44:33.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:33.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:44:33.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:44:33.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:33.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:44:33.928+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:33.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:44:33.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T05:45:04.260+0000] {processor.py:157} INFO - Started process (PID=93146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:45:04.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:45:04.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:04.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:45:04.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:45:04.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:04.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:45:04.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:04.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:45:04.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T05:45:34.679+0000] {processor.py:157} INFO - Started process (PID=93171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:45:34.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:45:34.682+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:34.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:45:34.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:45:34.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:34.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:45:34.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:34.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:45:34.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:46:05.087+0000] {processor.py:157} INFO - Started process (PID=93196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:46:05.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:46:05.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:05.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:46:05.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:46:05.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:05.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:46:05.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:05.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:46:05.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T05:46:35.578+0000] {processor.py:157} INFO - Started process (PID=93221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:46:35.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:46:35.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:35.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:46:35.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:46:35.610+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:35.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:46:35.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:35.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:46:35.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T05:47:06.028+0000] {processor.py:157} INFO - Started process (PID=93246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:47:06.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:47:06.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:06.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:47:06.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:47:06.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:06.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:47:06.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:06.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:47:06.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T05:47:36.472+0000] {processor.py:157} INFO - Started process (PID=93271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:47:36.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:47:36.475+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:36.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:47:36.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:47:36.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:36.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:47:36.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:36.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:47:36.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T05:48:06.876+0000] {processor.py:157} INFO - Started process (PID=93296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:48:06.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:48:06.881+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:06.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:48:06.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:48:06.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:06.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:48:06.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:06.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:48:06.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T05:48:37.330+0000] {processor.py:157} INFO - Started process (PID=93321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:48:37.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:48:37.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:37.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:48:37.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:48:37.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:37.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:48:37.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:37.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:48:37.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-20T05:49:07.765+0000] {processor.py:157} INFO - Started process (PID=93346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:49:07.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:49:07.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:07.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:49:07.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:49:07.799+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:07.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:49:07.810+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:07.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:49:07.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T05:49:38.199+0000] {processor.py:157} INFO - Started process (PID=93371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:49:38.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:49:38.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:38.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:49:38.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:49:38.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:38.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:49:38.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:38.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:49:38.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-20T05:50:08.633+0000] {processor.py:157} INFO - Started process (PID=93396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:50:08.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:50:08.635+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:08.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:50:08.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:50:08.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:08.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:50:08.671+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:08.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:50:08.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T05:50:39.078+0000] {processor.py:157} INFO - Started process (PID=93421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:50:39.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:50:39.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:39.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:50:39.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:50:39.121+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:39.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:50:39.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:39.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:50:39.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T05:51:09.534+0000] {processor.py:157} INFO - Started process (PID=93446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:51:09.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:51:09.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:09.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:51:09.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:51:09.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:09.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:51:09.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:09.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:51:09.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:51:39.945+0000] {processor.py:157} INFO - Started process (PID=93471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:51:39.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:51:39.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:39.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:51:39.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:51:39.987+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:39.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:51:40.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:39.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:51:40.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T05:52:10.417+0000] {processor.py:157} INFO - Started process (PID=93496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:52:10.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:52:10.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:10.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:52:10.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:52:10.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:10.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:52:10.455+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:10.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:52:10.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T05:52:40.806+0000] {processor.py:157} INFO - Started process (PID=93521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:52:40.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:52:40.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:40.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:52:40.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:52:40.830+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:40.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:52:40.840+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:40.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:52:40.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-20T05:53:11.236+0000] {processor.py:157} INFO - Started process (PID=93546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:53:11.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:53:11.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:11.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:53:11.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:53:11.273+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:11.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:53:11.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:11.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:53:11.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T05:53:41.660+0000] {processor.py:157} INFO - Started process (PID=93571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:53:41.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:53:41.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:41.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:53:41.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:53:41.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:41.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:53:41.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:41.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:53:41.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:54:12.111+0000] {processor.py:157} INFO - Started process (PID=93596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:54:12.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:54:12.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:12.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:54:12.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:54:12.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:12.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:54:12.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:12.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:54:12.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T05:54:42.574+0000] {processor.py:157} INFO - Started process (PID=93621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:54:42.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:54:42.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:42.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:54:42.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:54:42.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:42.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:54:42.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:42.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:54:42.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T05:55:12.968+0000] {processor.py:157} INFO - Started process (PID=93646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:55:12.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:55:12.971+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:12.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:55:12.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:55:12.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:12.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:55:13.010+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:13.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:55:13.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:55:43.422+0000] {processor.py:157} INFO - Started process (PID=93671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:55:43.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:55:43.427+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:43.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:55:43.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:55:43.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:43.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:55:43.466+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:43.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:55:43.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T05:56:13.818+0000] {processor.py:157} INFO - Started process (PID=93696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:56:13.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:56:13.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:13.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:56:13.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:56:13.853+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:13.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:56:13.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:13.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:56:13.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T05:56:44.235+0000] {processor.py:157} INFO - Started process (PID=93721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:56:44.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:56:44.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:44.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:56:44.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:56:44.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:44.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:56:44.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:44.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:56:44.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-20T05:57:14.659+0000] {processor.py:157} INFO - Started process (PID=93746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:57:14.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:57:14.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:14.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:57:14.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:57:14.688+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:14.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:57:14.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:14.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:57:14.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T05:57:45.075+0000] {processor.py:157} INFO - Started process (PID=93771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:57:45.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:57:45.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:45.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:57:45.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:57:45.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:45.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:57:45.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:45.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:57:45.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T05:58:15.432+0000] {processor.py:157} INFO - Started process (PID=93796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:58:15.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:58:15.434+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:15.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:58:15.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:58:15.461+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:15.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:58:15.470+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:15.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:58:15.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T05:58:45.885+0000] {processor.py:157} INFO - Started process (PID=93821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:58:45.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:58:45.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:45.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:58:45.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:58:45.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:45.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:58:45.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:45.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:58:45.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T05:59:16.273+0000] {processor.py:157} INFO - Started process (PID=93846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:59:16.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:59:16.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:16.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:59:16.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:59:16.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:16.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:59:16.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:16.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:59:16.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T05:59:46.738+0000] {processor.py:157} INFO - Started process (PID=93871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:59:46.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T05:59:46.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:46.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:59:46.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T05:59:46.772+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:46.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:59:46.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:46.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T05:59:46.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T06:00:17.167+0000] {processor.py:157} INFO - Started process (PID=93896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:00:17.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:00:17.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:17.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:00:17.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:00:17.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:17.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:00:17.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:17.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:00:17.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T06:00:47.611+0000] {processor.py:157} INFO - Started process (PID=93921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:00:47.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:00:47.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:47.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:00:47.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:00:47.639+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:47.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:00:47.649+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:47.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:00:47.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T06:01:17.982+0000] {processor.py:157} INFO - Started process (PID=93946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:01:17.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:01:17.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:17.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:01:18.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:01:18.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:18.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:01:18.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:18.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:01:18.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T06:01:48.428+0000] {processor.py:157} INFO - Started process (PID=93971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:01:48.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:01:48.431+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:48.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:01:48.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:01:48.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:48.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:01:48.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:48.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:01:48.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T06:02:18.903+0000] {processor.py:157} INFO - Started process (PID=93996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:02:18.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:02:18.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:18.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:02:18.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:02:18.932+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:18.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:02:18.944+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:18.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:02:18.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T06:02:49.283+0000] {processor.py:157} INFO - Started process (PID=94021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:02:49.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:02:49.287+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:49.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:02:49.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:02:49.313+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:49.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:02:49.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:49.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:02:49.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T06:03:19.766+0000] {processor.py:157} INFO - Started process (PID=94046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:03:19.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:03:19.771+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:19.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:03:19.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:03:19.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:19.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:03:19.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:19.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:03:19.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T06:03:50.183+0000] {processor.py:157} INFO - Started process (PID=94071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:03:50.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:03:50.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:50.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:03:50.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:03:50.228+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:50.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:03:50.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:50.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:03:50.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T06:04:20.606+0000] {processor.py:157} INFO - Started process (PID=94096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:04:20.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:04:20.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:20.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:04:20.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:04:20.637+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:20.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:04:20.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:20.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:04:20.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T06:04:51.073+0000] {processor.py:157} INFO - Started process (PID=94121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:04:51.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:04:51.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:51.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:04:51.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:04:51.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:51.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:04:51.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:51.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:04:51.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T06:05:21.451+0000] {processor.py:157} INFO - Started process (PID=94146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:05:21.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:05:21.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:21.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:05:21.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:05:21.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:21.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:05:21.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:21.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:05:21.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T06:05:51.904+0000] {processor.py:157} INFO - Started process (PID=94171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:05:51.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:05:51.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:51.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:05:51.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:05:51.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:51.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:05:51.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:51.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:05:51.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T06:06:22.327+0000] {processor.py:157} INFO - Started process (PID=94196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:06:22.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:06:22.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:22.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:06:22.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:06:22.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:22.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:06:22.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:22.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:06:22.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T06:06:52.749+0000] {processor.py:157} INFO - Started process (PID=94221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:06:52.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:06:52.754+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:52.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:06:52.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:06:52.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:52.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:06:52.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:52.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:06:52.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T06:07:23.150+0000] {processor.py:157} INFO - Started process (PID=94246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:07:23.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:07:23.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:23.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:07:23.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:07:23.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:23.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:07:23.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:23.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:07:23.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T06:07:53.567+0000] {processor.py:157} INFO - Started process (PID=94271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:07:53.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:07:53.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:53.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:07:53.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:07:53.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:53.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:07:53.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:53.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:07:53.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T06:08:23.998+0000] {processor.py:157} INFO - Started process (PID=94296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:08:24.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:08:24.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:24.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:08:24.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:08:24.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:24.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:08:24.055+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:24.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:08:24.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T06:08:54.432+0000] {processor.py:157} INFO - Started process (PID=94321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:08:54.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:08:54.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:54.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:08:54.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:08:54.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:54.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:08:54.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:54.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:08:54.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T06:09:24.847+0000] {processor.py:157} INFO - Started process (PID=94346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:09:24.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:09:24.853+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:24.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:09:24.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:09:24.887+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:24.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:09:24.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:24.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:09:24.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T06:09:55.295+0000] {processor.py:157} INFO - Started process (PID=94370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:09:55.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:09:55.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:55.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:09:55.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:09:55.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:55.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:09:55.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:55.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:09:55.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-20T06:10:25.805+0000] {processor.py:157} INFO - Started process (PID=94396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:10:25.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:10:25.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:25.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:10:25.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:10:25.855+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:25.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:10:25.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:25.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:10:25.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-20T06:10:56.268+0000] {processor.py:157} INFO - Started process (PID=94421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:10:56.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:10:56.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:56.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:10:56.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:10:56.314+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:56.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:10:56.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:56.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:10:56.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T06:11:26.752+0000] {processor.py:157} INFO - Started process (PID=94446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:11:26.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:11:26.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:26.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:11:26.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:11:26.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:26.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:11:26.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:26.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:11:26.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T06:11:57.205+0000] {processor.py:157} INFO - Started process (PID=94471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:11:57.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:11:57.211+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:57.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:11:57.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:11:57.252+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:57.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:11:57.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:57.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:11:57.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-20T06:12:27.654+0000] {processor.py:157} INFO - Started process (PID=94496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:12:27.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:12:27.658+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:27.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:12:27.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:12:27.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:27.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:12:27.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:27.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:12:27.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-20T06:12:58.100+0000] {processor.py:157} INFO - Started process (PID=94521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:12:58.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:12:58.107+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:58.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:12:58.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:12:58.146+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:58.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:12:58.159+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:58.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:12:58.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T06:13:28.524+0000] {processor.py:157} INFO - Started process (PID=94545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:13:28.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:13:28.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:28.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:13:28.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:13:28.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:28.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:13:28.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:28.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:13:28.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-20T06:13:58.987+0000] {processor.py:157} INFO - Started process (PID=94571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:13:58.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:13:58.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:58.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:13:58.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:13:59.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:59.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:13:59.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:59.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:13:59.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T06:14:29.819+0000] {processor.py:157} INFO - Started process (PID=94596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:14:29.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:14:29.825+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:14:29.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:14:29.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:14:29.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:14:29.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:14:29.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:14:29.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:14:29.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-20T06:15:00.318+0000] {processor.py:157} INFO - Started process (PID=94621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:15:00.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:15:00.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:15:00.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:15:00.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:15:00.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:15:00.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:15:00.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:15:00.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:15:00.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T06:16:27.669+0000] {processor.py:157} INFO - Started process (PID=94646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:16:27.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:16:27.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:16:27.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:16:27.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:16:27.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:16:27.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:16:27.728+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:16:27.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:16:27.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T06:49:15.647+0000] {processor.py:157} INFO - Started process (PID=94673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:49:15.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T06:49:15.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:49:15.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:49:15.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T06:49:15.714+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:49:15.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:49:15.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:49:15.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T06:49:15.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-20T07:30:16.062+0000] {processor.py:157} INFO - Started process (PID=94700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:30:16.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:30:16.064+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:16.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:30:16.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:30:16.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:16.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:30:16.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:16.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:30:16.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-20T07:30:46.543+0000] {processor.py:157} INFO - Started process (PID=94725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:30:46.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:30:46.548+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:46.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:30:46.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:30:46.585+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:46.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:30:46.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:46.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:30:46.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T07:33:25.902+0000] {processor.py:157} INFO - Started process (PID=94750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:33:25.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:33:25.906+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:33:25.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:33:25.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:33:25.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:33:25.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:33:25.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:33:25.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:33:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T07:34:09.261+0000] {processor.py:157} INFO - Started process (PID=94775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:34:09.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:34:09.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:09.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:34:09.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:34:09.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:09.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:34:09.306+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:09.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:34:09.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T07:34:39.691+0000] {processor.py:157} INFO - Started process (PID=94800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:34:39.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:34:39.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:39.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:34:39.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:34:39.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:39.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:34:39.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:39.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:34:39.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T07:46:22.071+0000] {processor.py:157} INFO - Started process (PID=94827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:46:22.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:46:22.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:46:22.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:46:22.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:46:22.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:46:22.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:46:22.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:46:22.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:46:22.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-20T07:47:04.656+0000] {processor.py:157} INFO - Started process (PID=94852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:47:04.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:47:04.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:04.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:47:04.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:47:04.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:04.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:47:04.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:04.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:47:04.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T07:47:35.097+0000] {processor.py:157} INFO - Started process (PID=94877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:47:35.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:47:35.101+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:35.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:47:35.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:47:35.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:35.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:47:35.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:35.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:47:35.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T07:49:56.461+0000] {processor.py:157} INFO - Started process (PID=94902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:49:56.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:49:56.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:49:56.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:49:56.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:49:56.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:49:56.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:49:56.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:49:56.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:49:56.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T07:50:39.831+0000] {processor.py:157} INFO - Started process (PID=94927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:50:39.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:50:39.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:50:39.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:50:39.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:50:39.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:50:39.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:50:39.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:50:39.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:50:39.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T07:51:10.298+0000] {processor.py:157} INFO - Started process (PID=94952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:51:10.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T07:51:10.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:51:10.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:51:10.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T07:51:10.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:51:10.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:51:10.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:51:10.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T07:51:10.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T08:14:02.298+0000] {processor.py:157} INFO - Started process (PID=94977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:14:02.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T08:14:02.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:02.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:14:02.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:14:02.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:02.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:14:02.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:02.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T08:14:02.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T08:14:32.710+0000] {processor.py:157} INFO - Started process (PID=95001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:14:32.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T08:14:32.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:32.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:14:32.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:14:32.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:32.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:14:32.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:32.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T08:14:32.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T08:15:10.410+0000] {processor.py:157} INFO - Started process (PID=95027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:15:10.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T08:15:10.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:15:10.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:15:10.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:15:10.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:15:10.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:15:10.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:15:10.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T08:15:10.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T08:35:58.591+0000] {processor.py:157} INFO - Started process (PID=95053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:35:58.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T08:35:58.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:35:58.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:35:58.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:35:58.619+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:35:58.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:35:58.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:35:58.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T08:35:58.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T08:36:29.003+0000] {processor.py:157} INFO - Started process (PID=95079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:36:29.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T08:36:29.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:36:29.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:36:29.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T08:36:29.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:36:29.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:36:29.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:36:29.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T08:36:29.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T09:15:03.733+0000] {processor.py:157} INFO - Started process (PID=95104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:15:03.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:15:03.739+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:03.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:15:03.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:15:03.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:03.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:15:03.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:03.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:15:03.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T09:15:34.201+0000] {processor.py:157} INFO - Started process (PID=95129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:15:34.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:15:34.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:34.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:15:34.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:15:34.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:34.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:15:34.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:34.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:15:34.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T09:26:31.524+0000] {processor.py:157} INFO - Started process (PID=95154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:26:31.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:26:31.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:26:31.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:26:31.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:26:31.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:26:31.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:26:31.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:26:31.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:26:31.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-20T09:27:02.097+0000] {processor.py:157} INFO - Started process (PID=95179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:27:02.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:27:02.099+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:27:02.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:27:02.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:27:02.126+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:27:02.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:27:02.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:27:02.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:27:02.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T09:35:24.709+0000] {processor.py:157} INFO - Started process (PID=95204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:35:24.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:35:24.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:35:24.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:35:24.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:35:24.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:35:24.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:35:24.760+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:35:24.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:35:24.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T09:36:33.904+0000] {processor.py:157} INFO - Started process (PID=95229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:36:33.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:36:33.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:36:33.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:36:33.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:36:33.938+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:36:33.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:36:33.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:36:33.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:36:33.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T09:37:04.395+0000] {processor.py:157} INFO - Started process (PID=95254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:37:04.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:37:04.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:37:04.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:37:04.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:37:04.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:37:04.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:37:04.435+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:37:04.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:37:04.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T09:50:22.674+0000] {processor.py:157} INFO - Started process (PID=95279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:50:22.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:50:22.677+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:22.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:50:22.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:50:22.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:22.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:50:22.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:22.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:50:22.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T09:50:53.220+0000] {processor.py:157} INFO - Started process (PID=95304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:50:53.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:50:53.224+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:53.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:50:53.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:50:53.253+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:53.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:50:53.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:53.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:50:53.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T09:53:36.182+0000] {processor.py:157} INFO - Started process (PID=95329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:53:36.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T09:53:36.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:53:36.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:53:36.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T09:53:36.219+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:53:36.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:53:36.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:53:36.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T09:53:36.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T10:16:06.001+0000] {processor.py:157} INFO - Started process (PID=95354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T10:16:06.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T10:16:06.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:06.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T10:16:06.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T10:16:06.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:06.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T10:16:06.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:06.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T10:16:06.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T10:16:36.487+0000] {processor.py:157} INFO - Started process (PID=95379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T10:16:36.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T10:16:36.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:36.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T10:16:36.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T10:16:36.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:36.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T10:16:36.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:36.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T10:16:36.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T11:17:02.946+0000] {processor.py:157} INFO - Started process (PID=95406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:17:02.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T11:17:02.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:02.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:17:02.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:17:03.017+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:03.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:17:03.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:03.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T11:17:03.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-20T11:17:33.682+0000] {processor.py:157} INFO - Started process (PID=95431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:17:33.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T11:17:33.688+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:33.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:17:33.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:17:33.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:33.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:17:33.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:33.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T11:17:33.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T11:55:28.868+0000] {processor.py:157} INFO - Started process (PID=95456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:55:28.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T11:55:28.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:28.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:55:28.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:55:28.895+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:28.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:55:28.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:28.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T11:55:28.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T11:55:59.338+0000] {processor.py:157} INFO - Started process (PID=95481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:55:59.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T11:55:59.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:59.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:55:59.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T11:55:59.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:59.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:55:59.377+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:59.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T11:55:59.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T12:03:27.322+0000] {processor.py:157} INFO - Started process (PID=95508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:03:27.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:03:27.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:03:27.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:03:27.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:03:27.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:03:27.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:03:27.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:03:27.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:03:27.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-20T12:04:59.530+0000] {processor.py:157} INFO - Started process (PID=95533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:04:59.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:04:59.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:04:59.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:04:59.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:04:59.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:04:59.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:04:59.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:04:59.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:04:59.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T12:05:29.960+0000] {processor.py:157} INFO - Started process (PID=95558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:05:29.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:05:29.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:05:29.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:05:29.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:05:29.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:05:29.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:05:29.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:05:29.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:05:30.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-20T12:18:14.518+0000] {processor.py:157} INFO - Started process (PID=95583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:18:14.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:18:14.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:14.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:18:14.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:18:14.551+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:14.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:18:14.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:14.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:18:14.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T12:18:45.002+0000] {processor.py:157} INFO - Started process (PID=95608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:18:45.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:18:45.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:45.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:18:45.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:18:45.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:45.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:18:45.044+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:45.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:18:45.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T12:29:26.204+0000] {processor.py:157} INFO - Started process (PID=95635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:29:26.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:29:26.211+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:29:26.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:29:26.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:29:26.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:29:26.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:29:26.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:29:26.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:29:26.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-20T12:30:58.524+0000] {processor.py:157} INFO - Started process (PID=95660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:30:58.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:30:58.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:30:58.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:30:58.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:30:58.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:30:58.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:30:58.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:30:58.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:30:58.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T12:31:28.948+0000] {processor.py:157} INFO - Started process (PID=95685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:31:28.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:31:28.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:31:28.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:31:28.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:31:28.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:31:28.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:31:28.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:31:28.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:31:28.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.038 seconds
[2024-07-20T12:32:32.249+0000] {processor.py:157} INFO - Started process (PID=95710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:32:32.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:32:32.252+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:32:32.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:32:32.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:32:32.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:32:32.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:32:32.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:32:32.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:32:32.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T12:48:15.360+0000] {processor.py:157} INFO - Started process (PID=95733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:48:15.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:48:15.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:48:15.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:48:15.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:48:15.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:48:15.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:48:15.744+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:48:15.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:48:15.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.429 seconds
[2024-07-20T12:49:53.103+0000] {processor.py:157} INFO - Started process (PID=95761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:49:53.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:49:53.110+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:49:53.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:49:53.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:49:53.163+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:49:53.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:49:53.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:49:53.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:49:53.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-20T12:50:23.533+0000] {processor.py:157} INFO - Started process (PID=95787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:50:23.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:50:23.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:23.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:50:23.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:50:23.564+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:23.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:50:23.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:23.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:50:23.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T12:50:53.927+0000] {processor.py:157} INFO - Started process (PID=95812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:50:53.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:50:53.932+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:53.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:50:53.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:50:53.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:53.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:50:53.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:53.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:50:53.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T12:51:24.392+0000] {processor.py:157} INFO - Started process (PID=95837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:51:24.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:51:24.394+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:24.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:51:24.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:51:24.421+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:24.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:51:24.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:24.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:51:24.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T12:51:54.837+0000] {processor.py:157} INFO - Started process (PID=95862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:51:54.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:51:54.840+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:54.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:51:54.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:51:54.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:54.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:51:54.880+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:54.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:51:54.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T12:52:25.241+0000] {processor.py:157} INFO - Started process (PID=95887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:52:25.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:52:25.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:25.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:52:25.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:52:25.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:25.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:52:25.280+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:25.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:52:25.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T12:52:55.679+0000] {processor.py:157} INFO - Started process (PID=95912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:52:55.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:52:55.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:55.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:52:55.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:52:55.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:55.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:52:55.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:55.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:52:55.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T12:53:26.066+0000] {processor.py:157} INFO - Started process (PID=95937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:53:26.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:53:26.071+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:26.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:53:26.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:53:26.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:26.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:53:26.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:26.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:53:26.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T12:53:56.542+0000] {processor.py:157} INFO - Started process (PID=95962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:53:56.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:53:56.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:56.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:53:56.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:53:56.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:56.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:53:56.583+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:56.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:53:56.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T12:54:26.917+0000] {processor.py:157} INFO - Started process (PID=95987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:54:26.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:54:26.919+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:26.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:54:26.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:54:26.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:26.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:54:26.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:26.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:54:26.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T12:54:57.328+0000] {processor.py:157} INFO - Started process (PID=96012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:54:57.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:54:57.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:57.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:54:57.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:54:57.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:57.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:54:57.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:57.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:54:57.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T12:55:27.760+0000] {processor.py:157} INFO - Started process (PID=96037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:55:27.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:55:27.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:27.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:55:27.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:55:27.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:27.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:55:27.803+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:27.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:55:27.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T12:55:58.214+0000] {processor.py:157} INFO - Started process (PID=96062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:55:58.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:55:58.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:58.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:55:58.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:55:58.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:58.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:55:58.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:58.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:55:58.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T12:56:28.638+0000] {processor.py:157} INFO - Started process (PID=96087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:56:28.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:56:28.642+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:28.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:56:28.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:56:28.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:28.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:56:28.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:28.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:56:28.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T12:56:59.072+0000] {processor.py:157} INFO - Started process (PID=96112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:56:59.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:56:59.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:59.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:56:59.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:56:59.105+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:59.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:56:59.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:59.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:56:59.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T12:57:29.511+0000] {processor.py:157} INFO - Started process (PID=96137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:57:29.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:57:29.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:29.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:57:29.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:57:29.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:29.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:57:29.549+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:29.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:57:29.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T12:57:59.971+0000] {processor.py:157} INFO - Started process (PID=96162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:57:59.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:57:59.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:59.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:57:59.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:58:00.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:00.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:58:00.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:00.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:58:00.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T12:58:30.385+0000] {processor.py:157} INFO - Started process (PID=96187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:58:30.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:58:30.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:30.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:58:30.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:58:30.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:30.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:58:30.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:30.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:58:30.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-20T12:59:00.885+0000] {processor.py:157} INFO - Started process (PID=96212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:59:00.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:59:00.892+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:00.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:59:00.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:59:00.940+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:00.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:59:00.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:00.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:59:00.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-20T12:59:31.358+0000] {processor.py:157} INFO - Started process (PID=96237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:59:31.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T12:59:31.361+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:31.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:59:31.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T12:59:31.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:31.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:59:31.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:31.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T12:59:31.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T13:00:01.769+0000] {processor.py:157} INFO - Started process (PID=96262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:00:01.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:00:01.774+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:01.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:00:01.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:00:01.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:01.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:00:01.827+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:01.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:00:01.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T13:00:32.186+0000] {processor.py:157} INFO - Started process (PID=96287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:00:32.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:00:32.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:32.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:00:32.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:00:32.216+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:32.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:00:32.228+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:32.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:00:32.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:01:02.576+0000] {processor.py:157} INFO - Started process (PID=96312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:01:02.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:01:02.579+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:02.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:01:02.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:01:02.607+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:02.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:01:02.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:02.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:01:02.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T13:01:32.958+0000] {processor.py:157} INFO - Started process (PID=96337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:01:32.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:01:32.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:32.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:01:32.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:01:32.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:32.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:01:32.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:32.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:01:33.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T13:02:03.401+0000] {processor.py:157} INFO - Started process (PID=96361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:02:03.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:02:03.404+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:03.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:02:03.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:02:03.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:03.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:02:03.455+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:03.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:02:03.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T13:02:33.876+0000] {processor.py:157} INFO - Started process (PID=96387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:02:33.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:02:33.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:33.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:02:33.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:02:33.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:33.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:02:33.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:33.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:02:33.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-20T13:03:04.345+0000] {processor.py:157} INFO - Started process (PID=96412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:03:04.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:03:04.351+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:04.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:03:04.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:03:04.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:04.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:03:04.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:04.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:03:04.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T13:03:34.828+0000] {processor.py:157} INFO - Started process (PID=96437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:03:34.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:03:34.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:34.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:03:34.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:03:34.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:34.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:03:34.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:34.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:03:34.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:04:05.283+0000] {processor.py:157} INFO - Started process (PID=96462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:04:05.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:04:05.287+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:05.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:04:05.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:04:05.319+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:05.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:04:05.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:05.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:04:05.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T13:04:35.696+0000] {processor.py:157} INFO - Started process (PID=96487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:04:35.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:04:35.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:35.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:04:35.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:04:35.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:35.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:04:35.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:35.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:04:35.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T13:05:06.185+0000] {processor.py:157} INFO - Started process (PID=96512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:05:06.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:05:06.191+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:06.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:05:06.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:05:06.226+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:06.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:05:06.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:06.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:05:06.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T13:05:36.597+0000] {processor.py:157} INFO - Started process (PID=96537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:05:36.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:05:36.600+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:36.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:05:36.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:05:36.629+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:36.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:05:36.642+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:36.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:05:36.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T13:06:07.051+0000] {processor.py:157} INFO - Started process (PID=96562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:06:07.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:06:07.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:07.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:06:07.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:06:07.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:07.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:06:07.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:07.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:06:07.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:06:37.439+0000] {processor.py:157} INFO - Started process (PID=96587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:06:37.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:06:37.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:37.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:06:37.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:06:37.469+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:37.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:06:37.482+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:37.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:06:37.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:07:07.843+0000] {processor.py:157} INFO - Started process (PID=96612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:07:07.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:07:07.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:07.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:07:07.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:07:07.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:07.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:07:07.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:07.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:07:07.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T13:07:38.301+0000] {processor.py:157} INFO - Started process (PID=96637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:07:38.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:07:38.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:38.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:07:38.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:07:38.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:38.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:07:38.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:38.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:07:38.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:08:08.779+0000] {processor.py:157} INFO - Started process (PID=96662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:08:08.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:08:08.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:08.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:08:08.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:08:08.810+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:08.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:08:08.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:08.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:08:08.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T13:08:39.230+0000] {processor.py:157} INFO - Started process (PID=96687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:08:39.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:08:39.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:39.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:08:39.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:08:39.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:39.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:08:39.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:39.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:08:39.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T13:09:09.670+0000] {processor.py:157} INFO - Started process (PID=96712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:09:09.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:09:09.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:09.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:09:09.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:09:09.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:09.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:09:09.730+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:09.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:09:09.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T13:09:40.162+0000] {processor.py:157} INFO - Started process (PID=96737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:09:40.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:09:40.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:40.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:09:40.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:09:40.195+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:40.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:09:40.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:40.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:09:40.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T13:10:10.638+0000] {processor.py:157} INFO - Started process (PID=96762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:10:10.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:10:10.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:10.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:10:10.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:10:10.667+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:10.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:10:10.676+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:10.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:10:10.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T13:10:41.099+0000] {processor.py:157} INFO - Started process (PID=96787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:10:41.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:10:41.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:41.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:10:41.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:10:41.133+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:41.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:10:41.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:41.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:10:41.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T13:11:11.590+0000] {processor.py:157} INFO - Started process (PID=96812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:11:11.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:11:11.594+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:11.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:11:11.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:11:11.625+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:11.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:11:11.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:11.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:11:11.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T13:11:42.036+0000] {processor.py:157} INFO - Started process (PID=96837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:11:42.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:11:42.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:42.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:11:42.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:11:42.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:42.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:11:42.093+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:42.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:11:42.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T13:12:12.450+0000] {processor.py:157} INFO - Started process (PID=96862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:12:12.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:12:12.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:12.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:12:12.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:12:12.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:12.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:12:12.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:12.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:12:12.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T13:12:42.879+0000] {processor.py:157} INFO - Started process (PID=96887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:12:42.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:12:42.881+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:42.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:12:42.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:12:42.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:42.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:12:42.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:42.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:12:42.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T13:13:13.325+0000] {processor.py:157} INFO - Started process (PID=96912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:13:13.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:13:13.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:13.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:13:13.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:13:13.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:13.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:13:13.365+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:13.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:13:13.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T13:13:43.856+0000] {processor.py:157} INFO - Started process (PID=96937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:13:43.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:13:43.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:43.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:13:43.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:13:43.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:43.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:13:43.937+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:43.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:13:43.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-20T13:14:14.398+0000] {processor.py:157} INFO - Started process (PID=96962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:14:14.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:14:14.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:14.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:14:14.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:14:14.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:14.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:14:14.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:14.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:14:14.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T13:14:44.767+0000] {processor.py:157} INFO - Started process (PID=96987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:14:44.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:14:44.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:44.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:14:44.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:14:44.799+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:44.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:14:44.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:44.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:14:44.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T13:15:15.180+0000] {processor.py:157} INFO - Started process (PID=97012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:15:15.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:15:15.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:15.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:15:15.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:15:15.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:15.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:15:15.223+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:15.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:15:15.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:15:45.658+0000] {processor.py:157} INFO - Started process (PID=97037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:15:45.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:15:45.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:45.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:15:45.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:15:45.702+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:45.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:15:45.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:45.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:15:45.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T13:16:16.109+0000] {processor.py:157} INFO - Started process (PID=97062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:16:16.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:16:16.112+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:16.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:16:16.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:16:16.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:16.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:16:16.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:16.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:16:16.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:16:46.604+0000] {processor.py:157} INFO - Started process (PID=97087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:16:46.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:16:46.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:46.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:16:46.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:16:46.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:46.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:16:46.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:46.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:16:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T13:17:22.526+0000] {processor.py:157} INFO - Started process (PID=97114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:17:22.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:17:22.529+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:22.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:17:22.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:17:22.559+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:22.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:17:22.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:22.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:17:22.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:17:52.999+0000] {processor.py:157} INFO - Started process (PID=97139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:17:53.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:17:53.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:53.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:17:53.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:17:53.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:53.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:17:53.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:53.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:17:53.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T13:18:23.425+0000] {processor.py:157} INFO - Started process (PID=97164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:18:23.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:18:23.430+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:23.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:18:23.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:18:23.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:23.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:18:23.474+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:23.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:18:23.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T13:18:53.916+0000] {processor.py:157} INFO - Started process (PID=97189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:18:53.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:18:53.919+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:53.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:18:53.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:18:53.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:53.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:18:53.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:53.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:18:53.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T13:19:24.379+0000] {processor.py:157} INFO - Started process (PID=97214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:19:24.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:19:24.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:24.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:19:24.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:19:24.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:24.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:19:24.433+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:24.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:19:24.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T13:19:54.840+0000] {processor.py:157} INFO - Started process (PID=97239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:19:54.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:19:54.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:54.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:19:54.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:19:54.875+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:54.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:19:54.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:54.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:19:54.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T13:20:25.254+0000] {processor.py:157} INFO - Started process (PID=97264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:20:25.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:20:25.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:25.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:20:25.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:20:25.284+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:25.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:20:25.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:25.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:20:25.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:20:55.663+0000] {processor.py:157} INFO - Started process (PID=97289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:20:55.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:20:55.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:55.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:20:55.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:20:55.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:55.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:20:55.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:55.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:20:55.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T13:21:26.140+0000] {processor.py:157} INFO - Started process (PID=97313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:21:26.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:21:26.151+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:26.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:21:26.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:21:26.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:26.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:21:26.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:26.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:21:26.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-20T13:21:56.613+0000] {processor.py:157} INFO - Started process (PID=97339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:21:56.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:21:56.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:56.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:21:56.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:21:56.642+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:56.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:21:56.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:56.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:21:56.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:22:27.102+0000] {processor.py:157} INFO - Started process (PID=97364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:22:27.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:22:27.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:27.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:22:27.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:22:27.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:27.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:22:27.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:27.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:22:27.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T13:22:57.572+0000] {processor.py:157} INFO - Started process (PID=97388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:22:57.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:22:57.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:57.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:22:57.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:22:57.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:57.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:22:57.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:57.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:22:57.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T13:23:28.044+0000] {processor.py:157} INFO - Started process (PID=97414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:23:28.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:23:28.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:28.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:23:28.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:23:28.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:28.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:23:28.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:28.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:23:28.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T13:23:58.507+0000] {processor.py:157} INFO - Started process (PID=97439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:23:58.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:23:58.511+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:58.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:23:58.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:23:58.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:58.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:23:58.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:58.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:23:58.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T13:24:28.923+0000] {processor.py:157} INFO - Started process (PID=97464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:24:28.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:24:28.927+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:28.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:24:28.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:24:28.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:28.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:24:28.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:28.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:24:28.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T13:24:59.387+0000] {processor.py:157} INFO - Started process (PID=97489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:24:59.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:24:59.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:59.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:24:59.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:24:59.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:59.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:24:59.425+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:59.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:24:59.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T13:25:29.847+0000] {processor.py:157} INFO - Started process (PID=97513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:25:29.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:25:29.850+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:25:29.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:25:29.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:25:29.875+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:25:29.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:25:29.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:25:29.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:25:29.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:26:00.292+0000] {processor.py:157} INFO - Started process (PID=97539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:26:00.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:26:00.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:00.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:26:00.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:26:00.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:00.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:26:00.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:00.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:26:00.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-20T13:26:30.794+0000] {processor.py:157} INFO - Started process (PID=97564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:26:30.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:26:30.797+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:30.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:26:30.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:26:30.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:30.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:26:30.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:30.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:26:30.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T13:27:01.301+0000] {processor.py:157} INFO - Started process (PID=97589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:27:01.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:27:01.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:01.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:27:01.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:27:01.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:01.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:27:01.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:01.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:27:01.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T13:27:31.835+0000] {processor.py:157} INFO - Started process (PID=97614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:27:31.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:27:31.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:31.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:27:31.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:27:31.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:31.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:27:31.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:31.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:27:31.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:28:02.275+0000] {processor.py:157} INFO - Started process (PID=97639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:28:02.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:28:02.279+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:02.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:28:02.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:28:02.306+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:02.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:28:02.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:02.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:28:02.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:28:32.792+0000] {processor.py:157} INFO - Started process (PID=97664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:28:32.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:28:32.797+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:32.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:28:32.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:28:32.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:32.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:28:32.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:32.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:28:32.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T13:29:03.187+0000] {processor.py:157} INFO - Started process (PID=97689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:29:03.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:29:03.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:03.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:29:03.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:29:03.219+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:03.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:29:03.229+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:03.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:29:03.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T13:29:33.657+0000] {processor.py:157} INFO - Started process (PID=97714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:29:33.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:29:33.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:33.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:29:33.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:29:33.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:33.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:29:33.700+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:33.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:29:33.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T13:30:04.051+0000] {processor.py:157} INFO - Started process (PID=97739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:30:04.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:30:04.055+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:04.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:30:04.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:30:04.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:04.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:30:04.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:04.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:30:04.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T13:30:34.453+0000] {processor.py:157} INFO - Started process (PID=97764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:30:34.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:30:34.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:34.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:30:34.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:30:34.485+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:34.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:30:34.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:34.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:30:34.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:31:04.908+0000] {processor.py:157} INFO - Started process (PID=97789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:31:04.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:31:04.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:04.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:31:04.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:31:04.940+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:04.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:31:04.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:04.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:31:04.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:31:35.353+0000] {processor.py:157} INFO - Started process (PID=97814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:31:35.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:31:35.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:35.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:31:35.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:31:35.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:35.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:31:35.394+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:35.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:31:35.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T13:32:05.859+0000] {processor.py:157} INFO - Started process (PID=97839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:32:05.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:32:05.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:05.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:32:05.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:32:05.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:05.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:32:05.902+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:05.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:32:05.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T13:32:36.338+0000] {processor.py:157} INFO - Started process (PID=97864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:32:36.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:32:36.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:36.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:32:36.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:32:36.378+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:36.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:32:36.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:36.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:32:36.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-20T13:33:06.802+0000] {processor.py:157} INFO - Started process (PID=97889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:33:06.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:33:06.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:06.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:33:06.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:33:06.833+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:06.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:33:06.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:06.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:33:06.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T13:33:37.262+0000] {processor.py:157} INFO - Started process (PID=97914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:33:37.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:33:37.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:37.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:33:37.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:33:37.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:37.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:33:37.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:37.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:33:37.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T13:34:07.761+0000] {processor.py:157} INFO - Started process (PID=97939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:34:07.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:34:07.766+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:07.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:34:07.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:34:07.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:07.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:34:07.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:07.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:34:07.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T13:34:38.223+0000] {processor.py:157} INFO - Started process (PID=97964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:34:38.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:34:38.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:38.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:34:38.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:34:38.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:38.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:34:38.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:38.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:34:38.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T13:35:08.659+0000] {processor.py:157} INFO - Started process (PID=97989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:35:08.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:35:08.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:08.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:35:08.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:35:08.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:08.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:35:08.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:08.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:35:08.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T13:35:39.137+0000] {processor.py:157} INFO - Started process (PID=98014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:35:39.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:35:39.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:39.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:35:39.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:35:39.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:39.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:35:39.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:39.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:35:39.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T13:36:09.646+0000] {processor.py:157} INFO - Started process (PID=98039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:36:09.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:36:09.648+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:09.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:36:09.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:36:09.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:09.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:36:09.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:09.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:36:09.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T13:36:40.160+0000] {processor.py:157} INFO - Started process (PID=98062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:36:40.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:36:40.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:40.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:36:40.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:36:40.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:40.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:36:40.218+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:40.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:36:40.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-20T13:37:10.637+0000] {processor.py:157} INFO - Started process (PID=98089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:37:10.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:37:10.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:10.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:37:10.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:37:10.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:10.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:37:10.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:10.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:37:10.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T13:37:41.153+0000] {processor.py:157} INFO - Started process (PID=98114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:37:41.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:37:41.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:41.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:37:41.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:37:41.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:41.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:37:41.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:41.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:37:41.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T13:38:11.665+0000] {processor.py:157} INFO - Started process (PID=98139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:38:11.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:38:11.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:11.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:38:11.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:38:11.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:11.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:38:11.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:11.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:38:11.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T13:38:42.147+0000] {processor.py:157} INFO - Started process (PID=98164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:38:42.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:38:42.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:42.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:38:42.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:38:42.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:42.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:38:42.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:42.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:38:42.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:39:12.603+0000] {processor.py:157} INFO - Started process (PID=98189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:39:12.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:39:12.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:12.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:39:12.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:39:12.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:12.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:39:12.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:12.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:39:12.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T13:39:43.115+0000] {processor.py:157} INFO - Started process (PID=98214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:39:43.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:39:43.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:43.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:39:43.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:39:43.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:43.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:39:43.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:43.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:39:43.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T13:40:13.615+0000] {processor.py:157} INFO - Started process (PID=98238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:40:13.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:40:13.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:40:13.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:40:13.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:40:13.666+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:40:13.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:40:13.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:40:13.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:40:13.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-20T13:41:13.315+0000] {processor.py:157} INFO - Started process (PID=98266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:41:13.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:41:13.317+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:13.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:41:13.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:41:13.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:13.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:41:13.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:13.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:41:13.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T13:41:43.781+0000] {processor.py:157} INFO - Started process (PID=98291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:41:43.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:41:43.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:43.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:41:43.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:41:43.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:43.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:41:43.825+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:43.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:41:43.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T13:42:19.035+0000] {processor.py:157} INFO - Started process (PID=98316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:42:19.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:42:19.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:42:19.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:42:19.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:42:19.065+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:42:19.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:42:19.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:42:19.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:42:19.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T13:59:20.505+0000] {processor.py:157} INFO - Started process (PID=98341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:59:20.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:59:20.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:20.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:59:20.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:59:20.579+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:20.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:59:20.610+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:20.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:59:20.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-20T13:59:51.217+0000] {processor.py:157} INFO - Started process (PID=98368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:59:51.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T13:59:51.220+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:51.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:59:51.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T13:59:51.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:51.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:59:51.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:51.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T13:59:51.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T14:00:49.337+0000] {processor.py:157} INFO - Started process (PID=98393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:00:49.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:00:49.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:00:49.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:00:49.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:00:49.384+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:00:49.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:00:49.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:00:49.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:00:49.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T14:01:19.868+0000] {processor.py:157} INFO - Started process (PID=98418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:01:19.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:01:19.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:19.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:01:19.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:01:19.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:19.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:01:19.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:19.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:01:19.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T14:01:50.410+0000] {processor.py:157} INFO - Started process (PID=98443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:01:50.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:01:50.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:50.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:01:50.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:01:50.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:50.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:01:50.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:50.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:01:50.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:02:20.874+0000] {processor.py:157} INFO - Started process (PID=98468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:02:20.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:02:20.878+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:20.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:02:20.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:02:20.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:20.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:02:20.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:20.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:02:20.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:02:51.305+0000] {processor.py:157} INFO - Started process (PID=98493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:02:51.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:02:51.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:51.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:02:51.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:02:51.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:51.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:02:51.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:51.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:02:51.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T14:03:21.734+0000] {processor.py:157} INFO - Started process (PID=98518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:03:21.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:03:21.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:21.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:03:21.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:03:21.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:21.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:03:21.774+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:21.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:03:21.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:03:52.286+0000] {processor.py:157} INFO - Started process (PID=98543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:03:52.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:03:52.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:52.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:03:52.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:03:52.314+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:52.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:03:52.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:52.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:03:52.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:04:22.942+0000] {processor.py:157} INFO - Started process (PID=98568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:04:22.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:04:22.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:22.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:04:22.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:04:22.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:22.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:04:22.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:22.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:04:23.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T14:04:53.437+0000] {processor.py:157} INFO - Started process (PID=98593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:04:53.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:04:53.440+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:53.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:04:53.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:04:53.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:53.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:04:53.479+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:53.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:04:53.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T14:05:23.880+0000] {processor.py:157} INFO - Started process (PID=98618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:05:23.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:05:23.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:23.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:05:23.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:05:23.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:23.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:05:23.924+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:23.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:05:23.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T14:05:54.314+0000] {processor.py:157} INFO - Started process (PID=98643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:05:54.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:05:54.319+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:54.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:05:54.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:05:54.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:54.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:05:54.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:54.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:05:54.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:06:24.745+0000] {processor.py:157} INFO - Started process (PID=98668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:06:24.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:06:24.749+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:24.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:06:24.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:06:24.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:24.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:06:24.787+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:24.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:06:24.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T14:06:55.167+0000] {processor.py:157} INFO - Started process (PID=98693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:06:55.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:06:55.172+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:55.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:06:55.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:06:55.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:55.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:06:55.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:55.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:06:55.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T14:07:25.634+0000] {processor.py:157} INFO - Started process (PID=98718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:07:25.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:07:25.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:25.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:07:25.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:07:25.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:25.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:07:25.677+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:25.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:07:25.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T14:07:56.057+0000] {processor.py:157} INFO - Started process (PID=98743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:07:56.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:07:56.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:56.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:07:56.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:07:56.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:56.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:07:56.099+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:56.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:07:56.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T14:08:26.476+0000] {processor.py:157} INFO - Started process (PID=98768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:08:26.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:08:26.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:26.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:08:26.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:08:26.511+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:26.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:08:26.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:26.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:08:26.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T14:08:56.918+0000] {processor.py:157} INFO - Started process (PID=98793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:08:56.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:08:56.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:56.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:08:56.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:08:56.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:56.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:08:56.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:56.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:08:56.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T14:09:27.380+0000] {processor.py:157} INFO - Started process (PID=98818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:09:27.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:09:27.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:27.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:09:27.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:09:27.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:27.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:09:27.417+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:27.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:09:27.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T14:09:57.892+0000] {processor.py:157} INFO - Started process (PID=98843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:09:57.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:09:57.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:57.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:09:57.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:09:57.930+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:57.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:09:57.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:57.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:09:57.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-20T14:10:28.334+0000] {processor.py:157} INFO - Started process (PID=98868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:10:28.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:10:28.338+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:28.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:10:28.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:10:28.362+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:28.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:10:28.372+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:28.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:10:28.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T14:10:58.819+0000] {processor.py:157} INFO - Started process (PID=98893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:10:58.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:10:58.823+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:58.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:10:58.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:10:58.852+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:58.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:10:58.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:58.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:10:58.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T14:11:29.354+0000] {processor.py:157} INFO - Started process (PID=98918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:11:29.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:11:29.357+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:29.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:11:29.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:11:29.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:29.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:11:29.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:29.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:11:29.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T14:11:59.785+0000] {processor.py:157} INFO - Started process (PID=98943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:11:59.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:11:59.787+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:59.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:11:59.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:11:59.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:59.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:11:59.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:59.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:11:59.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:12:30.171+0000] {processor.py:157} INFO - Started process (PID=98968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:12:30.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:12:30.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:12:30.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:12:30.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:12:30.201+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:12:30.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:12:30.210+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:12:30.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:12:30.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T14:13:00.598+0000] {processor.py:157} INFO - Started process (PID=98993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:13:00.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:13:00.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:00.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:13:00.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:13:00.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:00.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:13:00.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:00.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:13:00.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:13:31.056+0000] {processor.py:157} INFO - Started process (PID=99018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:13:31.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:13:31.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:31.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:13:31.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:13:31.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:31.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:13:31.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:31.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:13:31.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T14:14:01.493+0000] {processor.py:157} INFO - Started process (PID=99043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:14:01.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:14:01.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:01.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:14:01.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:14:01.525+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:01.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:14:01.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:01.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:14:01.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T14:14:31.932+0000] {processor.py:157} INFO - Started process (PID=99068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:14:31.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:14:31.934+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:31.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:14:31.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:14:31.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:31.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:14:31.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:31.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:14:31.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:15:02.358+0000] {processor.py:157} INFO - Started process (PID=99093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:15:02.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:15:02.362+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:02.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:15:02.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:15:02.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:02.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:15:02.412+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:02.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:15:02.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T14:15:32.831+0000] {processor.py:157} INFO - Started process (PID=99118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:15:32.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:15:32.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:32.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:15:32.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:15:32.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:32.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:15:32.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:32.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:15:32.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T14:16:03.220+0000] {processor.py:157} INFO - Started process (PID=99143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:16:03.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:16:03.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:03.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:16:03.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:16:03.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:03.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:16:03.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:03.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:16:03.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:16:33.681+0000] {processor.py:157} INFO - Started process (PID=99168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:16:33.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:16:33.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:33.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:16:33.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:16:33.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:33.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:16:33.720+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:33.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:16:33.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T14:17:04.060+0000] {processor.py:157} INFO - Started process (PID=99193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:17:04.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:17:04.062+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:04.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:17:04.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:17:04.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:04.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:17:04.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:04.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:17:04.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-20T14:17:34.535+0000] {processor.py:157} INFO - Started process (PID=99218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:17:34.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:17:34.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:34.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:17:34.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:17:34.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:34.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:17:34.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:34.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:17:34.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:18:04.891+0000] {processor.py:157} INFO - Started process (PID=99243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:18:04.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:18:04.893+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:04.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:18:04.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:18:04.916+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:04.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:18:04.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:04.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:18:04.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T14:18:35.319+0000] {processor.py:157} INFO - Started process (PID=99268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:18:35.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:18:35.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:35.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:18:35.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:18:35.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:35.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:18:35.418+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:35.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:18:35.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T14:19:05.831+0000] {processor.py:157} INFO - Started process (PID=99293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:19:05.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:19:05.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:05.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:19:05.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:19:05.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:05.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:19:05.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:05.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:19:05.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T14:19:36.302+0000] {processor.py:157} INFO - Started process (PID=99318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:19:36.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:19:36.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:36.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:19:36.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:19:36.338+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:36.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:19:36.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:36.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:19:36.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T14:20:06.775+0000] {processor.py:157} INFO - Started process (PID=99343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:20:06.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:20:06.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:06.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:20:06.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:20:06.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:06.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:20:06.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:06.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:20:06.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-20T14:20:37.259+0000] {processor.py:157} INFO - Started process (PID=99367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:20:37.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:20:37.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:37.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:20:37.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:20:37.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:37.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:20:37.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:37.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:20:37.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T14:21:07.751+0000] {processor.py:157} INFO - Started process (PID=99393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:21:07.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:21:07.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:07.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:21:07.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:21:07.794+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:07.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:21:07.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:07.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:21:07.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T14:21:38.244+0000] {processor.py:157} INFO - Started process (PID=99418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:21:38.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:21:38.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:38.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:21:38.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:21:38.274+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:38.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:21:38.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:38.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:21:38.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:22:08.677+0000] {processor.py:157} INFO - Started process (PID=99443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:22:08.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:22:08.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:08.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:22:08.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:22:08.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:08.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:22:08.753+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:08.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:22:08.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-20T14:22:39.170+0000] {processor.py:157} INFO - Started process (PID=99468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:22:39.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:22:39.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:39.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:22:39.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:22:39.225+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:39.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:22:39.243+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:39.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:22:39.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-20T14:23:09.712+0000] {processor.py:157} INFO - Started process (PID=99493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:23:09.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:23:09.714+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:09.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:23:09.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:23:09.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:09.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:23:09.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:09.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:23:09.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T14:23:40.212+0000] {processor.py:157} INFO - Started process (PID=99518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:23:40.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:23:40.218+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:40.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:23:40.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:23:40.255+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:40.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:23:40.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:40.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:23:40.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T14:24:10.620+0000] {processor.py:157} INFO - Started process (PID=99543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:24:10.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:24:10.623+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:10.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:24:10.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:24:10.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:10.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:24:10.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:10.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:24:10.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T14:24:41.046+0000] {processor.py:157} INFO - Started process (PID=99568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:24:41.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:24:41.049+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:41.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:24:41.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:24:41.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:41.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:24:41.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:41.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:24:41.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:25:11.473+0000] {processor.py:157} INFO - Started process (PID=99593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:25:11.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:25:11.477+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:11.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:25:11.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:25:11.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:11.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:25:11.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:11.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:25:11.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T14:25:41.921+0000] {processor.py:157} INFO - Started process (PID=99618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:25:41.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:25:41.924+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:41.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:25:41.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:25:41.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:41.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:25:41.964+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:41.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:25:41.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:26:12.392+0000] {processor.py:157} INFO - Started process (PID=99643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:26:12.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:26:12.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:12.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:26:12.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:26:12.421+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:12.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:26:12.430+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:12.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:26:12.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T14:26:42.834+0000] {processor.py:157} INFO - Started process (PID=99668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:26:42.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:26:42.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:42.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:26:42.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:26:42.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:42.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:26:42.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:42.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:26:42.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:27:13.263+0000] {processor.py:157} INFO - Started process (PID=99693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:27:13.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:27:13.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:13.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:27:13.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:27:13.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:13.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:27:13.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:13.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:27:13.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T14:27:43.719+0000] {processor.py:157} INFO - Started process (PID=99718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:27:43.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:27:43.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:43.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:27:43.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:27:43.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:43.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:27:43.761+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:43.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:27:43.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T14:28:14.145+0000] {processor.py:157} INFO - Started process (PID=99743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:28:14.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:28:14.149+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:14.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:28:14.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:28:14.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:14.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:28:14.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:14.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:28:14.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:28:44.630+0000] {processor.py:157} INFO - Started process (PID=99768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:28:44.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:28:44.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:44.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:28:44.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:28:44.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:44.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:28:44.678+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:44.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:28:44.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T14:29:15.122+0000] {processor.py:157} INFO - Started process (PID=99793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:29:15.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:29:15.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:15.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:29:15.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:29:15.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:15.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:29:15.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:15.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:29:15.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T14:29:45.603+0000] {processor.py:157} INFO - Started process (PID=99818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:29:45.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:29:45.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:45.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:29:45.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:29:45.635+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:45.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:29:45.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:45.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:29:45.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:30:16.109+0000] {processor.py:157} INFO - Started process (PID=99843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:30:16.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:30:16.112+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:16.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:30:16.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:30:16.142+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:16.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:30:16.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:16.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:30:16.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T14:30:46.567+0000] {processor.py:157} INFO - Started process (PID=99868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:30:46.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:30:46.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:46.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:30:46.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:30:46.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:46.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:30:46.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:46.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:30:46.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-20T14:31:17.079+0000] {processor.py:157} INFO - Started process (PID=99893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:31:17.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:31:17.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:17.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:31:17.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:31:17.110+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:17.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:31:17.121+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:17.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:31:17.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T14:31:47.489+0000] {processor.py:157} INFO - Started process (PID=99918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:31:47.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:31:47.492+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:47.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:31:47.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:31:47.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:47.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:31:47.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:47.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:31:47.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:32:17.880+0000] {processor.py:157} INFO - Started process (PID=99943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:32:17.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:32:17.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:17.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:32:17.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:32:17.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:17.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:32:17.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:17.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:32:17.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:32:48.298+0000] {processor.py:157} INFO - Started process (PID=99968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:32:48.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:32:48.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:48.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:32:48.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:32:48.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:48.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:32:48.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:48.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:32:48.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T14:33:18.781+0000] {processor.py:157} INFO - Started process (PID=99993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:33:18.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:33:18.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:18.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:33:18.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:33:18.811+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:18.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:33:18.821+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:18.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:33:18.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:33:49.256+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:33:49.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:33:49.261+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:49.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:33:49.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:33:49.289+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:49.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:33:49.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:49.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:33:49.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T14:34:19.703+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:34:19.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:34:19.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:19.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:34:19.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:34:19.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:19.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:34:19.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:19.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:34:19.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:34:50.204+0000] {processor.py:157} INFO - Started process (PID=369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:34:50.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:34:50.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:50.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:34:50.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:34:50.232+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:50.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:34:50.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:50.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:34:50.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:35:20.651+0000] {processor.py:157} INFO - Started process (PID=394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:35:20.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:35:20.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:20.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:35:20.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:35:20.683+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:20.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:35:20.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:20.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:35:20.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T14:35:51.204+0000] {processor.py:157} INFO - Started process (PID=418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:35:51.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:35:51.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:51.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:35:51.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:35:51.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:51.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:35:51.255+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:51.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:35:51.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T14:36:21.744+0000] {processor.py:157} INFO - Started process (PID=444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:36:21.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:36:21.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:21.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:36:21.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:36:21.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:21.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:36:21.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:21.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:36:21.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T14:36:52.300+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:36:52.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:36:52.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:52.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:36:52.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:36:52.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:52.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:36:52.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:52.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:36:52.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T14:37:22.711+0000] {processor.py:157} INFO - Started process (PID=494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:37:22.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:37:22.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:22.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:37:22.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:37:22.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:22.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:37:22.749+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:22.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:37:22.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T14:37:53.074+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:37:53.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:37:53.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:53.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:37:53.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:37:53.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:53.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:37:53.112+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:53.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:37:53.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T14:38:23.493+0000] {processor.py:157} INFO - Started process (PID=544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:38:23.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:38:23.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:23.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:38:23.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:38:23.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:23.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:38:23.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:23.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:38:23.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-20T14:38:53.917+0000] {processor.py:157} INFO - Started process (PID=569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:38:53.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:38:53.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:53.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:38:53.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:38:53.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:53.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:38:53.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:53.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:38:53.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T14:39:24.419+0000] {processor.py:157} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:39:24.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:39:24.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:24.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:39:24.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:39:24.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:24.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:39:24.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:24.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:39:24.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T14:39:54.901+0000] {processor.py:157} INFO - Started process (PID=619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:39:54.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:39:54.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:54.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:39:54.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:39:54.930+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:54.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:39:54.939+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:54.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:39:54.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T14:40:25.291+0000] {processor.py:157} INFO - Started process (PID=644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:40:25.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:40:25.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:25.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:40:25.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:40:25.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:25.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:40:25.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:25.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:40:25.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:40:55.774+0000] {processor.py:157} INFO - Started process (PID=669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:40:55.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:40:55.778+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:55.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:40:55.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:40:55.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:55.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:40:55.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:55.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:40:55.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:41:26.233+0000] {processor.py:157} INFO - Started process (PID=694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:41:26.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:41:26.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:26.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:41:26.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:41:26.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:26.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:41:26.274+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:26.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:41:26.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:41:56.723+0000] {processor.py:157} INFO - Started process (PID=719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:41:56.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:41:56.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:56.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:41:56.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:41:56.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:56.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:41:56.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:56.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:41:56.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T14:42:27.133+0000] {processor.py:157} INFO - Started process (PID=744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:42:27.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:42:27.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:27.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:42:27.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:42:27.168+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:27.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:42:27.179+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:27.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:42:27.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T14:42:57.593+0000] {processor.py:157} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:42:57.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:42:57.595+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:57.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:42:57.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:42:57.622+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:57.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:42:57.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:57.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:42:57.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:43:28.025+0000] {processor.py:157} INFO - Started process (PID=794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:43:28.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:43:28.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:28.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:43:28.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:43:28.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:28.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:43:28.062+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:28.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:43:28.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T14:43:58.446+0000] {processor.py:157} INFO - Started process (PID=819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:43:58.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:43:58.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:58.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:43:58.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:43:58.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:58.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:43:58.488+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:58.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:43:58.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T14:44:28.948+0000] {processor.py:157} INFO - Started process (PID=844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:44:28.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:44:28.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:28.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:44:28.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:44:28.978+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:28.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:44:28.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:28.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:44:28.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T14:44:59.267+0000] {processor.py:157} INFO - Started process (PID=869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:44:59.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:44:59.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:59.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:44:59.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:44:59.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:59.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:44:59.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:59.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:44:59.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T14:45:29.692+0000] {processor.py:157} INFO - Started process (PID=894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:45:29.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:45:29.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:45:29.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:45:29.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:45:29.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:45:29.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:45:29.731+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:45:29.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:45:29.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T14:46:00.095+0000] {processor.py:157} INFO - Started process (PID=919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:46:00.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:46:00.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:00.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:46:00.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:46:00.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:00.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:46:00.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:00.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:46:00.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:46:30.512+0000] {processor.py:157} INFO - Started process (PID=944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:46:30.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:46:30.515+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:30.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:46:30.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:46:30.544+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:30.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:46:30.553+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:30.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:46:30.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T14:47:00.964+0000] {processor.py:157} INFO - Started process (PID=969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:47:00.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:47:00.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:00.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:47:00.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:47:00.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:00.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:47:01.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:01.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:47:01.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:47:31.379+0000] {processor.py:157} INFO - Started process (PID=994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:47:31.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:47:31.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:31.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:47:31.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:47:31.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:31.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:47:31.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:31.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:47:31.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T14:48:01.919+0000] {processor.py:157} INFO - Started process (PID=1019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:48:01.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:48:01.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:01.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:48:01.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:48:01.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:01.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:48:01.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:01.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:48:01.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:48:32.347+0000] {processor.py:157} INFO - Started process (PID=1044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:48:32.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:48:32.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:32.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:48:32.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:48:32.376+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:32.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:48:32.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:32.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:48:32.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:49:02.825+0000] {processor.py:157} INFO - Started process (PID=1069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:49:02.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:49:02.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:02.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:49:02.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:49:02.854+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:02.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:49:02.864+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:02.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:49:02.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:49:33.319+0000] {processor.py:157} INFO - Started process (PID=1094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:49:33.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:49:33.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:33.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:49:33.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:49:33.347+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:33.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:49:33.357+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:33.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:49:33.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T14:50:03.811+0000] {processor.py:157} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:50:03.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:50:03.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:03.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:50:03.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:50:03.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:03.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:50:03.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:03.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:50:03.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T14:50:34.368+0000] {processor.py:157} INFO - Started process (PID=1144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:50:34.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:50:34.372+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:34.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:50:34.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:50:34.399+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:34.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:50:34.409+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:34.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:50:34.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:51:04.813+0000] {processor.py:157} INFO - Started process (PID=1169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:51:04.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:51:04.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:04.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:51:04.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:51:04.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:04.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:51:04.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:04.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:51:04.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T14:51:35.240+0000] {processor.py:157} INFO - Started process (PID=1194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:51:35.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:51:35.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:35.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:51:35.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:51:35.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:35.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:51:35.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:35.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:51:35.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T14:52:05.694+0000] {processor.py:157} INFO - Started process (PID=1219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:52:05.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:52:05.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:05.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:52:05.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:52:05.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:05.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:52:05.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:05.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:52:05.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T14:52:36.136+0000] {processor.py:157} INFO - Started process (PID=1244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:52:36.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:52:36.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:36.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:52:36.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:52:36.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:36.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:52:36.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:36.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:52:36.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:53:06.529+0000] {processor.py:157} INFO - Started process (PID=1269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:53:06.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:53:06.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:06.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:53:06.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:53:06.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:06.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:53:06.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:06.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:53:06.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T14:53:36.966+0000] {processor.py:157} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:53:36.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:53:36.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:36.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:53:36.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:53:36.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:36.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:53:37.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:37.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:53:37.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T14:54:07.417+0000] {processor.py:157} INFO - Started process (PID=1319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:54:07.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:54:07.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:07.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:54:07.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:54:07.448+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:07.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:54:07.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:07.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:54:07.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:54:37.915+0000] {processor.py:157} INFO - Started process (PID=1344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:54:37.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:54:37.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:37.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:54:37.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:54:37.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:37.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:54:37.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:37.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:54:37.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:55:08.382+0000] {processor.py:157} INFO - Started process (PID=1369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:55:08.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:55:08.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:08.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:55:08.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:55:08.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:08.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:55:08.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:08.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:55:08.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:55:38.834+0000] {processor.py:157} INFO - Started process (PID=1394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:55:38.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:55:38.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:38.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:55:38.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:55:38.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:38.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:55:38.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:38.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:55:38.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:56:09.338+0000] {processor.py:157} INFO - Started process (PID=1419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:56:09.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:56:09.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:09.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:56:09.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:56:09.369+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:09.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:56:09.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:09.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:56:09.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:56:39.781+0000] {processor.py:157} INFO - Started process (PID=1444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:56:39.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:56:39.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:39.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:56:39.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:56:39.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:39.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:56:39.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:39.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:56:39.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-20T14:57:10.246+0000] {processor.py:157} INFO - Started process (PID=1469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:57:10.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:57:10.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:10.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:57:10.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:57:10.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:10.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:57:10.285+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:10.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:57:10.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T14:57:40.753+0000] {processor.py:157} INFO - Started process (PID=1494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:57:40.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:57:40.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:40.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:57:40.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:57:40.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:40.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:57:40.799+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:40.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:57:40.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:58:11.180+0000] {processor.py:157} INFO - Started process (PID=1519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:58:11.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:58:11.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:11.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:58:11.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:58:11.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:11.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:58:11.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:11.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:58:11.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T14:58:41.672+0000] {processor.py:157} INFO - Started process (PID=1544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:58:41.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:58:41.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:41.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:58:41.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:58:41.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:41.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:58:41.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:41.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:58:41.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T14:59:12.078+0000] {processor.py:157} INFO - Started process (PID=1569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:59:12.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:59:12.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:12.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:59:12.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:59:12.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:12.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:59:12.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:12.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:59:12.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T14:59:42.622+0000] {processor.py:157} INFO - Started process (PID=1594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:59:42.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T14:59:42.626+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:42.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:59:42.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T14:59:42.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:42.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:59:42.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:42.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T14:59:42.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T15:00:13.050+0000] {processor.py:157} INFO - Started process (PID=1619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:00:13.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:00:13.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:13.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:00:13.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:00:13.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:13.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:00:13.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:13.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:00:13.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T15:00:43.492+0000] {processor.py:157} INFO - Started process (PID=1644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:00:43.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:00:43.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:43.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:00:43.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:00:43.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:43.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:00:43.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:43.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:00:43.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T15:01:13.903+0000] {processor.py:157} INFO - Started process (PID=1669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:01:13.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:01:13.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:13.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:01:13.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:01:13.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:13.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:01:13.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:13.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:01:13.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:01:44.385+0000] {processor.py:157} INFO - Started process (PID=1694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:01:44.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:01:44.389+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:44.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:01:44.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:01:44.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:44.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:01:44.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:44.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:01:44.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:02:14.908+0000] {processor.py:157} INFO - Started process (PID=1719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:02:14.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:02:14.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:14.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:02:14.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:02:14.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:14.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:02:14.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:14.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:02:14.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T15:02:45.352+0000] {processor.py:157} INFO - Started process (PID=1744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:02:45.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:02:45.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:45.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:02:45.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:02:45.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:45.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:02:45.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:45.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:02:45.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:03:15.784+0000] {processor.py:157} INFO - Started process (PID=1769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:03:15.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:03:15.787+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:15.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:03:15.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:03:15.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:15.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:03:15.827+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:15.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:03:15.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:03:46.190+0000] {processor.py:157} INFO - Started process (PID=1794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:03:46.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:03:46.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:46.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:03:46.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:03:46.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:46.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:03:46.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:46.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:03:46.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:04:16.642+0000] {processor.py:157} INFO - Started process (PID=1819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:04:16.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:04:16.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:16.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:04:16.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:04:16.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:16.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:04:16.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:16.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:04:16.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:04:47.142+0000] {processor.py:157} INFO - Started process (PID=1844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:04:47.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:04:47.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:47.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:04:47.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:04:47.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:47.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:04:47.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:47.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:04:47.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:05:17.616+0000] {processor.py:157} INFO - Started process (PID=1869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:05:17.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:05:17.619+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:17.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:05:17.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:05:17.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:17.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:05:17.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:17.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:05:17.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:05:48.052+0000] {processor.py:157} INFO - Started process (PID=1894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:05:48.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:05:48.055+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:48.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:05:48.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:05:48.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:48.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:05:48.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:48.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:05:48.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:06:18.438+0000] {processor.py:157} INFO - Started process (PID=1919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:06:18.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:06:18.440+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:18.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:06:18.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:06:18.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:18.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:06:18.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:18.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:06:18.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:06:48.906+0000] {processor.py:157} INFO - Started process (PID=1944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:06:48.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:06:48.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:48.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:06:48.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:06:48.937+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:48.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:06:48.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:48.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:06:48.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:07:19.284+0000] {processor.py:157} INFO - Started process (PID=1969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:07:19.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:07:19.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:19.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:07:19.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:07:19.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:19.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:07:19.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:19.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:07:19.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T15:07:49.740+0000] {processor.py:157} INFO - Started process (PID=1994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:07:49.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:07:49.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:49.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:07:49.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:07:49.774+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:49.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:07:49.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:49.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:07:49.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:08:20.167+0000] {processor.py:157} INFO - Started process (PID=2019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:08:20.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:08:20.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:20.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:08:20.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:08:20.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:20.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:08:20.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:20.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:08:20.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T15:08:50.625+0000] {processor.py:157} INFO - Started process (PID=2044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:08:50.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:08:50.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:50.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:08:50.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:08:50.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:50.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:08:50.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:50.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:08:50.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:09:21.081+0000] {processor.py:157} INFO - Started process (PID=2069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:09:21.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:09:21.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:21.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:09:21.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:09:21.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:21.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:09:21.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:21.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:09:21.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T15:09:51.525+0000] {processor.py:157} INFO - Started process (PID=2094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:09:51.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:09:51.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:51.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:09:51.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:09:51.553+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:51.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:09:51.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:51.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:09:51.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:10:22.044+0000] {processor.py:157} INFO - Started process (PID=2119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:10:22.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:10:22.047+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:22.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:10:22.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:10:22.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:22.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:10:22.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:22.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:10:22.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T15:10:52.534+0000] {processor.py:157} INFO - Started process (PID=2144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:10:52.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:10:52.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:52.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:10:52.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:10:52.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:52.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:10:52.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:52.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:10:52.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:11:23.062+0000] {processor.py:157} INFO - Started process (PID=2169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:11:23.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:11:23.065+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:23.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:11:23.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:11:23.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:23.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:11:23.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:23.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:11:23.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:11:53.518+0000] {processor.py:157} INFO - Started process (PID=2194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:11:53.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:11:53.526+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:53.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:11:53.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:11:53.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:53.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:11:53.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:53.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:11:53.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:12:23.930+0000] {processor.py:157} INFO - Started process (PID=2219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:12:23.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:12:23.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:23.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:12:23.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:12:23.963+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:23.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:12:23.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:23.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:12:23.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:12:54.462+0000] {processor.py:157} INFO - Started process (PID=2244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:12:54.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:12:54.466+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:54.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:12:54.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:12:54.490+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:54.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:12:54.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:54.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:12:54.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:13:24.984+0000] {processor.py:157} INFO - Started process (PID=2269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:13:24.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:13:24.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:24.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:13:25.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:13:25.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:25.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:13:25.021+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:25.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:13:25.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T15:13:55.477+0000] {processor.py:157} INFO - Started process (PID=2294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:13:55.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:13:55.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:55.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:13:55.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:13:55.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:55.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:13:55.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:55.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:13:55.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:14:25.876+0000] {processor.py:157} INFO - Started process (PID=2319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:14:25.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:14:25.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:25.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:14:25.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:14:25.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:25.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:14:25.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:25.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:14:25.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:14:56.365+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:14:56.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:14:56.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:56.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:14:56.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:14:56.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:56.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:14:56.408+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:56.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:14:56.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:15:26.996+0000] {processor.py:157} INFO - Started process (PID=2369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:15:26.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:15:27.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:27.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:15:27.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:15:27.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:27.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:15:27.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:27.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:15:27.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:15:57.475+0000] {processor.py:157} INFO - Started process (PID=2394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:15:57.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:15:57.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:57.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:15:57.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:15:57.506+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:57.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:15:57.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:57.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:15:57.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:16:27.915+0000] {processor.py:157} INFO - Started process (PID=2419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:16:27.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:16:27.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:27.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:16:27.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:16:27.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:27.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:16:27.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:27.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:16:27.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:16:58.358+0000] {processor.py:157} INFO - Started process (PID=2444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:16:58.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:16:58.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:58.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:16:58.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:16:58.384+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:58.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:16:58.394+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:58.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:16:58.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T15:17:28.818+0000] {processor.py:157} INFO - Started process (PID=2469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:17:28.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:17:28.823+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:28.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:17:28.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:17:28.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:28.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:17:28.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:28.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:17:28.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T15:17:59.236+0000] {processor.py:157} INFO - Started process (PID=2494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:17:59.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:17:59.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:59.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:17:59.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:17:59.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:59.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:17:59.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:59.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:17:59.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:18:29.723+0000] {processor.py:157} INFO - Started process (PID=2519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:18:29.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:18:29.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:18:29.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:18:29.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:18:29.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:18:29.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:18:29.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:18:29.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:18:29.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T15:19:00.205+0000] {processor.py:157} INFO - Started process (PID=2544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:19:00.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:19:00.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:00.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:19:00.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:19:00.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:00.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:19:00.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:00.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:19:00.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T15:19:30.758+0000] {processor.py:157} INFO - Started process (PID=2569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:19:30.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:19:30.761+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:30.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:19:30.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:19:30.787+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:30.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:19:30.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:30.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:19:30.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:20:01.227+0000] {processor.py:157} INFO - Started process (PID=2594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:20:01.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:20:01.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:01.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:20:01.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:20:01.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:01.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:20:01.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:01.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:20:01.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T15:20:31.695+0000] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:20:31.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:20:31.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:31.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:20:31.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:20:31.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:31.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:20:31.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:31.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:20:31.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:21:02.178+0000] {processor.py:157} INFO - Started process (PID=2644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:21:02.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:21:02.181+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:02.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:21:02.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:21:02.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:02.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:21:02.220+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:02.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:21:02.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:21:32.610+0000] {processor.py:157} INFO - Started process (PID=2669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:21:32.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:21:32.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:32.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:21:32.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:21:32.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:32.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:21:32.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:32.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:21:32.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T15:22:03.052+0000] {processor.py:157} INFO - Started process (PID=2694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:22:03.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:22:03.056+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:03.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:22:03.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:22:03.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:03.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:22:03.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:03.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:22:03.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T15:22:33.487+0000] {processor.py:157} INFO - Started process (PID=2719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:22:33.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:22:33.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:33.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:22:33.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:22:33.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:33.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:22:33.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:33.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:22:33.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:23:03.993+0000] {processor.py:157} INFO - Started process (PID=2744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:23:03.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:23:03.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:03.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:23:04.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:23:04.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:04.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:23:04.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:04.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:23:04.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:23:34.425+0000] {processor.py:157} INFO - Started process (PID=2769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:23:34.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:23:34.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:34.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:23:34.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:23:34.455+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:34.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:23:34.465+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:34.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:23:34.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:24:04.883+0000] {processor.py:157} INFO - Started process (PID=2794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:24:04.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:24:04.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:04.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:24:04.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:24:04.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:04.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:24:04.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:04.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:24:04.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:24:35.339+0000] {processor.py:157} INFO - Started process (PID=2819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:24:35.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:24:35.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:35.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:24:35.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:24:35.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:35.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:24:35.377+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:35.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:24:35.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:25:05.858+0000] {processor.py:157} INFO - Started process (PID=2844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:25:05.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:25:05.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:05.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:25:05.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:25:05.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:05.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:25:05.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:05.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:25:05.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T15:25:36.361+0000] {processor.py:157} INFO - Started process (PID=2869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:25:36.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:25:36.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:36.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:25:36.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:25:36.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:36.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:25:36.404+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:36.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:25:36.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:26:06.820+0000] {processor.py:157} INFO - Started process (PID=2894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:26:06.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:26:06.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:06.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:26:06.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:26:06.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:06.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:26:06.862+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:06.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:26:06.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:26:37.223+0000] {processor.py:157} INFO - Started process (PID=2919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:26:37.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:26:37.226+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:37.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:26:37.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:26:37.253+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:37.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:26:37.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:37.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:26:37.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:27:07.614+0000] {processor.py:157} INFO - Started process (PID=2944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:27:07.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:27:07.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:07.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:27:07.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:27:07.642+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:07.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:27:07.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:07.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:27:07.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:27:38.070+0000] {processor.py:157} INFO - Started process (PID=2969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:27:38.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:27:38.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:38.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:27:38.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:27:38.101+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:38.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:27:38.111+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:38.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:27:38.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:28:08.593+0000] {processor.py:157} INFO - Started process (PID=2994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:28:08.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:28:08.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:08.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:28:08.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:28:08.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:08.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:28:08.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:08.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:28:08.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:28:39.056+0000] {processor.py:157} INFO - Started process (PID=3019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:28:39.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:28:39.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:39.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:28:39.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:28:39.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:39.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:28:39.096+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:39.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:28:39.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:29:09.589+0000] {processor.py:157} INFO - Started process (PID=3044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:29:09.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:29:09.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:09.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:29:09.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:29:09.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:09.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:29:09.635+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:09.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:29:09.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T15:29:40.002+0000] {processor.py:157} INFO - Started process (PID=3069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:29:40.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:29:40.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:40.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:29:40.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:29:40.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:40.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:29:40.039+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:40.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:29:40.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T15:30:10.432+0000] {processor.py:157} INFO - Started process (PID=3094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:30:10.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:30:10.434+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:10.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:30:10.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:30:10.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:10.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:30:10.473+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:10.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:30:10.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:30:40.891+0000] {processor.py:157} INFO - Started process (PID=3119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:30:40.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:30:40.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:40.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:30:40.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:30:40.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:40.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:30:40.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:40.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:30:40.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T15:31:11.402+0000] {processor.py:157} INFO - Started process (PID=3144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:31:11.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:31:11.405+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:11.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:31:11.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:31:11.434+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:11.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:31:11.443+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:11.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:31:11.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:31:41.847+0000] {processor.py:157} INFO - Started process (PID=3169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:31:41.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:31:41.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:41.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:31:41.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:31:41.881+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:41.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:31:41.891+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:41.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:31:41.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:32:12.277+0000] {processor.py:157} INFO - Started process (PID=3194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:32:12.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:32:12.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:12.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:32:12.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:32:12.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:12.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:32:12.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:12.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:32:12.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T15:32:42.678+0000] {processor.py:157} INFO - Started process (PID=3219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:32:42.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:32:42.682+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:42.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:32:42.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:32:42.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:42.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:32:42.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:42.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:32:42.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:33:13.154+0000] {processor.py:157} INFO - Started process (PID=3244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:33:13.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:33:13.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:13.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:33:13.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:33:13.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:13.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:33:13.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:13.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:33:13.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:33:43.716+0000] {processor.py:157} INFO - Started process (PID=3269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:33:43.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:33:43.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:43.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:33:43.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:33:43.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:43.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:33:43.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:43.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:33:43.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-20T15:34:14.266+0000] {processor.py:157} INFO - Started process (PID=3294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:34:14.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:34:14.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:14.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:34:14.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:34:14.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:14.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:34:14.317+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:14.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:34:14.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T15:34:44.706+0000] {processor.py:157} INFO - Started process (PID=3319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:34:44.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:34:44.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:44.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:34:44.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:34:44.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:44.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:34:44.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:44.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:34:44.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:35:15.154+0000] {processor.py:157} INFO - Started process (PID=3344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:35:15.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:35:15.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:15.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:35:15.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:35:15.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:15.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:35:15.197+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:15.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:35:15.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:35:45.675+0000] {processor.py:157} INFO - Started process (PID=3369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:35:45.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:35:45.680+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:45.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:35:45.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:35:45.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:45.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:35:45.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:45.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:35:45.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T15:36:16.157+0000] {processor.py:157} INFO - Started process (PID=3394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:36:16.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:36:16.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:16.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:36:16.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:36:16.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:16.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:36:16.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:16.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:36:16.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:36:46.693+0000] {processor.py:157} INFO - Started process (PID=3419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:36:46.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:36:46.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:46.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:36:46.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:36:46.728+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:46.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:36:46.739+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:46.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:36:46.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T15:37:17.154+0000] {processor.py:157} INFO - Started process (PID=3444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:37:17.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:37:17.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:17.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:37:17.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:37:17.197+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:17.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:37:17.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:17.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:37:17.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T15:37:47.595+0000] {processor.py:157} INFO - Started process (PID=3469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:37:47.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:37:47.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:47.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:37:47.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:37:47.625+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:47.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:37:47.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:47.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:37:47.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T15:38:18.051+0000] {processor.py:157} INFO - Started process (PID=3494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:38:18.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:38:18.055+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:18.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:38:18.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:38:18.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:18.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:38:18.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:18.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:38:18.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T15:38:48.537+0000] {processor.py:157} INFO - Started process (PID=3519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:38:48.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:38:48.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:48.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:38:48.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:38:48.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:48.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:38:48.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:48.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:38:48.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:39:19.051+0000] {processor.py:157} INFO - Started process (PID=3544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:39:19.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:39:19.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:19.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:39:19.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:39:19.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:19.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:39:19.096+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:19.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:39:19.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:39:49.566+0000] {processor.py:157} INFO - Started process (PID=3569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:39:49.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:39:49.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:49.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:39:49.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:39:49.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:49.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:39:49.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:49.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:39:49.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T15:40:20.071+0000] {processor.py:157} INFO - Started process (PID=3594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:40:20.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:40:20.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:20.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:40:20.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:40:20.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:20.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:40:20.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:20.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:40:20.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:40:50.511+0000] {processor.py:157} INFO - Started process (PID=3619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:40:50.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:40:50.515+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:50.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:40:50.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:40:50.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:50.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:40:50.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:50.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:40:50.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:41:20.995+0000] {processor.py:157} INFO - Started process (PID=3644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:41:20.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:41:20.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:20.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:41:21.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:41:21.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:21.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:41:21.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:21.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:41:21.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T15:41:51.360+0000] {processor.py:157} INFO - Started process (PID=3669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:41:51.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:41:51.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:51.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:41:51.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:41:51.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:51.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:41:51.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:51.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:41:51.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T15:42:21.844+0000] {processor.py:157} INFO - Started process (PID=3694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:42:21.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:42:21.848+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:21.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:42:21.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:42:21.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:21.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:42:21.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:21.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:42:21.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T15:42:52.251+0000] {processor.py:157} INFO - Started process (PID=3719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:42:52.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:42:52.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:52.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:42:52.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:42:52.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:52.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:42:52.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:52.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:42:52.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:43:22.741+0000] {processor.py:157} INFO - Started process (PID=3743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:43:22.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:43:22.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:22.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:43:22.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:43:22.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:22.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:43:22.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:22.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:43:22.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-20T15:43:53.234+0000] {processor.py:157} INFO - Started process (PID=3769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:43:53.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:43:53.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:53.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:43:53.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:43:53.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:53.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:43:53.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:53.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:43:53.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:44:23.640+0000] {processor.py:157} INFO - Started process (PID=3794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:44:23.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:44:23.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:23.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:44:23.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:44:23.666+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:23.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:44:23.676+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:23.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:44:23.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T15:44:54.135+0000] {processor.py:157} INFO - Started process (PID=3819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:44:54.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:44:54.141+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:54.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:44:54.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:44:54.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:54.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:44:54.191+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:54.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:44:54.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T15:45:24.607+0000] {processor.py:157} INFO - Started process (PID=3844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:45:24.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:45:24.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:24.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:45:24.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:45:24.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:24.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:45:24.667+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:24.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:45:24.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T15:45:55.093+0000] {processor.py:157} INFO - Started process (PID=3869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:45:55.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:45:55.099+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:55.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:45:55.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:45:55.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:55.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:45:55.151+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:55.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:45:55.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-20T15:46:25.611+0000] {processor.py:157} INFO - Started process (PID=3894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:46:25.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:46:25.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:25.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:46:25.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:46:25.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:25.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:46:25.677+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:25.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:46:25.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-20T15:46:56.082+0000] {processor.py:157} INFO - Started process (PID=3919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:46:56.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:46:56.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:56.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:46:56.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:46:56.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:56.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:46:56.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:56.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:46:56.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-20T15:47:26.496+0000] {processor.py:157} INFO - Started process (PID=3943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:47:26.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:47:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:26.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:47:26.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:47:26.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:26.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:47:26.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:26.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:47:26.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T15:47:56.991+0000] {processor.py:157} INFO - Started process (PID=3969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:47:56.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:47:56.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:56.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:47:57.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:47:57.025+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:57.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:47:57.035+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:57.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:47:57.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:48:27.418+0000] {processor.py:157} INFO - Started process (PID=3994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:48:27.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:48:27.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:27.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:48:27.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:48:27.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:27.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:48:27.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:27.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:48:27.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:48:57.879+0000] {processor.py:157} INFO - Started process (PID=4019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:48:57.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:48:57.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:57.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:48:57.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:48:57.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:57.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:48:57.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:57.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:48:57.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-20T15:49:28.365+0000] {processor.py:157} INFO - Started process (PID=4044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:49:28.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:49:28.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:28.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:49:28.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:49:28.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:28.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:49:28.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:28.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:49:28.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T15:49:58.799+0000] {processor.py:157} INFO - Started process (PID=4069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:49:58.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:49:58.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:58.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:49:58.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:49:58.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:58.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:49:58.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:58.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:49:58.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T15:50:29.235+0000] {processor.py:157} INFO - Started process (PID=4094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:50:29.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:50:29.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:29.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:50:29.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:50:29.275+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:29.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:50:29.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:29.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:50:29.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T15:50:59.723+0000] {processor.py:157} INFO - Started process (PID=4119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:50:59.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:50:59.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:59.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:50:59.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:50:59.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:59.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:50:59.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:59.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:50:59.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T15:51:30.136+0000] {processor.py:157} INFO - Started process (PID=4144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:51:30.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:51:30.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:51:30.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:51:30.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:51:30.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:51:30.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:51:30.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:51:30.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:51:30.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T15:52:00.556+0000] {processor.py:157} INFO - Started process (PID=4169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:52:00.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:52:00.558+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:00.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:52:00.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:52:00.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:00.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:52:00.596+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:00.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:52:00.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:52:30.988+0000] {processor.py:157} INFO - Started process (PID=4194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:52:30.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:52:30.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:30.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:52:31.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:52:31.033+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:31.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:52:31.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:31.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:52:31.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T15:53:01.492+0000] {processor.py:157} INFO - Started process (PID=4219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:53:01.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:53:01.500+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:01.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:53:01.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:53:01.525+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:01.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:53:01.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:01.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:53:01.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T15:53:31.976+0000] {processor.py:157} INFO - Started process (PID=4244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:53:31.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:53:31.980+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:31.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:53:31.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:53:32.020+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:32.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:53:32.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:32.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:53:32.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T15:54:02.389+0000] {processor.py:157} INFO - Started process (PID=4268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:54:02.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:54:02.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:02.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:54:02.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:54:02.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:02.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:54:02.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:02.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:54:02.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T15:54:32.870+0000] {processor.py:157} INFO - Started process (PID=4294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:54:32.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:54:32.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:32.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:54:32.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:54:32.902+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:32.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:54:32.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:32.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:54:32.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T15:55:03.355+0000] {processor.py:157} INFO - Started process (PID=4319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:55:03.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:55:03.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:03.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:55:03.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:55:03.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:03.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:55:03.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:03.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:55:03.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T15:55:33.746+0000] {processor.py:157} INFO - Started process (PID=4344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:55:33.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:55:33.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:33.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:55:33.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:55:33.789+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:33.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:55:33.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:33.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:55:33.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T15:56:04.256+0000] {processor.py:157} INFO - Started process (PID=4369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:56:04.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:56:04.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:04.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:56:04.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:56:04.290+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:04.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:56:04.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:04.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:56:04.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:56:34.686+0000] {processor.py:157} INFO - Started process (PID=4394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:56:34.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:56:34.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:34.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:56:34.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:56:34.716+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:34.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:56:34.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:34.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:56:34.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:57:05.080+0000] {processor.py:157} INFO - Started process (PID=4419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:57:05.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:57:05.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:05.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:57:05.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:57:05.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:05.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:57:05.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:05.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:57:05.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T15:57:35.580+0000] {processor.py:157} INFO - Started process (PID=4443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:57:35.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:57:35.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:35.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:57:35.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:57:35.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:35.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:57:35.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:35.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:57:35.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-20T15:58:06.062+0000] {processor.py:157} INFO - Started process (PID=4469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:58:06.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:58:06.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:06.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:58:06.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:58:06.093+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:06.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:58:06.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:06.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:58:06.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T15:58:36.546+0000] {processor.py:157} INFO - Started process (PID=4494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:58:36.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:58:36.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:36.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:58:36.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:58:36.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:36.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:58:36.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:36.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:58:36.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T15:59:06.916+0000] {processor.py:157} INFO - Started process (PID=4519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:59:06.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:59:06.919+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:06.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:59:06.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:59:06.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:06.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:59:06.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:06.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:59:06.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T15:59:37.410+0000] {processor.py:157} INFO - Started process (PID=4544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:59:37.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T15:59:37.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:37.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:59:37.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T15:59:37.440+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:37.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:59:37.450+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:37.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T15:59:37.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T16:00:07.844+0000] {processor.py:157} INFO - Started process (PID=4569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:00:07.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:00:07.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:07.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:00:07.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:00:07.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:07.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:00:07.911+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:07.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:00:07.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-20T16:00:38.298+0000] {processor.py:157} INFO - Started process (PID=4594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:00:38.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:00:38.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:38.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:00:38.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:00:38.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:38.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:00:38.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:38.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:00:38.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T16:01:08.766+0000] {processor.py:157} INFO - Started process (PID=4619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:01:08.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:01:08.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:08.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:01:08.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:01:08.794+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:08.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:01:08.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:08.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:01:08.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T16:01:39.154+0000] {processor.py:157} INFO - Started process (PID=4644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:01:39.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:01:39.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:39.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:01:39.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:01:39.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:39.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:01:39.201+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:39.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:01:39.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T16:02:09.534+0000] {processor.py:157} INFO - Started process (PID=4669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:02:09.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:02:09.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:09.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:02:09.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:02:09.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:09.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:02:09.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:09.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:02:09.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-20T16:02:40.026+0000] {processor.py:157} INFO - Started process (PID=4694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:02:40.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:02:40.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:40.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:02:40.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:02:40.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:40.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:02:40.067+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:40.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:02:40.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T16:03:10.506+0000] {processor.py:157} INFO - Started process (PID=4719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:03:10.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:03:10.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:10.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:03:10.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:03:10.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:10.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:03:10.553+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:10.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:03:10.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T16:03:40.949+0000] {processor.py:157} INFO - Started process (PID=4744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:03:40.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:03:40.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:40.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:03:40.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:03:40.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:40.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:03:41.011+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:41.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:03:41.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T16:04:11.402+0000] {processor.py:157} INFO - Started process (PID=4769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:04:11.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:04:11.409+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:11.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:04:11.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:04:11.435+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:11.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:04:11.448+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:11.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:04:11.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T16:04:41.887+0000] {processor.py:157} INFO - Started process (PID=4793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:04:41.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:04:41.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:41.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:04:41.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:04:41.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:41.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:04:41.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:41.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:04:41.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-20T16:05:12.397+0000] {processor.py:157} INFO - Started process (PID=4819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:05:12.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:05:12.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:12.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:05:12.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:05:12.430+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:12.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:05:12.440+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:12.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:05:12.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T16:05:42.839+0000] {processor.py:157} INFO - Started process (PID=4843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:05:42.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:05:42.845+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:42.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:05:42.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:05:42.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:42.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:05:42.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:42.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:05:42.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T16:06:13.267+0000] {processor.py:157} INFO - Started process (PID=4869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:06:13.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:06:13.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:13.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:06:13.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:06:13.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:13.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:06:13.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:13.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:06:13.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T16:06:43.689+0000] {processor.py:157} INFO - Started process (PID=4894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:06:43.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:06:43.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:43.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:06:43.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:06:43.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:43.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:06:43.728+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:43.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:06:43.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T16:07:14.104+0000] {processor.py:157} INFO - Started process (PID=4919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:07:14.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:07:14.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:14.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:07:14.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:07:14.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:14.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:07:14.163+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:14.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:07:14.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-20T16:07:44.561+0000] {processor.py:157} INFO - Started process (PID=4944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:07:44.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:07:44.565+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:44.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:07:44.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:07:44.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:44.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:07:44.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:44.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:07:44.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T16:08:14.985+0000] {processor.py:157} INFO - Started process (PID=4969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:08:14.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:08:14.988+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:14.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:08:14.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:08:15.010+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:15.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:08:15.019+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:15.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:08:15.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-20T16:08:45.372+0000] {processor.py:157} INFO - Started process (PID=4994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:08:45.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:08:45.378+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:45.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:08:45.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:08:45.409+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:45.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:08:45.419+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:45.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:08:45.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T16:09:15.849+0000] {processor.py:157} INFO - Started process (PID=5019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:09:15.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:09:15.854+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:15.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:09:15.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:09:15.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:15.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:09:15.911+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:15.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:09:15.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-20T16:09:46.645+0000] {processor.py:157} INFO - Started process (PID=5044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:09:46.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:09:46.648+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:46.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:09:46.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:09:46.678+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:46.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:09:46.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:46.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:09:46.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T16:10:17.084+0000] {processor.py:157} INFO - Started process (PID=5068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:10:17.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:10:17.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:17.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:10:17.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:10:17.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:17.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:10:17.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:17.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:10:17.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T16:10:47.542+0000] {processor.py:157} INFO - Started process (PID=5094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:10:47.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:10:47.549+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:47.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:10:47.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:10:47.579+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:47.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:10:47.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:47.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:10:47.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T16:11:17.950+0000] {processor.py:157} INFO - Started process (PID=5119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:11:17.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:11:17.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:17.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:11:17.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:11:17.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:17.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:11:17.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:17.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:11:18.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T16:11:48.320+0000] {processor.py:157} INFO - Started process (PID=5144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:11:48.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:11:48.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:48.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:11:48.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:11:48.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:48.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:11:48.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:48.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:11:48.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T16:12:18.836+0000] {processor.py:157} INFO - Started process (PID=5169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:12:18.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:12:18.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:18.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:12:18.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:12:18.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:18.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:12:18.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:18.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:12:18.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-20T16:12:49.301+0000] {processor.py:157} INFO - Started process (PID=5194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:12:49.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:12:49.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:49.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:12:49.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:12:49.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:49.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:12:49.346+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:49.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:12:49.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T16:13:19.784+0000] {processor.py:157} INFO - Started process (PID=5219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:13:19.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:13:19.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:19.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:13:19.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:13:19.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:19.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:13:19.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:19.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:13:19.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-20T16:13:50.296+0000] {processor.py:157} INFO - Started process (PID=5244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:13:50.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:13:50.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:50.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:13:50.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:13:50.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:50.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:13:50.353+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:50.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:13:50.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-20T16:14:20.692+0000] {processor.py:157} INFO - Started process (PID=5269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:14:20.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:14:20.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:20.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:14:20.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:14:20.728+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:20.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:14:20.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:20.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:14:20.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T16:14:51.148+0000] {processor.py:157} INFO - Started process (PID=5294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:14:51.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:14:51.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:51.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:14:51.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:14:51.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:51.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:14:51.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:51.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:14:51.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-20T16:15:21.672+0000] {processor.py:157} INFO - Started process (PID=5319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:15:21.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:15:21.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:21.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:15:21.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:15:21.730+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:21.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:15:21.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:21.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:15:21.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-20T16:15:52.148+0000] {processor.py:157} INFO - Started process (PID=5344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:15:52.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:15:52.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:52.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:15:52.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:15:52.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:52.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:15:52.232+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:52.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:15:52.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-20T16:16:22.700+0000] {processor.py:157} INFO - Started process (PID=5369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:16:22.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:16:22.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:22.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:16:22.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:16:22.759+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:22.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:16:22.772+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:22.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:16:22.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-20T16:16:53.196+0000] {processor.py:157} INFO - Started process (PID=5394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:16:53.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:16:53.201+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:53.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:16:53.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:16:53.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:53.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:16:53.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:53.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:16:53.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-20T16:17:23.602+0000] {processor.py:157} INFO - Started process (PID=5419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:17:23.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:17:23.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:23.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:17:23.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:17:23.637+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:23.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:17:23.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:23.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:17:23.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T16:17:54.079+0000] {processor.py:157} INFO - Started process (PID=5443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:17:54.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:17:54.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:54.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:17:54.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:17:54.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:54.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:17:54.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:54.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:17:54.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-07-20T16:18:24.651+0000] {processor.py:157} INFO - Started process (PID=5469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:18:24.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:18:24.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:24.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:18:24.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:18:24.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:24.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:18:24.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:24.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:18:24.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T16:18:55.178+0000] {processor.py:157} INFO - Started process (PID=5494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:18:55.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:18:55.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:55.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:18:55.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:18:55.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:55.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:18:55.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:55.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:18:55.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-20T16:19:25.822+0000] {processor.py:157} INFO - Started process (PID=5519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:19:25.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:19:25.830+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:25.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:19:25.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:19:25.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:25.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:19:25.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:25.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:19:25.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-20T16:19:56.340+0000] {processor.py:157} INFO - Started process (PID=5544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:19:56.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:19:56.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:56.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:19:56.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:19:56.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:56.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:19:56.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:56.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:19:56.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-20T16:20:26.772+0000] {processor.py:157} INFO - Started process (PID=5569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:20:26.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:20:26.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:26.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:20:26.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:20:26.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:26.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:20:26.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:26.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:20:26.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T16:20:57.237+0000] {processor.py:157} INFO - Started process (PID=5594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:20:57.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:20:57.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:57.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:20:57.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:20:57.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:57.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:20:57.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:57.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:20:57.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T16:21:27.597+0000] {processor.py:157} INFO - Started process (PID=5619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:21:27.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:21:27.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:27.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:21:27.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:21:27.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:27.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:21:27.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:27.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:21:27.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-20T16:21:58.065+0000] {processor.py:157} INFO - Started process (PID=5644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:21:58.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:21:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:58.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:21:58.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:21:58.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:58.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:21:58.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:58.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:21:58.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T16:22:28.525+0000] {processor.py:157} INFO - Started process (PID=5669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:22:28.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:22:28.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:28.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:22:28.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:22:28.590+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:28.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:22:28.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:28.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:22:28.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-20T16:22:59.049+0000] {processor.py:157} INFO - Started process (PID=5694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:22:59.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:22:59.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:59.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:22:59.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:22:59.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:59.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:22:59.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:59.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:22:59.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T16:23:29.821+0000] {processor.py:157} INFO - Started process (PID=5719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:23:29.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:23:29.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:23:29.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:23:29.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:23:29.891+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:23:29.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:23:29.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:23:29.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:23:29.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-20T16:24:00.592+0000] {processor.py:157} INFO - Started process (PID=5744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:24:00.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:24:00.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:00.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:24:00.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:24:00.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:00.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:24:00.671+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:00.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:24:00.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-20T16:24:31.105+0000] {processor.py:157} INFO - Started process (PID=5769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:24:31.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:24:31.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:31.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:24:31.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:24:31.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:31.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:24:31.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:31.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:24:31.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-20T16:25:01.548+0000] {processor.py:157} INFO - Started process (PID=5794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:25:01.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:25:01.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:01.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:25:01.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:25:01.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:01.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:25:01.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:01.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:25:01.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-20T16:25:32.045+0000] {processor.py:157} INFO - Started process (PID=5819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:25:32.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:25:32.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:32.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:25:32.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:25:32.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:32.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:25:32.099+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:32.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:25:32.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T16:26:02.564+0000] {processor.py:157} INFO - Started process (PID=5844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:26:02.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:26:02.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:02.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:26:02.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:26:02.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:02.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:26:02.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:02.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:26:02.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T16:26:33.043+0000] {processor.py:157} INFO - Started process (PID=5869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:26:33.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:26:33.046+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:33.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:26:33.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:26:33.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:33.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:26:33.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:33.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:26:33.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-07-20T16:27:03.767+0000] {processor.py:157} INFO - Started process (PID=5894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:27:03.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:27:03.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:03.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:27:03.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:27:03.792+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:03.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:27:03.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:03.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:27:03.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T16:27:34.218+0000] {processor.py:157} INFO - Started process (PID=5919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:27:34.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:27:34.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:34.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:27:34.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:27:34.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:34.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:27:34.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:34.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:27:34.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T16:28:04.661+0000] {processor.py:157} INFO - Started process (PID=5944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:28:04.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:28:04.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:04.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:28:04.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:28:04.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:04.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:28:04.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:04.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:28:04.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T16:28:35.082+0000] {processor.py:157} INFO - Started process (PID=5969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:28:35.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:28:35.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:35.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:28:35.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:28:35.113+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:35.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:28:35.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:35.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:28:35.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T16:29:05.562+0000] {processor.py:157} INFO - Started process (PID=5994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:29:05.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:29:05.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:05.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:29:05.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:29:05.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:05.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:29:05.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:05.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:29:05.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T16:29:35.991+0000] {processor.py:157} INFO - Started process (PID=6019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:29:35.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:29:35.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:35.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:29:36.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:29:36.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:36.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:29:36.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:36.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:29:36.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-20T16:30:06.554+0000] {processor.py:157} INFO - Started process (PID=6044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:30:06.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:30:06.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:06.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:30:06.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:30:06.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:06.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:30:06.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:06.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:30:06.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-20T16:30:36.999+0000] {processor.py:157} INFO - Started process (PID=6069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:30:37.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:30:37.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:37.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:30:37.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:30:37.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:37.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:30:37.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:37.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:30:37.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T16:31:07.476+0000] {processor.py:157} INFO - Started process (PID=6094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:31:07.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:31:07.479+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:07.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:31:07.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:31:07.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:07.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:31:07.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:07.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:31:07.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T16:31:37.956+0000] {processor.py:157} INFO - Started process (PID=6118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:31:37.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:31:37.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:37.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:31:37.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:31:38.009+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:38.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:31:38.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:38.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:31:38.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-20T16:32:08.449+0000] {processor.py:157} INFO - Started process (PID=6144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:32:08.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:32:08.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:08.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:32:08.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:32:08.477+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:08.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:32:08.487+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:08.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:32:08.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-07-20T16:32:39.089+0000] {processor.py:157} INFO - Started process (PID=6169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:32:39.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:32:39.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:39.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:32:39.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:32:39.121+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:39.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:32:39.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:39.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:32:39.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T16:33:09.553+0000] {processor.py:157} INFO - Started process (PID=6194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:33:09.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:33:09.556+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:09.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:33:09.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:33:09.584+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:09.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:33:09.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:09.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:33:09.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T16:33:39.967+0000] {processor.py:157} INFO - Started process (PID=6219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:33:39.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:33:39.971+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:39.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:33:39.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:33:39.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:39.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:33:40.007+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:40.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:33:40.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T16:34:10.450+0000] {processor.py:157} INFO - Started process (PID=6244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:34:10.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:34:10.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:10.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:34:10.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:34:10.499+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:10.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:34:10.515+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:10.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:34:10.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-20T16:34:41.080+0000] {processor.py:157} INFO - Started process (PID=6269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:34:41.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:34:41.105+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:41.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:34:41.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:34:41.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:41.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:34:41.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:41.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:34:41.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-20T16:35:11.564+0000] {processor.py:157} INFO - Started process (PID=6294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:35:11.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:35:11.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:11.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:35:11.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:35:11.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:11.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:35:11.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:11.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:35:11.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-20T16:35:42.185+0000] {processor.py:157} INFO - Started process (PID=6319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:35:42.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:35:42.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:42.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:35:42.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:35:42.226+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:42.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:35:42.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:42.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:35:42.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T16:36:12.646+0000] {processor.py:157} INFO - Started process (PID=6344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:36:12.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:36:12.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:12.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:36:12.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:36:12.683+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:12.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:36:12.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:12.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:36:12.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T16:36:43.082+0000] {processor.py:157} INFO - Started process (PID=6369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:36:43.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:36:43.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:43.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:36:43.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:36:43.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:43.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:36:43.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:43.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:36:43.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T16:37:13.531+0000] {processor.py:157} INFO - Started process (PID=6394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:37:13.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:37:13.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:13.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:37:13.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:37:13.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:13.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:37:13.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:13.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:37:13.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T16:37:43.955+0000] {processor.py:157} INFO - Started process (PID=6419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:37:43.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:37:43.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:43.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:37:43.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:37:43.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:43.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:37:44.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:44.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:37:44.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T16:38:14.366+0000] {processor.py:157} INFO - Started process (PID=6444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:38:14.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:38:14.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:14.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:38:14.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:38:14.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:14.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:38:14.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:14.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:38:14.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-07-20T16:38:45.019+0000] {processor.py:157} INFO - Started process (PID=6469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:38:45.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:38:45.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:45.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:38:45.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:38:45.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:45.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:38:45.093+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:45.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:38:45.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-20T16:39:15.461+0000] {processor.py:157} INFO - Started process (PID=6494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:39:15.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:39:15.465+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:15.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:39:15.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:39:15.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:15.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:39:15.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:15.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:39:15.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-20T16:39:46.036+0000] {processor.py:157} INFO - Started process (PID=6519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:39:46.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:39:46.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:46.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:39:46.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:39:46.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:46.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:39:46.095+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:46.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:39:46.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-20T16:40:16.465+0000] {processor.py:157} INFO - Started process (PID=6544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:40:16.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:40:16.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:16.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:40:16.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:40:16.499+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:16.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:40:16.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:16.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:40:16.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T16:40:46.931+0000] {processor.py:157} INFO - Started process (PID=6569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:40:46.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:40:46.938+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:46.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:40:46.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:40:46.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:46.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:40:46.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:46.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:40:47.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-07-20T16:41:17.538+0000] {processor.py:157} INFO - Started process (PID=6594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:41:17.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:41:17.544+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:17.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:41:17.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:41:17.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:17.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:41:17.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:17.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:41:17.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-20T16:41:48.027+0000] {processor.py:157} INFO - Started process (PID=6619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:41:48.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:41:48.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:48.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:41:48.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:41:48.064+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:48.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:41:48.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:48.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:41:48.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T16:42:18.447+0000] {processor.py:157} INFO - Started process (PID=6644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:42:18.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:42:18.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:18.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:42:18.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:42:18.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:18.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:42:18.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:18.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:42:18.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-20T16:42:49.045+0000] {processor.py:157} INFO - Started process (PID=6669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:42:49.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:42:49.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:49.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:42:49.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:42:49.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:49.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:42:49.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:49.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:42:49.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-20T16:43:19.558+0000] {processor.py:157} INFO - Started process (PID=6694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:43:19.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:43:19.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:19.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:43:19.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:43:19.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:19.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:43:19.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:19.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:43:19.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T16:43:50.117+0000] {processor.py:157} INFO - Started process (PID=6719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:43:50.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:43:50.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:50.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:43:50.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:43:50.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:50.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:43:50.164+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:50.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:43:50.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-20T16:44:20.941+0000] {processor.py:157} INFO - Started process (PID=6744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:44:20.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:44:20.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:20.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:44:20.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:44:21.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:21.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:44:21.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:21.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:44:21.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-20T16:44:51.454+0000] {processor.py:157} INFO - Started process (PID=6769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:44:51.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:44:51.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:51.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:44:51.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:44:51.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:51.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:44:51.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:51.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:44:51.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-20T16:45:22.030+0000] {processor.py:157} INFO - Started process (PID=6794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:45:22.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:45:22.039+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:22.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:45:22.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:45:22.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:22.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:45:22.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:22.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:45:22.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T16:45:52.423+0000] {processor.py:157} INFO - Started process (PID=6819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:45:52.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:45:52.431+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:52.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:45:52.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:45:52.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:52.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:45:52.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:52.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:45:52.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-20T16:46:23.011+0000] {processor.py:157} INFO - Started process (PID=6844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:46:23.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:46:23.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:23.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:46:23.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:46:23.058+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:23.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:46:23.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:23.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:46:23.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-07-20T16:46:53.730+0000] {processor.py:157} INFO - Started process (PID=6869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:46:53.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:46:53.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:53.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:46:53.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:46:53.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:53.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:46:53.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:53.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:46:53.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-07-20T16:47:24.454+0000] {processor.py:157} INFO - Started process (PID=6893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:47:24.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:47:24.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:24.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:47:24.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:47:24.510+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:24.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:47:24.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:24.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:47:24.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-20T16:47:55.007+0000] {processor.py:157} INFO - Started process (PID=6918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:47:55.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:47:55.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:55.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:47:55.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:47:55.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:55.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:47:55.074+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:55.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:47:55.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-20T16:48:25.506+0000] {processor.py:157} INFO - Started process (PID=6944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:48:25.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:48:25.519+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:25.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:48:25.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:48:25.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:25.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:48:25.590+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:25.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:48:25.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-20T16:48:56.571+0000] {processor.py:157} INFO - Started process (PID=6969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:48:56.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:48:56.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:56.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:48:56.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:48:56.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:56.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:48:56.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:56.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:48:56.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T16:49:27.076+0000] {processor.py:157} INFO - Started process (PID=6994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:49:27.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:49:27.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:27.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:49:27.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:49:27.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:27.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:49:27.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:27.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:49:27.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-07-20T16:49:57.683+0000] {processor.py:157} INFO - Started process (PID=7019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:49:57.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:49:57.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:57.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:49:57.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:49:57.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:57.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:49:57.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:57.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:49:57.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-07-20T16:50:28.256+0000] {processor.py:157} INFO - Started process (PID=7044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:50:28.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:50:28.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:28.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:50:28.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:50:28.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:28.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:50:28.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:28.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:50:28.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T16:50:58.770+0000] {processor.py:157} INFO - Started process (PID=7068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:50:58.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:50:58.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:58.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:50:58.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:50:58.840+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:58.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:50:58.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:58.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:50:58.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-20T16:51:29.300+0000] {processor.py:157} INFO - Started process (PID=7094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:51:29.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:51:29.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:29.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:51:29.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:51:29.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:29.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:51:29.361+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:29.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:51:29.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-20T16:51:59.772+0000] {processor.py:157} INFO - Started process (PID=7119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:51:59.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:51:59.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:59.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:51:59.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:51:59.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:59.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:51:59.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:59.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:51:59.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T16:52:30.228+0000] {processor.py:157} INFO - Started process (PID=7144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:52:30.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:52:30.235+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:52:30.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:52:30.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:52:30.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:52:30.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:52:30.421+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:52:30.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:52:30.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.209 seconds
[2024-07-20T16:53:01.982+0000] {processor.py:157} INFO - Started process (PID=7169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:53:01.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T16:53:01.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:53:01.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:53:01.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T16:53:02.010+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:53:02.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:53:02.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:53:02.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T16:53:02.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-20T17:08:30.685+0000] {processor.py:157} INFO - Started process (PID=7196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:08:30.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:08:30.689+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:08:30.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:08:30.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:08:30.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:08:30.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:08:30.767+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:08:30.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:08:30.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-20T17:09:01.304+0000] {processor.py:157} INFO - Started process (PID=7221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:09:01.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:09:01.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:01.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:09:01.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:09:01.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:01.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:09:01.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:01.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:09:01.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T17:09:31.677+0000] {processor.py:157} INFO - Started process (PID=7246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:09:31.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:09:31.680+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:31.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:09:31.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:09:31.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:31.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:09:31.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:31.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:09:31.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T17:10:02.125+0000] {processor.py:157} INFO - Started process (PID=7271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:10:02.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:10:02.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:02.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:10:02.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:10:02.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:02.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:10:02.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:02.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:10:02.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T17:10:32.572+0000] {processor.py:157} INFO - Started process (PID=7296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:10:32.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:10:32.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:32.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:10:32.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:10:32.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:32.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:10:32.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:32.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:10:32.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-20T17:25:58.436+0000] {processor.py:157} INFO - Started process (PID=7323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:25:58.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:25:58.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:25:58.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:25:58.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:25:58.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:25:58.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:25:58.474+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:25:58.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:25:58.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T17:26:28.868+0000] {processor.py:157} INFO - Started process (PID=7348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:26:28.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:26:28.875+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:28.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:26:28.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:26:28.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:28.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:26:28.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:28.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:26:28.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T17:26:59.321+0000] {processor.py:157} INFO - Started process (PID=7373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:26:59.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:26:59.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:59.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:26:59.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:26:59.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:59.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:26:59.362+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:59.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:26:59.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T17:27:29.778+0000] {processor.py:157} INFO - Started process (PID=7398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:27:29.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:27:29.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:27:29.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:27:29.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:27:29.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:27:29.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:27:29.821+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:27:29.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:27:29.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T17:43:03.564+0000] {processor.py:157} INFO - Started process (PID=7425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:43:03.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:43:03.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:03.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:43:03.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:43:03.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:03.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:43:03.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:03.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:43:03.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-20T17:43:34.242+0000] {processor.py:157} INFO - Started process (PID=7450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:43:34.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:43:34.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:34.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:43:34.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:43:34.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:34.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:43:34.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:34.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:43:34.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T17:44:04.922+0000] {processor.py:157} INFO - Started process (PID=7475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:44:04.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:44:04.926+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:04.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:44:04.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:44:04.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:04.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:44:04.964+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:04.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:44:04.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T17:44:35.357+0000] {processor.py:157} INFO - Started process (PID=7500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:44:35.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:44:35.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:35.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:44:35.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:44:35.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:35.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:44:35.399+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:35.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:44:35.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T17:45:05.787+0000] {processor.py:157} INFO - Started process (PID=7525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:45:05.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:45:05.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:05.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:45:05.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:45:05.820+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:05.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:45:05.831+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:05.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:45:05.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T17:45:36.291+0000] {processor.py:157} INFO - Started process (PID=7550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:45:36.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T17:45:36.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:36.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:45:36.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T17:45:36.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:36.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:45:36.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:36.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T17:45:36.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T18:01:56.100+0000] {processor.py:157} INFO - Started process (PID=7577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:01:56.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:01:56.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:01:56.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:01:56.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:01:56.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:01:56.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:01:56.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:01:56.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:01:56.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-07-20T18:02:26.836+0000] {processor.py:157} INFO - Started process (PID=7602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:02:26.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:02:26.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:26.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:02:26.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:02:26.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:26.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:02:26.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:26.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:02:26.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-20T18:02:57.493+0000] {processor.py:157} INFO - Started process (PID=7627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:02:57.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:02:57.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:57.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:02:57.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:02:57.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:57.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:02:57.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:57.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:02:57.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T18:03:27.958+0000] {processor.py:157} INFO - Started process (PID=7652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:03:27.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:03:27.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:27.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:03:27.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:03:27.987+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:27.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:03:27.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:27.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:03:28.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:03:58.442+0000] {processor.py:157} INFO - Started process (PID=7677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:03:58.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:03:58.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:58.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:03:58.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:03:58.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:58.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:03:58.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:58.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:03:58.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T18:04:28.914+0000] {processor.py:157} INFO - Started process (PID=7702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:04:28.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:04:28.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:28.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:04:28.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:04:28.944+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:28.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:04:28.954+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:28.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:04:28.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T18:04:59.393+0000] {processor.py:157} INFO - Started process (PID=7727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:04:59.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:04:59.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:59.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:04:59.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:04:59.427+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:59.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:04:59.510+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:59.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:04:59.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-20T18:05:29.973+0000] {processor.py:157} INFO - Started process (PID=7752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:05:29.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:05:29.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:05:29.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:05:29.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:05:30.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:05:30.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:05:30.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:05:30.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:05:30.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-20T18:06:00.544+0000] {processor.py:157} INFO - Started process (PID=7777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:06:00.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:06:00.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:00.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:06:00.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:06:00.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:00.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:06:00.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:00.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:06:00.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T18:06:31.040+0000] {processor.py:157} INFO - Started process (PID=7802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:06:31.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:06:31.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:31.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:06:31.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:06:31.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:31.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:06:31.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:31.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:06:31.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:07:01.494+0000] {processor.py:157} INFO - Started process (PID=7827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:07:01.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:07:01.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:01.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:07:01.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:07:01.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:01.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:07:01.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:01.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:07:01.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T18:07:31.958+0000] {processor.py:157} INFO - Started process (PID=7852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:07:31.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:07:31.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:31.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:07:31.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:07:31.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:31.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:07:31.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:31.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:07:32.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T18:08:02.632+0000] {processor.py:157} INFO - Started process (PID=7877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:08:02.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:08:02.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:02.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:08:02.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:08:02.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:02.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:08:02.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:02.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:08:02.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T18:08:33.287+0000] {processor.py:157} INFO - Started process (PID=7902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:08:33.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:08:33.290+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:33.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:08:33.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:08:33.317+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:33.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:08:33.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:33.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:08:33.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:09:03.768+0000] {processor.py:157} INFO - Started process (PID=7927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:09:03.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:09:03.772+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:03.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:09:03.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:09:03.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:03.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:09:03.817+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:03.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:09:03.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T18:09:34.199+0000] {processor.py:157} INFO - Started process (PID=7952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:09:34.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:09:34.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:34.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:09:34.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:09:34.232+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:34.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:09:34.243+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:34.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:09:34.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T18:10:04.575+0000] {processor.py:157} INFO - Started process (PID=7977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:10:04.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:10:04.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:04.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:10:04.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:10:04.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:04.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:10:04.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:04.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:10:04.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:10:35.080+0000] {processor.py:157} INFO - Started process (PID=8002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:10:35.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:10:35.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:35.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:10:35.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:10:35.111+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:35.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:10:35.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:35.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:10:35.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T18:11:05.631+0000] {processor.py:157} INFO - Started process (PID=8027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:11:05.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:11:05.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:05.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:11:05.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:11:05.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:05.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:11:05.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:05.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:11:05.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-20T18:11:36.338+0000] {processor.py:157} INFO - Started process (PID=8052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:11:36.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:11:36.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:36.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:11:36.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:11:36.369+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:36.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:11:36.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:36.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:11:36.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:12:06.730+0000] {processor.py:157} INFO - Started process (PID=8077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:12:06.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:12:06.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:06.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:12:06.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:12:06.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:06.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:12:06.766+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:06.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:12:06.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T18:12:37.224+0000] {processor.py:157} INFO - Started process (PID=8102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:12:37.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:12:37.227+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:37.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:12:37.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:12:37.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:37.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:12:37.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:37.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:12:37.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T18:13:07.688+0000] {processor.py:157} INFO - Started process (PID=8127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:13:07.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:13:07.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:07.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:13:07.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:13:07.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:07.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:13:07.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:07.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:13:07.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:13:38.273+0000] {processor.py:157} INFO - Started process (PID=8152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:13:38.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:13:38.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:38.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:13:38.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:13:38.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:38.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:13:38.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:38.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:13:38.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T18:14:08.792+0000] {processor.py:157} INFO - Started process (PID=8177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:14:08.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:14:08.794+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:08.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:14:08.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:14:08.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:08.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:14:08.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:08.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:14:08.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-20T18:14:39.355+0000] {processor.py:157} INFO - Started process (PID=8202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:14:39.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:14:39.358+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:39.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:14:39.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:14:39.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:39.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:14:39.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:39.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:14:39.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T18:15:09.858+0000] {processor.py:157} INFO - Started process (PID=8227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:15:09.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:15:09.862+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:09.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:15:09.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:15:09.890+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:09.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:15:09.901+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:09.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:15:09.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T18:15:40.293+0000] {processor.py:157} INFO - Started process (PID=8252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:15:40.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:15:40.296+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:40.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:15:40.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:15:40.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:40.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:15:40.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:40.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:15:40.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T18:16:10.689+0000] {processor.py:157} INFO - Started process (PID=8277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:16:10.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:16:10.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:10.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:16:10.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:16:10.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:10.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:16:10.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:10.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:16:10.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T18:16:41.342+0000] {processor.py:157} INFO - Started process (PID=8302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:16:41.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:16:41.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:41.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:16:41.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:16:41.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:41.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:16:41.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:41.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:16:41.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-20T18:17:11.906+0000] {processor.py:157} INFO - Started process (PID=8327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:17:11.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:17:11.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:11.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:17:11.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:17:11.936+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:11.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:17:12.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:12.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:17:12.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:17:42.497+0000] {processor.py:157} INFO - Started process (PID=8352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:17:42.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:17:42.500+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:42.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:17:42.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:17:42.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:42.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:17:42.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:42.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:17:42.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T18:18:12.938+0000] {processor.py:157} INFO - Started process (PID=8377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:18:12.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:18:12.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:12.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:18:12.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:18:12.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:12.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:18:12.978+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:12.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:18:12.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T18:18:43.357+0000] {processor.py:157} INFO - Started process (PID=8402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:18:43.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:18:43.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:43.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:18:43.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:18:43.387+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:43.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:18:43.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:43.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:18:43.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:19:13.807+0000] {processor.py:157} INFO - Started process (PID=8427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:19:13.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:19:13.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:13.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:19:13.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:19:13.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:13.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:19:13.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:13.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:19:13.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-20T18:19:44.437+0000] {processor.py:157} INFO - Started process (PID=8452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:19:44.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:19:44.440+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:44.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:19:44.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:19:44.466+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:44.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:19:44.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:44.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:19:44.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:20:14.967+0000] {processor.py:157} INFO - Started process (PID=8477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:20:14.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:20:14.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:14.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:20:14.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:20:15.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:15.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:20:15.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:15.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:20:15.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-20T18:20:45.513+0000] {processor.py:157} INFO - Started process (PID=8502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:20:45.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:20:45.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:45.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:20:45.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:20:45.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:45.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:20:45.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:45.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:20:45.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T18:21:15.979+0000] {processor.py:157} INFO - Started process (PID=8527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:21:15.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:21:15.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:15.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:21:15.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:21:16.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:16.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:21:16.017+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:16.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:21:16.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T18:21:46.419+0000] {processor.py:157} INFO - Started process (PID=8552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:21:46.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:21:46.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:46.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:21:46.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:21:46.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:46.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:21:46.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:46.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:21:46.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T18:22:16.948+0000] {processor.py:157} INFO - Started process (PID=8577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:22:16.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:22:16.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:16.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:22:16.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:22:16.971+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:16.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:22:17.049+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:17.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:22:17.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-20T18:22:47.507+0000] {processor.py:157} INFO - Started process (PID=8602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:22:47.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:22:47.510+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:47.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:22:47.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:22:47.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:47.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:22:47.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:47.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:22:47.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-20T18:23:18.060+0000] {processor.py:157} INFO - Started process (PID=8627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:23:18.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:23:18.064+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:18.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:23:18.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:23:18.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:18.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:23:18.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:18.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:23:18.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:23:48.535+0000] {processor.py:157} INFO - Started process (PID=8652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:23:48.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:23:48.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:48.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:23:48.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:23:48.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:48.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:23:48.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:48.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:23:48.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T18:24:18.973+0000] {processor.py:157} INFO - Started process (PID=8677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:24:18.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:24:18.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:18.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:24:18.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:24:19.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:19.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:24:19.010+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:19.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:24:19.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T18:24:49.434+0000] {processor.py:157} INFO - Started process (PID=8702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:24:49.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:24:49.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:49.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:24:49.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:24:49.463+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:49.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:24:49.473+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:49.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:24:49.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T18:25:20.093+0000] {processor.py:157} INFO - Started process (PID=8727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:25:20.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:25:20.096+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:20.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:25:20.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:25:20.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:20.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:25:20.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:20.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:25:20.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T18:25:50.663+0000] {processor.py:157} INFO - Started process (PID=8752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:25:50.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:25:50.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:50.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:25:50.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:25:50.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:50.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:25:50.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:50.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:25:50.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-20T18:26:21.198+0000] {processor.py:157} INFO - Started process (PID=8777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:26:21.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:26:21.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:21.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:26:21.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:26:21.228+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:21.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:26:21.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:21.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:26:21.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T18:26:51.699+0000] {processor.py:157} INFO - Started process (PID=8802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:26:51.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:26:51.702+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:51.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:26:51.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:26:51.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:51.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:26:51.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:51.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:26:51.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T18:27:22.209+0000] {processor.py:157} INFO - Started process (PID=8827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:27:22.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:27:22.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:22.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:27:22.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:27:22.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:22.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:27:22.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:22.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:27:22.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:27:52.707+0000] {processor.py:157} INFO - Started process (PID=8852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:27:52.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:27:52.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:52.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:27:52.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:27:52.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:52.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:27:52.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:52.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:27:52.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-20T18:28:23.324+0000] {processor.py:157} INFO - Started process (PID=8877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:28:23.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:28:23.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:23.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:28:23.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:28:23.358+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:23.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:28:23.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:23.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:28:23.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-20T18:28:53.886+0000] {processor.py:157} INFO - Started process (PID=8902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:28:53.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:28:53.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:53.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:28:53.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:28:53.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:53.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:28:54.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:54.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:28:54.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-20T18:29:24.454+0000] {processor.py:157} INFO - Started process (PID=8927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:29:24.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:29:24.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:24.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:29:24.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:29:24.488+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:24.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:29:24.499+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:24.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:29:24.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T18:29:54.935+0000] {processor.py:157} INFO - Started process (PID=8952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:29:54.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:29:54.938+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:54.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:29:54.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:29:54.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:54.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:29:54.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:54.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:29:54.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T18:30:25.384+0000] {processor.py:157} INFO - Started process (PID=8977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:30:25.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:30:25.387+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:25.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:30:25.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:30:25.418+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:25.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:30:25.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:25.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:30:25.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-20T18:30:55.959+0000] {processor.py:157} INFO - Started process (PID=9002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:30:55.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:30:55.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:55.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:30:55.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:30:55.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:55.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:30:56.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:56.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:30:56.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-20T18:31:26.509+0000] {processor.py:157} INFO - Started process (PID=9027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:31:26.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:31:26.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:26.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:31:26.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:31:26.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:26.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:31:26.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:26.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:31:26.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-20T18:31:57.200+0000] {processor.py:157} INFO - Started process (PID=9052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:31:57.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:31:57.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:57.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:31:57.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:31:57.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:57.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:31:57.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:57.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:31:57.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:32:27.564+0000] {processor.py:157} INFO - Started process (PID=9077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:32:27.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:32:27.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:27.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:32:27.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:32:27.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:27.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:32:27.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:27.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:32:27.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T18:32:58.039+0000] {processor.py:157} INFO - Started process (PID=9102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:32:58.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:32:58.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:58.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:32:58.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:32:58.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:58.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:32:58.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:58.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:32:58.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T18:33:28.517+0000] {processor.py:157} INFO - Started process (PID=9127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:33:28.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:33:28.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:28.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:33:28.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:33:28.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:28.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:33:28.556+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:28.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:33:28.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T18:33:59.202+0000] {processor.py:157} INFO - Started process (PID=9152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:33:59.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:33:59.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:59.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:33:59.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:33:59.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:59.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:33:59.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:59.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:33:59.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T18:34:29.723+0000] {processor.py:157} INFO - Started process (PID=9177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:34:29.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:34:29.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:34:29.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:34:29.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:34:29.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:34:29.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:34:29.843+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:34:29.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:34:29.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-20T18:35:00.297+0000] {processor.py:157} INFO - Started process (PID=9202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:35:00.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:35:00.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:00.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:35:00.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:35:00.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:00.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:35:00.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:00.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:35:00.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T18:35:30.740+0000] {processor.py:157} INFO - Started process (PID=9227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:35:30.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:35:30.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:30.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:35:30.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:35:30.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:30.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:35:30.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:30.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:35:30.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:36:01.204+0000] {processor.py:157} INFO - Started process (PID=9252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:36:01.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:36:01.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:01.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:36:01.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:36:01.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:01.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:36:01.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:01.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:36:01.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T18:36:31.745+0000] {processor.py:157} INFO - Started process (PID=9277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:36:31.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:36:31.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:31.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:36:31.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:36:31.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:31.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:36:31.852+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:31.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:36:31.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:37:02.327+0000] {processor.py:157} INFO - Started process (PID=9302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:37:02.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:37:02.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:02.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:37:02.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:37:02.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:02.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:37:02.434+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:02.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:37:02.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T18:37:33.000+0000] {processor.py:157} INFO - Started process (PID=9327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:37:33.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:37:33.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:33.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:37:33.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:37:33.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:33.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:37:33.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:33.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:37:33.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-20T18:38:03.541+0000] {processor.py:157} INFO - Started process (PID=9352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:38:03.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:38:03.544+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:03.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:38:03.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:38:03.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:03.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:38:03.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:03.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:38:03.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T18:38:33.946+0000] {processor.py:157} INFO - Started process (PID=9377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:38:33.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:38:33.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:33.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:38:33.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:38:33.978+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:33.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:38:33.987+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:33.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:38:33.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T18:39:04.407+0000] {processor.py:157} INFO - Started process (PID=9402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:39:04.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:39:04.411+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:04.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:39:04.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:39:04.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:04.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:39:04.455+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:04.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:39:04.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-20T18:39:34.943+0000] {processor.py:157} INFO - Started process (PID=9427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:39:34.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:39:34.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:34.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:39:34.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:39:34.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:34.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:39:35.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:35.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:39:35.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T18:40:05.482+0000] {processor.py:157} INFO - Started process (PID=9452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:40:05.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:40:05.485+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:05.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:40:05.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:40:05.513+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:05.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:40:05.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:05.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:40:05.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T18:40:36.170+0000] {processor.py:157} INFO - Started process (PID=9477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:40:36.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:40:36.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:36.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:40:36.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:40:36.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:36.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:40:36.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:36.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:40:36.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:41:06.779+0000] {processor.py:157} INFO - Started process (PID=9502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:41:06.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:41:06.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:06.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:41:06.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:41:06.804+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:06.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:41:06.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:06.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:41:06.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T18:41:37.235+0000] {processor.py:157} INFO - Started process (PID=9527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:41:37.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:41:37.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:37.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:41:37.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:41:37.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:37.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:41:37.273+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:37.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:41:37.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T18:42:07.753+0000] {processor.py:157} INFO - Started process (PID=9552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:42:07.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:42:07.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:07.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:42:07.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:42:07.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:07.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:42:07.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:07.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:42:07.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-20T18:42:38.348+0000] {processor.py:157} INFO - Started process (PID=9577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:42:38.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:42:38.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:38.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:42:38.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:42:38.376+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:38.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:42:38.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:38.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:42:38.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:43:09.002+0000] {processor.py:157} INFO - Started process (PID=9602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:43:09.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:43:09.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:09.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:43:09.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:43:09.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:09.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:43:09.107+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:09.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:43:09.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-20T18:43:39.691+0000] {processor.py:157} INFO - Started process (PID=9627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:43:39.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:43:39.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:39.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:43:39.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:43:39.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:39.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:43:39.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:39.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:43:39.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T18:44:10.110+0000] {processor.py:157} INFO - Started process (PID=9652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:44:10.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:44:10.112+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:10.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:44:10.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:44:10.142+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:10.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:44:10.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:10.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:44:10.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T18:44:40.535+0000] {processor.py:157} INFO - Started process (PID=9677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:44:40.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:44:40.538+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:40.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:44:40.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:44:40.565+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:40.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:44:40.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:40.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:44:40.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-20T18:45:11.086+0000] {processor.py:157} INFO - Started process (PID=9702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:45:11.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:45:11.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:11.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:45:11.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:45:11.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:11.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:45:11.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:11.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:45:11.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:45:41.778+0000] {processor.py:157} INFO - Started process (PID=9727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:45:41.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:45:41.787+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:41.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:45:41.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:45:41.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:41.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:45:41.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:41.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:45:41.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-20T18:46:12.480+0000] {processor.py:157} INFO - Started process (PID=9752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:46:12.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:46:12.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:12.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:46:12.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:46:12.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:12.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:46:12.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:12.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:46:12.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:46:43.137+0000] {processor.py:157} INFO - Started process (PID=9777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:46:43.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:46:43.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:43.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:46:43.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:46:43.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:43.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:46:43.178+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:43.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:46:43.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T18:47:13.589+0000] {processor.py:157} INFO - Started process (PID=9802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:47:13.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:47:13.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:13.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:47:13.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:47:13.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:13.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:47:13.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:13.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:47:13.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T18:47:44.033+0000] {processor.py:157} INFO - Started process (PID=9827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:47:44.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:47:44.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:44.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:47:44.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:47:44.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:44.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:47:44.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:44.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:47:44.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-20T18:48:14.664+0000] {processor.py:157} INFO - Started process (PID=9852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:48:14.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:48:14.666+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:14.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:48:14.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:48:14.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:14.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:48:14.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:14.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:48:14.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T18:48:45.228+0000] {processor.py:157} INFO - Started process (PID=9877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:48:45.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:48:45.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:45.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:48:45.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:48:45.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:45.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:48:45.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:45.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:48:45.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-20T18:49:15.892+0000] {processor.py:157} INFO - Started process (PID=9902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:49:15.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:49:15.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:15.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:49:15.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:49:15.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:15.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:49:16.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:16.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:49:16.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-20T18:49:46.547+0000] {processor.py:157} INFO - Started process (PID=9927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:49:46.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:49:46.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:46.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:49:46.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:49:46.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:46.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:49:46.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:46.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:49:46.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T18:50:17.049+0000] {processor.py:157} INFO - Started process (PID=9952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:50:17.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:50:17.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:17.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:50:17.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:50:17.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:17.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:50:17.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:17.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:50:17.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T18:50:47.461+0000] {processor.py:157} INFO - Started process (PID=9977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:50:47.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:50:47.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:47.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:50:47.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:50:47.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:47.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:50:47.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:47.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:50:47.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-20T18:51:18.133+0000] {processor.py:157} INFO - Started process (PID=10002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:51:18.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:51:18.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:18.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:51:18.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:51:18.162+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:18.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:51:18.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:18.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:51:18.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-20T18:51:48.804+0000] {processor.py:157} INFO - Started process (PID=10027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:51:48.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:51:48.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:48.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:51:48.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:51:48.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:48.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:51:48.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:48.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:51:48.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T18:52:19.459+0000] {processor.py:157} INFO - Started process (PID=10052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:52:19.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:52:19.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:19.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:52:19.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:52:19.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:19.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:52:19.504+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:19.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:52:19.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T18:52:49.877+0000] {processor.py:157} INFO - Started process (PID=10077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:52:49.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:52:49.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:49.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:52:49.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:52:49.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:49.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:52:49.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:49.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:52:49.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T18:53:20.352+0000] {processor.py:157} INFO - Started process (PID=10102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:53:20.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:53:20.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:20.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:53:20.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:53:20.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:20.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:53:20.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:20.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:53:20.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-20T18:53:50.931+0000] {processor.py:157} INFO - Started process (PID=10127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:53:50.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:53:50.934+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:50.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:53:50.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:53:50.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:50.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:53:51.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:51.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:53:51.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-20T18:54:21.489+0000] {processor.py:157} INFO - Started process (PID=10152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:54:21.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:54:21.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:21.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:54:21.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:54:21.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:21.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:54:21.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:21.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:54:21.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-20T18:54:52.038+0000] {processor.py:157} INFO - Started process (PID=10177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:54:52.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:54:52.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:52.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:54:52.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:54:52.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:52.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:54:52.146+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:52.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:54:52.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:55:22.616+0000] {processor.py:157} INFO - Started process (PID=10202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:55:22.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:55:22.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:22.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:55:22.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:55:22.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:22.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:55:22.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:22.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:55:22.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T18:55:53.146+0000] {processor.py:157} INFO - Started process (PID=10227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:55:53.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:55:53.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:53.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:55:53.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:55:53.181+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:53.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:55:53.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:53.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:55:53.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-20T18:56:23.641+0000] {processor.py:157} INFO - Started process (PID=10252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:56:23.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:56:23.643+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:23.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:56:23.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:56:23.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:23.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:56:23.678+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:23.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:56:23.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-07-20T18:56:54.363+0000] {processor.py:157} INFO - Started process (PID=10277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:56:54.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:56:54.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:54.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:56:54.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:56:54.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:54.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:56:54.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:54.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:56:54.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-20T18:57:24.938+0000] {processor.py:157} INFO - Started process (PID=10302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:57:24.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:57:24.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:24.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:57:24.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:57:25.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:25.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:57:25.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:25.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:57:25.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T18:57:55.610+0000] {processor.py:157} INFO - Started process (PID=10327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:57:55.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:57:55.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:55.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:57:55.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:57:55.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:55.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:57:55.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:55.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:57:55.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-20T18:58:26.284+0000] {processor.py:157} INFO - Started process (PID=10352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:58:26.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:58:26.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:26.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:58:26.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:58:26.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:26.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:58:26.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:26.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:58:26.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T18:58:56.741+0000] {processor.py:157} INFO - Started process (PID=10377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:58:56.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:58:56.744+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:56.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:58:56.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:58:56.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:56.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:58:56.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:56.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:58:56.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-20T18:59:27.324+0000] {processor.py:157} INFO - Started process (PID=10402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:59:27.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:59:27.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:27.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:59:27.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:59:27.353+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:27.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:59:27.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:27.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:59:27.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-20T18:59:57.854+0000] {processor.py:157} INFO - Started process (PID=10427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:59:57.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T18:59:57.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:57.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:59:57.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T18:59:57.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:57.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:59:57.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:57.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T18:59:57.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-20T19:00:28.430+0000] {processor.py:157} INFO - Started process (PID=10452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:00:28.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:00:28.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:28.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:00:28.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:00:28.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:28.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:00:28.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:28.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:00:28.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-20T19:00:59.045+0000] {processor.py:157} INFO - Started process (PID=10477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:00:59.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:00:59.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:59.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:00:59.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:00:59.149+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:59.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:00:59.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:59.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:00:59.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-20T19:01:29.832+0000] {processor.py:157} INFO - Started process (PID=10502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:01:29.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:01:29.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:01:29.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:01:29.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:01:29.864+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:01:29.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:01:29.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:01:29.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:01:29.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:02:00.248+0000] {processor.py:157} INFO - Started process (PID=10527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:02:00.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:02:00.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:00.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:02:00.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:02:00.274+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:00.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:02:00.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:00.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:02:00.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-20T19:02:30.674+0000] {processor.py:157} INFO - Started process (PID=10552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:02:30.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:02:30.683+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:30.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:02:30.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:02:30.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:30.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:02:30.714+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:30.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:02:30.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:03:01.047+0000] {processor.py:157} INFO - Started process (PID=10577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:03:01.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:03:01.049+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:01.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:03:01.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:03:01.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:01.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:03:01.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:01.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:03:01.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:03:31.496+0000] {processor.py:157} INFO - Started process (PID=10602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:03:31.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:03:31.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:31.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:03:31.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:03:31.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:31.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:03:31.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:31.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:03:31.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T19:04:01.990+0000] {processor.py:157} INFO - Started process (PID=10627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:04:01.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:04:01.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:01.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:04:02.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:04:02.019+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:02.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:04:02.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:02.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:04:02.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:04:32.406+0000] {processor.py:157} INFO - Started process (PID=10652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:04:32.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:04:32.409+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:32.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:04:32.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:04:32.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:32.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:04:32.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:32.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:04:32.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T19:05:02.929+0000] {processor.py:157} INFO - Started process (PID=10677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:05:02.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:05:02.932+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:02.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:05:02.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:05:02.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:02.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:05:02.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:02.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:05:02.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:05:33.352+0000] {processor.py:157} INFO - Started process (PID=10702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:05:33.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:05:33.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:33.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:05:33.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:05:33.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:33.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:05:33.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:33.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:05:33.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:06:03.804+0000] {processor.py:157} INFO - Started process (PID=10727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:06:03.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:06:03.811+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:03.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:06:03.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:06:03.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:03.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:06:03.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:03.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:06:03.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:06:34.228+0000] {processor.py:157} INFO - Started process (PID=10752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:06:34.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:06:34.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:34.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:06:34.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:06:34.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:34.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:06:34.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:34.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:06:34.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:07:04.724+0000] {processor.py:157} INFO - Started process (PID=10777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:07:04.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:07:04.731+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:04.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:07:04.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:07:04.755+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:04.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:07:04.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:04.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:07:04.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:07:35.185+0000] {processor.py:157} INFO - Started process (PID=10802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:07:35.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:07:35.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:35.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:07:35.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:07:35.214+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:35.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:07:35.225+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:35.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:07:35.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:08:05.612+0000] {processor.py:157} INFO - Started process (PID=10827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:08:05.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:08:05.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:05.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:08:05.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:08:05.643+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:05.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:08:05.653+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:05.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:08:05.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:08:36.128+0000] {processor.py:157} INFO - Started process (PID=10852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:08:36.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:08:36.131+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:36.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:08:36.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:08:36.159+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:36.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:08:36.168+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:36.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:08:36.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:09:06.582+0000] {processor.py:157} INFO - Started process (PID=10877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:09:06.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:09:06.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:06.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:09:06.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:09:06.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:06.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:09:06.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:06.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:09:06.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:09:37.104+0000] {processor.py:157} INFO - Started process (PID=10902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:09:37.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:09:37.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:37.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:09:37.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:09:37.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:37.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:09:37.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:37.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:09:37.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:10:07.529+0000] {processor.py:157} INFO - Started process (PID=10927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:10:07.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:10:07.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:07.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:10:07.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:10:07.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:07.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:10:07.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:07.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:10:07.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T19:10:37.925+0000] {processor.py:157} INFO - Started process (PID=10952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:10:37.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:10:37.928+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:37.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:10:37.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:10:37.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:37.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:10:37.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:37.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:10:37.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:11:08.382+0000] {processor.py:157} INFO - Started process (PID=10977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:11:08.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:11:08.384+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:08.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:11:08.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:11:08.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:08.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:11:08.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:08.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:11:08.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:11:38.820+0000] {processor.py:157} INFO - Started process (PID=11002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:11:38.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:11:38.823+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:38.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:11:38.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:11:38.848+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:38.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:11:38.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:38.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:11:38.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:12:09.292+0000] {processor.py:157} INFO - Started process (PID=11027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:12:09.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:12:09.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:09.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:12:09.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:12:09.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:09.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:12:09.334+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:09.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:12:09.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:12:39.753+0000] {processor.py:157} INFO - Started process (PID=11052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:12:39.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:12:39.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:39.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:12:39.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:12:39.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:39.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:12:39.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:39.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:12:39.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:13:10.203+0000] {processor.py:157} INFO - Started process (PID=11077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:13:10.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:13:10.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:10.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:13:10.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:13:10.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:10.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:13:10.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:10.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:13:10.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:13:40.616+0000] {processor.py:157} INFO - Started process (PID=11102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:13:40.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:13:40.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:40.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:13:40.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:13:40.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:40.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:13:40.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:40.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:13:40.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:14:11.111+0000] {processor.py:157} INFO - Started process (PID=11127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:14:11.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:14:11.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:11.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:14:11.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:14:11.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:11.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:14:11.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:11.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:14:11.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:14:41.578+0000] {processor.py:157} INFO - Started process (PID=11152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:14:41.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:14:41.583+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:41.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:14:41.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:14:41.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:41.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:14:41.623+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:41.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:14:41.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:15:12.041+0000] {processor.py:157} INFO - Started process (PID=11177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:15:12.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:15:12.044+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:12.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:15:12.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:15:12.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:12.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:15:12.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:12.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:15:12.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:15:42.542+0000] {processor.py:157} INFO - Started process (PID=11202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:15:42.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:15:42.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:42.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:15:42.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:15:42.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:42.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:15:42.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:42.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:15:42.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T19:16:13.029+0000] {processor.py:157} INFO - Started process (PID=11227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:16:13.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:16:13.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:13.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:16:13.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:16:13.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:13.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:16:13.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:13.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:16:13.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T19:16:43.438+0000] {processor.py:157} INFO - Started process (PID=11252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:16:43.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:16:43.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:43.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:16:43.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:16:43.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:43.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:16:43.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:43.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:16:43.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T19:17:13.882+0000] {processor.py:157} INFO - Started process (PID=11277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:17:13.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:17:13.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:13.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:17:13.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:17:13.911+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:13.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:17:13.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:13.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:17:13.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:17:44.363+0000] {processor.py:157} INFO - Started process (PID=11302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:17:44.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:17:44.365+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:44.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:17:44.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:17:44.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:44.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:17:44.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:44.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:17:44.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T19:18:14.831+0000] {processor.py:157} INFO - Started process (PID=11327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:18:14.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:18:14.833+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:14.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:18:14.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:18:14.862+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:14.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:18:14.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:14.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:18:14.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:18:45.246+0000] {processor.py:157} INFO - Started process (PID=11352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:18:45.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:18:45.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:45.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:18:45.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:18:45.273+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:45.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:18:45.285+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:45.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:18:45.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T19:19:15.710+0000] {processor.py:157} INFO - Started process (PID=11377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:19:15.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:19:15.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:15.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:19:15.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:19:15.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:15.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:19:15.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:15.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:19:15.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:19:46.206+0000] {processor.py:157} INFO - Started process (PID=11402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:19:46.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:19:46.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:46.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:19:46.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:19:46.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:46.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:19:46.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:46.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:19:46.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T19:20:16.689+0000] {processor.py:157} INFO - Started process (PID=11427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:20:16.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:20:16.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:16.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:20:16.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:20:16.720+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:16.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:20:16.730+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:16.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:20:16.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:20:47.076+0000] {processor.py:157} INFO - Started process (PID=11452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:20:47.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:20:47.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:47.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:20:47.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:20:47.107+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:47.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:20:47.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:47.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:20:47.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:21:17.517+0000] {processor.py:157} INFO - Started process (PID=11477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:21:17.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:21:17.519+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:17.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:21:17.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:21:17.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:17.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:21:17.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:17.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:21:17.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:21:47.970+0000] {processor.py:157} INFO - Started process (PID=11502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:21:47.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:21:47.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:47.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:21:47.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:21:48.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:48.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:21:48.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:48.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:21:48.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:22:18.438+0000] {processor.py:157} INFO - Started process (PID=11527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:22:18.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:22:18.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:18.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:22:18.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:22:18.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:18.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:22:18.477+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:18.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:22:18.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T19:22:48.920+0000] {processor.py:157} INFO - Started process (PID=11552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:22:48.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:22:48.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:48.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:22:48.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:22:48.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:48.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:22:48.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:48.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:22:48.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:23:19.360+0000] {processor.py:157} INFO - Started process (PID=11577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:23:19.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:23:19.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:19.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:23:19.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:23:19.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:19.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:23:19.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:19.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:23:19.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:23:49.843+0000] {processor.py:157} INFO - Started process (PID=11602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:23:49.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:23:49.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:49.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:23:49.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:23:49.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:49.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:23:49.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:49.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:23:49.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:24:20.277+0000] {processor.py:157} INFO - Started process (PID=11627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:24:20.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:24:20.279+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:20.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:24:20.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:24:20.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:20.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:24:20.317+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:20.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:24:20.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:24:50.797+0000] {processor.py:157} INFO - Started process (PID=11652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:24:50.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:24:50.799+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:50.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:24:50.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:24:50.827+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:50.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:24:50.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:50.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:24:50.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T19:25:21.202+0000] {processor.py:157} INFO - Started process (PID=11677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:25:21.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:25:21.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:21.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:25:21.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:25:21.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:21.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:25:21.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:21.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:25:21.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:25:51.687+0000] {processor.py:157} INFO - Started process (PID=11702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:25:51.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:25:51.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:51.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:25:51.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:25:51.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:51.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:25:51.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:51.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:25:51.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:26:22.149+0000] {processor.py:157} INFO - Started process (PID=11727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:26:22.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:26:22.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:22.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:26:22.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:26:22.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:22.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:26:22.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:22.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:26:22.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T19:26:52.660+0000] {processor.py:157} INFO - Started process (PID=11752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:26:52.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:26:52.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:52.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:26:52.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:26:52.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:52.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:26:52.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:52.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:26:52.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:27:23.133+0000] {processor.py:157} INFO - Started process (PID=11777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:27:23.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:27:23.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:23.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:27:23.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:27:23.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:23.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:27:23.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:23.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:27:23.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:27:53.606+0000] {processor.py:157} INFO - Started process (PID=11802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:27:53.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:27:53.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:53.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:27:53.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:27:53.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:53.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:27:53.650+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:53.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:27:53.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:28:24.071+0000] {processor.py:157} INFO - Started process (PID=11827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:28:24.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:28:24.074+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:24.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:28:24.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:28:24.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:24.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:28:24.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:24.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:28:24.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T19:28:54.513+0000] {processor.py:157} INFO - Started process (PID=11852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:28:54.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:28:54.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:54.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:28:54.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:28:54.543+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:54.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:28:54.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:54.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:28:54.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:29:24.973+0000] {processor.py:157} INFO - Started process (PID=11877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:29:24.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:29:24.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:24.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:29:24.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:29:25.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:25.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:29:25.010+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:25.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:29:25.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:29:55.394+0000] {processor.py:157} INFO - Started process (PID=11902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:29:55.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:29:55.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:55.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:29:55.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:29:55.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:55.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:29:55.434+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:55.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:29:55.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:30:25.810+0000] {processor.py:157} INFO - Started process (PID=11927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:30:25.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:30:25.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:25.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:30:25.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:30:25.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:25.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:30:25.852+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:25.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:30:25.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:30:56.330+0000] {processor.py:157} INFO - Started process (PID=11952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:30:56.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:30:56.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:56.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:30:56.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:30:56.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:56.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:30:56.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:56.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:30:56.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:31:26.762+0000] {processor.py:157} INFO - Started process (PID=11977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:31:26.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:31:26.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:26.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:31:26.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:31:26.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:26.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:31:26.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:26.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:31:26.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:31:57.206+0000] {processor.py:157} INFO - Started process (PID=12002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:31:57.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:31:57.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:57.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:31:57.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:31:57.235+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:57.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:31:57.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:57.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:31:57.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T19:32:27.635+0000] {processor.py:157} INFO - Started process (PID=12027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:32:27.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:32:27.639+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:27.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:32:27.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:32:27.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:27.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:32:27.678+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:27.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:32:27.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:32:58.100+0000] {processor.py:157} INFO - Started process (PID=12052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:32:58.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:32:58.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:58.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:32:58.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:32:58.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:58.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:32:58.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:58.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:32:58.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T19:33:28.502+0000] {processor.py:157} INFO - Started process (PID=12077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:33:28.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:33:28.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:28.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:33:28.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:33:28.533+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:28.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:33:28.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:28.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:33:28.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:33:59.017+0000] {processor.py:157} INFO - Started process (PID=12102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:33:59.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:33:59.025+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:59.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:33:59.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:33:59.049+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:59.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:33:59.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:59.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:33:59.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:34:29.440+0000] {processor.py:157} INFO - Started process (PID=12127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:34:29.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:34:29.444+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:29.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:34:29.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:34:29.473+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:29.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:34:29.486+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:29.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:34:29.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T19:34:59.835+0000] {processor.py:157} INFO - Started process (PID=12152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:34:59.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:34:59.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:59.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:34:59.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:34:59.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:59.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:34:59.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:59.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:34:59.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:35:30.248+0000] {processor.py:157} INFO - Started process (PID=12177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:35:30.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:35:30.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:35:30.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:35:30.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:35:30.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:35:30.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:35:30.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:35:30.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:35:30.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:36:00.667+0000] {processor.py:157} INFO - Started process (PID=12202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:36:00.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:36:00.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:00.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:36:00.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:36:00.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:00.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:36:00.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:00.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:36:00.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:36:31.155+0000] {processor.py:157} INFO - Started process (PID=12227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:36:31.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:36:31.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:31.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:36:31.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:36:31.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:31.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:36:31.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:31.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:36:31.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:37:01.529+0000] {processor.py:157} INFO - Started process (PID=12252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:37:01.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:37:01.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:01.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:37:01.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:37:01.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:01.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:37:01.573+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:01.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:37:01.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T19:37:32.022+0000] {processor.py:157} INFO - Started process (PID=12277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:37:32.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:37:32.025+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:32.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:37:32.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:37:32.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:32.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:37:32.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:32.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:37:32.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T19:38:02.493+0000] {processor.py:157} INFO - Started process (PID=12302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:38:02.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:38:02.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:02.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:38:02.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:38:02.525+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:02.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:38:02.535+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:02.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:38:02.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:38:32.861+0000] {processor.py:157} INFO - Started process (PID=12327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:38:32.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:38:32.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:32.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:38:32.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:38:32.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:32.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:38:32.901+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:32.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:38:32.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:39:03.344+0000] {processor.py:157} INFO - Started process (PID=12352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:39:03.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:39:03.346+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:03.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:39:03.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:39:03.375+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:03.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:39:03.387+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:03.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:39:03.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:39:33.806+0000] {processor.py:157} INFO - Started process (PID=12377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:39:33.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:39:33.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:33.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:39:33.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:39:33.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:33.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:39:33.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:33.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:39:33.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:40:04.292+0000] {processor.py:157} INFO - Started process (PID=12402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:40:04.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:40:04.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:04.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:40:04.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:40:04.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:04.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:40:04.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:04.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:40:04.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:40:34.733+0000] {processor.py:157} INFO - Started process (PID=12427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:40:34.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:40:34.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:34.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:40:34.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:40:34.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:34.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:40:34.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:34.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:40:34.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:41:05.321+0000] {processor.py:157} INFO - Started process (PID=12452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:41:05.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:41:05.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:05.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:41:05.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:41:05.351+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:05.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:41:05.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:05.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:41:05.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:41:35.804+0000] {processor.py:157} INFO - Started process (PID=12477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:41:35.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:41:35.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:35.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:41:35.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:41:35.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:35.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:41:35.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:35.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:41:35.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:42:06.234+0000] {processor.py:157} INFO - Started process (PID=12502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:42:06.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:42:06.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:06.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:42:06.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:42:06.261+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:06.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:42:06.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:06.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:42:06.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:42:36.702+0000] {processor.py:157} INFO - Started process (PID=12527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:42:36.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:42:36.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:36.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:42:36.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:42:36.730+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:36.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:42:36.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:36.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:42:36.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:43:07.199+0000] {processor.py:157} INFO - Started process (PID=12552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:43:07.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:43:07.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:07.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:43:07.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:43:07.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:07.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:43:07.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:07.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:43:07.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T19:43:37.692+0000] {processor.py:157} INFO - Started process (PID=12577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:43:37.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:43:37.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:37.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:43:37.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:43:37.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:37.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:43:37.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:37.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:43:37.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:44:08.155+0000] {processor.py:157} INFO - Started process (PID=12602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:44:08.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:44:08.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:08.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:44:08.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:44:08.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:08.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:44:08.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:08.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:44:08.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:44:38.651+0000] {processor.py:157} INFO - Started process (PID=12627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:44:38.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:44:38.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:38.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:44:38.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:44:38.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:38.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:44:38.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:38.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:44:38.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T19:45:09.120+0000] {processor.py:157} INFO - Started process (PID=12652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:45:09.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:45:09.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:09.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:45:09.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:45:09.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:09.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:45:09.164+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:09.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:45:09.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T19:45:39.572+0000] {processor.py:157} INFO - Started process (PID=12677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:45:39.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:45:39.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:39.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:45:39.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:45:39.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:39.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:45:39.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:39.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:45:39.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T19:46:10.020+0000] {processor.py:157} INFO - Started process (PID=12702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:46:10.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:46:10.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:10.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:46:10.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:46:10.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:10.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:46:10.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:10.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:46:10.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:46:40.425+0000] {processor.py:157} INFO - Started process (PID=12727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:46:40.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:46:40.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:40.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:46:40.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:46:40.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:40.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:46:40.473+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:40.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:46:40.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T19:47:10.943+0000] {processor.py:157} INFO - Started process (PID=12752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:47:10.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:47:10.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:10.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:47:10.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:47:10.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:10.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:47:10.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:10.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:47:10.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:47:41.355+0000] {processor.py:157} INFO - Started process (PID=12777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:47:41.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:47:41.358+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:41.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:47:41.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:47:41.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:41.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:47:41.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:41.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:47:41.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:48:11.769+0000] {processor.py:157} INFO - Started process (PID=12802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:48:11.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:48:11.772+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:11.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:48:11.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:48:11.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:11.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:48:11.811+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:11.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:48:11.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T19:48:42.204+0000] {processor.py:157} INFO - Started process (PID=12827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:48:42.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:48:42.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:42.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:48:42.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:48:42.234+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:42.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:48:42.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:42.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:48:42.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:49:12.611+0000] {processor.py:157} INFO - Started process (PID=12852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:49:12.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:49:12.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:12.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:49:12.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:49:12.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:12.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:49:12.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:12.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:49:12.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T19:49:43.088+0000] {processor.py:157} INFO - Started process (PID=12877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:49:43.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:49:43.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:43.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:49:43.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:49:43.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:43.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:49:43.131+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:43.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:49:43.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:50:13.535+0000] {processor.py:157} INFO - Started process (PID=12902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:50:13.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:50:13.538+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:13.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:50:13.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:50:13.565+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:13.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:50:13.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:13.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:50:13.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:50:43.960+0000] {processor.py:157} INFO - Started process (PID=12927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:50:43.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:50:43.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:43.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:50:43.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:50:43.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:43.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:50:44.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:44.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:50:44.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T19:51:14.372+0000] {processor.py:157} INFO - Started process (PID=12952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:51:14.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:51:14.374+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:14.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:51:14.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:51:14.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:14.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:51:14.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:14.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:51:14.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:51:44.779+0000] {processor.py:157} INFO - Started process (PID=12977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:51:44.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:51:44.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:44.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:51:44.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:51:44.810+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:44.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:51:44.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:44.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:51:44.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:52:15.242+0000] {processor.py:157} INFO - Started process (PID=13002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:52:15.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:52:15.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:15.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:52:15.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:52:15.274+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:15.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:52:15.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:15.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:52:15.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T19:52:45.673+0000] {processor.py:157} INFO - Started process (PID=13027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:52:45.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:52:45.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:45.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:52:45.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:52:45.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:45.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:52:45.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:45.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:52:45.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T19:53:16.187+0000] {processor.py:157} INFO - Started process (PID=13052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:53:16.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:53:16.195+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:16.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:53:16.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:53:16.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:16.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:53:16.229+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:16.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:53:16.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T19:53:46.629+0000] {processor.py:157} INFO - Started process (PID=13077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:53:46.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:53:46.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:46.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:53:46.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:53:46.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:46.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:53:46.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:46.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:53:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T19:54:17.081+0000] {processor.py:157} INFO - Started process (PID=13102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:54:17.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:54:17.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:17.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:54:17.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:54:17.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:17.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:54:17.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:17.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:54:17.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T19:54:47.572+0000] {processor.py:157} INFO - Started process (PID=13127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:54:47.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:54:47.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:47.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:54:47.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:54:47.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:47.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:54:47.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:47.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:54:47.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:55:17.969+0000] {processor.py:157} INFO - Started process (PID=13152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:55:17.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:55:17.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:17.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:55:17.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:55:18.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:18.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:55:18.011+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:18.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:55:18.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T19:55:48.414+0000] {processor.py:157} INFO - Started process (PID=13177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:55:48.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:55:48.418+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:48.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:55:48.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:55:48.447+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:48.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:55:48.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:48.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:55:48.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T19:56:18.864+0000] {processor.py:157} INFO - Started process (PID=13202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:56:18.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:56:18.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:18.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:56:18.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:56:18.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:18.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:56:18.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:18.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:56:18.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:56:49.274+0000] {processor.py:157} INFO - Started process (PID=13227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:56:49.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:56:49.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:49.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:56:49.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:56:49.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:49.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:56:49.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:49.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:56:49.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T19:57:19.734+0000] {processor.py:157} INFO - Started process (PID=13252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:57:19.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:57:19.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:19.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:57:19.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:57:19.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:19.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:57:19.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:19.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:57:19.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T19:57:50.122+0000] {processor.py:157} INFO - Started process (PID=13277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:57:50.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:57:50.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:50.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:57:50.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:57:50.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:50.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:57:50.163+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:50.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:57:50.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T19:58:20.620+0000] {processor.py:157} INFO - Started process (PID=13302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:58:20.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:58:20.623+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:20.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:58:20.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:58:20.649+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:20.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:58:20.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:20.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:58:20.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:58:51.020+0000] {processor.py:157} INFO - Started process (PID=13327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:58:51.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:58:51.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:51.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:58:51.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:58:51.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:51.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:58:51.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:51.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:58:51.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T19:59:21.496+0000] {processor.py:157} INFO - Started process (PID=13352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:59:21.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:59:21.499+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:21.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:59:21.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:59:21.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:21.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:59:21.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:21.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:59:21.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T19:59:51.892+0000] {processor.py:157} INFO - Started process (PID=13377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:59:51.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T19:59:51.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:51.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:59:51.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T19:59:51.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:51.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:59:51.932+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:51.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T19:59:51.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:00:22.383+0000] {processor.py:157} INFO - Started process (PID=13402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:00:22.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:00:22.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:22.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:00:22.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:00:22.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:22.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:00:22.423+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:22.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:00:22.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T20:00:52.819+0000] {processor.py:157} INFO - Started process (PID=13427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:00:52.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:00:52.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:52.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:00:52.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:00:52.848+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:52.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:00:52.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:52.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:00:52.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:01:23.298+0000] {processor.py:157} INFO - Started process (PID=13452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:01:23.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:01:23.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:23.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:01:23.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:01:23.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:23.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:01:23.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:23.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:01:23.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T20:01:53.721+0000] {processor.py:157} INFO - Started process (PID=13477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:01:53.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:01:53.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:53.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:01:53.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:01:53.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:53.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:01:53.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:53.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:01:53.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T20:02:24.170+0000] {processor.py:157} INFO - Started process (PID=13502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:02:24.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:02:24.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:24.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:02:24.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:02:24.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:24.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:02:24.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:24.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:02:24.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:02:54.628+0000] {processor.py:157} INFO - Started process (PID=13527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:02:54.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:02:54.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:54.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:02:54.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:02:54.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:54.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:02:54.671+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:54.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:02:54.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T20:18:26.287+0000] {processor.py:157} INFO - Started process (PID=13554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:18:26.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:18:26.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:26.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:18:26.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:18:26.361+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:26.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:18:26.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:26.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:18:26.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-20T20:18:56.878+0000] {processor.py:157} INFO - Started process (PID=13579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:18:56.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:18:56.881+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:56.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:18:56.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:18:56.911+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:56.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:18:56.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:56.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:18:56.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:19:27.361+0000] {processor.py:157} INFO - Started process (PID=13604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:19:27.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:19:27.365+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:27.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:19:27.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:19:27.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:27.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:19:27.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:27.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:19:27.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:19:57.823+0000] {processor.py:157} INFO - Started process (PID=13629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:19:57.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:19:57.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:57.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:19:57.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:19:57.857+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:57.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:19:57.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:57.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:19:57.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T20:20:28.264+0000] {processor.py:157} INFO - Started process (PID=13654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:20:28.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:20:28.267+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:28.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:20:28.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:20:28.299+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:28.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:20:28.312+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:28.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:20:28.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T20:20:58.716+0000] {processor.py:157} INFO - Started process (PID=13679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:20:58.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:20:58.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:58.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:20:58.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:20:58.746+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:58.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:20:58.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:58.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:20:58.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:21:29.146+0000] {processor.py:157} INFO - Started process (PID=13704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:21:29.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:21:29.149+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:29.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:21:29.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:21:29.178+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:29.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:21:29.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:29.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:21:29.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:21:59.625+0000] {processor.py:157} INFO - Started process (PID=13729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:21:59.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:21:59.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:59.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:21:59.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:21:59.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:59.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:21:59.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:59.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:21:59.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:22:29.978+0000] {processor.py:157} INFO - Started process (PID=13754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:22:29.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:22:29.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:22:29.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:22:29.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:22:30.007+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:22:30.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:22:30.018+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:22:30.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:22:30.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:23:00.439+0000] {processor.py:157} INFO - Started process (PID=13779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:23:00.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:23:00.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:00.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:23:00.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:23:00.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:00.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:23:00.483+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:00.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:23:00.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T20:23:30.909+0000] {processor.py:157} INFO - Started process (PID=13804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:23:30.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:23:30.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:30.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:23:30.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:23:30.944+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:30.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:23:30.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:30.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:23:30.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T20:24:01.362+0000] {processor.py:157} INFO - Started process (PID=13829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:24:01.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:24:01.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:01.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:24:01.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:24:01.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:01.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:24:01.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:01.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:24:01.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T20:24:31.834+0000] {processor.py:157} INFO - Started process (PID=13854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:24:31.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:24:31.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:31.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:24:31.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:24:31.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:31.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:24:31.877+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:31.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:24:31.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:25:02.274+0000] {processor.py:157} INFO - Started process (PID=13879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:25:02.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:25:02.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:02.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:25:02.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:25:02.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:02.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:25:02.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:02.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:25:02.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:25:32.785+0000] {processor.py:157} INFO - Started process (PID=13904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:25:32.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:25:32.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:32.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:25:32.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:25:32.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:32.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:25:32.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:32.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:25:32.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:26:03.164+0000] {processor.py:157} INFO - Started process (PID=13929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:26:03.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:26:03.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:03.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:26:03.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:26:03.191+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:03.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:26:03.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:03.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:26:03.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T20:26:33.572+0000] {processor.py:157} INFO - Started process (PID=13954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:26:33.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:26:33.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:33.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:26:33.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:26:33.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:33.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:26:33.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:33.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:26:33.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T20:27:04.005+0000] {processor.py:157} INFO - Started process (PID=13979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:27:04.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:27:04.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:04.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:27:04.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:27:04.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:04.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:27:04.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:04.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:27:04.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:27:34.382+0000] {processor.py:157} INFO - Started process (PID=14004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:27:34.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:27:34.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:34.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:27:34.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:27:34.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:34.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:27:34.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:34.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:27:34.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:28:04.862+0000] {processor.py:157} INFO - Started process (PID=14029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:28:04.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:28:04.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:04.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:28:04.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:28:04.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:04.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:28:04.906+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:04.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:28:04.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:28:35.310+0000] {processor.py:157} INFO - Started process (PID=14054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:28:35.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:28:35.313+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:35.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:28:35.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:28:35.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:35.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:28:35.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:35.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:28:35.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T20:29:05.796+0000] {processor.py:157} INFO - Started process (PID=14079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:29:05.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:29:05.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:05.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:29:05.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:29:05.827+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:05.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:29:05.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:05.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:29:05.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:29:36.243+0000] {processor.py:157} INFO - Started process (PID=14104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:29:36.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:29:36.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:36.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:29:36.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:29:36.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:36.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:29:36.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:36.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:29:36.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T20:30:06.707+0000] {processor.py:157} INFO - Started process (PID=14129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:30:06.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:30:06.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:06.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:30:06.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:30:06.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:06.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:30:06.744+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:06.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:30:06.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:30:37.136+0000] {processor.py:157} INFO - Started process (PID=14154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:30:37.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:30:37.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:37.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:30:37.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:30:37.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:37.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:30:37.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:37.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:30:37.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:31:07.570+0000] {processor.py:157} INFO - Started process (PID=14179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:31:07.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:31:07.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:07.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:31:07.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:31:07.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:07.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:31:07.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:07.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:31:07.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T20:31:38.060+0000] {processor.py:157} INFO - Started process (PID=14204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:31:38.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:31:38.063+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:38.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:31:38.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:31:38.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:38.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:31:38.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:38.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:31:38.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:32:08.492+0000] {processor.py:157} INFO - Started process (PID=14229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:32:08.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:32:08.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:08.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:32:08.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:32:08.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:08.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:32:08.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:08.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:32:08.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-20T20:32:38.946+0000] {processor.py:157} INFO - Started process (PID=14254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:32:38.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:32:38.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:38.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:32:38.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:32:38.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:38.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:32:38.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:38.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:32:38.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:33:09.389+0000] {processor.py:157} INFO - Started process (PID=14279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:33:09.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:33:09.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:09.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:33:09.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:33:09.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:09.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:33:09.431+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:09.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:33:09.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T20:33:39.845+0000] {processor.py:157} INFO - Started process (PID=14304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:33:39.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:33:39.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:39.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:33:39.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:33:39.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:39.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:33:39.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:39.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:33:39.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T20:34:10.329+0000] {processor.py:157} INFO - Started process (PID=14329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:34:10.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:34:10.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:10.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:34:10.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:34:10.361+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:10.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:34:10.375+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:10.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:34:10.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T20:34:40.781+0000] {processor.py:157} INFO - Started process (PID=14354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:34:40.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:34:40.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:40.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:34:40.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:34:40.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:40.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:34:40.825+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:40.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:34:40.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:35:11.266+0000] {processor.py:157} INFO - Started process (PID=14379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:35:11.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:35:11.275+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:11.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:35:11.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:35:11.298+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:11.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:35:11.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:11.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:35:11.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:35:41.707+0000] {processor.py:157} INFO - Started process (PID=14404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:35:41.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:35:41.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:41.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:35:41.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:35:41.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:41.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:35:41.749+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:41.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:35:41.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:36:12.167+0000] {processor.py:157} INFO - Started process (PID=14429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:36:12.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:36:12.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:12.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:36:12.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:36:12.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:12.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:36:12.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:12.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:36:12.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:36:42.589+0000] {processor.py:157} INFO - Started process (PID=14454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:36:42.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:36:42.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:42.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:36:42.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:36:42.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:42.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:36:42.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:42.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:36:42.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:37:13.014+0000] {processor.py:157} INFO - Started process (PID=14479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:37:13.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:37:13.018+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:13.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:37:13.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:37:13.047+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:13.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:37:13.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:13.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:37:13.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T20:37:43.513+0000] {processor.py:157} INFO - Started process (PID=14504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:37:43.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:37:43.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:43.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:37:43.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:37:43.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:43.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:37:43.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:43.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:37:43.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T20:38:13.970+0000] {processor.py:157} INFO - Started process (PID=14529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:38:13.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:38:13.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:13.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:38:13.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:38:14.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:14.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:38:14.009+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:14.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:38:14.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T20:38:44.457+0000] {processor.py:157} INFO - Started process (PID=14554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:38:44.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:38:44.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:44.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:38:44.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:38:44.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:44.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:38:44.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:44.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:38:44.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T20:39:14.847+0000] {processor.py:157} INFO - Started process (PID=14579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:39:14.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:39:14.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:14.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:39:14.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:39:14.877+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:14.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:39:14.887+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:14.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:39:14.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:39:45.371+0000] {processor.py:157} INFO - Started process (PID=14604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:39:45.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:39:45.373+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:45.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:39:45.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:39:45.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:45.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:39:45.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:45.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:39:45.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:40:15.829+0000] {processor.py:157} INFO - Started process (PID=14629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:40:15.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:40:15.831+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:15.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:40:15.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:40:15.855+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:15.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:40:15.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:15.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:40:15.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-20T20:40:46.248+0000] {processor.py:157} INFO - Started process (PID=14654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:40:46.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:40:46.252+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:46.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:40:46.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:40:46.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:46.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:40:46.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:46.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:40:46.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:41:16.722+0000] {processor.py:157} INFO - Started process (PID=14679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:41:16.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:41:16.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:16.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:41:16.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:41:16.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:16.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:41:16.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:16.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:41:16.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:41:47.158+0000] {processor.py:157} INFO - Started process (PID=14704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:41:47.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:41:47.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:47.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:41:47.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:41:47.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:47.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:41:47.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:47.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:41:47.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:42:17.677+0000] {processor.py:157} INFO - Started process (PID=14729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:42:17.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:42:17.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:17.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:42:17.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:42:17.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:17.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:42:17.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:17.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:42:17.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:42:48.089+0000] {processor.py:157} INFO - Started process (PID=14754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:42:48.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:42:48.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:48.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:42:48.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:42:48.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:48.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:42:48.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:48.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:42:48.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:43:18.506+0000] {processor.py:157} INFO - Started process (PID=14779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:43:18.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:43:18.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:18.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:43:18.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:43:18.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:18.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:43:18.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:18.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:43:18.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T20:43:49.011+0000] {processor.py:157} INFO - Started process (PID=14804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:43:49.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:43:49.014+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:49.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:43:49.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:43:49.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:49.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:43:49.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:49.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:43:49.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T20:44:19.483+0000] {processor.py:157} INFO - Started process (PID=14829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:44:19.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:44:19.486+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:19.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:44:19.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:44:19.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:19.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:44:19.525+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:19.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:44:19.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T20:44:49.940+0000] {processor.py:157} INFO - Started process (PID=14854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:44:49.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:44:49.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:49.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:44:49.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:44:49.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:49.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:44:49.979+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:49.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:44:49.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T20:45:20.412+0000] {processor.py:157} INFO - Started process (PID=14879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:45:20.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:45:20.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:20.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:45:20.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:45:20.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:20.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:45:20.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:20.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:45:20.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:45:50.864+0000] {processor.py:157} INFO - Started process (PID=14904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:45:50.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:45:50.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:50.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:45:50.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:45:50.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:50.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:45:50.906+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:50.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:45:50.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:46:21.301+0000] {processor.py:157} INFO - Started process (PID=14929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:46:21.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:46:21.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:21.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:46:21.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:46:21.334+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:21.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:46:21.347+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:21.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:46:21.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T20:46:51.743+0000] {processor.py:157} INFO - Started process (PID=14954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:46:51.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:46:51.746+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:51.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:46:51.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:46:51.773+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:51.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:46:51.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:51.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:46:51.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:47:22.132+0000] {processor.py:157} INFO - Started process (PID=14979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:47:22.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:47:22.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:22.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:47:22.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:47:22.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:22.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:47:22.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:22.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:47:22.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-20T20:47:52.558+0000] {processor.py:157} INFO - Started process (PID=15004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:47:52.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:47:52.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:52.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:47:52.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:47:52.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:52.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:47:52.599+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:52.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:47:52.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:48:23.040+0000] {processor.py:157} INFO - Started process (PID=15029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:48:23.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:48:23.044+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:23.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:48:23.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:48:23.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:23.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:48:23.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:23.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:48:23.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:48:53.545+0000] {processor.py:157} INFO - Started process (PID=15054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:48:53.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:48:53.548+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:53.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:48:53.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:48:53.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:53.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:48:53.584+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:53.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:48:53.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T20:49:23.974+0000] {processor.py:157} INFO - Started process (PID=15079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:49:23.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:49:23.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:23.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:49:23.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:49:24.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:24.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:49:24.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:24.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:49:24.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:49:54.426+0000] {processor.py:157} INFO - Started process (PID=15104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:49:54.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:49:54.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:54.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:49:54.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:49:54.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:54.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:49:54.469+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:54.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:49:54.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T20:50:24.829+0000] {processor.py:157} INFO - Started process (PID=15129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:50:24.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:50:24.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:24.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:50:24.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:50:24.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:24.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:50:24.870+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:24.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:50:24.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:50:55.309+0000] {processor.py:157} INFO - Started process (PID=15154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:50:55.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:50:55.312+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:55.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:50:55.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:50:55.337+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:55.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:50:55.348+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:55.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:50:55.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T20:51:25.738+0000] {processor.py:157} INFO - Started process (PID=15179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:51:25.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:51:25.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:25.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:51:25.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:51:25.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:25.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:51:25.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:25.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:51:25.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:51:56.180+0000] {processor.py:157} INFO - Started process (PID=15204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:51:56.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:51:56.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:56.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:51:56.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:51:56.210+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:56.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:51:56.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:56.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:51:56.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:52:26.598+0000] {processor.py:157} INFO - Started process (PID=15229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:52:26.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:52:26.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:26.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:52:26.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:52:26.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:26.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:52:26.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:26.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:52:26.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T20:52:57.022+0000] {processor.py:157} INFO - Started process (PID=15254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:52:57.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:52:57.025+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:57.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:52:57.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:52:57.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:57.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:52:57.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:57.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:52:57.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:53:27.498+0000] {processor.py:157} INFO - Started process (PID=15279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:53:27.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:53:27.502+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:27.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:53:27.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:53:27.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:27.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:53:27.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:27.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:53:27.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:53:57.997+0000] {processor.py:157} INFO - Started process (PID=15304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:53:57.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:53:57.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:57.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:53:58.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:53:58.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:58.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:53:58.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:58.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:53:58.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T20:54:28.490+0000] {processor.py:157} INFO - Started process (PID=15329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:54:28.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:54:28.492+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:28.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:54:28.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:54:28.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:28.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:54:28.533+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:28.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:54:28.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:54:58.983+0000] {processor.py:157} INFO - Started process (PID=15354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:54:58.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:54:58.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:58.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:54:59.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:54:59.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:59.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:54:59.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:59.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:54:59.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:55:29.421+0000] {processor.py:157} INFO - Started process (PID=15379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:55:29.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:55:29.425+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:29.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:55:29.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:55:29.451+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:29.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:55:29.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:29.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:55:29.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:55:59.854+0000] {processor.py:157} INFO - Started process (PID=15404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:55:59.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:55:59.857+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:59.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:55:59.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:55:59.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:59.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:55:59.892+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:59.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:55:59.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T20:56:30.289+0000] {processor.py:157} INFO - Started process (PID=15429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:56:30.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:56:30.292+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:56:30.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:56:30.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:56:30.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:56:30.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:56:30.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:56:30.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:56:30.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T20:57:00.719+0000] {processor.py:157} INFO - Started process (PID=15454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:57:00.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:57:00.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:00.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:57:00.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:57:00.749+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:00.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:57:00.761+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:00.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:57:00.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:57:31.147+0000] {processor.py:157} INFO - Started process (PID=15479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:57:31.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:57:31.149+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:31.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:57:31.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:57:31.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:31.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:57:31.191+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:31.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:57:31.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T20:58:01.586+0000] {processor.py:157} INFO - Started process (PID=15504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:58:01.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:58:01.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:01.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:58:01.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:58:01.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:01.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:58:01.626+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:01.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:58:01.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T20:58:32.031+0000] {processor.py:157} INFO - Started process (PID=15529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:58:32.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:58:32.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:32.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:58:32.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:58:32.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:32.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:58:32.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:32.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:58:32.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T20:59:02.501+0000] {processor.py:157} INFO - Started process (PID=15554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:59:02.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:59:02.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:02.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:59:02.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:59:02.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:02.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:59:02.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:02.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:59:02.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T20:59:32.912+0000] {processor.py:157} INFO - Started process (PID=15579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:59:32.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T20:59:32.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:32.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:59:32.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T20:59:32.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:32.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:59:32.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:32.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T20:59:32.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:00:03.342+0000] {processor.py:157} INFO - Started process (PID=15604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:00:03.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:00:03.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:03.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:00:03.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:00:03.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:03.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:00:03.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:03.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:00:03.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:00:33.829+0000] {processor.py:157} INFO - Started process (PID=15629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:00:33.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:00:33.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:33.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:00:33.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:00:33.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:33.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:00:33.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:33.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:00:33.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:01:04.271+0000] {processor.py:157} INFO - Started process (PID=15654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:01:04.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:01:04.273+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:04.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:01:04.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:01:04.298+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:04.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:01:04.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:04.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:01:04.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:01:34.755+0000] {processor.py:157} INFO - Started process (PID=15679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:01:34.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:01:34.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:34.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:01:34.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:01:34.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:34.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:01:34.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:34.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:01:34.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T21:02:05.144+0000] {processor.py:157} INFO - Started process (PID=15704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:02:05.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:02:05.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:05.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:02:05.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:02:05.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:05.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:02:05.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:05.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:02:05.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:02:35.637+0000] {processor.py:157} INFO - Started process (PID=15729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:02:35.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:02:35.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:35.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:02:35.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:02:35.667+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:35.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:02:35.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:35.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:02:35.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-20T21:03:06.106+0000] {processor.py:157} INFO - Started process (PID=15754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:03:06.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:03:06.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:06.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:03:06.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:03:06.133+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:06.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:03:06.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:06.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:03:06.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:03:36.572+0000] {processor.py:157} INFO - Started process (PID=15779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:03:36.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:03:36.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:36.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:03:36.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:03:36.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:36.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:03:36.619+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:36.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:03:36.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T21:04:06.975+0000] {processor.py:157} INFO - Started process (PID=15804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:04:06.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:04:06.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:06.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:04:06.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:04:07.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:07.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:04:07.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:07.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:04:07.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:04:37.373+0000] {processor.py:157} INFO - Started process (PID=15829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:04:37.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:04:37.376+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:37.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:04:37.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:04:37.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:37.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:04:37.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:37.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:04:37.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:05:07.862+0000] {processor.py:157} INFO - Started process (PID=15854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:05:07.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:05:07.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:07.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:05:07.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:05:07.893+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:07.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:05:07.903+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:07.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:05:07.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:05:38.295+0000] {processor.py:157} INFO - Started process (PID=15879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:05:38.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:05:38.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:38.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:05:38.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:05:38.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:38.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:05:38.338+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:38.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:05:38.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T21:06:08.773+0000] {processor.py:157} INFO - Started process (PID=15904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:06:08.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:06:08.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:08.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:06:08.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:06:08.803+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:08.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:06:08.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:08.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:06:08.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:06:39.225+0000] {processor.py:157} INFO - Started process (PID=15929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:06:39.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:06:39.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:39.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:06:39.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:06:39.255+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:39.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:06:39.267+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:39.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:06:39.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:07:09.683+0000] {processor.py:157} INFO - Started process (PID=15954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:07:09.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:07:09.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:09.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:07:09.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:07:09.716+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:09.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:07:09.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:09.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:07:09.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:07:40.116+0000] {processor.py:157} INFO - Started process (PID=15979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:07:40.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:07:40.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:40.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:07:40.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:07:40.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:40.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:07:40.159+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:40.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:07:40.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:08:10.571+0000] {processor.py:157} INFO - Started process (PID=16004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:08:10.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:08:10.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:10.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:08:10.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:08:10.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:10.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:08:10.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:10.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:08:10.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T21:08:41.042+0000] {processor.py:157} INFO - Started process (PID=16029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:08:41.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:08:41.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:41.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:08:41.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:08:41.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:41.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:08:41.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:41.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:08:41.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T21:09:11.455+0000] {processor.py:157} INFO - Started process (PID=16054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:09:11.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:09:11.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:11.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:09:11.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:09:11.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:11.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:09:11.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:11.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:09:11.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:09:41.880+0000] {processor.py:157} INFO - Started process (PID=16079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:09:41.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:09:41.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:41.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:09:41.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:09:41.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:41.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:09:41.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:41.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:09:41.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:10:12.309+0000] {processor.py:157} INFO - Started process (PID=16104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:10:12.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:10:12.312+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:12.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:10:12.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:10:12.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:12.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:10:12.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:12.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:10:12.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:10:42.770+0000] {processor.py:157} INFO - Started process (PID=16129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:10:42.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:10:42.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:42.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:10:42.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:10:42.803+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:42.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:10:42.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:42.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:10:42.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T21:11:13.280+0000] {processor.py:157} INFO - Started process (PID=16154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:11:13.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:11:13.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:13.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:11:13.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:11:13.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:13.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:11:13.319+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:13.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:11:13.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:11:43.789+0000] {processor.py:157} INFO - Started process (PID=16179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:11:43.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:11:43.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:43.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:11:43.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:11:43.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:43.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:11:43.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:43.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:11:43.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T21:12:14.255+0000] {processor.py:157} INFO - Started process (PID=16204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:12:14.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:12:14.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:14.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:12:14.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:12:14.287+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:14.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:12:14.296+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:14.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:12:14.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:12:44.678+0000] {processor.py:157} INFO - Started process (PID=16229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:12:44.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:12:44.682+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:44.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:12:44.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:12:44.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:44.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:12:44.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:44.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:12:44.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:13:15.161+0000] {processor.py:157} INFO - Started process (PID=16254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:13:15.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:13:15.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:15.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:13:15.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:13:15.197+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:15.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:13:15.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:15.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:13:15.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T21:13:45.619+0000] {processor.py:157} INFO - Started process (PID=16279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:13:45.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:13:45.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:45.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:13:45.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:13:45.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:45.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:13:45.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:45.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:13:45.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:14:15.959+0000] {processor.py:157} INFO - Started process (PID=16304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:14:15.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:14:15.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:15.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:14:15.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:14:15.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:15.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:14:16.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:16.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:14:16.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T21:14:46.377+0000] {processor.py:157} INFO - Started process (PID=16329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:14:46.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:14:46.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:46.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:14:46.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:14:46.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:46.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:14:46.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:46.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:14:46.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:15:16.775+0000] {processor.py:157} INFO - Started process (PID=16354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:15:16.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:15:16.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:16.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:15:16.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:15:16.799+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:16.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:15:16.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:16.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:15:16.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-20T21:15:47.215+0000] {processor.py:157} INFO - Started process (PID=16379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:15:47.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:15:47.218+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:47.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:15:47.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:15:47.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:47.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:15:47.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:47.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:15:47.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:16:17.671+0000] {processor.py:157} INFO - Started process (PID=16404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:16:17.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:16:17.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:17.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:16:17.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:16:17.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:17.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:16:17.707+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:17.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:16:17.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-20T21:16:48.147+0000] {processor.py:157} INFO - Started process (PID=16429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:16:48.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:16:48.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:48.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:16:48.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:16:48.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:48.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:16:48.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:48.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:16:48.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T21:17:18.625+0000] {processor.py:157} INFO - Started process (PID=16454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:17:18.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:17:18.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:18.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:17:18.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:17:18.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:18.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:17:18.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:18.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:17:18.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:17:49.051+0000] {processor.py:157} INFO - Started process (PID=16479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:17:49.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:17:49.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:49.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:17:49.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:17:49.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:49.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:17:49.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:49.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:17:49.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:18:19.478+0000] {processor.py:157} INFO - Started process (PID=16504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:18:19.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:18:19.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:19.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:18:19.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:18:19.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:19.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:18:19.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:19.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:18:19.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:18:49.950+0000] {processor.py:157} INFO - Started process (PID=16529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:18:49.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:18:49.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:49.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:18:49.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:18:49.979+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:49.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:18:49.988+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:49.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:18:49.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T21:19:20.414+0000] {processor.py:157} INFO - Started process (PID=16554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:19:20.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:19:20.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:20.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:19:20.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:19:20.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:20.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:19:20.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:20.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:19:20.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:19:50.881+0000] {processor.py:157} INFO - Started process (PID=16579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:19:50.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:19:50.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:50.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:19:50.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:19:50.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:50.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:19:50.927+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:50.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:19:50.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:20:21.357+0000] {processor.py:157} INFO - Started process (PID=16604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:20:21.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:20:21.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:21.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:20:21.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:20:21.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:21.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:20:21.400+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:21.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:20:21.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:20:51.816+0000] {processor.py:157} INFO - Started process (PID=16629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:20:51.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:20:51.820+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:51.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:20:51.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:20:51.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:51.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:20:51.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:51.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:20:51.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:21:22.311+0000] {processor.py:157} INFO - Started process (PID=16654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:21:22.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:21:22.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:22.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:21:22.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:21:22.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:22.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:21:22.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:22.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:21:22.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:21:52.787+0000] {processor.py:157} INFO - Started process (PID=16679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:21:52.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:21:52.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:52.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:21:52.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:21:52.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:52.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:21:52.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:52.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:21:52.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:22:23.282+0000] {processor.py:157} INFO - Started process (PID=16704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:22:23.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:22:23.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:23.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:22:23.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:22:23.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:23.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:22:23.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:23.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:22:23.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T21:22:53.742+0000] {processor.py:157} INFO - Started process (PID=16729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:22:53.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:22:53.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:53.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:22:53.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:22:53.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:53.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:22:53.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:53.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:22:53.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:23:24.239+0000] {processor.py:157} INFO - Started process (PID=16754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:23:24.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:23:24.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:24.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:23:24.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:23:24.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:24.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:23:24.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:24.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:23:24.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:23:54.712+0000] {processor.py:157} INFO - Started process (PID=16779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:23:54.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:23:54.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:54.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:23:54.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:23:54.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:54.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:23:54.754+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:54.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:23:54.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:24:25.151+0000] {processor.py:157} INFO - Started process (PID=16804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:24:25.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:24:25.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:25.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:24:25.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:24:25.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:25.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:24:25.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:25.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:24:25.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:24:55.569+0000] {processor.py:157} INFO - Started process (PID=16829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:24:55.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:24:55.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:55.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:24:55.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:24:55.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:55.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:24:55.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:55.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:24:55.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:25:25.998+0000] {processor.py:157} INFO - Started process (PID=16854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:25:26.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:25:26.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:26.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:25:26.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:25:26.035+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:26.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:25:26.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:26.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:25:26.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T21:25:56.413+0000] {processor.py:157} INFO - Started process (PID=16879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:25:56.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:25:56.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:56.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:25:56.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:25:56.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:56.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:25:56.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:56.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:25:56.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:26:26.856+0000] {processor.py:157} INFO - Started process (PID=16904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:26:26.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:26:26.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:26.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:26:26.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:26:26.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:26.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:26:26.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:26.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:26:26.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:26:57.256+0000] {processor.py:157} INFO - Started process (PID=16929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:26:57.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:26:57.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:57.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:26:57.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:26:57.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:57.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:26:57.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:57.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:26:57.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T21:27:27.722+0000] {processor.py:157} INFO - Started process (PID=16954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:27:27.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:27:27.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:27.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:27:27.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:27:27.755+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:27.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:27:27.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:27.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:27:27.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T21:27:58.193+0000] {processor.py:157} INFO - Started process (PID=16979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:27:58.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:27:58.195+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:58.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:27:58.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:27:58.225+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:58.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:27:58.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:58.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:27:58.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:28:28.600+0000] {processor.py:157} INFO - Started process (PID=17004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:28:28.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:28:28.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:28.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:28:28.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:28:28.632+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:28.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:28:28.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:28.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:28:28.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:28:59.047+0000] {processor.py:157} INFO - Started process (PID=17029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:28:59.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:28:59.049+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:59.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:28:59.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:28:59.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:59.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:28:59.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:59.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:28:59.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:29:29.438+0000] {processor.py:157} INFO - Started process (PID=17054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:29:29.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:29:29.440+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:29.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:29:29.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:29:29.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:29.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:29:29.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:29.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:29:29.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:29:59.911+0000] {processor.py:157} INFO - Started process (PID=17079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:29:59.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:29:59.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:59.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:29:59.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:29:59.938+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:59.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:29:59.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:59.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:29:59.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:30:30.384+0000] {processor.py:157} INFO - Started process (PID=17104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:30:30.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:30:30.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:30:30.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:30:30.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:30:30.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:30:30.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:30:30.421+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:30:30.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:30:30.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T21:31:00.804+0000] {processor.py:157} INFO - Started process (PID=17129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:31:00.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:31:00.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:00.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:31:00.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:31:00.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:00.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:31:00.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:00.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:31:00.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:31:31.167+0000] {processor.py:157} INFO - Started process (PID=17154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:31:31.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:31:31.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:31.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:31:31.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:31:31.197+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:31.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:31:31.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:31.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:31:31.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:32:01.617+0000] {processor.py:157} INFO - Started process (PID=17179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:32:01.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:32:01.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:01.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:32:01.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:32:01.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:01.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:32:01.658+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:01.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:32:01.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:32:32.095+0000] {processor.py:157} INFO - Started process (PID=17204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:32:32.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:32:32.099+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:32.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:32:32.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:32:32.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:32.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:32:32.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:32.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:32:32.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:33:02.559+0000] {processor.py:157} INFO - Started process (PID=17229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:33:02.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:33:02.561+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:02.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:33:02.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:33:02.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:02.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:33:02.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:02.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:33:02.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:33:33.048+0000] {processor.py:157} INFO - Started process (PID=17254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:33:33.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:33:33.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:33.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:33:33.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:33:33.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:33.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:33:33.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:33.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:33:33.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:34:03.483+0000] {processor.py:157} INFO - Started process (PID=17279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:34:03.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:34:03.486+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:03.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:34:03.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:34:03.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:03.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:34:03.525+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:03.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:34:03.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:34:33.993+0000] {processor.py:157} INFO - Started process (PID=17304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:34:33.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:34:33.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:33.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:34:34.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:34:34.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:34.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:34:34.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:34.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:34:34.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:35:04.413+0000] {processor.py:157} INFO - Started process (PID=17329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:35:04.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:35:04.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:04.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:35:04.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:35:04.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:04.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:35:04.454+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:04.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:35:04.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:35:34.872+0000] {processor.py:157} INFO - Started process (PID=17354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:35:34.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:35:34.875+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:34.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:35:34.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:35:34.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:34.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:35:34.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:34.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:35:34.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T21:36:05.294+0000] {processor.py:157} INFO - Started process (PID=17379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:36:05.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:36:05.296+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:05.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:36:05.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:36:05.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:05.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:36:05.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:05.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:36:05.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:36:35.681+0000] {processor.py:157} INFO - Started process (PID=17404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:36:35.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:36:35.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:35.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:36:35.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:36:35.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:35.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:36:35.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:35.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:36:35.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:37:06.127+0000] {processor.py:157} INFO - Started process (PID=17429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:37:06.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:37:06.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:06.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:37:06.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:37:06.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:06.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:37:06.168+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:06.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:37:06.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:37:36.623+0000] {processor.py:157} INFO - Started process (PID=17454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:37:36.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:37:36.626+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:36.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:37:36.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:37:36.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:36.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:37:36.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:36.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:37:36.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T21:38:07.084+0000] {processor.py:157} INFO - Started process (PID=17479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:38:07.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:38:07.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:07.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:38:07.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:38:07.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:07.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:38:07.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:07.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:38:07.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T21:38:37.595+0000] {processor.py:157} INFO - Started process (PID=17504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:38:37.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:38:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:37.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:38:37.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:38:37.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:37.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:38:37.635+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:37.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:38:37.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:39:08.012+0000] {processor.py:157} INFO - Started process (PID=17529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:39:08.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:39:08.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:08.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:39:08.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:39:08.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:08.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:39:08.056+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:08.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:39:08.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:39:38.418+0000] {processor.py:157} INFO - Started process (PID=17554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:39:38.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:39:38.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:38.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:39:38.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:39:38.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:38.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:39:38.461+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:38.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:39:38.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:40:08.839+0000] {processor.py:157} INFO - Started process (PID=17579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:40:08.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:40:08.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:08.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:40:08.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:40:08.877+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:08.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:40:08.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:08.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:40:08.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-20T21:40:39.296+0000] {processor.py:157} INFO - Started process (PID=17604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:40:39.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:40:39.298+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:39.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:40:39.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:40:39.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:39.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:40:39.335+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:39.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:40:39.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:41:09.774+0000] {processor.py:157} INFO - Started process (PID=17629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:41:09.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:41:09.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:09.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:41:09.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:41:09.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:09.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:41:09.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:09.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:41:09.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:41:40.244+0000] {processor.py:157} INFO - Started process (PID=17654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:41:40.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:41:40.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:40.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:41:40.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:41:40.274+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:40.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:41:40.285+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:40.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:41:40.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:42:10.646+0000] {processor.py:157} INFO - Started process (PID=17679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:42:10.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:42:10.649+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:10.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:42:10.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:42:10.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:10.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:42:10.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:10.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:42:10.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:42:41.098+0000] {processor.py:157} INFO - Started process (PID=17704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:42:41.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:42:41.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:41.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:42:41.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:42:41.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:41.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:42:41.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:41.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:42:41.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T21:43:11.575+0000] {processor.py:157} INFO - Started process (PID=17729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:43:11.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:43:11.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:11.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:43:11.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:43:11.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:11.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:43:11.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:11.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:43:11.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:43:42.057+0000] {processor.py:157} INFO - Started process (PID=17754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:43:42.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:43:42.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:42.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:43:42.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:43:42.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:42.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:43:42.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:42.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:43:42.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T21:44:12.466+0000] {processor.py:157} INFO - Started process (PID=17779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:44:12.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:44:12.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:12.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:44:12.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:44:12.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:12.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:44:12.511+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:12.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:44:12.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:44:42.913+0000] {processor.py:157} INFO - Started process (PID=17804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:44:42.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:44:42.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:42.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:44:42.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:44:42.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:42.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:44:42.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:42.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:44:42.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T21:45:13.355+0000] {processor.py:157} INFO - Started process (PID=17829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:45:13.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:45:13.358+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:13.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:45:13.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:45:13.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:13.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:45:13.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:13.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:45:13.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:45:43.805+0000] {processor.py:157} INFO - Started process (PID=17854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:45:43.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:45:43.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:43.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:45:43.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:45:43.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:43.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:45:43.848+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:43.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:45:43.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:46:14.237+0000] {processor.py:157} INFO - Started process (PID=17879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:46:14.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:46:14.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:14.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:46:14.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:46:14.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:14.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:46:14.274+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:14.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:46:14.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:46:44.677+0000] {processor.py:157} INFO - Started process (PID=17904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:46:44.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:46:44.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:44.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:46:44.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:46:44.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:44.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:46:44.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:44.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:46:44.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:47:15.074+0000] {processor.py:157} INFO - Started process (PID=17929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:47:15.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:47:15.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:15.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:47:15.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:47:15.105+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:15.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:47:15.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:15.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:47:15.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:47:45.488+0000] {processor.py:157} INFO - Started process (PID=17954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:47:45.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:47:45.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:45.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:47:45.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:47:45.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:45.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:47:45.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:45.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:47:45.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:48:15.966+0000] {processor.py:157} INFO - Started process (PID=17979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:48:15.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:48:15.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:15.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:48:15.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:48:15.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:15.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:48:16.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:16.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:48:16.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:48:46.385+0000] {processor.py:157} INFO - Started process (PID=18004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:48:46.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:48:46.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:46.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:48:46.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:48:46.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:46.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:48:46.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:46.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:48:46.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:49:16.901+0000] {processor.py:157} INFO - Started process (PID=18029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:49:16.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:49:16.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:16.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:49:16.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:49:16.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:16.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:49:16.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:16.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:49:16.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:49:47.325+0000] {processor.py:157} INFO - Started process (PID=18054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:49:47.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:49:47.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:47.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:49:47.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:49:47.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:47.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:49:47.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:47.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:49:47.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:50:17.761+0000] {processor.py:157} INFO - Started process (PID=18079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:50:17.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:50:17.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:17.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:50:17.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:50:17.792+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:17.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:50:17.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:17.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:50:17.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T21:50:48.278+0000] {processor.py:157} INFO - Started process (PID=18104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:50:48.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:50:48.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:48.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:50:48.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:50:48.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:48.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:50:48.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:48.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:50:48.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:51:18.794+0000] {processor.py:157} INFO - Started process (PID=18129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:51:18.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:51:18.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:18.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:51:18.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:51:18.827+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:18.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:51:18.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:18.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:51:18.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:51:49.232+0000] {processor.py:157} INFO - Started process (PID=18154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:51:49.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:51:49.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:49.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:51:49.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:51:49.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:49.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:51:49.280+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:49.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:51:49.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T21:52:19.684+0000] {processor.py:157} INFO - Started process (PID=18179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:52:19.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:52:19.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:19.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:52:19.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:52:19.714+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:19.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:52:19.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:19.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:52:19.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:52:50.140+0000] {processor.py:157} INFO - Started process (PID=18204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:52:50.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:52:50.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:50.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:52:50.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:52:50.171+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:50.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:52:50.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:50.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:52:50.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:53:20.569+0000] {processor.py:157} INFO - Started process (PID=18229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:53:20.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:53:20.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:20.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:53:20.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:53:20.599+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:20.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:53:20.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:20.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:53:20.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:53:51.079+0000] {processor.py:157} INFO - Started process (PID=18254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:53:51.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:53:51.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:51.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:53:51.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:53:51.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:51.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:53:51.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:51.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:53:51.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:54:21.554+0000] {processor.py:157} INFO - Started process (PID=18279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:54:21.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:54:21.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:21.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:54:21.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:54:21.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:21.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:54:21.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:21.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:54:21.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T21:54:52.027+0000] {processor.py:157} INFO - Started process (PID=18304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:54:52.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:54:52.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:52.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:54:52.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:54:52.058+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:52.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:54:52.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:52.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:54:52.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T21:55:22.446+0000] {processor.py:157} INFO - Started process (PID=18329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:55:22.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:55:22.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:22.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:55:22.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:55:22.477+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:22.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:55:22.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:22.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:55:22.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T21:55:52.918+0000] {processor.py:157} INFO - Started process (PID=18354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:55:52.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:55:52.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:52.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:55:52.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:55:52.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:52.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:55:52.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:52.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:55:52.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T21:56:23.328+0000] {processor.py:157} INFO - Started process (PID=18379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:56:23.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:56:23.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:23.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:56:23.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:56:23.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:23.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:56:23.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:23.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:56:23.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T21:56:53.776+0000] {processor.py:157} INFO - Started process (PID=18404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:56:53.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:56:53.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:53.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:56:53.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:56:53.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:53.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:56:53.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:53.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:56:53.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T21:57:24.255+0000] {processor.py:157} INFO - Started process (PID=18429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:57:24.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:57:24.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:24.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:57:24.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:57:24.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:24.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:57:24.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:24.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:57:24.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T21:57:54.667+0000] {processor.py:157} INFO - Started process (PID=18454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:57:54.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:57:54.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:54.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:57:54.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:57:54.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:54.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:57:54.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:54.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:57:54.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T21:58:25.146+0000] {processor.py:157} INFO - Started process (PID=18479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:58:25.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:58:25.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:25.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:58:25.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:58:25.178+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:25.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:58:25.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:25.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:58:25.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T21:58:55.644+0000] {processor.py:157} INFO - Started process (PID=18504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:58:55.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:58:55.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:55.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:58:55.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:58:55.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:55.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:58:55.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:55.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:58:55.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T21:59:26.117+0000] {processor.py:157} INFO - Started process (PID=18529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:59:26.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:59:26.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:26.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:59:26.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:59:26.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:26.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:59:26.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:26.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:59:26.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T21:59:56.596+0000] {processor.py:157} INFO - Started process (PID=18554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:59:56.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T21:59:56.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:56.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:59:56.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T21:59:56.629+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:56.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:59:56.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:56.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T21:59:56.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T22:00:26.994+0000] {processor.py:157} INFO - Started process (PID=18579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:00:26.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:00:26.998+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:26.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:00:27.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:00:27.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:27.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:00:27.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:27.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:00:27.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T22:00:57.504+0000] {processor.py:157} INFO - Started process (PID=18604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:00:57.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:00:57.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:57.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:00:57.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:00:57.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:57.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:00:57.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:57.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:00:57.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T22:01:27.919+0000] {processor.py:157} INFO - Started process (PID=18629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:01:27.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:01:27.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:27.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:01:27.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:01:27.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:27.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:01:27.963+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:27.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:01:27.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T22:01:58.415+0000] {processor.py:157} INFO - Started process (PID=18654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:01:58.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:01:58.417+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:58.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:01:58.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:01:58.448+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:58.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:01:58.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:58.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:01:58.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T22:02:28.853+0000] {processor.py:157} INFO - Started process (PID=18679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:02:28.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:02:28.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:28.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:02:28.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:02:28.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:28.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:02:28.893+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:28.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:02:28.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T22:02:59.352+0000] {processor.py:157} INFO - Started process (PID=18704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:02:59.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:02:59.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:59.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:02:59.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:02:59.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:59.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:02:59.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:59.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:02:59.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T22:18:41.599+0000] {processor.py:157} INFO - Started process (PID=18728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:18:41.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:18:41.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:18:41.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:18:41.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:18:41.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:18:41.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:18:41.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:18:41.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:18:41.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T22:22:08.198+0000] {processor.py:157} INFO - Started process (PID=18756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:22:08.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:22:08.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:08.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:22:08.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:22:08.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:08.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:22:08.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:08.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:22:08.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-20T22:22:38.749+0000] {processor.py:157} INFO - Started process (PID=18781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:22:38.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:22:38.754+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:38.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:22:38.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:22:38.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:38.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:22:38.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:38.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:22:38.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T22:23:09.204+0000] {processor.py:157} INFO - Started process (PID=18806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:23:09.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:23:09.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:09.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:23:09.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:23:09.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:09.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:23:09.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:09.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:23:09.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-20T22:23:39.757+0000] {processor.py:157} INFO - Started process (PID=18831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:23:39.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:23:39.760+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:39.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:23:39.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:23:39.786+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:39.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:23:39.797+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:39.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:23:39.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T22:24:10.164+0000] {processor.py:157} INFO - Started process (PID=18856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:24:10.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:24:10.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:10.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:24:10.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:24:10.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:10.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:24:10.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:10.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:24:10.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T22:24:40.515+0000] {processor.py:157} INFO - Started process (PID=18881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:24:40.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:24:40.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:40.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:24:40.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:24:40.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:40.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:24:40.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:40.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:24:40.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T22:25:10.948+0000] {processor.py:157} INFO - Started process (PID=18906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:25:10.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:25:10.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:10.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:25:10.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:25:10.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:10.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:25:10.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:10.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:25:11.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T22:25:41.382+0000] {processor.py:157} INFO - Started process (PID=18931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:25:41.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:25:41.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:41.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:25:41.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:25:41.418+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:41.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:25:41.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:41.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:25:41.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T22:26:11.880+0000] {processor.py:157} INFO - Started process (PID=18956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:26:11.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:26:11.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:11.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:26:11.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:26:11.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:11.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:26:11.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:11.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:26:11.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T22:26:42.358+0000] {processor.py:157} INFO - Started process (PID=18981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:26:42.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:26:42.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:42.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:26:42.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:26:42.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:42.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:26:42.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:42.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:26:42.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-20T22:27:12.780+0000] {processor.py:157} INFO - Started process (PID=19005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:27:12.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:27:12.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:12.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:27:12.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:27:12.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:12.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:27:12.817+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:12.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:27:12.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T22:27:43.211+0000] {processor.py:157} INFO - Started process (PID=19031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:27:43.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:27:43.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:43.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:27:43.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:27:43.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:43.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:27:43.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:43.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:27:43.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-20T22:28:13.638+0000] {processor.py:157} INFO - Started process (PID=19056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:28:13.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:28:13.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:13.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:28:13.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:28:13.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:13.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:28:13.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:13.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:28:13.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T22:28:44.132+0000] {processor.py:157} INFO - Started process (PID=19081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:28:44.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:28:44.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:44.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:28:44.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:28:44.163+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:44.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:28:44.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:44.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:28:44.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T22:29:14.537+0000] {processor.py:157} INFO - Started process (PID=19106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:29:14.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:29:14.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:14.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:29:14.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:29:14.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:14.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:29:14.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:14.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:29:14.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T22:29:45.049+0000] {processor.py:157} INFO - Started process (PID=19131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:29:45.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:29:45.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:45.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:29:45.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:29:45.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:45.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:29:45.096+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:45.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:29:45.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T22:30:15.456+0000] {processor.py:157} INFO - Started process (PID=19156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:30:15.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:30:15.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:15.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:30:15.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:30:15.486+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:15.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:30:15.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:15.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:30:15.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T22:30:45.928+0000] {processor.py:157} INFO - Started process (PID=19181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:30:45.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:30:45.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:45.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:30:45.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:30:45.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:45.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:30:45.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:45.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:30:45.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T22:31:16.339+0000] {processor.py:157} INFO - Started process (PID=19206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:31:16.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:31:16.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:16.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:31:16.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:31:16.371+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:16.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:31:16.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:16.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:31:16.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T22:31:46.717+0000] {processor.py:157} INFO - Started process (PID=19231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:31:46.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:31:46.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:46.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:31:46.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:31:46.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:46.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:31:46.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:46.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:31:46.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T22:32:17.192+0000] {processor.py:157} INFO - Started process (PID=19256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:32:17.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:32:17.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:17.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:32:17.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:32:17.224+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:17.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:32:17.234+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:17.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:32:17.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T22:32:47.654+0000] {processor.py:157} INFO - Started process (PID=19281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:32:47.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:32:47.658+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:47.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:32:47.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:32:47.689+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:47.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:32:47.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:47.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:32:47.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T22:33:18.035+0000] {processor.py:157} INFO - Started process (PID=19306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:33:18.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:33:18.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:18.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:33:18.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:33:18.063+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:18.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:33:18.074+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:18.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:33:18.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T22:33:48.494+0000] {processor.py:157} INFO - Started process (PID=19331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:33:48.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:33:48.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:48.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:33:48.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:33:48.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:48.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:33:48.533+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:48.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:33:48.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T22:34:18.982+0000] {processor.py:157} INFO - Started process (PID=19356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:34:18.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:34:18.987+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:18.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:34:19.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:34:19.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:19.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:34:19.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:19.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:34:19.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-20T22:34:49.517+0000] {processor.py:157} INFO - Started process (PID=19381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:34:49.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:34:49.522+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:49.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:34:49.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:34:49.549+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:49.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:34:49.559+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:49.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:34:49.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T22:35:19.956+0000] {processor.py:157} INFO - Started process (PID=19406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:35:19.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:35:19.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:19.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:35:19.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:35:19.984+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:19.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:35:19.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:19.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:35:20.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T22:35:50.406+0000] {processor.py:157} INFO - Started process (PID=19431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:35:50.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:35:50.408+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:50.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:35:50.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:35:50.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:50.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:35:50.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:50.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:35:50.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T22:36:20.833+0000] {processor.py:157} INFO - Started process (PID=19456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:36:20.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:36:20.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:20.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:36:20.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:36:20.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:20.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:36:20.875+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:20.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:36:20.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T22:36:51.259+0000] {processor.py:157} INFO - Started process (PID=19481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:36:51.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:36:51.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:51.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:36:51.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:36:51.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:51.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:36:51.298+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:51.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:36:51.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T22:53:18.396+0000] {processor.py:157} INFO - Started process (PID=19506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:53:18.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:53:18.400+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:18.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:53:18.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:53:18.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:18.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:53:18.438+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:18.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:53:18.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T22:53:48.823+0000] {processor.py:157} INFO - Started process (PID=19533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:53:48.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:53:48.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:48.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:53:48.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:53:48.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:48.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:53:48.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:48.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:53:48.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T22:54:19.233+0000] {processor.py:157} INFO - Started process (PID=19558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:54:19.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:54:19.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:19.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:54:19.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:54:19.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:19.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:54:19.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:19.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:54:19.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T22:54:49.597+0000] {processor.py:157} INFO - Started process (PID=19583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:54:49.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T22:54:49.599+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:49.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:54:49.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T22:54:49.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:49.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:54:49.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:49.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T22:54:49.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T23:10:45.923+0000] {processor.py:157} INFO - Started process (PID=19610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:10:45.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:10:45.927+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:10:45.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:10:45.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:10:45.957+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:10:45.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:10:45.967+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:10:45.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:10:45.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T23:11:16.460+0000] {processor.py:157} INFO - Started process (PID=19635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:11:16.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:11:16.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:16.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:11:16.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:11:16.495+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:16.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:11:16.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:16.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:11:16.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T23:11:46.963+0000] {processor.py:157} INFO - Started process (PID=19660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:11:46.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:11:46.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:46.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:11:46.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:11:47.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:47.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:11:47.014+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:47.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:11:47.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-20T23:12:17.420+0000] {processor.py:157} INFO - Started process (PID=19685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:12:17.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:12:17.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:17.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:12:17.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:12:17.448+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:17.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:12:17.461+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:17.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:12:17.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:12:47.835+0000] {processor.py:157} INFO - Started process (PID=19710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:12:47.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:12:47.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:47.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:12:47.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:12:47.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:47.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:12:47.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:47.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:12:47.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:13:18.322+0000] {processor.py:157} INFO - Started process (PID=19735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:13:18.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:13:18.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:18.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:13:18.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:13:18.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:18.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:13:18.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:18.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:13:18.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:13:48.832+0000] {processor.py:157} INFO - Started process (PID=19760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:13:48.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:13:48.835+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:48.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:13:48.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:13:48.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:48.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:13:48.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:48.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:13:48.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T23:14:19.260+0000] {processor.py:157} INFO - Started process (PID=19785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:14:19.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:14:19.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:19.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:14:19.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:14:19.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:19.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:14:19.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:19.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:14:19.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-20T23:14:49.713+0000] {processor.py:157} INFO - Started process (PID=19810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:14:49.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:14:49.716+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:49.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:14:49.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:14:49.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:49.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:14:49.753+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:49.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:14:49.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:15:20.199+0000] {processor.py:157} INFO - Started process (PID=19835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:15:20.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:15:20.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:20.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:15:20.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:15:20.229+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:20.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:15:20.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:20.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:15:20.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T23:15:50.697+0000] {processor.py:157} INFO - Started process (PID=19860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:15:50.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:15:50.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:50.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:15:50.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:15:50.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:50.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:15:50.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:50.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:15:50.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T23:16:21.201+0000] {processor.py:157} INFO - Started process (PID=19885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:16:21.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:16:21.205+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:21.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:16:21.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:16:21.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:21.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:16:21.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:21.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:16:21.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T23:16:51.747+0000] {processor.py:157} INFO - Started process (PID=19910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:16:51.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:16:51.751+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:51.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:16:51.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:16:51.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:51.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:16:51.786+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:51.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:16:51.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T23:17:22.238+0000] {processor.py:157} INFO - Started process (PID=19935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:17:22.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:17:22.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:22.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:17:22.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:17:22.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:22.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:17:22.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:22.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:17:22.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:17:52.762+0000] {processor.py:157} INFO - Started process (PID=19960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:17:52.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:17:52.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:52.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:17:52.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:17:52.792+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:52.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:17:52.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:52.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:17:52.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:18:23.186+0000] {processor.py:157} INFO - Started process (PID=19985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:18:23.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:18:23.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:23.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:18:23.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:18:23.219+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:23.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:18:23.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:23.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:18:23.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T23:18:53.704+0000] {processor.py:157} INFO - Started process (PID=20010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:18:53.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:18:53.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:53.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:18:53.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:18:53.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:53.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:18:53.744+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:53.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:18:53.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:19:24.148+0000] {processor.py:157} INFO - Started process (PID=20035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:19:24.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:19:24.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:24.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:19:24.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:19:24.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:24.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:19:24.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:24.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:19:24.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T23:19:54.584+0000] {processor.py:157} INFO - Started process (PID=20060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:19:54.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:19:54.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:54.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:19:54.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:19:54.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:54.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:19:54.629+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:54.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:19:54.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T23:20:25.018+0000] {processor.py:157} INFO - Started process (PID=20085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:20:25.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:20:25.021+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:25.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:20:25.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:20:25.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:25.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:20:25.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:25.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:20:25.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T23:20:55.429+0000] {processor.py:157} INFO - Started process (PID=20110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:20:55.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:20:55.433+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:55.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:20:55.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:20:55.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:55.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:20:55.470+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:55.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:20:55.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:21:25.956+0000] {processor.py:157} INFO - Started process (PID=20135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:21:25.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:21:25.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:25.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:21:25.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:21:25.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:25.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:21:25.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:25.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:21:26.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:21:56.354+0000] {processor.py:157} INFO - Started process (PID=20160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:21:56.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:21:56.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:56.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:21:56.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:21:56.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:56.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:21:56.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:56.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:21:56.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T23:22:26.879+0000] {processor.py:157} INFO - Started process (PID=20185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:22:26.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:22:26.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:26.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:22:26.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:22:26.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:26.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:22:26.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:26.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:22:26.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T23:22:57.332+0000] {processor.py:157} INFO - Started process (PID=20210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:22:57.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:22:57.334+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:57.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:22:57.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:22:57.362+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:57.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:22:57.374+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:57.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:22:57.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T23:23:27.839+0000] {processor.py:157} INFO - Started process (PID=20235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:23:27.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:23:27.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:27.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:23:27.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:23:27.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:27.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:23:27.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:27.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:23:27.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:23:58.308+0000] {processor.py:157} INFO - Started process (PID=20260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:23:58.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:23:58.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:58.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:23:58.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:23:58.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:58.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:23:58.353+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:58.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:23:58.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:24:28.768+0000] {processor.py:157} INFO - Started process (PID=20285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:24:28.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:24:28.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:28.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:24:28.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:24:28.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:28.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:24:28.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:28.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:24:28.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-20T23:24:59.259+0000] {processor.py:157} INFO - Started process (PID=20310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:24:59.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:24:59.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:59.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:24:59.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:24:59.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:59.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:24:59.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:59.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:24:59.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T23:25:29.664+0000] {processor.py:157} INFO - Started process (PID=20335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:25:29.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:25:29.667+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:25:29.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:25:29.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:25:29.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:25:29.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:25:29.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:25:29.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:25:29.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:26:00.152+0000] {processor.py:157} INFO - Started process (PID=20360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:26:00.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:26:00.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:00.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:26:00.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:26:00.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:00.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:26:00.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:00.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:26:00.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T23:26:30.563+0000] {processor.py:157} INFO - Started process (PID=20385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:26:30.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:26:30.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:30.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:26:30.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:26:30.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:30.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:26:30.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:30.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:26:30.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:27:01.076+0000] {processor.py:157} INFO - Started process (PID=20410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:27:01.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:27:01.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:01.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:27:01.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:27:01.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:01.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:27:01.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:01.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:27:01.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-20T23:27:31.586+0000] {processor.py:157} INFO - Started process (PID=20435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:27:31.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:27:31.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:31.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:27:31.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:27:31.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:31.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:27:31.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:31.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:27:31.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:28:02.030+0000] {processor.py:157} INFO - Started process (PID=20460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:28:02.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:28:02.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:02.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:28:02.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:28:02.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:02.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:28:02.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:02.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:28:02.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:28:32.437+0000] {processor.py:157} INFO - Started process (PID=20485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:28:32.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:28:32.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:32.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:28:32.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:28:32.465+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:32.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:28:32.475+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:32.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:28:32.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T23:29:02.910+0000] {processor.py:157} INFO - Started process (PID=20510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:29:02.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:29:02.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:02.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:29:02.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:29:02.944+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:02.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:29:02.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:02.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:29:02.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T23:29:33.329+0000] {processor.py:157} INFO - Started process (PID=20535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:29:33.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:29:33.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:33.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:29:33.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:29:33.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:33.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:29:33.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:33.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:29:33.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:30:03.691+0000] {processor.py:157} INFO - Started process (PID=20560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:30:03.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:30:03.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:03.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:30:03.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:30:03.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:03.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:30:03.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:03.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:30:03.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:30:34.167+0000] {processor.py:157} INFO - Started process (PID=20585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:30:34.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:30:34.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:34.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:30:34.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:30:34.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:34.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:30:34.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:34.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:30:34.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:31:04.671+0000] {processor.py:157} INFO - Started process (PID=20610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:31:04.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:31:04.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:04.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:31:04.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:31:04.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:04.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:31:04.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:04.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:31:04.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T23:31:35.197+0000] {processor.py:157} INFO - Started process (PID=20635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:31:35.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:31:35.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:35.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:31:35.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:31:35.229+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:35.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:31:35.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:35.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:31:35.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T23:32:05.661+0000] {processor.py:157} INFO - Started process (PID=20660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:32:05.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:32:05.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:05.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:32:05.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:32:05.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:05.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:32:05.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:05.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:32:05.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:32:36.072+0000] {processor.py:157} INFO - Started process (PID=20685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:32:36.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:32:36.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:36.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:32:36.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:32:36.115+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:36.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:32:36.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:36.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:32:36.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-20T23:33:06.518+0000] {processor.py:157} INFO - Started process (PID=20710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:33:06.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:33:06.522+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:06.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:33:06.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:33:06.551+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:06.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:33:06.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:06.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:33:06.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T23:33:37.028+0000] {processor.py:157} INFO - Started process (PID=20735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:33:37.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:33:37.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:37.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:33:37.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:33:37.058+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:37.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:33:37.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:37.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:33:37.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T23:34:07.523+0000] {processor.py:157} INFO - Started process (PID=20760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:34:07.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:34:07.525+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:07.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:34:07.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:34:07.554+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:07.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:34:07.564+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:07.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:34:07.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:34:37.939+0000] {processor.py:157} INFO - Started process (PID=20785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:34:37.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:34:37.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:37.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:34:37.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:34:37.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:37.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:34:37.978+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:37.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:34:37.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T23:35:08.402+0000] {processor.py:157} INFO - Started process (PID=20810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:35:08.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:35:08.404+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:08.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:35:08.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:35:08.430+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:08.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:35:08.443+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:08.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:35:08.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:35:38.985+0000] {processor.py:157} INFO - Started process (PID=20835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:35:38.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:35:38.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:38.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:35:39.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:35:39.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:39.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:35:39.049+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:39.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:35:39.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-20T23:36:09.504+0000] {processor.py:157} INFO - Started process (PID=20860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:36:09.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:36:09.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:09.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:36:09.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:36:09.533+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:09.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:36:09.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:09.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:36:09.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T23:36:39.934+0000] {processor.py:157} INFO - Started process (PID=20885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:36:39.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:36:39.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:39.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:36:39.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:36:39.965+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:39.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:36:39.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:39.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:36:39.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:37:10.328+0000] {processor.py:157} INFO - Started process (PID=20910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:37:10.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:37:10.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:10.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:37:10.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:37:10.357+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:10.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:37:10.369+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:10.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:37:10.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:37:40.697+0000] {processor.py:157} INFO - Started process (PID=20935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:37:40.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:37:40.700+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:40.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:37:40.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:37:40.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:40.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:37:40.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:40.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:37:40.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T23:38:11.172+0000] {processor.py:157} INFO - Started process (PID=20960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:38:11.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:38:11.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:11.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:38:11.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:38:11.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:11.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:38:11.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:11.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:38:11.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T23:38:41.628+0000] {processor.py:157} INFO - Started process (PID=20985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:38:41.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:38:41.632+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:41.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:38:41.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:38:41.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:41.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:38:41.671+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:41.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:38:41.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:39:12.130+0000] {processor.py:157} INFO - Started process (PID=21010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:39:12.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:39:12.133+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:12.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:39:12.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:39:12.162+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:12.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:39:12.171+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:12.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:39:12.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T23:39:42.646+0000] {processor.py:157} INFO - Started process (PID=21035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:39:42.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:39:42.650+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:42.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:39:42.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:39:42.680+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:42.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:39:42.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:42.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:39:42.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T23:40:13.074+0000] {processor.py:157} INFO - Started process (PID=21060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:40:13.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:40:13.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:13.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:40:13.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:40:13.101+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:13.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:40:13.111+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:13.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:40:13.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T23:40:43.469+0000] {processor.py:157} INFO - Started process (PID=21085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:40:43.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:40:43.472+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:43.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:40:43.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:40:43.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:43.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:40:43.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:43.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:40:43.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T23:41:13.959+0000] {processor.py:157} INFO - Started process (PID=21110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:41:13.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:41:13.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:13.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:41:13.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:41:13.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:13.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:41:13.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:13.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:41:14.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:41:44.373+0000] {processor.py:157} INFO - Started process (PID=21135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:41:44.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:41:44.375+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:44.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:41:44.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:41:44.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:44.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:41:44.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:44.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:41:44.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-20T23:42:14.811+0000] {processor.py:157} INFO - Started process (PID=21160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:42:14.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:42:14.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:14.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:42:14.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:42:14.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:14.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:42:14.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:14.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:42:14.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-20T23:42:45.217+0000] {processor.py:157} INFO - Started process (PID=21185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:42:45.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:42:45.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:45.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:42:45.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:42:45.252+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:45.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:42:45.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:45.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:42:45.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T23:43:15.591+0000] {processor.py:157} INFO - Started process (PID=21210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:43:15.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:43:15.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:15.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:43:15.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:43:15.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:15.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:43:15.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:15.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:43:15.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T23:43:46.029+0000] {processor.py:157} INFO - Started process (PID=21235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:43:46.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:43:46.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:46.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:43:46.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:43:46.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:46.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:43:46.067+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:46.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:43:46.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-20T23:44:16.466+0000] {processor.py:157} INFO - Started process (PID=21260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:44:16.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:44:16.469+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:16.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:44:16.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:44:16.499+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:16.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:44:16.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:16.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:44:16.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:44:46.945+0000] {processor.py:157} INFO - Started process (PID=21285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:44:46.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:44:46.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:46.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:44:46.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:44:46.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:46.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:44:46.988+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:46.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:44:46.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:45:17.404+0000] {processor.py:157} INFO - Started process (PID=21310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:45:17.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:45:17.405+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:17.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:45:17.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:45:17.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:17.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:45:17.435+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:17.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:45:17.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-20T23:45:47.800+0000] {processor.py:157} INFO - Started process (PID=21335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:45:47.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:45:47.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:47.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:45:47.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:45:47.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:47.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:45:47.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:47.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:45:47.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-20T23:46:18.277+0000] {processor.py:157} INFO - Started process (PID=21360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:46:18.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:46:18.280+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:18.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:46:18.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:46:18.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:18.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:46:18.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:18.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:46:18.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:46:48.756+0000] {processor.py:157} INFO - Started process (PID=21385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:46:48.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:46:48.760+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:48.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:46:48.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:46:48.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:48.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:46:48.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:48.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:46:48.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:47:19.214+0000] {processor.py:157} INFO - Started process (PID=21410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:47:19.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:47:19.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:19.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:47:19.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:47:19.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:19.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:47:19.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:19.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:47:19.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T23:47:49.642+0000] {processor.py:157} INFO - Started process (PID=21435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:47:49.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:47:49.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:49.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:47:49.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:47:49.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:49.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:47:49.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:49.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:47:49.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T23:48:20.199+0000] {processor.py:157} INFO - Started process (PID=21460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:48:20.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:48:20.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:20.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:48:20.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:48:20.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:20.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:48:20.243+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:20.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:48:20.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T23:48:50.574+0000] {processor.py:157} INFO - Started process (PID=21485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:48:50.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:48:50.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:50.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:48:50.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:48:50.596+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:50.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:48:50.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:50.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:48:50.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-20T23:49:21.094+0000] {processor.py:157} INFO - Started process (PID=21510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:49:21.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:49:21.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:21.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:49:21.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:49:21.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:21.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:49:21.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:21.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:49:21.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T23:49:51.606+0000] {processor.py:157} INFO - Started process (PID=21535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:49:51.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:49:51.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:51.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:49:51.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:49:51.635+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:51.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:49:51.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:51.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:49:51.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T23:50:22.129+0000] {processor.py:157} INFO - Started process (PID=21560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:50:22.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:50:22.132+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:22.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:50:22.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:50:22.160+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:22.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:50:22.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:22.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:50:22.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:50:52.600+0000] {processor.py:157} INFO - Started process (PID=21585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:50:52.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:50:52.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:52.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:50:52.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:50:52.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:52.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:50:52.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:52.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:50:52.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:51:23.065+0000] {processor.py:157} INFO - Started process (PID=21610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:51:23.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:51:23.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:23.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:51:23.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:51:23.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:23.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:51:23.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:23.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:51:23.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-20T23:51:53.576+0000] {processor.py:157} INFO - Started process (PID=21635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:51:53.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:51:53.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:53.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:51:53.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:51:53.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:53.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:51:53.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:53.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:51:53.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-20T23:52:23.984+0000] {processor.py:157} INFO - Started process (PID=21660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:52:23.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:52:23.988+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:23.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:52:24.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:52:24.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:24.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:52:24.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:24.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:52:24.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-20T23:52:54.489+0000] {processor.py:157} INFO - Started process (PID=21685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:52:54.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:52:54.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:54.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:52:54.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:52:54.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:54.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:52:54.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:54.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:52:54.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-20T23:53:24.981+0000] {processor.py:157} INFO - Started process (PID=21710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:53:24.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:53:24.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:24.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:53:25.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:53:25.014+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:25.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:53:25.027+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:25.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:53:25.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-20T23:53:55.477+0000] {processor.py:157} INFO - Started process (PID=21735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:53:55.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:53:55.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:55.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:53:55.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:53:55.506+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:55.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:53:55.519+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:55.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:53:55.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-20T23:54:25.909+0000] {processor.py:157} INFO - Started process (PID=21760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:54:25.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:54:25.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:25.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:54:25.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:54:25.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:25.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:54:25.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:25.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:54:25.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-20T23:54:56.344+0000] {processor.py:157} INFO - Started process (PID=21785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:54:56.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:54:56.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:56.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:54:56.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:54:56.375+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:56.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:54:56.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:56.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:54:56.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-20T23:55:26.875+0000] {processor.py:157} INFO - Started process (PID=21810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:55:26.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-20T23:55:26.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:55:26.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:55:26.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-20T23:55:26.902+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:55:26.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:55:26.915+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:55:26.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-20T23:55:26.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
