[2024-07-20T00:00:16.308+0000] {processor.py:157} INFO - Started process (PID=85057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:00:16.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:00:16.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:16.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:00:16.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:00:16.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:16.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:00:16.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:16.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:00:16.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T00:00:46.879+0000] {processor.py:157} INFO - Started process (PID=85082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:00:46.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:00:46.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:46.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:00:46.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:00:46.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:46.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:00:46.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:00:46.923+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:00:46.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T00:01:17.331+0000] {processor.py:157} INFO - Started process (PID=85107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:01:17.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:01:17.337+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:17.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:01:17.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:01:17.365+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:17.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:01:17.374+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:17.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:01:17.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T00:01:47.802+0000] {processor.py:157} INFO - Started process (PID=85132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:01:47.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:01:47.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:47.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:01:47.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:01:47.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:47.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:01:47.844+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:01:47.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:01:47.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T00:02:18.254+0000] {processor.py:157} INFO - Started process (PID=85157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:02:18.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:02:18.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:18.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:02:18.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:02:18.280+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:18.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:02:18.289+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:18.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:02:18.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-20T00:02:48.666+0000] {processor.py:157} INFO - Started process (PID=85182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:02:48.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:02:48.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:48.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:02:48.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:02:48.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:48.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:02:48.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:02:48.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:02:48.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T00:03:19.114+0000] {processor.py:157} INFO - Started process (PID=85207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:03:19.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:03:19.121+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:19.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:03:19.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:03:19.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:19.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:03:19.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:19.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:03:19.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T00:03:49.600+0000] {processor.py:157} INFO - Started process (PID=85232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:03:49.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:03:49.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:49.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:03:49.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:03:49.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:49.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:03:49.651+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:03:49.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:03:49.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T00:04:20.077+0000] {processor.py:157} INFO - Started process (PID=85257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:04:20.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:04:20.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:20.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:04:20.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:04:20.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:20.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:04:20.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:20.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:04:20.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T00:04:50.534+0000] {processor.py:157} INFO - Started process (PID=85282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:04:50.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:04:50.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:50.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:04:50.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:04:50.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:50.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:04:50.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:04:50.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:04:50.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T00:05:21.084+0000] {processor.py:157} INFO - Started process (PID=85307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:05:21.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:05:21.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:21.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:05:21.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:05:21.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:21.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:05:21.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:21.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:05:21.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T00:05:51.560+0000] {processor.py:157} INFO - Started process (PID=85332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:05:51.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:05:51.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:51.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:05:51.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:05:51.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:51.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:05:51.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:05:51.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:05:51.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T00:06:22.002+0000] {processor.py:157} INFO - Started process (PID=85357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:06:22.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:06:22.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:22.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:06:22.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:06:22.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:22.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:06:22.046+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:22.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:06:22.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T00:06:52.433+0000] {processor.py:157} INFO - Started process (PID=85382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:06:52.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:06:52.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:52.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:06:52.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:06:52.465+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:52.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:06:52.474+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:06:52.474+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:06:52.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T00:07:22.922+0000] {processor.py:157} INFO - Started process (PID=85407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:07:22.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:07:22.926+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:22.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:07:22.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:07:22.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:22.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:07:22.963+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:22.963+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:07:22.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T00:07:53.686+0000] {processor.py:157} INFO - Started process (PID=85432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:07:53.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:07:53.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:53.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:07:53.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:07:53.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:53.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:07:53.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:07:53.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:07:53.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T00:23:47.835+0000] {processor.py:157} INFO - Started process (PID=85457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:23:47.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:23:47.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:23:47.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:23:47.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:23:47.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:23:47.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:23:47.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:23:47.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:23:47.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-20T00:24:18.416+0000] {processor.py:157} INFO - Started process (PID=85484) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:24:18.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:24:18.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:24:18.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:24:18.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:24:18.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:24:18.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:24:18.473+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:24:18.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:24:18.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T00:40:32.893+0000] {processor.py:157} INFO - Started process (PID=85509) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:40:32.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:40:32.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:40:32.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:40:32.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:40:32.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:40:32.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:40:32.936+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:40:32.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-19T00:30:00+00:00, run_after=2024-07-20T00:30:00+00:00
[2024-07-20T00:40:32.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T00:41:03.339+0000] {processor.py:157} INFO - Started process (PID=85929) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:41:03.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:41:03.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:03.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:41:03.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:41:03.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:03.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:41:03.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T00:41:33.813+0000] {processor.py:157} INFO - Started process (PID=85954) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:41:33.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:41:33.820+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:33.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:41:33.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:41:33.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:41:33.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:41:33.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T00:42:04.209+0000] {processor.py:157} INFO - Started process (PID=85979) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:42:04.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:42:04.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:04.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:42:04.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:42:04.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:04.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:42:04.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T00:42:34.576+0000] {processor.py:157} INFO - Started process (PID=86004) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:42:34.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:42:34.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:34.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:42:34.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:42:34.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:42:34.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:42:34.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T00:43:04.966+0000] {processor.py:157} INFO - Started process (PID=86032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:43:04.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:43:04.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:43:04.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:43:04.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:43:05.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:43:05.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:43:05.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:43:05.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T00:43:05.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T00:59:29.762+0000] {processor.py:157} INFO - Started process (PID=86058) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:59:29.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T00:59:29.767+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:59:29.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:59:29.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T00:59:29.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:59:29.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T00:59:29.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T00:59:29.833+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T00:59:29.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-20T01:07:59.218+0000] {processor.py:157} INFO - Started process (PID=86084) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:07:59.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:07:59.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:07:59.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:07:59.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:07:59.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:07:59.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:07:59.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:07:59.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:07:59.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T01:08:29.694+0000] {processor.py:157} INFO - Started process (PID=86500) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:08:29.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:08:29.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:08:29.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:08:29.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:08:29.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:08:29.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:08:29.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:08:29.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:08:29.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T01:24:23.427+0000] {processor.py:157} INFO - Started process (PID=86527) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:24:23.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:24:23.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:23.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:24:23.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:24:23.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:23.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:24:23.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:23.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:24:23.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T01:24:53.867+0000] {processor.py:157} INFO - Started process (PID=86552) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:24:53.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:24:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:53.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:24:53.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:24:53.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:53.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:24:53.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:24:53.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:24:53.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T01:25:24.380+0000] {processor.py:157} INFO - Started process (PID=86577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:25:24.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:25:24.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:24.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:25:24.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:25:24.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:24.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:25:24.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:24.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:25:24.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T01:25:54.852+0000] {processor.py:157} INFO - Started process (PID=86602) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:25:54.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:25:54.855+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:54.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:25:54.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:25:54.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:54.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:25:54.900+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:25:54.900+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:25:54.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T01:26:25.290+0000] {processor.py:157} INFO - Started process (PID=86627) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:26:25.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:26:25.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:26:25.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:26:25.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:26:25.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:26:25.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:26:25.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:26:25.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:26:25.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T01:43:02.853+0000] {processor.py:157} INFO - Started process (PID=86654) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:43:02.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:43:02.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:02.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:43:02.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:43:02.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:02.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:43:02.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:02.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:43:02.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-20T01:43:33.504+0000] {processor.py:157} INFO - Started process (PID=86679) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:43:33.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:43:33.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:33.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:43:33.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:43:33.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:33.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:43:33.549+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:43:33.549+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:43:33.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T01:44:03.925+0000] {processor.py:157} INFO - Started process (PID=86704) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:44:03.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:44:03.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:03.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:44:03.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:44:03.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:03.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:44:03.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:03.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:44:03.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T01:44:34.409+0000] {processor.py:157} INFO - Started process (PID=86729) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:44:34.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:44:34.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:34.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:44:34.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:44:34.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:34.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:44:34.461+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:44:34.460+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:44:34.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T01:45:04.930+0000] {processor.py:157} INFO - Started process (PID=86754) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:45:04.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:45:04.944+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:45:04.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:45:04.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:45:04.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:45:04.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:45:04.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:45:04.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:45:05.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T01:59:14.212+0000] {processor.py:157} INFO - Started process (PID=86779) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:59:14.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:59:14.216+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:14.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:59:14.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:59:14.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:14.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:59:14.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:14.257+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:59:14.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T01:59:44.679+0000] {processor.py:157} INFO - Started process (PID=86806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:59:44.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T01:59:44.683+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:44.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:59:44.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T01:59:44.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:44.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T01:59:44.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T01:59:44.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T01:59:44.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T02:00:15.224+0000] {processor.py:157} INFO - Started process (PID=86831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:00:15.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:00:15.226+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:15.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:00:15.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:00:15.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:15.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:00:15.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:15.265+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:00:15.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T02:00:45.637+0000] {processor.py:157} INFO - Started process (PID=86856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:00:45.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:00:45.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:45.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:00:45.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:00:45.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:45.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:00:45.678+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:00:45.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:00:45.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T02:01:16.141+0000] {processor.py:157} INFO - Started process (PID=86881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:01:16.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:01:16.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:16.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:01:16.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:01:16.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:16.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:01:16.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:16.182+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:01:16.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T02:01:46.690+0000] {processor.py:157} INFO - Started process (PID=86906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:01:46.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:01:46.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:46.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:01:46.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:01:46.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:46.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:01:46.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:01:46.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:01:46.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T02:02:17.149+0000] {processor.py:157} INFO - Started process (PID=86931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:02:17.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:02:17.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:02:17.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:02:17.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:02:17.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:02:17.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:02:17.192+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:02:17.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:02:17.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T02:08:55.508+0000] {processor.py:157} INFO - Started process (PID=86956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:08:55.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:08:55.513+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:08:55.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:08:55.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:08:55.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:08:55.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:08:55.556+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:08:55.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:08:55.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T02:09:26.049+0000] {processor.py:157} INFO - Started process (PID=86981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:09:26.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:09:26.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:26.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:09:26.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:09:26.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:26.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:09:26.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:26.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:09:26.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T02:09:56.606+0000] {processor.py:157} INFO - Started process (PID=87006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:09:56.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:09:56.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:56.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:09:56.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:09:56.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:56.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:09:56.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:09:56.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:09:56.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T02:10:27.025+0000] {processor.py:157} INFO - Started process (PID=87031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:10:27.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:10:27.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:27.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:10:27.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:10:27.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:27.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:10:27.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:27.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:10:27.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T02:10:57.492+0000] {processor.py:157} INFO - Started process (PID=87056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:10:57.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:10:57.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:57.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:10:57.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:10:57.526+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:57.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:10:57.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:10:57.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:10:57.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T02:11:27.968+0000] {processor.py:157} INFO - Started process (PID=87081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:11:27.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:11:27.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:27.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:11:27.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:11:28.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:28.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:11:28.011+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:28.011+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:11:28.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T02:11:58.461+0000] {processor.py:157} INFO - Started process (PID=87106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:11:58.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:11:58.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:58.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:11:58.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:11:58.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:58.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:11:58.503+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:11:58.503+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:11:58.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T02:12:28.869+0000] {processor.py:157} INFO - Started process (PID=87131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:12:28.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:12:28.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:12:28.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:12:28.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:12:28.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:12:28.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:12:28.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:12:28.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:12:28.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T02:29:53.960+0000] {processor.py:157} INFO - Started process (PID=87158) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:29:53.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:29:53.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:29:53.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:29:53.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:29:54.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:29:54.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:29:54.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:29:54.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:29:54.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T02:30:24.436+0000] {processor.py:157} INFO - Started process (PID=87183) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:30:24.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:30:24.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:24.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:30:24.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:30:24.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:24.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:30:24.474+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:24.474+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:30:24.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T02:30:54.862+0000] {processor.py:157} INFO - Started process (PID=87208) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:30:54.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:30:54.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:54.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:30:54.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:30:54.892+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:54.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:30:54.902+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:30:54.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:30:54.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T02:31:25.355+0000] {processor.py:157} INFO - Started process (PID=87233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:31:25.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:31:25.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:25.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:31:25.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:31:25.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:25.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:31:25.409+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:25.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:31:25.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T02:31:55.762+0000] {processor.py:157} INFO - Started process (PID=87258) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:31:55.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:31:55.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:55.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:31:55.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:31:55.792+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:55.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:31:55.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:31:55.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:31:55.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T02:32:26.246+0000] {processor.py:157} INFO - Started process (PID=87283) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:32:26.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:32:26.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:26.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:32:26.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:32:26.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:26.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:32:26.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:26.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:32:26.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T02:32:56.698+0000] {processor.py:157} INFO - Started process (PID=87308) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:32:56.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:32:56.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:56.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:32:56.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:32:56.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:56.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:32:56.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:32:56.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:32:56.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T02:33:27.155+0000] {processor.py:157} INFO - Started process (PID=87333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:33:27.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:33:27.160+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:27.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:33:27.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:33:27.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:27.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:33:27.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:27.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:33:27.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T02:33:57.617+0000] {processor.py:157} INFO - Started process (PID=87358) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:33:57.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:33:57.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:57.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:33:57.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:33:57.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:57.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:33:57.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:33:57.657+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:33:57.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T02:34:28.054+0000] {processor.py:157} INFO - Started process (PID=87383) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:34:28.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:34:28.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:28.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:34:28.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:34:28.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:28.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:34:28.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:28.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:34:28.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T02:34:58.557+0000] {processor.py:157} INFO - Started process (PID=87408) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:34:58.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:34:58.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:58.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:34:58.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:34:58.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:58.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:34:58.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:34:58.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:34:58.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T02:35:29.009+0000] {processor.py:157} INFO - Started process (PID=87433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:35:29.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:35:29.014+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:29.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:35:29.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:35:29.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:29.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:35:29.063+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:29.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:35:29.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T02:35:59.492+0000] {processor.py:157} INFO - Started process (PID=87458) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:35:59.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:35:59.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:59.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:35:59.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:35:59.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:59.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:35:59.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:35:59.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:35:59.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T02:36:29.908+0000] {processor.py:157} INFO - Started process (PID=87483) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:36:29.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:36:29.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:36:29.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:36:29.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:36:29.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:36:29.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:36:29.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:36:29.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:36:29.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T02:37:00.341+0000] {processor.py:157} INFO - Started process (PID=87508) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:37:00.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:37:00.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:00.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:37:00.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:37:00.371+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:00.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:37:00.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:00.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:37:00.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T02:37:30.751+0000] {processor.py:157} INFO - Started process (PID=87533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:37:30.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:37:30.755+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:30.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:37:30.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:37:30.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:30.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:37:30.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:37:30.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:37:30.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T02:43:52.396+0000] {processor.py:157} INFO - Started process (PID=87560) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:43:52.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:43:52.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:43:52.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:43:52.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:43:52.443+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:43:52.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:43:52.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:43:52.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:43:52.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-20T02:44:23.082+0000] {processor.py:157} INFO - Started process (PID=87585) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:44:23.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:44:23.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:44:23.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:44:23.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:44:23.112+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:44:23.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:44:23.122+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:44:23.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:44:23.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T02:51:04.587+0000] {processor.py:157} INFO - Started process (PID=87610) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:51:04.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:51:04.590+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:04.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:51:04.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:51:04.632+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:04.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:51:04.651+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:04.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:51:04.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T02:51:35.077+0000] {processor.py:157} INFO - Started process (PID=87635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:51:35.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T02:51:35.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:35.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:51:35.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T02:51:35.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:35.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T02:51:35.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T02:51:35.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T02:51:35.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T03:08:30.704+0000] {processor.py:157} INFO - Started process (PID=87662) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:08:30.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:08:30.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:08:30.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:08:30.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:08:30.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:08:30.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:08:30.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:08:30.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:08:30.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T03:09:01.114+0000] {processor.py:157} INFO - Started process (PID=87687) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:09:01.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:09:01.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:09:01.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:09:01.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:09:01.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:09:01.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:09:01.181+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:09:01.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:09:01.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T03:10:28.882+0000] {processor.py:157} INFO - Started process (PID=87712) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:10:28.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:10:28.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:10:28.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:10:28.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:10:28.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:10:28.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:10:28.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:10:28.923+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:10:28.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T03:25:56.866+0000] {processor.py:157} INFO - Started process (PID=87737) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:25:56.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:25:56.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:25:56.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:25:56.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:25:56.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:25:56.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:25:56.957+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:25:56.956+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:25:56.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-20T03:26:27.563+0000] {processor.py:157} INFO - Started process (PID=87762) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:26:27.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:26:27.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:26:27.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:26:27.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:26:27.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:26:27.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:26:27.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:26:27.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:26:27.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T03:27:25.786+0000] {processor.py:157} INFO - Started process (PID=87789) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:27:25.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:27:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:27:25.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:27:25.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:27:25.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:27:25.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:27:25.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:27:25.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:27:25.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T03:42:54.521+0000] {processor.py:157} INFO - Started process (PID=87814) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:42:54.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:42:54.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:42:54.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:42:54.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:42:54.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:42:54.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:42:54.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:42:54.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:42:54.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-20T03:43:25.139+0000] {processor.py:157} INFO - Started process (PID=87839) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:43:25.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:43:25.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:25.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:43:25.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:43:25.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:25.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:43:25.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:25.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:43:25.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-20T03:43:55.648+0000] {processor.py:157} INFO - Started process (PID=87864) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:43:55.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:43:55.651+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:55.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:43:55.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:43:55.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:55.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:43:55.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:43:55.696+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:43:55.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T03:44:26.142+0000] {processor.py:157} INFO - Started process (PID=87889) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:44:26.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:44:26.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:26.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:44:26.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:44:26.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:26.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:44:26.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:26.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:44:26.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T03:44:56.629+0000] {processor.py:157} INFO - Started process (PID=87914) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:44:56.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:44:56.632+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:56.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:44:56.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:44:56.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:56.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:44:56.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:44:56.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:44:56.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T03:45:27.074+0000] {processor.py:157} INFO - Started process (PID=87939) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:45:27.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:45:27.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:45:27.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:45:27.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:45:27.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:45:27.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:45:27.115+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:45:27.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:45:27.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T03:53:25.176+0000] {processor.py:157} INFO - Started process (PID=87966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:53:25.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:53:25.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:25.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:53:25.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:53:25.227+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:25.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:53:25.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:25.248+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:53:25.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-20T03:53:55.765+0000] {processor.py:157} INFO - Started process (PID=87991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:53:55.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:53:55.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:55.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:53:55.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:53:55.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:55.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:53:55.803+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:53:55.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:53:55.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T03:54:26.292+0000] {processor.py:157} INFO - Started process (PID=88016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:54:26.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:54:26.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:26.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:54:26.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:54:26.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:26.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:54:26.337+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:26.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:54:26.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T03:54:56.776+0000] {processor.py:157} INFO - Started process (PID=88041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:54:56.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:54:56.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:56.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:54:56.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:54:56.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:56.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:54:56.817+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:54:56.817+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:54:56.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T03:55:27.181+0000] {processor.py:157} INFO - Started process (PID=88066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:55:27.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:55:27.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:27.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:55:27.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:55:27.211+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:27.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:55:27.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:27.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:55:27.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T03:55:57.643+0000] {processor.py:157} INFO - Started process (PID=88091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:55:57.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:55:57.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:57.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:55:57.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:55:57.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:57.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:55:57.682+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:55:57.682+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:55:57.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T03:56:28.112+0000] {processor.py:157} INFO - Started process (PID=88116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:56:28.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:56:28.115+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:28.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:56:28.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:56:28.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:28.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:56:28.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:28.155+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:56:28.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T03:56:58.583+0000] {processor.py:157} INFO - Started process (PID=88141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:56:58.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:56:58.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:58.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:56:58.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:56:58.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:58.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:56:58.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:56:58.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:56:58.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T03:57:29.088+0000] {processor.py:157} INFO - Started process (PID=88166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:57:29.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:57:29.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:29.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:57:29.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:57:29.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:29.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:57:29.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:29.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:57:29.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T03:57:59.531+0000] {processor.py:157} INFO - Started process (PID=88191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:57:59.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:57:59.535+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:59.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:57:59.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:57:59.565+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:59.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:57:59.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:57:59.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:57:59.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T03:58:30.040+0000] {processor.py:157} INFO - Started process (PID=88216) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:58:30.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:58:30.044+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:58:30.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:58:30.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:58:30.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:58:30.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:58:30.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:58:30.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:58:30.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T03:59:00.575+0000] {processor.py:157} INFO - Started process (PID=88241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:59:00.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:59:00.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:00.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:59:00.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:59:00.607+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:00.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:59:00.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:00.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:59:00.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T03:59:31.063+0000] {processor.py:157} INFO - Started process (PID=88266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:59:31.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T03:59:31.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:31.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:59:31.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T03:59:31.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:31.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T03:59:31.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T03:59:31.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T03:59:31.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T04:00:01.572+0000] {processor.py:157} INFO - Started process (PID=88291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:00:01.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:00:01.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:01.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:00:01.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:00:01.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:01.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:00:01.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:01.617+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:00:01.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T04:00:31.962+0000] {processor.py:157} INFO - Started process (PID=88316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:00:31.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:00:31.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:31.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:00:31.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:00:31.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:31.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:00:32.009+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:00:32.009+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:00:32.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T04:01:02.386+0000] {processor.py:157} INFO - Started process (PID=88341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:01:02.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:01:02.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:02.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:01:02.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:01:02.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:02.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:01:02.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:02.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:01:02.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T04:01:32.879+0000] {processor.py:157} INFO - Started process (PID=88366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:01:32.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:01:32.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:32.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:01:32.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:01:32.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:32.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:01:32.924+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:01:32.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:01:32.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:02:03.287+0000] {processor.py:157} INFO - Started process (PID=88391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:02:03.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:02:03.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:03.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:02:03.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:02:03.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:03.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:02:03.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:03.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:02:03.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:02:33.738+0000] {processor.py:157} INFO - Started process (PID=88416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:02:33.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:02:33.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:33.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:02:33.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:02:33.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:33.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:02:33.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:02:33.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:02:33.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:03:04.176+0000] {processor.py:157} INFO - Started process (PID=88441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:03:04.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:03:04.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:04.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:03:04.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:03:04.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:04.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:03:04.219+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:04.219+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:03:04.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:03:34.620+0000] {processor.py:157} INFO - Started process (PID=88466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:03:34.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:03:34.623+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:34.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:03:34.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:03:34.650+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:34.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:03:34.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:03:34.660+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:03:34.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T04:04:05.062+0000] {processor.py:157} INFO - Started process (PID=88491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:04:05.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:04:05.067+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:05.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:04:05.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:04:05.097+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:05.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:04:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:05.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:04:05.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T04:04:35.524+0000] {processor.py:157} INFO - Started process (PID=88516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:04:35.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:04:35.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:35.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:04:35.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:04:35.556+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:35.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:04:35.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:04:35.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:04:35.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:05:06.039+0000] {processor.py:157} INFO - Started process (PID=88541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:05:06.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:05:06.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:06.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:05:06.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:05:06.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:06.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:05:06.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:06.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:05:06.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:05:36.488+0000] {processor.py:157} INFO - Started process (PID=88566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:05:36.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:05:36.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:36.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:05:36.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:05:36.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:36.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:05:36.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:05:36.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:05:36.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T04:06:06.896+0000] {processor.py:157} INFO - Started process (PID=88591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:06:06.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:06:06.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:06.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:06:06.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:06:06.924+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:06.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:06:06.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:06.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:06:06.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T04:06:37.392+0000] {processor.py:157} INFO - Started process (PID=88616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:06:37.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:06:37.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:37.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:06:37.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:06:37.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:37.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:06:37.435+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:06:37.435+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:06:37.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:07:07.900+0000] {processor.py:157} INFO - Started process (PID=88641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:07:07.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:07:07.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:07.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:07:07.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:07:07.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:07.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:07:07.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:07.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:07:07.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:07:38.324+0000] {processor.py:157} INFO - Started process (PID=88666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:07:38.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:07:38.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:38.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:07:38.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:07:38.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:38.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:07:38.365+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:07:38.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:07:38.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:08:08.794+0000] {processor.py:157} INFO - Started process (PID=88691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:08:08.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:08:08.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:08.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:08:08.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:08:08.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:08.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:08:08.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:08.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:08:08.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:08:39.305+0000] {processor.py:157} INFO - Started process (PID=88716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:08:39.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:08:39.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:39.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:08:39.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:08:39.335+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:39.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:08:39.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:08:39.345+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:08:39.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:09:09.795+0000] {processor.py:157} INFO - Started process (PID=88741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:09:09.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:09:09.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:09:09.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:09:09.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:09:09.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:09:09.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:09:09.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:09:09.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:09:09.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:16:17.797+0000] {processor.py:157} INFO - Started process (PID=88766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:16:17.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:16:17.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:17.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:16:17.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:16:17.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:17.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:16:17.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:17.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:16:17.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-20T04:16:48.487+0000] {processor.py:157} INFO - Started process (PID=88793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:16:48.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:16:48.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:48.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:16:48.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:16:48.533+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:48.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:16:48.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:16:48.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:16:48.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T04:17:18.993+0000] {processor.py:157} INFO - Started process (PID=88818) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:17:18.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:17:18.998+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:18.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:17:19.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:17:19.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:19.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:17:19.039+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:19.039+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:17:19.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T04:17:49.395+0000] {processor.py:157} INFO - Started process (PID=88843) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:17:49.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:17:49.400+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:49.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:17:49.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:17:49.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:49.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:17:49.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:17:49.452+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:17:49.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T04:18:19.868+0000] {processor.py:157} INFO - Started process (PID=88868) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:18:19.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:18:19.870+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:19.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:18:19.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:18:19.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:19.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:18:19.906+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:19.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:18:19.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T04:18:50.312+0000] {processor.py:157} INFO - Started process (PID=88893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:18:50.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:18:50.316+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:50.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:18:50.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:18:50.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:50.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:18:50.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:18:50.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:18:50.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:19:20.686+0000] {processor.py:157} INFO - Started process (PID=88918) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:19:20.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:19:20.688+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:20.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:19:20.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:19:20.714+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:20.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:19:20.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:20.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:19:20.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T04:19:51.084+0000] {processor.py:157} INFO - Started process (PID=88943) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:19:51.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:19:51.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:51.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:19:51.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:19:51.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:51.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:19:51.126+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:19:51.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:19:51.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:20:21.510+0000] {processor.py:157} INFO - Started process (PID=88968) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:20:21.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:20:21.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:21.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:20:21.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:20:21.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:21.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:20:21.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:21.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:20:21.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:20:51.971+0000] {processor.py:157} INFO - Started process (PID=88993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:20:51.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:20:51.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:51.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:20:51.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:20:52.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:52.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:20:52.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:20:52.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:20:52.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:21:22.409+0000] {processor.py:157} INFO - Started process (PID=89018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:21:22.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:21:22.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:22.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:21:22.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:21:22.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:22.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:21:22.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:22.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:21:22.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T04:21:52.821+0000] {processor.py:157} INFO - Started process (PID=89043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:21:52.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:21:52.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:52.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:21:52.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:21:52.853+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:52.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:21:52.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:21:52.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:21:52.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:22:23.185+0000] {processor.py:157} INFO - Started process (PID=89068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:22:23.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:22:23.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:23.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:22:23.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:22:23.214+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:23.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:22:23.224+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:23.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:22:23.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T04:22:53.536+0000] {processor.py:157} INFO - Started process (PID=89093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:22:53.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:22:53.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:53.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:22:53.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:22:53.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:53.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:22:53.579+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:22:53.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:22:53.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:23:23.936+0000] {processor.py:157} INFO - Started process (PID=89118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:23:23.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:23:23.939+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:23.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:23:23.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:23:23.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:23.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:23:23.980+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:23.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:23:23.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T04:23:54.319+0000] {processor.py:157} INFO - Started process (PID=89143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:23:54.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:23:54.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:54.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:23:54.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:23:54.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:54.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:23:54.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:23:54.366+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:23:54.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:24:24.746+0000] {processor.py:157} INFO - Started process (PID=89168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:24:24.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:24:24.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:24.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:24:24.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:24:24.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:24.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:24:24.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:24.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:24:24.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:24:55.179+0000] {processor.py:157} INFO - Started process (PID=89193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:24:55.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:24:55.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:55.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:24:55.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:24:55.211+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:55.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:24:55.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:24:55.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:24:55.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:25:25.566+0000] {processor.py:157} INFO - Started process (PID=89218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:25:25.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:25:25.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:25.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:25:25.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:25:25.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:25.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:25:25.607+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:25.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:25:25.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T04:25:55.984+0000] {processor.py:157} INFO - Started process (PID=89243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:25:55.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:25:55.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:55.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:25:56.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:25:56.019+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:56.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:25:56.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:25:56.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:25:56.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T04:26:26.451+0000] {processor.py:157} INFO - Started process (PID=89268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:26:26.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:26:26.454+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:26.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:26:26.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:26:26.483+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:26.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:26:26.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:26.497+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:26:26.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:26:56.857+0000] {processor.py:157} INFO - Started process (PID=89293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:26:56.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:26:56.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:56.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:26:56.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:26:56.890+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:56.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:26:56.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:26:56.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:26:56.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:27:27.317+0000] {processor.py:157} INFO - Started process (PID=89318) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:27:27.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:27:27.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:27.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:27:27.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:27:27.346+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:27.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:27:27.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:27.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:27:27.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T04:27:57.747+0000] {processor.py:157} INFO - Started process (PID=89343) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:27:57.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:27:57.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:57.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:27:57.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:27:57.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:57.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:27:57.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:27:57.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:27:57.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T04:28:28.213+0000] {processor.py:157} INFO - Started process (PID=89368) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:28:28.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:28:28.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:28.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:28:28.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:28:28.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:28.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:28:28.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:28.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:28:28.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T04:28:58.661+0000] {processor.py:157} INFO - Started process (PID=89393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:28:58.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:28:58.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:58.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:28:58.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:28:58.689+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:58.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:28:58.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:28:58.698+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:28:58.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T04:29:29.070+0000] {processor.py:157} INFO - Started process (PID=89418) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:29:29.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:29:29.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:29.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:29:29.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:29:29.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:29.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:29:29.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:29.108+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:29:29.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:29:59.467+0000] {processor.py:157} INFO - Started process (PID=89443) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:29:59.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:29:59.472+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:59.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:29:59.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:29:59.500+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:59.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:29:59.511+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:29:59.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:29:59.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:30:29.933+0000] {processor.py:157} INFO - Started process (PID=89468) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:30:29.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:30:29.936+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:30:29.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:30:29.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:30:29.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:30:29.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:30:29.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:30:29.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:30:29.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:31:00.377+0000] {processor.py:157} INFO - Started process (PID=89493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:31:00.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:31:00.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:00.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:31:00.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:31:00.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:00.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:31:00.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:00.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:31:00.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:31:30.786+0000] {processor.py:157} INFO - Started process (PID=89518) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:31:30.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:31:30.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:30.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:31:30.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:31:30.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:30.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:31:30.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:31:30.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:31:30.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T04:32:01.213+0000] {processor.py:157} INFO - Started process (PID=89543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:32:01.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:32:01.218+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:01.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:32:01.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:32:01.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:01.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:32:01.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:01.257+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:32:01.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:32:31.681+0000] {processor.py:157} INFO - Started process (PID=89568) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:32:31.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:32:31.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:31.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:32:31.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:32:31.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:31.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:32:31.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:32:31.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:32:31.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:33:02.127+0000] {processor.py:157} INFO - Started process (PID=89593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:33:02.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:33:02.131+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:02.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:33:02.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:33:02.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:02.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:33:02.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:02.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:33:02.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:33:32.569+0000] {processor.py:157} INFO - Started process (PID=89618) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:33:32.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:33:32.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:32.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:33:32.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:33:32.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:32.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:33:32.610+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:33:32.610+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:33:32.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:34:02.981+0000] {processor.py:157} INFO - Started process (PID=89643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:34:02.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:34:02.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:02.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:34:02.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:34:03.018+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:03.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:34:03.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:03.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:34:03.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:34:33.387+0000] {processor.py:157} INFO - Started process (PID=89668) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:34:33.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:34:33.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:33.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:34:33.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:34:33.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:33.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:34:33.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:34:33.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:34:33.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:35:03.808+0000] {processor.py:157} INFO - Started process (PID=89693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:35:03.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:35:03.810+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:03.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:35:03.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:35:03.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:03.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:35:03.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:03.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:35:03.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:35:34.236+0000] {processor.py:157} INFO - Started process (PID=89718) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:35:34.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:35:34.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:34.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:35:34.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:35:34.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:34.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:35:34.280+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:35:34.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:35:34.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:36:04.686+0000] {processor.py:157} INFO - Started process (PID=89743) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:36:04.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:36:04.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:04.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:36:04.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:36:04.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:04.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:36:04.746+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:04.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:36:04.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T04:36:35.169+0000] {processor.py:157} INFO - Started process (PID=89768) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:36:35.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:36:35.172+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:35.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:36:35.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:36:35.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:35.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:36:35.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:36:35.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:36:35.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:37:05.585+0000] {processor.py:157} INFO - Started process (PID=89793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:37:05.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:37:05.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:05.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:37:05.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:37:05.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:05.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:37:05.622+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:05.622+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:37:05.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T04:37:36.351+0000] {processor.py:157} INFO - Started process (PID=89818) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:37:36.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:37:36.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:36.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:37:36.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:37:36.408+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:36.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:37:36.423+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:37:36.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:37:36.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-20T04:38:06.853+0000] {processor.py:157} INFO - Started process (PID=89843) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:38:06.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:38:06.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:06.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:38:06.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:38:06.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:06.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:38:06.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:06.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:38:06.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T04:38:37.298+0000] {processor.py:157} INFO - Started process (PID=89868) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:38:37.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:38:37.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:37.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:38:37.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:38:37.334+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:37.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:38:37.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:38:37.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:38:37.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:39:07.720+0000] {processor.py:157} INFO - Started process (PID=89893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:39:07.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:39:07.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:07.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:39:07.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:39:07.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:07.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:39:07.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:07.776+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:39:07.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T04:39:38.128+0000] {processor.py:157} INFO - Started process (PID=89918) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:39:38.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:39:38.133+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:38.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:39:38.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:39:38.160+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:38.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:39:38.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:39:38.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:39:38.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T04:40:08.549+0000] {processor.py:157} INFO - Started process (PID=89943) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:40:08.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:40:08.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:08.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:40:08.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:40:08.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:08.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:40:08.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:08.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:40:08.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.141 seconds
[2024-07-20T04:40:39.084+0000] {processor.py:157} INFO - Started process (PID=89968) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:40:39.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:40:39.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:39.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:40:39.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:40:39.113+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:39.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:40:39.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:40:39.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:40:39.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:41:09.527+0000] {processor.py:157} INFO - Started process (PID=89993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:41:09.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:41:09.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:09.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:41:09.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:41:09.556+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:09.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:41:09.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:09.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:41:09.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:41:39.991+0000] {processor.py:157} INFO - Started process (PID=90018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:41:39.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:41:39.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:39.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:41:40.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:41:40.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:40.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:41:40.035+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:41:40.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:41:40.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:42:10.357+0000] {processor.py:157} INFO - Started process (PID=90043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:42:10.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:42:10.361+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:10.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:42:10.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:42:10.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:10.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:42:10.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:10.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:42:10.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T04:42:40.813+0000] {processor.py:157} INFO - Started process (PID=90068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:42:40.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:42:40.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:40.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:42:40.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:42:40.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:40.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:42:40.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:42:40.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:42:40.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T04:43:11.262+0000] {processor.py:157} INFO - Started process (PID=90093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:43:11.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:43:11.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:11.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:43:11.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:43:11.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:11.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:43:11.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:11.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:43:11.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T04:43:41.643+0000] {processor.py:157} INFO - Started process (PID=90118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:43:41.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:43:41.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:41.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:43:41.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:43:41.680+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:41.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:43:41.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:43:41.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:43:41.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T04:44:12.160+0000] {processor.py:157} INFO - Started process (PID=90143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:44:12.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:44:12.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:12.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:44:12.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:44:12.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:12.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:44:12.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:12.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:44:12.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T04:44:42.703+0000] {processor.py:157} INFO - Started process (PID=90168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:44:42.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:44:42.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:42.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:44:42.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:44:42.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:42.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:44:42.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:44:42.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:44:42.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-20T04:45:13.243+0000] {processor.py:157} INFO - Started process (PID=90193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:45:13.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:45:13.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:13.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:45:13.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:45:13.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:13.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:45:13.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:13.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:45:13.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-20T04:45:43.735+0000] {processor.py:157} INFO - Started process (PID=90218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:45:43.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:45:43.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:43.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:45:43.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:45:43.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:43.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:45:43.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:45:43.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:45:43.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-20T04:46:14.211+0000] {processor.py:157} INFO - Started process (PID=90243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:46:14.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:46:14.214+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:14.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:46:14.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:46:14.243+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:14.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:46:14.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:14.257+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:46:14.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T04:46:44.654+0000] {processor.py:157} INFO - Started process (PID=90268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:46:44.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:46:44.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:44.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:46:44.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:46:44.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:44.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:46:44.699+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:46:44.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:46:44.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:47:15.045+0000] {processor.py:157} INFO - Started process (PID=90293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:47:15.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:47:15.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:15.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:47:15.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:47:15.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:15.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:47:15.095+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:15.095+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:47:15.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-20T04:47:45.462+0000] {processor.py:157} INFO - Started process (PID=90318) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:47:45.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:47:45.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:45.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:47:45.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:47:45.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:45.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:47:45.519+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:47:45.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:47:45.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T04:48:15.856+0000] {processor.py:157} INFO - Started process (PID=90343) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:48:15.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:48:15.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:15.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:48:15.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:48:15.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:15.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:48:15.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:15.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:48:15.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T04:48:46.305+0000] {processor.py:157} INFO - Started process (PID=90368) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:48:46.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:48:46.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:46.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:48:46.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:48:46.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:46.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:48:46.346+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:48:46.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:48:46.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:49:16.724+0000] {processor.py:157} INFO - Started process (PID=90393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:49:16.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:49:16.728+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:16.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:49:16.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:49:16.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:16.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:49:16.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:16.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:49:16.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T04:49:47.171+0000] {processor.py:157} INFO - Started process (PID=90418) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:49:47.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:49:47.177+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:47.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:49:47.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:49:47.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:47.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:49:47.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:49:47.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:49:47.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-20T04:50:17.615+0000] {processor.py:157} INFO - Started process (PID=90443) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:50:17.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:50:17.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:17.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:50:17.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:50:17.642+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:17.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:50:17.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:17.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:50:17.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T04:50:47.927+0000] {processor.py:157} INFO - Started process (PID=90468) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:50:47.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:50:47.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:47.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:50:47.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:50:47.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:47.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:50:47.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:50:47.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:50:47.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:51:18.367+0000] {processor.py:157} INFO - Started process (PID=90493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:51:18.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:51:18.373+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:18.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:51:18.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:51:18.400+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:18.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:51:18.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:18.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:51:18.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:51:48.798+0000] {processor.py:157} INFO - Started process (PID=90518) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:51:48.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:51:48.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:48.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:51:48.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:51:48.850+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:48.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:51:48.864+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:51:48.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:51:48.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-20T04:52:19.215+0000] {processor.py:157} INFO - Started process (PID=90543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:52:19.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:52:19.219+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:19.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:52:19.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:52:19.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:19.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:52:19.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:19.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:52:19.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:52:49.642+0000] {processor.py:157} INFO - Started process (PID=90568) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:52:49.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:52:49.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:49.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:52:49.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:52:49.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:49.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:52:49.682+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:52:49.682+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:52:49.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:53:20.082+0000] {processor.py:157} INFO - Started process (PID=90593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:53:20.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:53:20.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:20.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:53:20.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:53:20.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:20.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:53:20.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:20.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:53:20.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:53:50.520+0000] {processor.py:157} INFO - Started process (PID=90618) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:53:50.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:53:50.524+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:50.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:53:50.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:53:50.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:50.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:53:50.565+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:53:50.565+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:53:50.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:54:20.920+0000] {processor.py:157} INFO - Started process (PID=90643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:54:20.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:54:20.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:20.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:54:20.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:54:20.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:20.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:54:20.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:20.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:54:20.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:54:51.335+0000] {processor.py:157} INFO - Started process (PID=90668) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:54:51.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:54:51.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:51.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:54:51.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:54:51.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:51.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:54:51.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:54:51.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:54:51.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T04:55:21.775+0000] {processor.py:157} INFO - Started process (PID=90693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:55:21.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:55:21.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:21.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:55:21.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:55:21.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:21.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:55:21.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:21.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:55:21.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:55:52.217+0000] {processor.py:157} INFO - Started process (PID=90718) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:55:52.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:55:52.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:52.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:55:52.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:55:52.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:52.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:55:52.261+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:55:52.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:55:52.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:56:22.632+0000] {processor.py:157} INFO - Started process (PID=90743) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:56:22.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:56:22.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:22.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:56:22.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:56:22.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:22.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:56:22.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:22.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:56:22.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T04:56:53.020+0000] {processor.py:157} INFO - Started process (PID=90768) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:56:53.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:56:53.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:53.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:56:53.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:56:53.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:53.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:56:53.064+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:56:53.064+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:56:53.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:57:23.467+0000] {processor.py:157} INFO - Started process (PID=90793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:57:23.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:57:23.470+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:23.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:57:23.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:57:23.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:23.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:57:23.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:23.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:57:23.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:57:53.838+0000] {processor.py:157} INFO - Started process (PID=90818) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:57:53.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:57:53.843+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:53.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:57:53.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:57:53.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:53.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:57:53.881+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:57:53.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:57:53.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T04:58:24.280+0000] {processor.py:157} INFO - Started process (PID=90843) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:58:24.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:58:24.284+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:24.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:58:24.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:58:24.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:24.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:58:24.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:24.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:58:24.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T04:58:54.716+0000] {processor.py:157} INFO - Started process (PID=90868) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:58:54.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:58:54.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:54.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:58:54.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:58:54.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:54.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:58:54.761+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:58:54.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:58:54.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T04:59:25.111+0000] {processor.py:157} INFO - Started process (PID=90893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:59:25.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:59:25.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:25.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:59:25.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:59:25.142+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:25.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:59:25.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:25.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:59:25.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T04:59:55.562+0000] {processor.py:157} INFO - Started process (PID=90918) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:59:55.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T04:59:55.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:55.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:59:55.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T04:59:55.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:55.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T04:59:55.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T04:59:55.603+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T04:59:55.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:00:25.971+0000] {processor.py:157} INFO - Started process (PID=90943) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:00:25.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:00:25.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:25.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:00:25.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:00:26.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:26.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:00:26.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:26.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:00:26.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T05:00:56.404+0000] {processor.py:157} INFO - Started process (PID=90968) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:00:56.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:00:56.408+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:56.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:00:56.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:00:56.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:56.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:00:56.451+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:00:56.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:00:56.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T05:01:26.823+0000] {processor.py:157} INFO - Started process (PID=90993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:01:26.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:01:26.827+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:26.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:01:26.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:01:26.854+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:26.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:01:26.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:26.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:01:26.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T05:01:57.257+0000] {processor.py:157} INFO - Started process (PID=91018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:01:57.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:01:57.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:57.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:01:57.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:01:57.289+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:57.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:01:57.317+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:01:57.316+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:01:57.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-20T05:02:27.732+0000] {processor.py:157} INFO - Started process (PID=91043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:02:27.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:02:27.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:27.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:02:27.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:02:27.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:27.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:02:27.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:27.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:02:27.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T05:02:58.149+0000] {processor.py:157} INFO - Started process (PID=91068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:02:58.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:02:58.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:58.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:02:58.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:02:58.178+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:58.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:02:58.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:02:58.187+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:02:58.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:03:28.582+0000] {processor.py:157} INFO - Started process (PID=91093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:03:28.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:03:28.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:28.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:03:28.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:03:28.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:28.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:03:28.625+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:28.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:03:28.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:03:58.998+0000] {processor.py:157} INFO - Started process (PID=91118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:03:58.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:03:59.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:59.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:03:59.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:03:59.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:59.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:03:59.038+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:03:59.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:03:59.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T05:04:29.436+0000] {processor.py:157} INFO - Started process (PID=91143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:04:29.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:04:29.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:29.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:04:29.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:04:29.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:29.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:04:29.477+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:29.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:04:29.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T05:04:59.875+0000] {processor.py:157} INFO - Started process (PID=91168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:04:59.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:04:59.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:59.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:04:59.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:04:59.906+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:59.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:04:59.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:04:59.917+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:04:59.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:05:30.300+0000] {processor.py:157} INFO - Started process (PID=91193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:05:30.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:05:30.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:05:30.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:05:30.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:05:30.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:05:30.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:05:30.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:05:30.341+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:05:30.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:06:00.738+0000] {processor.py:157} INFO - Started process (PID=91218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:06:00.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:06:00.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:00.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:06:00.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:06:00.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:00.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:06:00.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:00.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:06:00.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T05:06:31.138+0000] {processor.py:157} INFO - Started process (PID=91243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:06:31.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:06:31.141+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:31.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:06:31.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:06:31.168+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:31.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:06:31.178+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:06:31.178+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:06:31.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T05:07:01.578+0000] {processor.py:157} INFO - Started process (PID=91268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:07:01.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:07:01.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:01.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:07:01.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:07:01.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:01.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:07:01.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:01.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:07:01.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:07:31.991+0000] {processor.py:157} INFO - Started process (PID=91293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:07:31.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:07:31.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:31.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:07:32.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:07:32.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:32.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:07:32.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:07:32.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:07:32.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:08:02.368+0000] {processor.py:157} INFO - Started process (PID=91318) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:08:02.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:08:02.372+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:02.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:08:02.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:08:02.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:02.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:08:02.408+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:02.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:08:02.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T05:08:32.821+0000] {processor.py:157} INFO - Started process (PID=91343) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:08:32.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:08:32.824+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:32.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:08:32.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:08:32.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:32.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:08:32.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:08:32.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:08:32.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:09:03.227+0000] {processor.py:157} INFO - Started process (PID=91368) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:09:03.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:09:03.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:03.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:09:03.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:09:03.253+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:03.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:09:03.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:03.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:09:03.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-20T05:09:33.679+0000] {processor.py:157} INFO - Started process (PID=91393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:09:33.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:09:33.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:33.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:09:33.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:09:33.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:33.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:09:33.720+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:09:33.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:09:33.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T05:10:04.138+0000] {processor.py:157} INFO - Started process (PID=91418) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:10:04.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:10:04.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:04.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:10:04.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:10:04.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:04.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:10:04.192+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:04.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:10:04.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T05:10:34.588+0000] {processor.py:157} INFO - Started process (PID=91443) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:10:34.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:10:34.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:34.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:10:34.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:10:34.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:34.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:10:34.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:10:34.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:10:34.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:11:05.023+0000] {processor.py:157} INFO - Started process (PID=91468) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:11:05.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:11:05.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:05.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:11:05.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:11:05.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:05.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:11:05.064+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:05.064+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:11:05.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:11:35.455+0000] {processor.py:157} INFO - Started process (PID=91493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:11:35.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:11:35.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:35.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:11:35.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:11:35.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:35.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:11:35.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:11:35.500+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:11:35.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:12:05.918+0000] {processor.py:157} INFO - Started process (PID=91518) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:12:05.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:12:05.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:05.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:12:05.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:12:05.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:05.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:12:05.964+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:05.964+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:12:05.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T05:12:36.294+0000] {processor.py:157} INFO - Started process (PID=91543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:12:36.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:12:36.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:36.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:12:36.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:12:36.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:36.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:12:36.338+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:12:36.338+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:12:36.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T05:13:06.729+0000] {processor.py:157} INFO - Started process (PID=91568) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:13:06.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:13:06.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:06.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:13:06.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:13:06.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:06.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:13:06.774+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:06.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:13:06.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:13:37.149+0000] {processor.py:157} INFO - Started process (PID=91593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:13:37.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:13:37.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:37.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:13:37.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:13:37.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:37.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:13:37.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:13:37.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:13:37.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:14:07.547+0000] {processor.py:157} INFO - Started process (PID=91618) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:14:07.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:14:07.551+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:07.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:14:07.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:14:07.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:07.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:14:07.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:07.591+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:14:07.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:14:37.993+0000] {processor.py:157} INFO - Started process (PID=91643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:14:37.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:14:37.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:37.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:14:38.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:14:38.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:38.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:14:38.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:14:38.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:14:38.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T05:15:08.441+0000] {processor.py:157} INFO - Started process (PID=91668) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:15:08.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:15:08.444+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:08.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:15:08.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:15:08.472+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:08.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:15:08.485+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:08.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:15:08.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:15:38.843+0000] {processor.py:157} INFO - Started process (PID=91693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:15:38.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:15:38.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:38.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:15:38.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:15:38.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:38.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:15:38.887+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:15:38.887+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:15:38.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:16:09.316+0000] {processor.py:157} INFO - Started process (PID=91718) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:16:09.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:16:09.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:09.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:16:09.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:16:09.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:09.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:16:09.362+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:09.362+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:16:09.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T05:16:39.721+0000] {processor.py:157} INFO - Started process (PID=91743) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:16:39.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:16:39.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:39.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:16:39.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:16:39.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:39.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:16:39.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:16:39.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:16:39.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:17:10.113+0000] {processor.py:157} INFO - Started process (PID=91768) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:17:10.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:17:10.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:10.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:17:10.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:17:10.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:10.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:17:10.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:10.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:17:10.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:17:40.543+0000] {processor.py:157} INFO - Started process (PID=91793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:17:40.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:17:40.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:40.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:17:40.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:17:40.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:40.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:17:40.584+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:17:40.584+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:17:40.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T05:18:10.929+0000] {processor.py:157} INFO - Started process (PID=91818) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:18:10.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:18:10.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:10.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:18:10.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:18:10.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:10.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:18:10.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:10.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:18:10.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:18:41.301+0000] {processor.py:157} INFO - Started process (PID=91843) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:18:41.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:18:41.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:41.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:18:41.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:18:41.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:41.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:18:41.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:18:41.344+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:18:41.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:19:11.698+0000] {processor.py:157} INFO - Started process (PID=91868) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:19:11.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:19:11.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:11.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:19:11.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:19:11.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:11.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:19:11.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:11.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:19:11.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T05:19:42.132+0000] {processor.py:157} INFO - Started process (PID=91893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:19:42.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:19:42.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:42.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:19:42.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:19:42.163+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:42.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:19:42.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:19:42.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:19:42.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:20:12.575+0000] {processor.py:157} INFO - Started process (PID=91918) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:20:12.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:20:12.579+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:12.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:20:12.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:20:12.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:12.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:20:12.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:12.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:20:12.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:20:42.952+0000] {processor.py:157} INFO - Started process (PID=91943) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:20:42.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:20:42.957+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:42.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:20:42.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:20:42.984+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:42.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:20:42.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:20:42.994+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:20:43.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T05:21:13.397+0000] {processor.py:157} INFO - Started process (PID=91968) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:21:13.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:21:13.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:13.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:21:13.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:21:13.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:13.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:21:13.438+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:13.438+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:21:13.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:21:43.786+0000] {processor.py:157} INFO - Started process (PID=91993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:21:43.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:21:43.789+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:43.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:21:43.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:21:43.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:43.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:21:43.825+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:21:43.825+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:21:43.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T05:22:14.189+0000] {processor.py:157} INFO - Started process (PID=92018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:22:14.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:22:14.192+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:14.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:22:14.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:22:14.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:14.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:22:14.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:14.231+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:22:14.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:22:44.594+0000] {processor.py:157} INFO - Started process (PID=92043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:22:44.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:22:44.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:44.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:22:44.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:22:44.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:44.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:22:44.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:22:44.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:22:44.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T05:23:15.000+0000] {processor.py:157} INFO - Started process (PID=92068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:23:15.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:23:15.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:15.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:23:15.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:23:15.033+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:15.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:23:15.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:15.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:23:15.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T05:23:45.407+0000] {processor.py:157} INFO - Started process (PID=92093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:23:45.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:23:45.411+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:45.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:23:45.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:23:45.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:45.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:23:45.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:23:45.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:23:45.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:24:15.818+0000] {processor.py:157} INFO - Started process (PID=92118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:24:15.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:24:15.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:15.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:24:15.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:24:15.850+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:15.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:24:15.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:15.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:24:15.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:24:46.198+0000] {processor.py:157} INFO - Started process (PID=92143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:24:46.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:24:46.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:46.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:24:46.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:24:46.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:46.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:24:46.255+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:24:46.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:24:46.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T05:25:16.669+0000] {processor.py:157} INFO - Started process (PID=92168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:25:16.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:25:16.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:16.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:25:16.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:25:16.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:16.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:25:16.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:16.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:25:16.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:25:47.090+0000] {processor.py:157} INFO - Started process (PID=92193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:25:47.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:25:47.093+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:47.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:25:47.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:25:47.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:47.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:25:47.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:25:47.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:25:47.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:26:17.490+0000] {processor.py:157} INFO - Started process (PID=92218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:26:17.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:26:17.492+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:17.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:26:17.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:26:17.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:17.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:26:17.535+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:17.535+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:26:17.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T05:26:47.930+0000] {processor.py:157} INFO - Started process (PID=92243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:26:47.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:26:47.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:47.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:26:47.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:26:47.963+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:47.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:26:47.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:26:47.976+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:26:47.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:27:18.337+0000] {processor.py:157} INFO - Started process (PID=92268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:27:18.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:27:18.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:18.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:27:18.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:27:18.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:18.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:27:18.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:18.380+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:27:18.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:27:48.706+0000] {processor.py:157} INFO - Started process (PID=92293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:27:48.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:27:48.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:48.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:27:48.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:27:48.733+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:48.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:27:48.744+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:27:48.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:27:48.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T05:28:19.084+0000] {processor.py:157} INFO - Started process (PID=92318) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:28:19.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:28:19.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:19.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:28:19.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:28:19.115+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:19.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:28:19.126+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:19.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:28:19.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:28:49.546+0000] {processor.py:157} INFO - Started process (PID=92343) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:28:49.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:28:49.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:49.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:28:49.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:28:49.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:49.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:28:49.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:28:49.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:28:49.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:29:19.999+0000] {processor.py:157} INFO - Started process (PID=92368) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:29:20.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:29:20.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:20.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:29:20.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:29:20.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:20.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:29:20.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:20.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:29:20.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:29:50.467+0000] {processor.py:157} INFO - Started process (PID=92393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:29:50.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:29:50.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:50.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:29:50.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:29:50.503+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:50.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:29:50.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:29:50.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:29:50.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:30:20.875+0000] {processor.py:157} INFO - Started process (PID=92418) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:30:20.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:30:20.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:20.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:30:20.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:30:20.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:20.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:30:20.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:20.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:30:20.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T05:30:51.260+0000] {processor.py:157} INFO - Started process (PID=92443) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:30:51.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:30:51.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:51.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:30:51.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:30:51.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:51.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:30:51.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:30:51.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:30:51.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-20T05:31:21.709+0000] {processor.py:157} INFO - Started process (PID=92468) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:31:21.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:31:21.714+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:21.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:31:21.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:31:21.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:21.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:31:21.753+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:21.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:31:21.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:31:52.085+0000] {processor.py:157} INFO - Started process (PID=92493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:31:52.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:31:52.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:52.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:31:52.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:31:52.113+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:52.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:31:52.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:31:52.123+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:31:52.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T05:32:22.480+0000] {processor.py:157} INFO - Started process (PID=92518) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:32:22.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:32:22.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:22.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:32:22.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:32:22.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:22.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:32:22.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:22.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:32:22.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T05:32:52.930+0000] {processor.py:157} INFO - Started process (PID=92543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:32:52.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:32:52.940+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:52.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:32:52.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:32:53.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:53.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:32:53.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:32:53.029+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:32:53.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-20T05:33:23.518+0000] {processor.py:157} INFO - Started process (PID=92568) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:33:23.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:33:23.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:23.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:33:23.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:33:23.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:23.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:33:23.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:23.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:33:23.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.150 seconds
[2024-07-20T05:33:54.096+0000] {processor.py:157} INFO - Started process (PID=92593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:33:54.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:33:54.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:54.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:33:54.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:33:54.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:54.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:33:54.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:33:54.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:33:54.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-20T05:34:24.612+0000] {processor.py:157} INFO - Started process (PID=92618) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:34:24.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:34:24.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:24.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:34:24.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:34:24.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:24.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:34:24.658+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:24.658+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:34:24.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T05:34:55.089+0000] {processor.py:157} INFO - Started process (PID=92643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:34:55.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:34:55.095+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:55.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:34:55.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:34:55.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:55.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:34:55.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:34:55.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:34:55.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-20T05:35:25.644+0000] {processor.py:157} INFO - Started process (PID=92668) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:35:25.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:35:25.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:25.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:35:25.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:35:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:25.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:35:25.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:25.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:35:25.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-20T05:35:56.229+0000] {processor.py:157} INFO - Started process (PID=92693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:35:56.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:35:56.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:56.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:35:56.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:35:56.289+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:56.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:35:56.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:35:56.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:35:56.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-20T05:36:26.747+0000] {processor.py:157} INFO - Started process (PID=92718) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:36:26.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:36:26.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:26.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:36:26.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:36:26.778+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:26.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:36:26.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:26.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:36:26.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:36:57.175+0000] {processor.py:157} INFO - Started process (PID=92743) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:36:57.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:36:57.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:57.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:36:57.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:36:57.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:57.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:36:57.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:36:57.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:36:57.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-20T05:37:27.682+0000] {processor.py:157} INFO - Started process (PID=92768) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:37:27.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:37:27.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:27.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:37:27.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:37:27.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:27.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:37:27.728+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:27.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:37:27.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T05:37:58.165+0000] {processor.py:157} INFO - Started process (PID=92793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:37:58.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:37:58.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:58.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:37:58.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:37:58.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:58.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:37:58.292+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:37:58.292+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:37:58.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.151 seconds
[2024-07-20T05:38:28.710+0000] {processor.py:157} INFO - Started process (PID=92818) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:38:28.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:38:28.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:28.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:38:28.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:38:28.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:28.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:38:28.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:28.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:38:28.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T05:38:59.154+0000] {processor.py:157} INFO - Started process (PID=92843) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:38:59.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:38:59.160+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:59.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:38:59.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:38:59.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:59.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:38:59.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:38:59.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:38:59.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T05:39:29.575+0000] {processor.py:157} INFO - Started process (PID=92868) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:39:29.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:39:29.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:29.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:39:29.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:39:29.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:29.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:39:29.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:29.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:39:29.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T05:39:59.978+0000] {processor.py:157} INFO - Started process (PID=92893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:39:59.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:39:59.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:39:59.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:39:59.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:40:00.007+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:00.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:40:00.017+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:00.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:40:00.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:40:30.375+0000] {processor.py:157} INFO - Started process (PID=92918) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:40:30.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:40:30.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:30.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:40:30.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:40:30.412+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:30.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:40:30.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:40:30.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:40:30.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-20T05:41:00.782+0000] {processor.py:157} INFO - Started process (PID=92943) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:41:00.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:41:00.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:00.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:41:00.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:41:00.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:00.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:41:00.850+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:00.850+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:41:00.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-20T05:41:31.265+0000] {processor.py:157} INFO - Started process (PID=92968) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:41:31.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:41:31.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:31.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:41:31.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:41:31.298+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:31.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:41:31.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:41:31.308+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:41:31.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:42:01.641+0000] {processor.py:157} INFO - Started process (PID=92993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:42:01.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:42:01.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:01.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:42:01.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:42:01.671+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:01.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:42:01.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:01.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:42:01.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:42:32.089+0000] {processor.py:157} INFO - Started process (PID=93018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:42:32.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:42:32.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:32.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:42:32.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:42:32.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:32.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:42:32.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:42:32.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:42:32.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T05:43:02.531+0000] {processor.py:157} INFO - Started process (PID=93043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:43:02.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:43:02.535+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:02.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:43:02.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:43:02.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:02.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:43:02.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:02.575+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:43:02.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T05:43:32.990+0000] {processor.py:157} INFO - Started process (PID=93068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:43:32.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:43:32.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:32.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:43:33.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:43:33.020+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:33.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:43:33.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:43:33.031+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:43:33.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:44:03.440+0000] {processor.py:157} INFO - Started process (PID=93093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:44:03.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:44:03.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:03.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:44:03.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:44:03.483+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:03.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:44:03.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:03.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:44:03.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-20T05:44:33.879+0000] {processor.py:157} INFO - Started process (PID=93118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:44:33.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:44:33.886+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:33.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:44:33.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:44:33.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:33.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:44:33.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:44:33.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:44:33.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T05:45:04.259+0000] {processor.py:157} INFO - Started process (PID=93143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:45:04.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:45:04.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:04.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:45:04.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:45:04.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:04.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:45:04.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:04.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:45:04.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T05:45:34.678+0000] {processor.py:157} INFO - Started process (PID=93168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:45:34.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:45:34.680+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:34.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:45:34.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:45:34.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:34.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:45:34.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:45:34.721+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:45:34.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T05:46:05.086+0000] {processor.py:157} INFO - Started process (PID=93193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:46:05.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:46:05.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:05.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:46:05.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:46:05.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:05.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:46:05.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:05.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:46:05.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:46:35.575+0000] {processor.py:157} INFO - Started process (PID=93218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:46:35.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:46:35.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:35.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:46:35.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:46:35.607+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:35.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:46:35.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:46:35.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:46:35.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:47:06.024+0000] {processor.py:157} INFO - Started process (PID=93243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:47:06.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:47:06.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:06.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:47:06.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:47:06.067+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:06.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:47:06.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:06.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:47:06.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T05:47:36.471+0000] {processor.py:157} INFO - Started process (PID=93268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:47:36.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:47:36.474+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:36.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:47:36.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:47:36.506+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:36.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:47:36.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:47:36.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:47:36.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T05:48:06.876+0000] {processor.py:157} INFO - Started process (PID=93293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:48:06.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:48:06.880+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:06.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:48:06.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:48:06.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:06.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:48:06.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:06.918+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:48:06.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T05:48:37.330+0000] {processor.py:157} INFO - Started process (PID=93318) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:48:37.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:48:37.335+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:37.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:48:37.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:48:37.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:37.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:48:37.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:48:37.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:48:37.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-20T05:49:07.762+0000] {processor.py:157} INFO - Started process (PID=93343) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:49:07.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:49:07.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:07.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:49:07.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:49:07.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:07.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:49:07.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:07.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:49:07.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-20T05:49:38.198+0000] {processor.py:157} INFO - Started process (PID=93368) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:49:38.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:49:38.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:38.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:49:38.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:49:38.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:38.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:49:38.261+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:49:38.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:49:38.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T05:50:08.633+0000] {processor.py:157} INFO - Started process (PID=93393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:50:08.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:50:08.635+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:08.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:50:08.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:50:08.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:08.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:50:08.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:08.690+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:50:08.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T05:50:39.076+0000] {processor.py:157} INFO - Started process (PID=93418) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:50:39.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:50:39.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:39.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:50:39.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:50:39.122+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:39.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:50:39.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:50:39.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:50:39.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T05:51:09.534+0000] {processor.py:157} INFO - Started process (PID=93443) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:51:09.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:51:09.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:09.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:51:09.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:51:09.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:09.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:51:09.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:09.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:51:09.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T05:51:39.942+0000] {processor.py:157} INFO - Started process (PID=93468) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:51:39.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:51:39.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:39.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:51:39.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:51:39.987+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:39.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:51:40.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:51:40.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:51:40.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T05:52:10.415+0000] {processor.py:157} INFO - Started process (PID=93493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:52:10.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:52:10.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:10.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:52:10.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:52:10.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:10.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:52:10.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:10.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:52:10.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:52:40.806+0000] {processor.py:157} INFO - Started process (PID=93518) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:52:40.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:52:40.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:40.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:52:40.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:52:40.831+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:40.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:52:40.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:52:40.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:52:40.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-20T05:53:11.234+0000] {processor.py:157} INFO - Started process (PID=93543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:53:11.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:53:11.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:11.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:53:11.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:53:11.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:11.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:53:11.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:11.277+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:53:11.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:53:41.660+0000] {processor.py:157} INFO - Started process (PID=93568) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:53:41.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:53:41.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:41.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:53:41.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:53:41.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:41.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:53:41.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:53:41.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:53:41.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:54:12.111+0000] {processor.py:157} INFO - Started process (PID=93593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:54:12.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:54:12.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:12.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:54:12.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:54:12.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:12.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:54:12.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:12.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:54:12.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T05:54:42.572+0000] {processor.py:157} INFO - Started process (PID=93618) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:54:42.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:54:42.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:42.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:54:42.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:54:42.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:42.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:54:42.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:54:42.617+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:54:42.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T05:55:12.967+0000] {processor.py:157} INFO - Started process (PID=93643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:55:12.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:55:12.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:12.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:55:12.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:55:12.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:12.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:55:13.007+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:13.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:55:13.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T05:55:43.421+0000] {processor.py:157} INFO - Started process (PID=93668) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:55:43.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:55:43.425+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:43.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:55:43.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:55:43.454+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:43.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:55:43.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:55:43.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:55:43.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T05:56:13.812+0000] {processor.py:157} INFO - Started process (PID=93693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:56:13.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:56:13.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:13.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:56:13.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:56:13.852+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:13.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:56:13.862+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:13.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:56:13.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T05:56:44.233+0000] {processor.py:157} INFO - Started process (PID=93718) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:56:44.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:56:44.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:44.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:56:44.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:56:44.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:44.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:56:44.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:56:44.295+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:56:44.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T05:57:14.656+0000] {processor.py:157} INFO - Started process (PID=93743) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:57:14.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:57:14.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:14.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:57:14.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:57:14.689+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:14.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:57:14.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:14.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:57:14.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T05:57:45.075+0000] {processor.py:157} INFO - Started process (PID=93768) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:57:45.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:57:45.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:45.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:57:45.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:57:45.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:45.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:57:45.113+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:57:45.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:57:45.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T05:58:15.428+0000] {processor.py:157} INFO - Started process (PID=93793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:58:15.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:58:15.431+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:15.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:58:15.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:58:15.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:15.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:58:15.475+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:15.475+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:58:15.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T05:58:45.884+0000] {processor.py:157} INFO - Started process (PID=93818) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:58:45.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:58:45.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:45.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:58:45.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:58:45.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:45.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:58:45.926+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:58:45.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:58:45.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T05:59:16.271+0000] {processor.py:157} INFO - Started process (PID=93843) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:59:16.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:59:16.275+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:16.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:59:16.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:59:16.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:16.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:59:16.317+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:16.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:59:16.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T05:59:46.733+0000] {processor.py:157} INFO - Started process (PID=93868) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:59:46.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T05:59:46.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:46.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:59:46.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T05:59:46.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:46.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T05:59:46.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T05:59:46.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T05:59:46.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T06:00:17.166+0000] {processor.py:157} INFO - Started process (PID=93893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:00:17.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:00:17.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:17.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:00:17.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:00:17.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:17.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:00:17.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:17.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:00:17.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T06:00:47.611+0000] {processor.py:157} INFO - Started process (PID=93918) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:00:47.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:00:47.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:47.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:00:47.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:00:47.639+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:47.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:00:47.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:00:47.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:00:47.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T06:01:17.978+0000] {processor.py:157} INFO - Started process (PID=93943) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:01:17.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:01:17.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:17.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:01:17.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:01:18.014+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:18.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:01:18.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:18.023+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:01:18.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T06:01:48.427+0000] {processor.py:157} INFO - Started process (PID=93968) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:01:48.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:01:48.431+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:48.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:01:48.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:01:48.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:48.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:01:48.470+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:01:48.470+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:01:48.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T06:02:18.901+0000] {processor.py:157} INFO - Started process (PID=93993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:02:18.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:02:18.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:18.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:02:18.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:02:18.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:18.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:02:18.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:18.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:02:18.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T06:02:49.280+0000] {processor.py:157} INFO - Started process (PID=94018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:02:49.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:02:49.284+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:49.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:02:49.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:02:49.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:49.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:02:49.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:02:49.326+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:02:49.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T06:03:19.765+0000] {processor.py:157} INFO - Started process (PID=94043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:03:19.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:03:19.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:19.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:03:19.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:03:19.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:19.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:03:19.803+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:19.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:03:19.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T06:03:50.177+0000] {processor.py:157} INFO - Started process (PID=94068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:03:50.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:03:50.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:50.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:03:50.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:03:50.220+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:50.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:03:50.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:03:50.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:03:50.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-20T06:04:20.604+0000] {processor.py:157} INFO - Started process (PID=94093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:04:20.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:04:20.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:20.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:04:20.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:04:20.637+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:20.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:04:20.649+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:20.649+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:04:20.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T06:04:51.072+0000] {processor.py:157} INFO - Started process (PID=94118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:04:51.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:04:51.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:51.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:04:51.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:04:51.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:51.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:04:51.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:04:51.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:04:51.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T06:05:21.449+0000] {processor.py:157} INFO - Started process (PID=94143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:05:21.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:05:21.454+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:21.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:05:21.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:05:21.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:21.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:05:21.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:21.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:05:21.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T06:05:51.904+0000] {processor.py:157} INFO - Started process (PID=94168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:05:51.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:05:51.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:51.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:05:51.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:05:51.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:51.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:05:51.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:05:51.943+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:05:51.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T06:06:22.325+0000] {processor.py:157} INFO - Started process (PID=94193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:06:22.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:06:22.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:22.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:06:22.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:06:22.358+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:22.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:06:22.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:22.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:06:22.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T06:06:52.747+0000] {processor.py:157} INFO - Started process (PID=94218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:06:52.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:06:52.754+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:52.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:06:52.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:06:52.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:52.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:06:52.792+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:06:52.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:06:52.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T06:07:23.148+0000] {processor.py:157} INFO - Started process (PID=94243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:07:23.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:07:23.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:23.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:07:23.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:07:23.181+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:23.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:07:23.192+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:23.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:07:23.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T06:07:53.565+0000] {processor.py:157} INFO - Started process (PID=94268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:07:53.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:07:53.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:53.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:07:53.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:07:53.600+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:53.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:07:53.610+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:07:53.610+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:07:53.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T06:08:23.997+0000] {processor.py:157} INFO - Started process (PID=94293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:08:23.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:08:24.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:24.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:08:24.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:08:24.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:24.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:08:24.055+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:24.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:08:24.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-20T06:08:54.427+0000] {processor.py:157} INFO - Started process (PID=94318) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:08:54.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:08:54.431+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:54.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:08:54.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:08:54.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:54.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:08:54.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:08:54.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:08:54.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T06:09:24.846+0000] {processor.py:157} INFO - Started process (PID=94343) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:09:24.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:09:24.852+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:24.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:09:24.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:09:24.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:24.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:09:24.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:24.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:09:24.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T06:09:55.295+0000] {processor.py:157} INFO - Started process (PID=94368) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:09:55.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:09:55.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:55.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:09:55.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:09:55.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:55.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:09:55.384+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:09:55.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:09:55.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-20T06:10:25.804+0000] {processor.py:157} INFO - Started process (PID=94393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:10:25.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:10:25.811+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:25.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:10:25.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:10:25.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:25.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:10:25.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:25.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:10:25.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-20T06:10:56.265+0000] {processor.py:157} INFO - Started process (PID=94418) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:10:56.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:10:56.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:56.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:10:56.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:10:56.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:56.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:10:56.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:10:56.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:10:56.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T06:11:26.751+0000] {processor.py:157} INFO - Started process (PID=94443) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:11:26.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:11:26.755+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:26.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:11:26.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:11:26.786+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:26.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:11:26.797+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:26.797+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:11:26.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T06:11:57.205+0000] {processor.py:157} INFO - Started process (PID=94468) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:11:57.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:11:57.211+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:57.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:11:57.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:11:57.252+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:57.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:11:57.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:11:57.268+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:11:57.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T06:12:27.650+0000] {processor.py:157} INFO - Started process (PID=94493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:12:27.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:12:27.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:27.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:12:27.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:12:27.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:27.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:12:27.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:27.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:12:27.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-20T06:12:58.095+0000] {processor.py:157} INFO - Started process (PID=94518) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:12:58.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:12:58.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:58.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:12:58.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:12:58.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:58.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:12:58.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:12:58.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:12:58.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T06:13:28.524+0000] {processor.py:157} INFO - Started process (PID=94543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:13:28.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:13:28.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:28.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:13:28.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:13:28.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:28.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:13:28.643+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:28.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:13:28.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-20T06:13:58.985+0000] {processor.py:157} INFO - Started process (PID=94568) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:13:58.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:13:58.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:58.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:13:58.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:13:59.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:59.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:13:59.021+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:13:59.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:13:59.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T06:14:29.819+0000] {processor.py:157} INFO - Started process (PID=94593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:14:29.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:14:29.825+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:14:29.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:14:29.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:14:29.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:14:29.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:14:29.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:14:29.889+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:14:29.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-20T06:15:00.317+0000] {processor.py:157} INFO - Started process (PID=94618) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:15:00.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:15:00.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:15:00.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:15:00.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:15:00.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:15:00.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:15:00.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:15:00.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:15:00.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T06:16:27.665+0000] {processor.py:157} INFO - Started process (PID=94643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:16:27.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:16:27.671+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:16:27.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:16:27.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:16:27.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:16:27.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:16:27.730+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:16:27.730+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:16:27.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-20T06:49:15.646+0000] {processor.py:157} INFO - Started process (PID=94670) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:49:15.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T06:49:15.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:49:15.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:49:15.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T06:49:15.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:49:15.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T06:49:15.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T06:49:15.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T06:49:15.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-20T07:30:16.059+0000] {processor.py:157} INFO - Started process (PID=94697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:30:16.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:30:16.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:16.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:30:16.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:30:16.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:16.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:30:16.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:16.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:30:16.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-20T07:30:46.542+0000] {processor.py:157} INFO - Started process (PID=94722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:30:46.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:30:46.548+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:46.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:30:46.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:30:46.585+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:46.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:30:46.596+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:30:46.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:30:46.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T07:33:25.902+0000] {processor.py:157} INFO - Started process (PID=94747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:33:25.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:33:25.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:33:25.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:33:25.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:33:25.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:33:25.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:33:25.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:33:25.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:33:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T07:34:09.259+0000] {processor.py:157} INFO - Started process (PID=94772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:34:09.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:34:09.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:09.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:34:09.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:34:09.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:09.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:34:09.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:09.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:34:09.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T07:34:39.689+0000] {processor.py:157} INFO - Started process (PID=94797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:34:39.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:34:39.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:39.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:34:39.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:34:39.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:39.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:34:39.731+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:34:39.731+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:34:39.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T07:46:22.069+0000] {processor.py:157} INFO - Started process (PID=94824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:46:22.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:46:22.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:46:22.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:46:22.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:46:22.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:46:22.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:46:22.146+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:46:22.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:46:22.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-20T07:47:04.654+0000] {processor.py:157} INFO - Started process (PID=94849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:47:04.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:47:04.658+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:04.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:47:04.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:47:04.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:04.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:47:04.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:04.696+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:47:04.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T07:47:35.097+0000] {processor.py:157} INFO - Started process (PID=94874) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:47:35.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:47:35.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:35.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:47:35.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:47:35.131+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:35.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:47:35.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:47:35.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:47:35.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T07:49:56.459+0000] {processor.py:157} INFO - Started process (PID=94899) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:49:56.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:49:56.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:49:56.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:49:56.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:49:56.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:49:56.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:49:56.502+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:49:56.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:49:56.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T07:50:39.829+0000] {processor.py:157} INFO - Started process (PID=94924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:50:39.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:50:39.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:50:39.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:50:39.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:50:39.870+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:50:39.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:50:39.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:50:39.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:50:39.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T07:51:10.296+0000] {processor.py:157} INFO - Started process (PID=94949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:51:10.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T07:51:10.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:51:10.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:51:10.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T07:51:10.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:51:10.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T07:51:10.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T07:51:10.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T07:51:10.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T08:14:02.298+0000] {processor.py:157} INFO - Started process (PID=94974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:14:02.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T08:14:02.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:02.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:14:02.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:14:02.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:02.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:14:02.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:02.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T08:14:02.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T08:14:32.710+0000] {processor.py:157} INFO - Started process (PID=94999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:14:32.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T08:14:32.716+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:32.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:14:32.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:14:32.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:32.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:14:32.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:14:32.764+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T08:14:32.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T08:15:10.410+0000] {processor.py:157} INFO - Started process (PID=95024) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:15:10.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T08:15:10.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:15:10.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:15:10.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:15:10.438+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:15:10.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:15:10.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:15:10.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T08:15:10.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T08:35:58.591+0000] {processor.py:157} INFO - Started process (PID=95050) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:35:58.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T08:35:58.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:35:58.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:35:58.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:35:58.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:35:58.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:35:58.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:35:58.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T08:35:58.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-20T08:36:29.003+0000] {processor.py:157} INFO - Started process (PID=95076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:36:29.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T08:36:29.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:36:29.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:36:29.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T08:36:29.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:36:29.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T08:36:29.038+0000] {logging_mixin.py:151} INFO - [2024-07-20T08:36:29.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T08:36:29.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-20T09:15:03.733+0000] {processor.py:157} INFO - Started process (PID=95101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:15:03.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:15:03.739+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:03.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:15:03.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:15:03.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:03.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:15:03.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:03.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:15:03.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T09:15:34.199+0000] {processor.py:157} INFO - Started process (PID=95126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:15:34.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:15:34.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:34.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:15:34.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:15:34.234+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:34.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:15:34.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:15:34.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:15:34.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T09:26:31.523+0000] {processor.py:157} INFO - Started process (PID=95151) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:26:31.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:26:31.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:26:31.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:26:31.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:26:31.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:26:31.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:26:31.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:26:31.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:26:31.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T09:27:02.095+0000] {processor.py:157} INFO - Started process (PID=95176) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:27:02.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:27:02.097+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:27:02.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:27:02.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:27:02.126+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:27:02.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:27:02.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:27:02.136+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:27:02.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T09:35:24.702+0000] {processor.py:157} INFO - Started process (PID=95201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:35:24.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:35:24.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:35:24.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:35:24.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:35:24.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:35:24.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:35:24.753+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:35:24.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:35:24.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T09:36:33.904+0000] {processor.py:157} INFO - Started process (PID=95226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:36:33.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:36:33.907+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:36:33.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:36:33.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:36:33.939+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:36:33.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:36:33.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:36:33.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:36:33.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T09:37:04.394+0000] {processor.py:157} INFO - Started process (PID=95251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:37:04.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:37:04.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:37:04.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:37:04.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:37:04.426+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:37:04.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:37:04.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:37:04.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:37:04.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T09:50:22.672+0000] {processor.py:157} INFO - Started process (PID=95276) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:50:22.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:50:22.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:22.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:50:22.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:50:22.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:22.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:50:22.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:22.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:50:22.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T09:50:53.218+0000] {processor.py:157} INFO - Started process (PID=95301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:50:53.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:50:53.223+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:53.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:50:53.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:50:53.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:53.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:50:53.261+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:50:53.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:50:53.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T09:53:36.181+0000] {processor.py:157} INFO - Started process (PID=95326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:53:36.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T09:53:36.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:53:36.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:53:36.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T09:53:36.214+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:53:36.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T09:53:36.232+0000] {logging_mixin.py:151} INFO - [2024-07-20T09:53:36.231+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T09:53:36.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-20T10:16:06.001+0000] {processor.py:157} INFO - Started process (PID=95351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T10:16:06.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T10:16:06.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:06.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T10:16:06.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T10:16:06.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:06.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T10:16:06.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:06.051+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T10:16:06.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T10:16:36.486+0000] {processor.py:157} INFO - Started process (PID=95376) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T10:16:36.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T10:16:36.488+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:36.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T10:16:36.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T10:16:36.513+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:36.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T10:16:36.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T10:16:36.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T10:16:36.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T11:17:02.943+0000] {processor.py:157} INFO - Started process (PID=95403) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:17:02.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T11:17:02.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:02.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:17:02.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:17:03.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:03.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:17:03.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:03.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T11:17:03.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-20T11:17:33.682+0000] {processor.py:157} INFO - Started process (PID=95428) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:17:33.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T11:17:33.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:33.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:17:33.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:17:33.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:33.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:17:33.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:17:33.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T11:17:33.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T11:55:28.864+0000] {processor.py:157} INFO - Started process (PID=95453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:55:28.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T11:55:28.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:28.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:55:28.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:55:28.891+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:28.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:55:28.902+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:28.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T11:55:28.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T11:55:59.338+0000] {processor.py:157} INFO - Started process (PID=95478) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:55:59.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T11:55:59.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:59.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:55:59.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T11:55:59.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:59.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T11:55:59.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T11:55:59.380+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T11:55:59.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T12:03:27.322+0000] {processor.py:157} INFO - Started process (PID=95505) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:03:27.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:03:27.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:03:27.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:03:27.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:03:27.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:03:27.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:03:27.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:03:27.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:03:27.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T12:04:59.529+0000] {processor.py:157} INFO - Started process (PID=95530) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:04:59.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:04:59.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:04:59.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:04:59.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:04:59.559+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:04:59.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:04:59.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:04:59.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:04:59.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T12:05:29.960+0000] {processor.py:157} INFO - Started process (PID=95555) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:05:29.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:05:29.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:05:29.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:05:29.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:05:29.984+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:05:29.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:05:29.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:05:29.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:05:30.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-20T12:18:14.517+0000] {processor.py:157} INFO - Started process (PID=95580) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:18:14.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:18:14.519+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:14.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:18:14.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:18:14.548+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:14.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:18:14.558+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:14.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:18:14.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T12:18:45.001+0000] {processor.py:157} INFO - Started process (PID=95605) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:18:45.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:18:45.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:45.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:18:45.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:18:45.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:45.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:18:45.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:18:45.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:18:45.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T12:29:26.201+0000] {processor.py:157} INFO - Started process (PID=95632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:29:26.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:29:26.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:29:26.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:29:26.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:29:26.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:29:26.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:29:26.289+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:29:26.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:29:26.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-20T12:30:58.523+0000] {processor.py:157} INFO - Started process (PID=95657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:30:58.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:30:58.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:30:58.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:30:58.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:30:58.554+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:30:58.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:30:58.564+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:30:58.564+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:30:58.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T12:31:28.948+0000] {processor.py:157} INFO - Started process (PID=95682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:31:28.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:31:28.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:31:28.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:31:28.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:31:28.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:31:28.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:31:28.980+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:31:28.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:31:28.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-20T12:32:32.247+0000] {processor.py:157} INFO - Started process (PID=95707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:32:32.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:32:32.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:32:32.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:32:32.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:32:32.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:32:32.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:32:32.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:32:32.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:32:32.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T12:48:15.360+0000] {processor.py:157} INFO - Started process (PID=95732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:48:15.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:48:15.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:48:15.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:48:15.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:48:15.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:48:15.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:48:15.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:48:15.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:48:15.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.430 seconds
[2024-07-20T12:49:53.103+0000] {processor.py:157} INFO - Started process (PID=95759) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:49:53.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:49:53.110+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:49:53.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:49:53.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:49:53.163+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:49:53.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:49:53.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:49:53.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:49:53.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-20T12:50:23.532+0000] {processor.py:157} INFO - Started process (PID=95784) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:50:23.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:50:23.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:23.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:50:23.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:50:23.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:23.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:50:23.573+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:23.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:50:23.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T12:50:53.927+0000] {processor.py:157} INFO - Started process (PID=95809) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:50:53.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:50:53.932+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:53.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:50:53.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:50:53.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:53.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:50:53.983+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:50:53.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:50:53.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T12:51:24.389+0000] {processor.py:157} INFO - Started process (PID=95834) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:51:24.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:51:24.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:24.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:51:24.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:51:24.419+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:24.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:51:24.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:24.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:51:24.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T12:51:54.837+0000] {processor.py:157} INFO - Started process (PID=95859) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:51:54.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:51:54.840+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:54.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:51:54.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:51:54.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:54.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:51:54.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:51:54.876+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:51:54.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T12:52:25.240+0000] {processor.py:157} INFO - Started process (PID=95884) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:52:25.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:52:25.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:25.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:52:25.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:52:25.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:25.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:52:25.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:25.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:52:25.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T12:52:55.676+0000] {processor.py:157} INFO - Started process (PID=95909) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:52:55.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:52:55.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:55.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:52:55.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:52:55.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:55.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:52:55.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:52:55.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:52:55.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T12:53:26.066+0000] {processor.py:157} INFO - Started process (PID=95934) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:53:26.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:53:26.071+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:26.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:53:26.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:53:26.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:26.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:53:26.107+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:26.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:53:26.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T12:53:56.542+0000] {processor.py:157} INFO - Started process (PID=95959) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:53:56.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:53:56.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:56.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:53:56.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:53:56.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:56.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:53:56.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:53:56.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:53:56.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T12:54:26.914+0000] {processor.py:157} INFO - Started process (PID=95984) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:54:26.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:54:26.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:26.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:54:26.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:54:26.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:26.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:54:26.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:26.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:54:26.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-20T12:54:57.326+0000] {processor.py:157} INFO - Started process (PID=96009) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:54:57.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:54:57.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:57.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:54:57.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:54:57.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:57.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:54:57.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:54:57.368+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:54:57.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T12:55:27.760+0000] {processor.py:157} INFO - Started process (PID=96034) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:55:27.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:55:27.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:27.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:55:27.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:55:27.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:27.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:55:27.799+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:27.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:55:27.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T12:55:58.214+0000] {processor.py:157} INFO - Started process (PID=96059) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:55:58.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:55:58.216+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:58.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:55:58.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:55:58.243+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:58.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:55:58.253+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:55:58.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:55:58.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T12:56:28.638+0000] {processor.py:157} INFO - Started process (PID=96084) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:56:28.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:56:28.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:28.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:56:28.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:56:28.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:28.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:56:28.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:28.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:56:28.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T12:56:59.070+0000] {processor.py:157} INFO - Started process (PID=96109) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:56:59.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:56:59.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:59.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:56:59.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:56:59.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:59.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:56:59.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:56:59.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:56:59.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T12:57:29.510+0000] {processor.py:157} INFO - Started process (PID=96134) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:57:29.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:57:29.515+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:29.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:57:29.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:57:29.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:29.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:57:29.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:29.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:57:29.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T12:57:59.970+0000] {processor.py:157} INFO - Started process (PID=96159) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:57:59.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:57:59.974+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:59.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:57:59.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:57:59.999+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:57:59.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:58:00.010+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:00.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:58:00.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T12:58:30.385+0000] {processor.py:157} INFO - Started process (PID=96184) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:58:30.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:58:30.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:30.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:58:30.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:58:30.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:30.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:58:30.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:58:30.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:58:30.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-20T12:59:00.885+0000] {processor.py:157} INFO - Started process (PID=96209) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:59:00.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:59:00.892+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:00.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:59:00.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:59:00.940+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:00.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:59:00.957+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:00.957+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:59:00.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-20T12:59:31.355+0000] {processor.py:157} INFO - Started process (PID=96234) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:59:31.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T12:59:31.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:31.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:59:31.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T12:59:31.389+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:31.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T12:59:31.400+0000] {logging_mixin.py:151} INFO - [2024-07-20T12:59:31.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T12:59:31.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T13:00:01.768+0000] {processor.py:157} INFO - Started process (PID=96259) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:00:01.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:00:01.773+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:01.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:00:01.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:00:01.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:01.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:00:01.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:01.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:00:01.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T13:00:32.185+0000] {processor.py:157} INFO - Started process (PID=96284) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:00:32.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:00:32.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:32.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:00:32.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:00:32.215+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:32.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:00:32.225+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:00:32.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:00:32.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:01:02.575+0000] {processor.py:157} INFO - Started process (PID=96309) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:01:02.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:01:02.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:02.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:01:02.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:01:02.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:02.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:01:02.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:02.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:01:02.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T13:01:32.957+0000] {processor.py:157} INFO - Started process (PID=96334) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:01:32.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:01:32.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:32.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:01:32.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:01:32.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:32.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:01:32.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:01:32.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:01:33.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T13:02:03.401+0000] {processor.py:157} INFO - Started process (PID=96359) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:02:03.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:02:03.405+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:03.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:02:03.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:02:03.443+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:03.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:02:03.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:03.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:02:03.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T13:02:33.868+0000] {processor.py:157} INFO - Started process (PID=96384) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:02:33.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:02:33.878+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:33.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:02:33.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:02:33.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:33.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:02:33.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:02:33.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:02:33.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-20T13:03:04.345+0000] {processor.py:157} INFO - Started process (PID=96409) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:03:04.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:03:04.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:04.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:03:04.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:03:04.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:04.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:03:04.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:04.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:03:04.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T13:03:34.828+0000] {processor.py:157} INFO - Started process (PID=96434) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:03:34.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:03:34.831+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:34.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:03:34.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:03:34.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:34.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:03:34.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:03:34.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:03:34.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T13:04:05.275+0000] {processor.py:157} INFO - Started process (PID=96459) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:04:05.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:04:05.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:05.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:04:05.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:04:05.316+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:05.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:04:05.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:05.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:04:05.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T13:04:35.695+0000] {processor.py:157} INFO - Started process (PID=96484) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:04:35.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:04:35.714+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:35.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:04:35.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:04:35.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:35.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:04:35.753+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:04:35.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:04:35.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T13:05:06.182+0000] {processor.py:157} INFO - Started process (PID=96509) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:05:06.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:05:06.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:06.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:05:06.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:05:06.226+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:06.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:05:06.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:06.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:05:06.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T13:05:36.596+0000] {processor.py:157} INFO - Started process (PID=96534) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:05:36.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:05:36.600+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:36.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:05:36.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:05:36.629+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:36.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:05:36.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:05:36.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:05:36.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T13:06:07.051+0000] {processor.py:157} INFO - Started process (PID=96559) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:06:07.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:06:07.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:07.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:06:07.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:06:07.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:07.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:06:07.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:07.092+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:06:07.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T13:06:37.438+0000] {processor.py:157} INFO - Started process (PID=96584) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:06:37.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:06:37.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:37.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:06:37.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:06:37.469+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:37.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:06:37.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:06:37.478+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:06:37.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T13:07:07.843+0000] {processor.py:157} INFO - Started process (PID=96609) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:07:07.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:07:07.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:07.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:07:07.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:07:07.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:07.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:07:07.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:07.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:07:07.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T13:07:38.299+0000] {processor.py:157} INFO - Started process (PID=96634) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:07:38.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:07:38.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:38.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:07:38.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:07:38.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:38.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:07:38.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:07:38.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:07:38.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:08:08.778+0000] {processor.py:157} INFO - Started process (PID=96659) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:08:08.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:08:08.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:08.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:08:08.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:08:08.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:08.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:08:08.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:08.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:08:08.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T13:08:39.229+0000] {processor.py:157} INFO - Started process (PID=96684) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:08:39.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:08:39.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:39.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:08:39.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:08:39.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:39.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:08:39.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:08:39.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:08:39.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T13:09:09.667+0000] {processor.py:157} INFO - Started process (PID=96709) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:09:09.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:09:09.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:09.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:09:09.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:09:09.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:09.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:09:09.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:09.729+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:09:09.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T13:09:40.161+0000] {processor.py:157} INFO - Started process (PID=96734) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:09:40.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:09:40.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:40.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:09:40.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:09:40.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:40.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:09:40.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:09:40.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:09:40.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T13:10:10.634+0000] {processor.py:157} INFO - Started process (PID=96759) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:10:10.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:10:10.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:10.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:10:10.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:10:10.661+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:10.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:10:10.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:10.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:10:10.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T13:10:41.095+0000] {processor.py:157} INFO - Started process (PID=96784) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:10:41.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:10:41.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:41.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:10:41.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:10:41.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:41.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:10:41.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:10:41.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:10:41.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T13:11:11.588+0000] {processor.py:157} INFO - Started process (PID=96809) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:11:11.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:11:11.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:11.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:11:11.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:11:11.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:11.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:11:11.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:11.633+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:11:11.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T13:11:42.035+0000] {processor.py:157} INFO - Started process (PID=96834) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:11:42.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:11:42.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:42.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:11:42.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:11:42.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:42.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:11:42.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:11:42.090+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:11:42.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T13:12:12.448+0000] {processor.py:157} INFO - Started process (PID=96859) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:12:12.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:12:12.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:12.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:12:12.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:12:12.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:12.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:12:12.487+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:12.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:12:12.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T13:12:42.877+0000] {processor.py:157} INFO - Started process (PID=96884) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:12:42.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:12:42.881+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:42.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:12:42.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:12:42.908+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:42.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:12:42.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:12:42.917+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:12:42.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T13:13:13.322+0000] {processor.py:157} INFO - Started process (PID=96909) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:13:13.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:13:13.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:13.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:13:13.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:13:13.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:13.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:13:13.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:13.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:13:13.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T13:13:43.856+0000] {processor.py:157} INFO - Started process (PID=96934) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:13:43.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:13:43.864+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:43.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:13:43.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:13:43.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:43.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:13:43.938+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:13:43.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:13:43.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-20T13:14:14.398+0000] {processor.py:157} INFO - Started process (PID=96959) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:14:14.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:14:14.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:14.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:14:14.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:14:14.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:14.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:14:14.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:14.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:14:14.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T13:14:44.761+0000] {processor.py:157} INFO - Started process (PID=96984) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:14:44.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:14:44.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:44.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:14:44.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:14:44.791+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:44.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:14:44.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:14:44.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:14:44.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T13:15:15.179+0000] {processor.py:157} INFO - Started process (PID=97009) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:15:15.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:15:15.183+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:15.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:15:15.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:15:15.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:15.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:15:15.223+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:15.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:15:15.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T13:15:45.658+0000] {processor.py:157} INFO - Started process (PID=97034) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:15:45.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:15:45.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:45.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:15:45.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:15:45.703+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:45.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:15:45.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:15:45.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:15:45.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T13:16:16.107+0000] {processor.py:157} INFO - Started process (PID=97059) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:16:16.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:16:16.110+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:16.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:16:16.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:16:16.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:16.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:16:16.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:16.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:16:16.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:16:46.604+0000] {processor.py:157} INFO - Started process (PID=97084) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:16:46.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:16:46.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:46.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:16:46.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:16:46.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:46.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:16:46.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:16:46.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:16:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-20T13:17:22.524+0000] {processor.py:157} INFO - Started process (PID=97111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:17:22.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:17:22.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:22.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:17:22.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:17:22.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:22.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:17:22.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:22.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:17:22.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T13:17:52.997+0000] {processor.py:157} INFO - Started process (PID=97136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:17:52.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:17:53.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:53.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:17:53.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:17:53.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:53.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:17:53.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:17:53.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:17:53.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:18:23.424+0000] {processor.py:157} INFO - Started process (PID=97161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:18:23.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:18:23.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:23.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:18:23.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:18:23.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:23.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:18:23.474+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:23.474+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:18:23.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T13:18:53.915+0000] {processor.py:157} INFO - Started process (PID=97186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:18:53.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:18:53.919+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:53.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:18:53.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:18:53.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:53.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:18:53.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:18:53.959+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:18:53.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T13:19:24.376+0000] {processor.py:157} INFO - Started process (PID=97211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:19:24.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:19:24.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:24.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:19:24.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:19:24.421+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:24.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:19:24.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:24.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:19:24.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T13:19:54.840+0000] {processor.py:157} INFO - Started process (PID=97236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:19:54.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:19:54.843+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:54.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:19:54.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:19:54.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:54.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:19:54.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:19:54.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:19:54.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T13:20:25.253+0000] {processor.py:157} INFO - Started process (PID=97261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:20:25.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:20:25.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:25.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:20:25.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:20:25.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:25.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:20:25.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:25.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:20:25.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T13:20:55.660+0000] {processor.py:157} INFO - Started process (PID=97286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:20:55.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:20:55.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:55.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:20:55.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:20:55.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:55.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:20:55.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:20:55.704+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:20:55.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T13:21:26.140+0000] {processor.py:157} INFO - Started process (PID=97311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:21:26.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:21:26.151+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:26.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:21:26.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:21:26.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:26.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:21:26.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:26.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:21:26.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T13:21:56.612+0000] {processor.py:157} INFO - Started process (PID=97336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:21:56.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:21:56.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:56.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:21:56.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:21:56.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:56.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:21:56.651+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:21:56.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:21:56.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T13:22:27.100+0000] {processor.py:157} INFO - Started process (PID=97361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:22:27.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:22:27.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:27.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:22:27.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:22:27.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:27.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:22:27.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:27.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:22:27.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T13:22:57.572+0000] {processor.py:157} INFO - Started process (PID=97386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:22:57.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:22:57.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:57.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:22:57.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:22:57.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:57.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:22:57.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:22:57.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:22:57.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T13:23:28.044+0000] {processor.py:157} INFO - Started process (PID=97411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:23:28.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:23:28.047+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:28.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:23:28.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:23:28.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:28.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:23:28.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:28.083+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:23:28.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T13:23:58.505+0000] {processor.py:157} INFO - Started process (PID=97436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:23:58.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:23:58.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:58.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:23:58.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:23:58.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:58.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:23:58.553+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:23:58.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:23:58.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T13:24:28.923+0000] {processor.py:157} INFO - Started process (PID=97461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:24:28.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:24:28.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:28.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:24:28.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:24:28.954+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:28.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:24:28.965+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:28.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:24:28.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:24:59.385+0000] {processor.py:157} INFO - Started process (PID=97486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:24:59.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:24:59.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:59.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:24:59.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:24:59.417+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:59.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:24:59.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:24:59.428+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:24:59.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T13:25:29.847+0000] {processor.py:157} INFO - Started process (PID=97511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:25:29.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:25:29.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:25:29.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:25:29.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:25:29.875+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:25:29.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:25:29.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:25:29.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:25:29.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T13:26:00.292+0000] {processor.py:157} INFO - Started process (PID=97536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:26:00.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:26:00.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:00.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:26:00.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:26:00.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:00.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:26:00.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:00.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:26:00.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T13:26:30.793+0000] {processor.py:157} INFO - Started process (PID=97561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:26:30.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:26:30.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:30.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:26:30.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:26:30.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:30.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:26:30.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:26:30.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:26:30.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T13:27:01.302+0000] {processor.py:157} INFO - Started process (PID=97586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:27:01.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:27:01.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:01.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:27:01.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:27:01.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:01.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:27:01.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:01.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:27:01.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T13:27:31.833+0000] {processor.py:157} INFO - Started process (PID=97611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:27:31.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:27:31.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:31.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:27:31.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:27:31.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:31.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:27:31.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:27:31.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:27:31.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T13:28:02.274+0000] {processor.py:157} INFO - Started process (PID=97636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:28:02.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:28:02.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:02.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:28:02.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:28:02.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:02.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:28:02.316+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:02.316+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:28:02.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:28:32.791+0000] {processor.py:157} INFO - Started process (PID=97661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:28:32.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:28:32.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:32.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:28:32.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:28:32.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:32.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:28:32.845+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:28:32.845+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:28:32.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-20T13:29:03.185+0000] {processor.py:157} INFO - Started process (PID=97686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:29:03.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:29:03.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:03.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:29:03.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:29:03.220+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:03.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:29:03.232+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:03.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:29:03.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T13:29:33.652+0000] {processor.py:157} INFO - Started process (PID=97711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:29:33.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:29:33.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:33.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:29:33.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:29:33.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:33.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:29:33.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:29:33.697+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:29:33.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T13:30:04.050+0000] {processor.py:157} INFO - Started process (PID=97736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:30:04.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:30:04.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:04.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:30:04.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:30:04.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:04.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:30:04.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:04.089+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:30:04.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T13:30:34.452+0000] {processor.py:157} INFO - Started process (PID=97761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:30:34.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:30:34.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:34.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:30:34.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:30:34.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:34.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:30:34.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:30:34.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:30:34.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T13:31:04.906+0000] {processor.py:157} INFO - Started process (PID=97786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:31:04.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:31:04.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:04.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:31:04.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:31:04.940+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:04.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:31:04.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:04.949+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:31:04.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T13:31:35.351+0000] {processor.py:157} INFO - Started process (PID=97811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:31:35.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:31:35.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:35.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:31:35.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:31:35.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:35.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:31:35.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:31:35.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:31:35.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:32:05.855+0000] {processor.py:157} INFO - Started process (PID=97836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:32:05.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:32:05.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:05.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:32:05.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:32:05.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:05.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:32:05.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:05.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:32:05.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T13:32:36.334+0000] {processor.py:157} INFO - Started process (PID=97861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:32:36.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:32:36.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:36.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:32:36.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:32:36.378+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:36.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:32:36.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:32:36.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:32:36.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T13:33:06.799+0000] {processor.py:157} INFO - Started process (PID=97886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:33:06.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:33:06.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:06.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:33:06.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:33:06.831+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:06.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:33:06.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:06.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:33:06.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T13:33:37.259+0000] {processor.py:157} INFO - Started process (PID=97911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:33:37.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:33:37.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:37.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:33:37.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:33:37.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:37.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:33:37.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:33:37.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:33:37.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T13:34:07.759+0000] {processor.py:157} INFO - Started process (PID=97936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:34:07.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:34:07.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:07.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:34:07.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:34:07.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:07.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:34:07.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:07.809+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:34:07.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-20T13:34:38.216+0000] {processor.py:157} INFO - Started process (PID=97961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:34:38.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:34:38.220+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:38.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:34:38.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:34:38.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:38.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:34:38.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:34:38.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:34:38.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T13:35:08.659+0000] {processor.py:157} INFO - Started process (PID=97986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:35:08.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:35:08.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:08.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:35:08.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:35:08.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:08.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:35:08.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:08.704+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:35:08.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T13:35:39.132+0000] {processor.py:157} INFO - Started process (PID=98011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:35:39.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:35:39.142+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:39.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:35:39.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:35:39.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:39.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:35:39.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:35:39.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:35:39.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-20T13:36:09.641+0000] {processor.py:157} INFO - Started process (PID=98036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:36:09.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:36:09.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:09.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:36:09.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:36:09.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:09.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:36:09.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:09.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:36:09.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T13:36:40.160+0000] {processor.py:157} INFO - Started process (PID=98061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:36:40.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:36:40.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:40.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:36:40.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:36:40.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:40.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:36:40.214+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:36:40.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:36:40.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T13:37:10.635+0000] {processor.py:157} INFO - Started process (PID=98086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:37:10.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:37:10.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:10.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:37:10.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:37:10.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:10.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:37:10.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:10.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:37:10.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T13:37:41.153+0000] {processor.py:157} INFO - Started process (PID=98111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:37:41.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:37:41.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:41.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:37:41.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:37:41.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:41.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:37:41.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:37:41.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:37:41.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-20T13:38:11.663+0000] {processor.py:157} INFO - Started process (PID=98136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:38:11.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:38:11.667+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:11.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:38:11.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:38:11.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:11.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:38:11.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:11.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:38:11.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T13:38:42.147+0000] {processor.py:157} INFO - Started process (PID=98161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:38:42.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:38:42.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:42.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:38:42.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:38:42.183+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:42.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:38:42.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:38:42.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:38:42.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T13:39:12.597+0000] {processor.py:157} INFO - Started process (PID=98186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:39:12.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:39:12.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:12.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:39:12.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:39:12.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:12.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:39:12.642+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:12.642+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:39:12.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T13:39:43.115+0000] {processor.py:157} INFO - Started process (PID=98211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:39:43.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:39:43.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:43.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:39:43.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:39:43.146+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:43.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:39:43.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:39:43.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:39:43.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T13:40:13.615+0000] {processor.py:157} INFO - Started process (PID=98236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:40:13.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:40:13.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:40:13.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:40:13.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:40:13.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:40:13.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:40:13.678+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:40:13.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:40:13.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-20T13:41:13.309+0000] {processor.py:157} INFO - Started process (PID=98263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:41:13.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:41:13.314+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:13.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:41:13.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:41:13.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:13.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:41:13.353+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:13.353+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:41:13.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T13:41:43.780+0000] {processor.py:157} INFO - Started process (PID=98288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:41:43.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:41:43.785+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:43.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:41:43.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:41:43.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:43.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:41:43.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:41:43.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:41:43.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T13:42:19.034+0000] {processor.py:157} INFO - Started process (PID=98313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:42:19.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:42:19.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:42:19.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:42:19.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:42:19.067+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:42:19.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:42:19.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:42:19.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:42:19.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T13:59:20.505+0000] {processor.py:157} INFO - Started process (PID=98338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:59:20.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:59:20.513+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:20.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:59:20.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:59:20.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:20.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:59:20.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:20.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:59:20.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-20T13:59:51.216+0000] {processor.py:157} INFO - Started process (PID=98365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:59:51.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T13:59:51.220+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:51.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:59:51.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T13:59:51.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:51.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T13:59:51.267+0000] {logging_mixin.py:151} INFO - [2024-07-20T13:59:51.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T13:59:51.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-20T14:00:49.334+0000] {processor.py:157} INFO - Started process (PID=98390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:00:49.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:00:49.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:00:49.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:00:49.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:00:49.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:00:49.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:00:49.395+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:00:49.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:00:49.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-20T14:01:19.868+0000] {processor.py:157} INFO - Started process (PID=98415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:01:19.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:01:19.871+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:19.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:01:19.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:01:19.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:19.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:01:19.911+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:19.911+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:01:19.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:01:50.410+0000] {processor.py:157} INFO - Started process (PID=98440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:01:50.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:01:50.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:50.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:01:50.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:01:50.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:50.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:01:50.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:01:50.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:01:50.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T14:02:20.874+0000] {processor.py:157} INFO - Started process (PID=98465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:02:20.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:02:20.878+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:20.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:02:20.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:02:20.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:20.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:02:20.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:20.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:02:20.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T14:02:51.305+0000] {processor.py:157} INFO - Started process (PID=98490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:02:51.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:02:51.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:51.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:02:51.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:02:51.337+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:51.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:02:51.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:02:51.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:02:51.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:03:21.732+0000] {processor.py:157} INFO - Started process (PID=98515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:03:21.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:03:21.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:21.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:03:21.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:03:21.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:21.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:03:21.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:21.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:03:21.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:03:52.286+0000] {processor.py:157} INFO - Started process (PID=98540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:03:52.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:03:52.289+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:52.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:03:52.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:03:52.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:52.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:03:52.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:03:52.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:03:52.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:04:22.942+0000] {processor.py:157} INFO - Started process (PID=98565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:04:22.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:04:22.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:22.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:04:22.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:04:22.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:22.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:04:23.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:23.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:04:23.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-20T14:04:53.436+0000] {processor.py:157} INFO - Started process (PID=98590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:04:53.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:04:53.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:53.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:04:53.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:04:53.465+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:53.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:04:53.475+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:04:53.475+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:04:53.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:05:23.879+0000] {processor.py:157} INFO - Started process (PID=98615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:05:23.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:05:23.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:23.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:05:23.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:05:23.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:23.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:05:23.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:23.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:05:23.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T14:05:54.311+0000] {processor.py:157} INFO - Started process (PID=98640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:05:54.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:05:54.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:54.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:05:54.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:05:54.345+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:54.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:05:54.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:05:54.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:05:54.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:06:24.739+0000] {processor.py:157} INFO - Started process (PID=98665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:06:24.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:06:24.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:24.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:06:24.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:06:24.774+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:24.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:06:24.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:24.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:06:24.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:06:55.165+0000] {processor.py:157} INFO - Started process (PID=98690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:06:55.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:06:55.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:55.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:06:55.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:06:55.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:55.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:06:55.205+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:06:55.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:06:55.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:07:25.631+0000] {processor.py:157} INFO - Started process (PID=98715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:07:25.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:07:25.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:25.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:07:25.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:07:25.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:25.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:07:25.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:25.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:07:25.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:07:56.056+0000] {processor.py:157} INFO - Started process (PID=98740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:07:56.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:07:56.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:56.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:07:56.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:07:56.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:56.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:07:56.095+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:07:56.095+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:07:56.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:08:26.476+0000] {processor.py:157} INFO - Started process (PID=98765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:08:26.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:08:26.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:26.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:08:26.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:08:26.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:26.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:08:26.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:26.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:08:26.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T14:08:56.912+0000] {processor.py:157} INFO - Started process (PID=98790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:08:56.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:08:56.915+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:56.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:08:56.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:08:56.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:56.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:08:56.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:08:56.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:08:56.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:09:27.379+0000] {processor.py:157} INFO - Started process (PID=98815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:09:27.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:09:27.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:27.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:09:27.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:09:27.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:27.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:09:27.417+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:27.417+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:09:27.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T14:09:57.891+0000] {processor.py:157} INFO - Started process (PID=98840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:09:57.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:09:57.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:57.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:09:57.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:09:57.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:57.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:09:57.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:09:57.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:09:57.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T14:10:28.332+0000] {processor.py:157} INFO - Started process (PID=98865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:10:28.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:10:28.337+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:28.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:10:28.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:10:28.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:28.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:10:28.376+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:28.376+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:10:28.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:10:58.818+0000] {processor.py:157} INFO - Started process (PID=98890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:10:58.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:10:58.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:58.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:10:58.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:10:58.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:58.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:10:58.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:10:58.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:10:58.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:11:29.353+0000] {processor.py:157} INFO - Started process (PID=98915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:11:29.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:11:29.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:29.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:11:29.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:11:29.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:29.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:11:29.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:29.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:11:29.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:11:59.783+0000] {processor.py:157} INFO - Started process (PID=98940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:11:59.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:11:59.786+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:59.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:11:59.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:11:59.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:59.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:11:59.823+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:11:59.823+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:11:59.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T14:12:30.169+0000] {processor.py:157} INFO - Started process (PID=98965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:12:30.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:12:30.171+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:12:30.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:12:30.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:12:30.201+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:12:30.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:12:30.215+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:12:30.215+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:12:30.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T14:13:00.595+0000] {processor.py:157} INFO - Started process (PID=98990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:13:00.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:13:00.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:00.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:13:00.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:13:00.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:00.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:13:00.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:00.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:13:00.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T14:13:31.055+0000] {processor.py:157} INFO - Started process (PID=99015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:13:31.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:13:31.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:31.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:13:31.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:13:31.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:31.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:13:31.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:13:31.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:13:31.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:14:01.492+0000] {processor.py:157} INFO - Started process (PID=99040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:14:01.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:14:01.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:01.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:14:01.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:14:01.524+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:01.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:14:01.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:01.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:14:01.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:14:31.932+0000] {processor.py:157} INFO - Started process (PID=99065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:14:31.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:14:31.935+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:31.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:14:31.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:14:31.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:31.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:14:31.978+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:14:31.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:14:31.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T14:15:02.356+0000] {processor.py:157} INFO - Started process (PID=99090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:15:02.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:15:02.361+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:02.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:15:02.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:15:02.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:02.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:15:02.411+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:02.411+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:15:02.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T14:15:32.830+0000] {processor.py:157} INFO - Started process (PID=99115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:15:32.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:15:32.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:32.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:15:32.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:15:32.864+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:32.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:15:32.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:15:32.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:15:32.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T14:16:03.220+0000] {processor.py:157} INFO - Started process (PID=99140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:16:03.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:16:03.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:03.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:16:03.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:16:03.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:03.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:16:03.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:03.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:16:03.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:16:33.681+0000] {processor.py:157} INFO - Started process (PID=99165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:16:33.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:16:33.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:33.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:16:33.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:16:33.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:33.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:16:33.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:16:33.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:16:33.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:17:04.060+0000] {processor.py:157} INFO - Started process (PID=99190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:17:04.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:17:04.062+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:04.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:17:04.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:17:04.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:04.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:17:04.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:04.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:17:04.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-20T14:17:34.534+0000] {processor.py:157} INFO - Started process (PID=99215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:17:34.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:17:34.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:34.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:17:34.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:17:34.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:34.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:17:34.573+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:17:34.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:17:34.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T14:18:04.889+0000] {processor.py:157} INFO - Started process (PID=99240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:18:04.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:18:04.891+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:04.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:18:04.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:18:04.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:04.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:18:04.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:04.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:18:04.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:18:35.311+0000] {processor.py:157} INFO - Started process (PID=99265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:18:35.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:18:35.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:35.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:18:35.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:18:35.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:35.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:18:35.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:18:35.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:18:35.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T14:19:05.831+0000] {processor.py:157} INFO - Started process (PID=99290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:19:05.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:19:05.835+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:05.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:19:05.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:19:05.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:05.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:19:05.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:05.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:19:05.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-20T14:19:36.302+0000] {processor.py:157} INFO - Started process (PID=99315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:19:36.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:19:36.307+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:36.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:19:36.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:19:36.337+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:36.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:19:36.347+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:19:36.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:19:36.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T14:20:06.775+0000] {processor.py:157} INFO - Started process (PID=99340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:20:06.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:20:06.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:06.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:20:06.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:20:06.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:06.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:20:06.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:06.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:20:06.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-20T14:20:37.259+0000] {processor.py:157} INFO - Started process (PID=99365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:20:37.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:20:37.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:37.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:20:37.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:20:37.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:37.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:20:37.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:20:37.326+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:20:37.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-20T14:21:07.751+0000] {processor.py:157} INFO - Started process (PID=99390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:21:07.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:21:07.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:07.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:21:07.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:21:07.794+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:07.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:21:07.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:07.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:21:07.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T14:21:38.243+0000] {processor.py:157} INFO - Started process (PID=99415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:21:38.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:21:38.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:38.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:21:38.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:21:38.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:38.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:21:38.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:21:38.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:21:38.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T14:22:08.676+0000] {processor.py:157} INFO - Started process (PID=99440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:22:08.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:22:08.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:08.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:22:08.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:22:08.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:08.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:22:08.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:08.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:22:08.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-20T14:22:39.163+0000] {processor.py:157} INFO - Started process (PID=99465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:22:39.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:22:39.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:39.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:22:39.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:22:39.225+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:39.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:22:39.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:22:39.245+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:22:39.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-20T14:23:09.708+0000] {processor.py:157} INFO - Started process (PID=99490) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:23:09.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:23:09.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:09.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:23:09.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:23:09.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:09.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:23:09.755+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:09.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:23:09.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T14:23:40.210+0000] {processor.py:157} INFO - Started process (PID=99515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:23:40.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:23:40.218+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:40.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:23:40.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:23:40.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:40.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:23:40.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:23:40.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:23:40.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T14:24:10.617+0000] {processor.py:157} INFO - Started process (PID=99540) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:24:10.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:24:10.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:10.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:24:10.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:24:10.648+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:10.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:24:10.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:10.658+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:24:10.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:24:41.045+0000] {processor.py:157} INFO - Started process (PID=99565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:24:41.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:24:41.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:41.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:24:41.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:24:41.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:41.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:24:41.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:24:41.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:24:41.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T14:25:11.472+0000] {processor.py:157} INFO - Started process (PID=99590) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:25:11.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:25:11.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:11.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:25:11.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:25:11.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:11.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:25:11.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:11.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:25:11.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T14:25:41.919+0000] {processor.py:157} INFO - Started process (PID=99615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:25:41.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:25:41.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:41.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:25:41.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:25:41.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:41.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:25:41.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:25:41.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:25:41.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:26:12.387+0000] {processor.py:157} INFO - Started process (PID=99640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:26:12.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:26:12.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:12.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:26:12.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:26:12.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:12.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:26:12.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:12.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:26:12.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:26:42.830+0000] {processor.py:157} INFO - Started process (PID=99665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:26:42.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:26:42.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:42.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:26:42.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:26:42.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:42.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:26:42.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:26:42.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:26:42.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:27:13.259+0000] {processor.py:157} INFO - Started process (PID=99690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:27:13.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:27:13.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:13.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:27:13.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:27:13.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:13.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:27:13.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:13.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:27:13.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:27:43.716+0000] {processor.py:157} INFO - Started process (PID=99715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:27:43.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:27:43.720+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:43.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:27:43.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:27:43.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:43.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:27:43.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:27:43.758+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:27:43.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:28:14.143+0000] {processor.py:157} INFO - Started process (PID=99740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:28:14.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:28:14.149+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:14.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:28:14.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:28:14.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:14.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:28:14.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:14.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:28:14.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T14:28:44.629+0000] {processor.py:157} INFO - Started process (PID=99765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:28:44.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:28:44.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:44.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:28:44.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:28:44.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:44.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:28:44.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:28:44.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:28:44.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-20T14:29:15.122+0000] {processor.py:157} INFO - Started process (PID=99790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:29:15.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:29:15.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:15.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:29:15.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:29:15.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:15.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:29:15.170+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:15.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:29:15.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T14:29:45.600+0000] {processor.py:157} INFO - Started process (PID=99815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:29:45.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:29:45.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:45.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:29:45.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:29:45.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:45.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:29:45.648+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:29:45.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:29:45.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T14:30:16.106+0000] {processor.py:157} INFO - Started process (PID=99840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:30:16.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:30:16.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:16.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:30:16.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:30:16.141+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:16.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:30:16.151+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:16.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:30:16.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T14:30:46.567+0000] {processor.py:157} INFO - Started process (PID=99865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:30:46.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:30:46.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:46.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:30:46.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:30:46.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:46.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:30:46.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:30:46.602+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:30:46.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-20T14:31:17.075+0000] {processor.py:157} INFO - Started process (PID=99890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:31:17.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:31:17.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:17.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:31:17.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:31:17.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:17.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:31:17.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:17.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:31:17.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:31:47.488+0000] {processor.py:157} INFO - Started process (PID=99915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:31:47.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:31:47.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:47.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:31:47.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:31:47.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:47.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:31:47.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:31:47.527+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:31:47.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T14:32:17.879+0000] {processor.py:157} INFO - Started process (PID=99940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:32:17.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:32:17.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:17.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:32:17.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:32:17.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:17.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:32:17.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:17.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:32:17.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:32:48.298+0000] {processor.py:157} INFO - Started process (PID=99965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:32:48.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:32:48.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:48.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:32:48.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:32:48.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:48.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:32:48.338+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:32:48.338+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:32:48.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:33:18.780+0000] {processor.py:157} INFO - Started process (PID=99990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:33:18.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:33:18.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:18.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:33:18.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:33:18.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:18.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:33:18.824+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:18.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:33:18.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:33:49.255+0000] {processor.py:157} INFO - Started process (PID=316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:33:49.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:33:49.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:49.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:33:49.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:33:49.287+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:49.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:33:49.298+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:33:49.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:33:49.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:34:19.701+0000] {processor.py:157} INFO - Started process (PID=341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:34:19.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:34:19.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:19.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:34:19.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:34:19.731+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:19.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:34:19.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:19.740+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:34:19.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T14:34:50.201+0000] {processor.py:157} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:34:50.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:34:50.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:50.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:34:50.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:34:50.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:50.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:34:50.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:34:50.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:34:50.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:35:20.649+0000] {processor.py:157} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:35:20.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:35:20.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:20.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:35:20.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:35:20.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:20.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:35:20.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:20.695+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:35:20.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T14:35:51.204+0000] {processor.py:157} INFO - Started process (PID=416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:35:51.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:35:51.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:51.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:35:51.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:35:51.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:51.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:35:51.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:35:51.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:35:51.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T14:36:21.737+0000] {processor.py:157} INFO - Started process (PID=441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:36:21.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:36:21.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:21.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:36:21.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:36:21.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:21.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:36:21.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:21.793+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:36:21.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T14:36:52.298+0000] {processor.py:157} INFO - Started process (PID=466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:36:52.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:36:52.304+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:52.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:36:52.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:36:52.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:52.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:36:52.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:36:52.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:36:52.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:37:22.708+0000] {processor.py:157} INFO - Started process (PID=491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:37:22.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:37:22.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:22.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:37:22.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:37:22.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:22.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:37:22.753+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:22.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:37:22.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T14:37:53.072+0000] {processor.py:157} INFO - Started process (PID=516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:37:53.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:37:53.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:53.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:37:53.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:37:53.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:53.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:37:53.111+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:37:53.111+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:37:53.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:38:23.493+0000] {processor.py:157} INFO - Started process (PID=541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:38:23.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:38:23.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:23.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:38:23.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:38:23.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:23.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:38:23.529+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:23.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:38:23.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-20T14:38:53.914+0000] {processor.py:157} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:38:53.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:38:53.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:53.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:38:53.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:38:53.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:53.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:38:53.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:38:53.959+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:38:53.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T14:39:24.418+0000] {processor.py:157} INFO - Started process (PID=591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:39:24.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:39:24.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:24.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:39:24.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:39:24.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:24.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:39:24.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:24.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:39:24.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T14:39:54.901+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:39:54.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:39:54.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:54.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:39:54.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:39:54.930+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:54.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:39:54.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:39:54.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:39:54.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:40:25.288+0000] {processor.py:157} INFO - Started process (PID=641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:40:25.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:40:25.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:25.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:40:25.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:40:25.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:25.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:40:25.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:25.331+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:40:25.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:40:55.772+0000] {processor.py:157} INFO - Started process (PID=666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:40:55.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:40:55.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:55.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:40:55.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:40:55.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:55.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:40:55.817+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:40:55.817+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:40:55.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:41:26.229+0000] {processor.py:157} INFO - Started process (PID=691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:41:26.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:41:26.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:26.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:41:26.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:41:26.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:26.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:41:26.275+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:26.275+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:41:26.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T14:41:56.721+0000] {processor.py:157} INFO - Started process (PID=716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:41:56.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:41:56.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:56.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:41:56.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:41:56.755+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:56.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:41:56.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:41:56.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:41:56.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:42:27.132+0000] {processor.py:157} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:42:27.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:42:27.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:27.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:42:27.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:42:27.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:27.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:42:27.172+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:27.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:42:27.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:42:57.591+0000] {processor.py:157} INFO - Started process (PID=766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:42:57.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:42:57.594+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:57.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:42:57.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:42:57.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:57.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:42:57.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:42:57.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:42:57.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:43:28.022+0000] {processor.py:157} INFO - Started process (PID=791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:43:28.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:43:28.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:28.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:43:28.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:43:28.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:28.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:43:28.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:28.061+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:43:28.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:43:58.443+0000] {processor.py:157} INFO - Started process (PID=816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:43:58.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:43:58.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:58.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:43:58.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:43:58.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:58.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:43:58.487+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:43:58.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:43:58.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:44:28.947+0000] {processor.py:157} INFO - Started process (PID=841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:44:28.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:44:28.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:28.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:44:28.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:44:28.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:28.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:44:28.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:28.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:44:28.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:44:59.263+0000] {processor.py:157} INFO - Started process (PID=866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:44:59.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:44:59.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:59.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:44:59.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:44:59.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:59.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:44:59.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:44:59.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:44:59.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T14:45:29.690+0000] {processor.py:157} INFO - Started process (PID=891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:45:29.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:45:29.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:45:29.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:45:29.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:45:29.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:45:29.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:45:29.730+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:45:29.730+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:45:29.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:46:00.094+0000] {processor.py:157} INFO - Started process (PID=916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:46:00.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:46:00.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:00.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:46:00.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:46:00.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:00.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:46:00.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:00.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:46:00.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:46:30.510+0000] {processor.py:157} INFO - Started process (PID=941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:46:30.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:46:30.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:30.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:46:30.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:46:30.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:30.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:46:30.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:46:30.557+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:46:30.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T14:47:00.962+0000] {processor.py:157} INFO - Started process (PID=966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:47:00.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:47:00.965+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:00.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:47:00.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:47:00.994+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:00.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:47:01.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:01.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:47:01.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:47:31.375+0000] {processor.py:157} INFO - Started process (PID=991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:47:31.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:47:31.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:31.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:47:31.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:47:31.409+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:31.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:47:31.419+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:47:31.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:47:31.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:48:01.917+0000] {processor.py:157} INFO - Started process (PID=1016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:48:01.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:48:01.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:01.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:48:01.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:48:01.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:01.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:48:01.957+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:01.956+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:48:01.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T14:48:32.344+0000] {processor.py:157} INFO - Started process (PID=1041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:48:32.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:48:32.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:32.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:48:32.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:48:32.378+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:32.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:48:32.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:48:32.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:48:32.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T14:49:02.823+0000] {processor.py:157} INFO - Started process (PID=1066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:49:02.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:49:02.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:02.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:49:02.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:49:02.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:02.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:49:02.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:02.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:49:02.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T14:49:33.318+0000] {processor.py:157} INFO - Started process (PID=1091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:49:33.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:49:33.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:33.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:49:33.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:49:33.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:33.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:49:33.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:49:33.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:49:33.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T14:50:03.808+0000] {processor.py:157} INFO - Started process (PID=1116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:50:03.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:50:03.812+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:03.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:50:03.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:50:03.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:03.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:50:03.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:03.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:50:03.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:50:34.366+0000] {processor.py:157} INFO - Started process (PID=1141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:50:34.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:50:34.371+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:34.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:50:34.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:50:34.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:34.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:50:34.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:50:34.406+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:50:34.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T14:51:04.812+0000] {processor.py:157} INFO - Started process (PID=1166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:51:04.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:51:04.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:04.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:51:04.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:51:04.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:04.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:51:04.855+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:04.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:51:04.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:51:35.240+0000] {processor.py:157} INFO - Started process (PID=1191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:51:35.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:51:35.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:35.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:51:35.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:51:35.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:35.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:51:35.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:51:35.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:51:35.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T14:52:05.692+0000] {processor.py:157} INFO - Started process (PID=1216) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:52:05.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:52:05.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:05.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:52:05.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:52:05.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:05.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:52:05.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:05.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:52:05.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T14:52:36.132+0000] {processor.py:157} INFO - Started process (PID=1241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:52:36.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:52:36.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:36.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:52:36.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:52:36.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:36.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:52:36.179+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:52:36.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:52:36.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T14:53:06.528+0000] {processor.py:157} INFO - Started process (PID=1266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:53:06.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:53:06.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:06.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:53:06.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:53:06.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:06.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:53:06.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:06.563+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:53:06.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-20T14:53:36.964+0000] {processor.py:157} INFO - Started process (PID=1291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:53:36.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:53:36.967+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:36.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:53:36.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:53:36.998+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:36.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:53:37.007+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:53:37.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:53:37.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T14:54:07.413+0000] {processor.py:157} INFO - Started process (PID=1316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:54:07.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:54:07.417+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:07.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:54:07.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:54:07.451+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:07.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:54:07.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:07.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:54:07.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T14:54:37.913+0000] {processor.py:157} INFO - Started process (PID=1341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:54:37.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:54:37.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:37.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:54:37.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:54:37.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:37.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:54:37.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:54:37.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:54:37.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:55:08.380+0000] {processor.py:157} INFO - Started process (PID=1366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:55:08.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:55:08.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:08.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:55:08.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:55:08.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:08.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:55:08.423+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:08.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:55:08.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T14:55:38.831+0000] {processor.py:157} INFO - Started process (PID=1391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:55:38.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:55:38.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:38.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:55:38.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:55:38.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:38.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:55:38.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:55:38.876+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:55:38.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T14:56:09.337+0000] {processor.py:157} INFO - Started process (PID=1416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:56:09.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:56:09.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:09.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:56:09.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:56:09.372+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:09.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:56:09.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:09.382+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:56:09.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T14:56:39.777+0000] {processor.py:157} INFO - Started process (PID=1441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:56:39.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:56:39.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:39.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:56:39.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:56:39.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:39.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:56:39.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:56:39.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:56:39.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T14:57:10.244+0000] {processor.py:157} INFO - Started process (PID=1466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:57:10.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:57:10.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:10.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:57:10.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:57:10.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:10.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:57:10.290+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:10.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:57:10.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:57:40.751+0000] {processor.py:157} INFO - Started process (PID=1491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:57:40.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:57:40.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:40.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:57:40.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:57:40.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:40.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:57:40.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:57:40.793+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:57:40.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T14:58:11.178+0000] {processor.py:157} INFO - Started process (PID=1516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:58:11.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:58:11.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:11.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:58:11.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:58:11.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:11.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:58:11.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:11.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:58:11.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T14:58:41.671+0000] {processor.py:157} INFO - Started process (PID=1541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:58:41.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:58:41.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:41.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:58:41.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:58:41.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:41.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:58:41.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:58:41.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:58:41.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T14:59:12.074+0000] {processor.py:157} INFO - Started process (PID=1566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:59:12.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:59:12.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:12.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:59:12.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:59:12.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:12.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:59:12.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:12.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:59:12.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T14:59:42.621+0000] {processor.py:157} INFO - Started process (PID=1591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:59:42.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T14:59:42.625+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:42.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:59:42.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T14:59:42.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:42.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T14:59:42.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T14:59:42.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T14:59:42.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T15:00:13.050+0000] {processor.py:157} INFO - Started process (PID=1616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:00:13.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:00:13.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:13.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:00:13.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:00:13.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:13.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:00:13.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:13.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:00:13.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T15:00:43.491+0000] {processor.py:157} INFO - Started process (PID=1641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:00:43.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:00:43.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:43.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:00:43.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:00:43.519+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:43.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:00:43.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:00:43.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:00:43.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T15:01:13.903+0000] {processor.py:157} INFO - Started process (PID=1666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:01:13.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:01:13.907+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:13.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:01:13.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:01:13.930+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:13.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:01:13.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:13.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:01:13.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T15:01:44.383+0000] {processor.py:157} INFO - Started process (PID=1691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:01:44.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:01:44.389+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:44.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:01:44.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:01:44.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:44.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:01:44.427+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:01:44.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:01:44.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T15:02:14.906+0000] {processor.py:157} INFO - Started process (PID=1716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:02:14.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:02:14.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:14.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:02:14.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:02:14.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:14.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:02:14.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:14.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:02:14.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T15:02:45.350+0000] {processor.py:157} INFO - Started process (PID=1741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:02:45.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:02:45.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:45.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:02:45.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:02:45.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:45.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:02:45.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:02:45.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:02:45.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T15:03:15.778+0000] {processor.py:157} INFO - Started process (PID=1766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:03:15.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:03:15.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:15.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:03:15.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:03:15.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:15.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:03:15.824+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:15.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:03:15.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:03:46.190+0000] {processor.py:157} INFO - Started process (PID=1791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:03:46.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:03:46.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:46.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:03:46.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:03:46.223+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:46.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:03:46.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:03:46.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:03:46.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T15:04:16.641+0000] {processor.py:157} INFO - Started process (PID=1816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:04:16.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:04:16.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:16.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:04:16.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:04:16.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:16.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:04:16.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:16.685+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:04:16.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T15:04:47.140+0000] {processor.py:157} INFO - Started process (PID=1841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:04:47.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:04:47.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:47.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:04:47.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:04:47.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:47.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:04:47.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:04:47.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:04:47.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:05:17.616+0000] {processor.py:157} INFO - Started process (PID=1866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:05:17.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:05:17.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:17.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:05:17.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:05:17.650+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:17.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:05:17.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:17.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:05:17.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:05:48.052+0000] {processor.py:157} INFO - Started process (PID=1891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:05:48.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:05:48.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:48.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:05:48.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:05:48.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:48.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:05:48.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:05:48.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:05:48.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T15:06:18.438+0000] {processor.py:157} INFO - Started process (PID=1916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:06:18.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:06:18.440+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:18.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:06:18.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:06:18.469+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:18.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:06:18.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:18.480+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:06:18.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:06:48.901+0000] {processor.py:157} INFO - Started process (PID=1941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:06:48.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:06:48.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:48.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:06:48.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:06:48.932+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:48.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:06:48.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:06:48.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:06:48.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T15:07:19.282+0000] {processor.py:157} INFO - Started process (PID=1966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:07:19.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:07:19.284+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:19.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:07:19.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:07:19.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:19.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:07:19.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:19.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:07:19.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-20T15:07:49.737+0000] {processor.py:157} INFO - Started process (PID=1991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:07:49.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:07:49.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:49.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:07:49.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:07:49.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:49.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:07:49.778+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:07:49.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:07:49.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T15:08:20.161+0000] {processor.py:157} INFO - Started process (PID=2016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:08:20.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:08:20.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:20.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:08:20.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:08:20.201+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:20.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:08:20.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:20.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:08:20.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T15:08:50.622+0000] {processor.py:157} INFO - Started process (PID=2041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:08:50.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:08:50.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:50.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:08:50.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:08:50.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:50.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:08:50.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:08:50.665+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:08:50.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T15:09:21.079+0000] {processor.py:157} INFO - Started process (PID=2066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:09:21.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:09:21.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:21.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:09:21.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:09:21.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:21.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:09:21.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:21.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:09:21.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T15:09:51.525+0000] {processor.py:157} INFO - Started process (PID=2091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:09:51.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:09:51.528+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:51.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:09:51.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:09:51.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:51.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:09:51.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:09:51.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:09:51.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T15:10:22.042+0000] {processor.py:157} INFO - Started process (PID=2116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:10:22.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:10:22.046+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:22.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:10:22.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:10:22.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:22.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:10:22.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:22.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:10:22.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T15:10:52.531+0000] {processor.py:157} INFO - Started process (PID=2141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:10:52.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:10:52.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:52.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:10:52.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:10:52.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:52.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:10:52.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:10:52.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:10:52.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T15:11:23.060+0000] {processor.py:157} INFO - Started process (PID=2166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:11:23.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:11:23.065+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:23.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:11:23.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:11:23.095+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:23.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:11:23.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:23.106+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:11:23.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T15:11:53.513+0000] {processor.py:157} INFO - Started process (PID=2191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:11:53.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:11:53.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:53.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:11:53.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:11:53.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:53.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:11:53.551+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:11:53.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:11:53.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T15:12:23.925+0000] {processor.py:157} INFO - Started process (PID=2216) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:12:23.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:12:23.930+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:23.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:12:23.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:12:23.963+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:23.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:12:23.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:23.976+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:12:23.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T15:12:54.460+0000] {processor.py:157} INFO - Started process (PID=2241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:12:54.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:12:54.466+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:54.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:12:54.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:12:54.490+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:54.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:12:54.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:12:54.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:12:54.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T15:13:24.976+0000] {processor.py:157} INFO - Started process (PID=2266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:13:24.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:13:24.981+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:24.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:13:24.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:13:25.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:25.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:13:25.021+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:25.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:13:25.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:13:55.475+0000] {processor.py:157} INFO - Started process (PID=2291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:13:55.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:13:55.479+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:55.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:13:55.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:13:55.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:55.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:13:55.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:13:55.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:13:55.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:14:25.876+0000] {processor.py:157} INFO - Started process (PID=2316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:14:25.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:14:25.878+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:25.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:14:25.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:14:25.905+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:25.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:14:25.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:25.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:14:25.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T15:14:56.363+0000] {processor.py:157} INFO - Started process (PID=2341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:14:56.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:14:56.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:56.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:14:56.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:14:56.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:56.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:14:56.405+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:14:56.405+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:14:56.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:15:26.993+0000] {processor.py:157} INFO - Started process (PID=2366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:15:26.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:15:27.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:27.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:15:27.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:15:27.027+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:27.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:15:27.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:27.041+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:15:27.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T15:15:57.472+0000] {processor.py:157} INFO - Started process (PID=2391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:15:57.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:15:57.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:57.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:15:57.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:15:57.502+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:57.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:15:57.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:15:57.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:15:57.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:16:27.915+0000] {processor.py:157} INFO - Started process (PID=2416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:16:27.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:16:27.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:27.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:16:27.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:16:27.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:27.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:16:27.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:27.956+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:16:27.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T15:16:58.356+0000] {processor.py:157} INFO - Started process (PID=2441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:16:58.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:16:58.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:58.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:16:58.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:16:58.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:58.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:16:58.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:16:58.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:16:58.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T15:17:28.813+0000] {processor.py:157} INFO - Started process (PID=2466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:17:28.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:17:28.821+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:28.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:17:28.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:17:28.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:28.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:17:28.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:28.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:17:28.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T15:17:59.234+0000] {processor.py:157} INFO - Started process (PID=2491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:17:59.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:17:59.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:59.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:17:59.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:17:59.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:59.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:17:59.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:17:59.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:17:59.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T15:18:29.722+0000] {processor.py:157} INFO - Started process (PID=2516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:18:29.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:18:29.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:18:29.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:18:29.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:18:29.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:18:29.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:18:29.772+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:18:29.772+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:18:29.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T15:19:00.201+0000] {processor.py:157} INFO - Started process (PID=2541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:19:00.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:19:00.205+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:00.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:19:00.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:19:00.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:00.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:19:00.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:00.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:19:00.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T15:19:30.756+0000] {processor.py:157} INFO - Started process (PID=2566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:19:30.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:19:30.761+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:30.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:19:30.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:19:30.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:30.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:19:30.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:19:30.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:19:30.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:20:01.226+0000] {processor.py:157} INFO - Started process (PID=2591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:20:01.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:20:01.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:01.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:20:01.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:20:01.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:01.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:20:01.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:01.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:20:01.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T15:20:31.694+0000] {processor.py:157} INFO - Started process (PID=2616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:20:31.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:20:31.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:31.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:20:31.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:20:31.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:31.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:20:31.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:20:31.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:20:31.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T15:21:02.177+0000] {processor.py:157} INFO - Started process (PID=2641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:21:02.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:21:02.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:02.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:21:02.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:21:02.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:02.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:21:02.216+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:02.216+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:21:02.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T15:21:32.609+0000] {processor.py:157} INFO - Started process (PID=2666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:21:32.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:21:32.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:32.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:21:32.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:21:32.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:32.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:21:32.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:21:32.657+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:21:32.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T15:22:03.052+0000] {processor.py:157} INFO - Started process (PID=2691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:22:03.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:22:03.055+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:03.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:22:03.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:22:03.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:03.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:22:03.097+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:03.097+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:22:03.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T15:22:33.484+0000] {processor.py:157} INFO - Started process (PID=2716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:22:33.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:22:33.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:33.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:22:33.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:22:33.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:33.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:22:33.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:22:33.527+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:22:33.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T15:23:03.989+0000] {processor.py:157} INFO - Started process (PID=2741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:23:03.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:23:03.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:03.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:23:04.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:23:04.019+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:04.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:23:04.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:04.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:23:04.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:23:34.424+0000] {processor.py:157} INFO - Started process (PID=2766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:23:34.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:23:34.427+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:34.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:23:34.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:23:34.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:34.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:23:34.461+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:23:34.461+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:23:34.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T15:24:04.881+0000] {processor.py:157} INFO - Started process (PID=2791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:24:04.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:24:04.886+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:04.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:24:04.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:24:04.916+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:04.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:24:04.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:04.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:24:04.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:24:35.337+0000] {processor.py:157} INFO - Started process (PID=2816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:24:35.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:24:35.341+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:35.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:24:35.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:24:35.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:35.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:24:35.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:24:35.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:24:35.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:25:05.858+0000] {processor.py:157} INFO - Started process (PID=2841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:25:05.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:25:05.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:05.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:25:05.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:25:05.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:05.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:25:05.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:05.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:25:05.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T15:25:36.360+0000] {processor.py:157} INFO - Started process (PID=2866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:25:36.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:25:36.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:36.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:25:36.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:25:36.394+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:36.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:25:36.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:25:36.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:25:36.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T15:26:06.816+0000] {processor.py:157} INFO - Started process (PID=2891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:26:06.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:26:06.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:06.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:26:06.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:26:06.849+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:06.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:26:06.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:06.859+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:26:06.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T15:26:37.220+0000] {processor.py:157} INFO - Started process (PID=2916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:26:37.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:26:37.224+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:37.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:26:37.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:26:37.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:37.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:26:37.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:26:37.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:26:37.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:27:07.607+0000] {processor.py:157} INFO - Started process (PID=2941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:27:07.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:27:07.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:07.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:27:07.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:27:07.642+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:07.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:27:07.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:07.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:27:07.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:27:38.068+0000] {processor.py:157} INFO - Started process (PID=2966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:27:38.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:27:38.074+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:38.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:27:38.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:27:38.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:38.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:27:38.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:27:38.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:27:38.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:28:08.591+0000] {processor.py:157} INFO - Started process (PID=2991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:28:08.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:28:08.595+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:08.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:28:08.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:28:08.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:08.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:28:08.637+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:08.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:28:08.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T15:28:39.053+0000] {processor.py:157} INFO - Started process (PID=3016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:28:39.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:28:39.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:39.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:28:39.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:28:39.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:39.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:28:39.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:28:39.100+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:28:39.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T15:29:09.585+0000] {processor.py:157} INFO - Started process (PID=3041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:29:09.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:29:09.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:09.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:29:09.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:29:09.619+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:09.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:29:09.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:09.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:29:09.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T15:29:40.000+0000] {processor.py:157} INFO - Started process (PID=3066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:29:40.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:29:40.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:40.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:29:40.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:29:40.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:40.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:29:40.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:29:40.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:29:40.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T15:30:10.429+0000] {processor.py:157} INFO - Started process (PID=3091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:30:10.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:30:10.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:10.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:30:10.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:30:10.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:10.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:30:10.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:10.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:30:10.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T15:30:40.888+0000] {processor.py:157} INFO - Started process (PID=3116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:30:40.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:30:40.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:40.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:30:40.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:30:40.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:40.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:30:40.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:30:40.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:30:40.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T15:31:11.399+0000] {processor.py:157} INFO - Started process (PID=3141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:31:11.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:31:11.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:11.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:31:11.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:31:11.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:11.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:31:11.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:11.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:31:11.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:31:41.843+0000] {processor.py:157} INFO - Started process (PID=3166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:31:41.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:31:41.848+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:41.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:31:41.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:31:41.878+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:41.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:31:41.887+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:31:41.887+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:31:41.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:32:12.273+0000] {processor.py:157} INFO - Started process (PID=3191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:32:12.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:32:12.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:12.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:32:12.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:32:12.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:12.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:32:12.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:12.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:32:12.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T15:32:42.677+0000] {processor.py:157} INFO - Started process (PID=3216) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:32:42.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:32:42.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:42.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:32:42.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:32:42.707+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:42.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:32:42.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:32:42.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:32:42.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:33:13.152+0000] {processor.py:157} INFO - Started process (PID=3241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:33:13.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:33:13.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:13.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:33:13.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:33:13.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:13.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:33:13.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:13.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:33:13.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T15:33:43.711+0000] {processor.py:157} INFO - Started process (PID=3266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:33:43.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:33:43.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:43.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:33:43.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:33:43.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:43.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:33:43.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:33:43.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:33:43.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-20T15:34:14.263+0000] {processor.py:157} INFO - Started process (PID=3291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:34:14.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:34:14.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:14.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:34:14.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:34:14.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:14.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:34:14.314+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:14.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:34:14.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-20T15:34:44.704+0000] {processor.py:157} INFO - Started process (PID=3316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:34:44.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:34:44.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:44.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:34:44.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:34:44.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:44.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:34:44.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:34:44.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:34:44.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:35:15.153+0000] {processor.py:157} INFO - Started process (PID=3341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:35:15.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:35:15.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:15.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:35:15.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:35:15.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:15.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:35:15.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:15.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:35:15.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:35:45.672+0000] {processor.py:157} INFO - Started process (PID=3366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:35:45.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:35:45.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:45.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:35:45.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:35:45.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:45.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:35:45.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:35:45.729+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:35:45.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T15:36:16.155+0000] {processor.py:157} INFO - Started process (PID=3391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:36:16.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:36:16.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:16.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:36:16.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:36:16.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:16.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:36:16.205+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:16.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:36:16.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T15:36:46.689+0000] {processor.py:157} INFO - Started process (PID=3416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:36:46.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:36:46.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:46.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:36:46.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:36:46.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:46.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:36:46.739+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:36:46.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:36:46.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T15:37:17.151+0000] {processor.py:157} INFO - Started process (PID=3441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:37:17.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:37:17.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:17.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:37:17.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:37:17.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:17.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:37:17.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:17.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:37:17.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-20T15:37:47.593+0000] {processor.py:157} INFO - Started process (PID=3466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:37:47.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:37:47.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:47.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:37:47.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:37:47.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:47.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:37:47.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:37:47.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:37:47.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T15:38:18.049+0000] {processor.py:157} INFO - Started process (PID=3491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:38:18.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:38:18.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:18.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:38:18.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:38:18.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:18.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:38:18.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:18.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:38:18.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T15:38:48.534+0000] {processor.py:157} INFO - Started process (PID=3516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:38:48.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:38:48.540+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:48.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:38:48.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:38:48.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:48.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:38:48.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:38:48.580+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:38:48.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T15:39:19.051+0000] {processor.py:157} INFO - Started process (PID=3541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:39:19.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:39:19.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:19.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:39:19.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:39:19.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:19.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:39:19.099+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:19.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:39:19.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T15:39:49.565+0000] {processor.py:157} INFO - Started process (PID=3566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:39:49.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:39:49.571+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:49.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:39:49.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:39:49.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:49.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:39:49.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:39:49.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:39:49.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-20T15:40:20.071+0000] {processor.py:157} INFO - Started process (PID=3591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:40:20.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:40:20.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:20.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:40:20.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:40:20.092+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:20.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:40:20.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:20.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:40:20.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-20T15:40:50.508+0000] {processor.py:157} INFO - Started process (PID=3616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:40:50.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:40:50.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:50.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:40:50.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:40:50.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:50.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:40:50.553+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:40:50.553+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:40:50.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:41:20.993+0000] {processor.py:157} INFO - Started process (PID=3641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:41:20.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:41:20.998+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:20.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:41:21.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:41:21.027+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:21.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:41:21.038+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:21.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:41:21.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:41:51.360+0000] {processor.py:157} INFO - Started process (PID=3666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:41:51.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:41:51.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:51.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:41:51.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:41:51.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:51.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:41:51.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:41:51.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:41:51.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T15:42:21.843+0000] {processor.py:157} INFO - Started process (PID=3691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:42:21.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:42:21.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:21.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:42:21.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:42:21.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:21.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:42:21.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:21.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:42:21.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T15:42:52.249+0000] {processor.py:157} INFO - Started process (PID=3716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:42:52.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:42:52.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:52.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:42:52.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:42:52.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:52.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:42:52.292+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:42:52.292+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:42:52.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T15:43:22.740+0000] {processor.py:157} INFO - Started process (PID=3741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:43:22.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:43:22.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:22.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:43:22.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:43:22.783+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:22.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:43:22.794+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:22.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:43:22.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T15:43:53.233+0000] {processor.py:157} INFO - Started process (PID=3766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:43:53.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:43:53.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:53.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:43:53.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:43:53.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:53.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:43:53.274+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:43:53.274+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:43:53.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T15:44:23.636+0000] {processor.py:157} INFO - Started process (PID=3791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:44:23.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:44:23.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:23.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:44:23.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:44:23.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:23.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:44:23.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:23.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:44:23.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T15:44:54.130+0000] {processor.py:157} INFO - Started process (PID=3816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:44:54.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:44:54.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:54.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:44:54.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:44:54.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:54.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:44:54.191+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:44:54.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:44:54.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T15:45:24.604+0000] {processor.py:157} INFO - Started process (PID=3841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:45:24.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:45:24.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:24.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:45:24.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:45:24.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:24.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:45:24.666+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:24.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:45:24.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-20T15:45:55.090+0000] {processor.py:157} INFO - Started process (PID=3866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:45:55.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:45:55.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:55.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:45:55.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:45:55.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:55.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:45:55.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:45:55.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:45:55.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-20T15:46:25.610+0000] {processor.py:157} INFO - Started process (PID=3891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:46:25.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:46:25.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:25.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:46:25.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:46:25.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:25.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:46:25.676+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:25.676+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:46:25.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T15:46:56.079+0000] {processor.py:157} INFO - Started process (PID=3916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:46:56.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:46:56.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:56.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:46:56.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:46:56.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:56.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:46:56.131+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:46:56.131+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:46:56.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T15:47:26.494+0000] {processor.py:157} INFO - Started process (PID=3941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:47:26.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:47:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:26.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:47:26.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:47:26.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:26.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:47:26.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:26.555+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:47:26.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-20T15:47:56.988+0000] {processor.py:157} INFO - Started process (PID=3966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:47:56.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:47:56.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:56.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:47:57.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:47:57.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:57.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:47:57.033+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:47:57.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:47:57.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:48:27.411+0000] {processor.py:157} INFO - Started process (PID=3991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:48:27.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:48:27.414+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:27.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:48:27.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:48:27.444+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:27.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:48:27.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:27.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:48:27.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T15:48:57.879+0000] {processor.py:157} INFO - Started process (PID=4016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:48:57.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:48:57.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:57.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:48:57.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:48:57.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:57.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:48:57.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:48:57.943+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:48:57.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T15:49:28.364+0000] {processor.py:157} INFO - Started process (PID=4041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:49:28.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:49:28.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:28.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:49:28.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:49:28.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:28.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:49:28.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:28.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:49:28.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:49:58.796+0000] {processor.py:157} INFO - Started process (PID=4066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:49:58.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:49:58.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:58.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:49:58.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:49:58.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:58.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:49:58.845+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:49:58.844+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:49:58.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T15:50:29.234+0000] {processor.py:157} INFO - Started process (PID=4091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:50:29.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:50:29.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:29.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:50:29.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:50:29.275+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:29.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:50:29.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:29.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:50:29.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T15:50:59.721+0000] {processor.py:157} INFO - Started process (PID=4116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:50:59.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:50:59.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:59.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:50:59.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:50:59.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:59.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:50:59.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:50:59.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:50:59.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T15:51:30.127+0000] {processor.py:157} INFO - Started process (PID=4141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:51:30.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:51:30.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:51:30.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:51:30.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:51:30.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:51:30.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:51:30.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:51:30.185+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:51:30.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T15:52:00.552+0000] {processor.py:157} INFO - Started process (PID=4166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:52:00.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:52:00.558+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:00.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:52:00.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:52:00.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:00.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:52:00.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:00.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:52:00.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T15:52:30.987+0000] {processor.py:157} INFO - Started process (PID=4191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:52:30.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:52:30.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:30.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:52:31.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:52:31.033+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:31.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:52:31.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:52:31.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:52:31.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T15:53:01.484+0000] {processor.py:157} INFO - Started process (PID=4216) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:53:01.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:53:01.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:01.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:53:01.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:53:01.519+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:01.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:53:01.533+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:01.533+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:53:01.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T15:53:31.973+0000] {processor.py:157} INFO - Started process (PID=4241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:53:31.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:53:31.980+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:31.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:53:31.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:53:32.019+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:32.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:53:32.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:53:32.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:53:32.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-20T15:54:02.389+0000] {processor.py:157} INFO - Started process (PID=4266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:54:02.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:54:02.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:02.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:54:02.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:54:02.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:02.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:54:02.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:02.445+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:54:02.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T15:54:32.870+0000] {processor.py:157} INFO - Started process (PID=4291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:54:32.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:54:32.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:32.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:54:32.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:54:32.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:32.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:54:32.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:54:32.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:54:32.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T15:55:03.351+0000] {processor.py:157} INFO - Started process (PID=4316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:55:03.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:55:03.358+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:03.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:55:03.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:55:03.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:03.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:55:03.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:03.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:55:03.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-20T15:55:33.742+0000] {processor.py:157} INFO - Started process (PID=4341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:55:33.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:55:33.749+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:33.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:55:33.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:55:33.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:33.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:55:33.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:55:33.798+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:55:33.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-20T15:56:04.253+0000] {processor.py:157} INFO - Started process (PID=4366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:56:04.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:56:04.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:04.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:56:04.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:56:04.290+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:04.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:56:04.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:04.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:56:04.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T15:56:34.686+0000] {processor.py:157} INFO - Started process (PID=4391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:56:34.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:56:34.689+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:34.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:56:34.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:56:34.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:34.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:56:34.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:56:34.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:56:34.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T15:57:05.077+0000] {processor.py:157} INFO - Started process (PID=4416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:57:05.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:57:05.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:05.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:57:05.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:57:05.111+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:05.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:57:05.122+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:05.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:57:05.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T15:57:35.580+0000] {processor.py:157} INFO - Started process (PID=4441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:57:35.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:57:35.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:35.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:57:35.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:57:35.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:35.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:57:35.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:57:35.654+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:57:35.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-20T15:58:06.060+0000] {processor.py:157} INFO - Started process (PID=4466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:58:06.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:58:06.065+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:06.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:58:06.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:58:06.093+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:06.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:58:06.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:06.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:58:06.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T15:58:36.544+0000] {processor.py:157} INFO - Started process (PID=4491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:58:36.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:58:36.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:36.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:58:36.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:58:36.590+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:36.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:58:36.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:58:36.603+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:58:36.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-20T15:59:06.914+0000] {processor.py:157} INFO - Started process (PID=4516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:59:06.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:59:06.918+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:06.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:59:06.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:59:06.944+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:06.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:59:06.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:06.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:59:06.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T15:59:37.405+0000] {processor.py:157} INFO - Started process (PID=4541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:59:37.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T15:59:37.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:37.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:59:37.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T15:59:37.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:37.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T15:59:37.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T15:59:37.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T15:59:37.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T16:00:07.841+0000] {processor.py:157} INFO - Started process (PID=4566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:00:07.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:00:07.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:07.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:00:07.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:00:07.896+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:07.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:00:07.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:07.910+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:00:07.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-20T16:00:38.296+0000] {processor.py:157} INFO - Started process (PID=4591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:00:38.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:00:38.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:38.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:00:38.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:00:38.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:38.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:00:38.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:00:38.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:00:38.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T16:01:08.763+0000] {processor.py:157} INFO - Started process (PID=4616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:01:08.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:01:08.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:08.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:01:08.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:01:08.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:08.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:01:08.803+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:08.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:01:08.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T16:01:39.151+0000] {processor.py:157} INFO - Started process (PID=4641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:01:39.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:01:39.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:39.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:01:39.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:01:39.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:39.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:01:39.197+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:01:39.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:01:39.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T16:02:09.531+0000] {processor.py:157} INFO - Started process (PID=4666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:02:09.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:02:09.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:09.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:02:09.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:02:09.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:09.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:02:09.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:09.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:02:09.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T16:02:40.023+0000] {processor.py:157} INFO - Started process (PID=4691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:02:40.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:02:40.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:40.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:02:40.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:02:40.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:40.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:02:40.069+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:02:40.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:02:40.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T16:03:10.502+0000] {processor.py:157} INFO - Started process (PID=4716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:03:10.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:03:10.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:10.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:03:10.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:03:10.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:10.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:03:10.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:10.549+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:03:10.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T16:03:40.947+0000] {processor.py:157} INFO - Started process (PID=4741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:03:40.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:03:40.954+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:40.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:03:40.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:03:40.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:40.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:03:41.011+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:03:41.011+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:03:41.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T16:04:11.396+0000] {processor.py:157} INFO - Started process (PID=4766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:04:11.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:04:11.399+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:11.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:04:11.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:04:11.430+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:11.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:04:11.447+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:11.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:04:11.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T16:04:41.887+0000] {processor.py:157} INFO - Started process (PID=4791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:04:41.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:04:41.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:41.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:04:41.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:04:41.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:41.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:04:41.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:04:41.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:04:41.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-20T16:05:12.394+0000] {processor.py:157} INFO - Started process (PID=4816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:05:12.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:05:12.400+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:12.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:05:12.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:05:12.427+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:12.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:05:12.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:12.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:05:12.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T16:05:42.838+0000] {processor.py:157} INFO - Started process (PID=4841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:05:42.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:05:42.843+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:42.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:05:42.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:05:42.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:42.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:05:42.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:05:42.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:05:42.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T16:06:13.265+0000] {processor.py:157} INFO - Started process (PID=4866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:06:13.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:06:13.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:13.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:06:13.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:06:13.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:13.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:06:13.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:13.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:06:13.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T16:06:43.685+0000] {processor.py:157} INFO - Started process (PID=4891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:06:43.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:06:43.688+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:43.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:06:43.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:06:43.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:43.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:06:43.728+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:06:43.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:06:43.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T16:07:14.102+0000] {processor.py:157} INFO - Started process (PID=4916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:07:14.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:07:14.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:14.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:07:14.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:07:14.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:14.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:07:14.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:14.166+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:07:14.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-20T16:07:44.558+0000] {processor.py:157} INFO - Started process (PID=4941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:07:44.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:07:44.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:44.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:07:44.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:07:44.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:44.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:07:44.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:07:44.604+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:07:44.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T16:08:14.984+0000] {processor.py:157} INFO - Started process (PID=4966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:08:14.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:08:14.988+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:14.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:08:14.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:08:15.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:15.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:08:15.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:15.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:08:15.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T16:08:45.370+0000] {processor.py:157} INFO - Started process (PID=4991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:08:45.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:08:45.377+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:45.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:08:45.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:08:45.409+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:45.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:08:45.419+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:08:45.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:08:45.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T16:09:15.847+0000] {processor.py:157} INFO - Started process (PID=5016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:09:15.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:09:15.854+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:15.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:09:15.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:09:15.897+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:15.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:09:15.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:15.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:09:15.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-20T16:09:46.642+0000] {processor.py:157} INFO - Started process (PID=5041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:09:46.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:09:46.648+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:46.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:09:46.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:09:46.676+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:46.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:09:46.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:09:46.687+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:09:46.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T16:10:17.084+0000] {processor.py:157} INFO - Started process (PID=5066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:10:17.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:10:17.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:17.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:10:17.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:10:17.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:17.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:10:17.141+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:17.140+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:10:17.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T16:10:47.533+0000] {processor.py:157} INFO - Started process (PID=5091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:10:47.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:10:47.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:47.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:10:47.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:10:47.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:47.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:10:47.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:10:47.580+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:10:47.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-20T16:11:17.947+0000] {processor.py:157} INFO - Started process (PID=5116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:11:17.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:11:17.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:17.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:11:17.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:11:17.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:17.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:11:17.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:17.993+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:11:18.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T16:11:48.318+0000] {processor.py:157} INFO - Started process (PID=5141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:11:48.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:11:48.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:48.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:11:48.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:11:48.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:48.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:11:48.365+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:11:48.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:11:48.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T16:12:18.836+0000] {processor.py:157} INFO - Started process (PID=5166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:12:18.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:12:18.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:18.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:12:18.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:12:18.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:18.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:12:18.895+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:18.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:12:18.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-20T16:12:49.298+0000] {processor.py:157} INFO - Started process (PID=5191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:12:49.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:12:49.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:49.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:12:49.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:12:49.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:49.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:12:49.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:12:49.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:12:49.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T16:13:19.784+0000] {processor.py:157} INFO - Started process (PID=5216) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:13:19.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:13:19.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:19.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:13:19.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:13:19.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:19.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:13:19.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:19.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:13:19.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-20T16:13:50.296+0000] {processor.py:157} INFO - Started process (PID=5241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:13:50.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:13:50.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:50.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:13:50.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:13:50.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:50.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:13:50.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:13:50.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:13:50.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T16:14:20.689+0000] {processor.py:157} INFO - Started process (PID=5266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:14:20.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:14:20.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:20.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:14:20.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:14:20.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:20.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:14:20.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:20.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:14:20.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T16:14:51.147+0000] {processor.py:157} INFO - Started process (PID=5291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:14:51.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:14:51.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:51.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:14:51.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:14:51.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:51.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:14:51.210+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:14:51.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:14:51.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.234 seconds
[2024-07-20T16:15:21.672+0000] {processor.py:157} INFO - Started process (PID=5316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:15:21.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:15:21.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:21.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:15:21.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:15:21.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:21.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:15:21.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:21.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:15:21.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-20T16:15:52.148+0000] {processor.py:157} INFO - Started process (PID=5341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:15:52.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:15:52.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:52.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:15:52.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:15:52.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:52.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:15:52.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:15:52.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:15:52.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-20T16:16:22.700+0000] {processor.py:157} INFO - Started process (PID=5366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:16:22.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:16:22.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:22.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:16:22.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:16:22.759+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:22.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:16:22.772+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:22.772+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:16:22.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-20T16:16:53.193+0000] {processor.py:157} INFO - Started process (PID=5391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:16:53.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:16:53.198+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:53.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:16:53.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:16:53.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:53.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:16:53.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:16:53.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:16:53.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-20T16:17:23.599+0000] {processor.py:157} INFO - Started process (PID=5416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:17:23.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:17:23.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:23.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:17:23.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:17:23.632+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:23.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:17:23.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:23.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:17:23.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T16:17:54.079+0000] {processor.py:157} INFO - Started process (PID=5441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:17:54.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:17:54.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:54.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:17:54.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:17:54.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:54.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:17:54.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:17:54.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:17:54.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.201 seconds
[2024-07-20T16:18:24.647+0000] {processor.py:157} INFO - Started process (PID=5466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:18:24.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:18:24.651+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:24.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:18:24.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:18:24.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:24.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:18:24.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:24.695+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:18:24.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T16:18:55.178+0000] {processor.py:157} INFO - Started process (PID=5491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:18:55.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:18:55.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:55.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:18:55.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:18:55.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:55.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:18:55.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:18:55.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:18:55.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-20T16:19:25.817+0000] {processor.py:157} INFO - Started process (PID=5516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:19:25.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:19:25.830+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:25.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:19:25.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:19:25.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:25.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:19:25.915+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:25.915+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:19:25.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-20T16:19:56.337+0000] {processor.py:157} INFO - Started process (PID=5541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:19:56.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:19:56.343+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:56.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:19:56.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:19:56.374+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:56.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:19:56.389+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:19:56.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:19:56.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-20T16:20:26.766+0000] {processor.py:157} INFO - Started process (PID=5566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:20:26.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:20:26.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:26.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:20:26.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:20:26.845+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:26.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:20:26.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:26.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:20:26.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-20T16:20:57.234+0000] {processor.py:157} INFO - Started process (PID=5591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:20:57.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:20:57.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:57.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:20:57.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:20:57.268+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:57.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:20:57.279+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:20:57.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:20:57.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T16:21:27.594+0000] {processor.py:157} INFO - Started process (PID=5616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:21:27.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:21:27.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:27.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:21:27.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:21:27.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:27.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:21:27.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:27.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:21:27.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-20T16:21:58.060+0000] {processor.py:157} INFO - Started process (PID=5641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:21:58.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:21:58.064+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:58.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:21:58.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:21:58.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:58.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:21:58.104+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:21:58.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:21:58.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T16:22:28.523+0000] {processor.py:157} INFO - Started process (PID=5666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:22:28.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:22:28.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:28.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:22:28.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:22:28.590+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:28.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:22:28.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:28.602+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:22:28.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-20T16:22:59.048+0000] {processor.py:157} INFO - Started process (PID=5691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:22:59.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:22:59.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:59.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:22:59.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:22:59.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:59.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:22:59.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:22:59.089+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:22:59.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T16:23:29.821+0000] {processor.py:157} INFO - Started process (PID=5716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:23:29.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:23:29.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:23:29.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:23:29.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:23:29.892+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:23:29.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:23:29.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:23:29.910+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:23:30.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.372 seconds
[2024-07-20T16:24:00.588+0000] {processor.py:157} INFO - Started process (PID=5741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:24:00.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:24:00.594+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:00.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:24:00.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:24:00.652+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:00.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:24:00.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:00.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:24:00.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-20T16:24:31.101+0000] {processor.py:157} INFO - Started process (PID=5766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:24:31.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:24:31.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:31.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:24:31.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:24:31.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:31.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:24:31.151+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:24:31.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:24:31.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T16:25:01.547+0000] {processor.py:157} INFO - Started process (PID=5791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:25:01.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:25:01.556+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:01.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:25:01.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:25:01.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:01.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:25:01.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:01.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:25:01.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-20T16:25:32.044+0000] {processor.py:157} INFO - Started process (PID=5816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:25:32.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:25:32.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:32.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:25:32.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:25:32.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:32.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:25:32.098+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:25:32.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:25:32.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T16:26:02.561+0000] {processor.py:157} INFO - Started process (PID=5841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:26:02.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:26:02.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:02.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:26:02.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:26:02.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:02.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:26:02.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:02.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:26:02.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T16:26:33.040+0000] {processor.py:157} INFO - Started process (PID=5866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:26:33.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:26:33.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:33.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:26:33.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:26:33.071+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:33.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:26:33.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:26:33.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:26:33.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.222 seconds
[2024-07-20T16:27:03.765+0000] {processor.py:157} INFO - Started process (PID=5891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:27:03.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:27:03.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:03.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:27:03.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:27:03.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:03.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:27:03.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:03.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:27:03.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T16:27:34.214+0000] {processor.py:157} INFO - Started process (PID=5916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:27:34.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:27:34.221+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:34.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:27:34.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:27:34.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:34.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:27:34.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:27:34.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:27:34.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T16:28:04.659+0000] {processor.py:157} INFO - Started process (PID=5941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:28:04.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:28:04.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:04.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:28:04.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:28:04.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:04.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:28:04.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:04.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:28:04.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T16:28:35.080+0000] {processor.py:157} INFO - Started process (PID=5966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:28:35.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:28:35.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:35.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:28:35.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:28:35.115+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:35.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:28:35.126+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:28:35.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:28:35.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T16:29:05.559+0000] {processor.py:157} INFO - Started process (PID=5991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:29:05.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:29:05.565+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:05.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:29:05.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:29:05.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:05.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:29:05.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:05.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:29:05.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T16:29:35.987+0000] {processor.py:157} INFO - Started process (PID=6016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:29:35.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:29:35.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:35.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:29:36.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:29:36.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:36.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:29:36.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:29:36.050+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:29:36.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-20T16:30:06.554+0000] {processor.py:157} INFO - Started process (PID=6041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:30:06.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:30:06.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:06.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:30:06.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:30:06.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:06.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:30:06.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:06.633+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:30:06.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-20T16:30:36.996+0000] {processor.py:157} INFO - Started process (PID=6066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:30:36.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:30:37.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:36.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:30:37.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:30:37.027+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:37.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:30:37.039+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:30:37.039+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:30:37.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T16:31:07.473+0000] {processor.py:157} INFO - Started process (PID=6091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:31:07.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:31:07.479+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:07.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:31:07.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:31:07.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:07.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:31:07.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:07.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:31:07.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T16:31:37.956+0000] {processor.py:157} INFO - Started process (PID=6116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:31:37.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:31:37.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:37.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:31:37.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:31:38.010+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:38.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:31:38.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:31:38.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:31:38.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-20T16:32:08.448+0000] {processor.py:157} INFO - Started process (PID=6141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:32:08.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:32:08.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:08.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:32:08.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:32:08.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:08.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:32:08.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:08.488+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:32:08.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.185 seconds
[2024-07-20T16:32:39.088+0000] {processor.py:157} INFO - Started process (PID=6166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:32:39.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:32:39.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:39.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:32:39.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:32:39.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:39.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:32:39.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:32:39.130+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:32:39.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T16:33:09.552+0000] {processor.py:157} INFO - Started process (PID=6191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:33:09.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:33:09.556+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:09.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:33:09.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:33:09.583+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:09.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:33:09.593+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:09.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:33:09.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T16:33:39.966+0000] {processor.py:157} INFO - Started process (PID=6216) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:33:39.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:33:39.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:39.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:33:39.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:33:39.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:39.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:33:40.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:33:40.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:33:40.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T16:34:10.450+0000] {processor.py:157} INFO - Started process (PID=6241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:34:10.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:34:10.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:10.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:34:10.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:34:10.499+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:10.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:34:10.515+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:10.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:34:10.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-20T16:34:41.080+0000] {processor.py:157} INFO - Started process (PID=6266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:34:41.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:34:41.105+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:41.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:34:41.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:34:41.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:41.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:34:41.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:34:41.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:34:41.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-20T16:35:11.561+0000] {processor.py:157} INFO - Started process (PID=6291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:35:11.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:35:11.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:11.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:35:11.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:35:11.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:11.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:35:11.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:11.609+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:35:11.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.196 seconds
[2024-07-20T16:35:42.182+0000] {processor.py:157} INFO - Started process (PID=6316) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:35:42.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:35:42.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:42.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:35:42.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:35:42.226+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:42.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:35:42.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:35:42.239+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:35:42.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T16:36:12.640+0000] {processor.py:157} INFO - Started process (PID=6341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:36:12.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:36:12.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:12.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:36:12.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:36:12.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:12.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:36:12.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:12.685+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:36:12.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T16:36:43.079+0000] {processor.py:157} INFO - Started process (PID=6366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:36:43.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:36:43.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:43.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:36:43.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:36:43.108+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:43.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:36:43.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:36:43.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:36:43.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T16:37:13.529+0000] {processor.py:157} INFO - Started process (PID=6391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:37:13.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:37:13.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:13.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:37:13.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:37:13.573+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:13.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:37:13.589+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:13.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:37:13.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-20T16:37:43.954+0000] {processor.py:157} INFO - Started process (PID=6416) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:37:43.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:37:43.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:43.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:37:43.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:37:43.988+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:43.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:37:43.998+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:37:43.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:37:44.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T16:38:14.363+0000] {processor.py:157} INFO - Started process (PID=6441) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:38:14.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:38:14.369+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:14.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:38:14.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:38:14.398+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:14.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:38:14.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:14.563+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:38:14.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.217 seconds
[2024-07-20T16:38:45.016+0000] {processor.py:157} INFO - Started process (PID=6466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:38:45.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:38:45.028+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:45.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:38:45.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:38:45.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:45.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:38:45.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:38:45.089+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:38:45.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-20T16:39:15.458+0000] {processor.py:157} INFO - Started process (PID=6491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:39:15.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:39:15.463+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:15.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:39:15.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:39:15.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:15.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:39:15.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:15.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:39:15.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-20T16:39:46.036+0000] {processor.py:157} INFO - Started process (PID=6516) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:39:46.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:39:46.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:46.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:39:46.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:39:46.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:46.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:39:46.094+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:39:46.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:39:46.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-20T16:40:16.462+0000] {processor.py:157} INFO - Started process (PID=6541) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:40:16.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:40:16.465+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:16.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:40:16.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:40:16.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:16.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:40:16.506+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:16.506+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:40:16.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T16:40:46.925+0000] {processor.py:157} INFO - Started process (PID=6566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:40:46.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:40:46.928+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:46.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:40:46.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:40:46.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:46.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:40:46.964+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:40:46.963+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:40:47.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.215 seconds
[2024-07-20T16:41:17.536+0000] {processor.py:157} INFO - Started process (PID=6591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:41:17.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:41:17.544+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:17.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:41:17.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:41:17.582+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:17.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:41:17.596+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:17.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:41:17.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-20T16:41:48.026+0000] {processor.py:157} INFO - Started process (PID=6616) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:41:48.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:41:48.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:48.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:41:48.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:41:48.062+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:48.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:41:48.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:41:48.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:41:48.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T16:42:18.445+0000] {processor.py:157} INFO - Started process (PID=6641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:42:18.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:42:18.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:18.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:42:18.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:42:18.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:18.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:42:18.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:18.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:42:18.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-20T16:42:49.042+0000] {processor.py:157} INFO - Started process (PID=6666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:42:49.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:42:49.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:49.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:42:49.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:42:49.097+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:49.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:42:49.110+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:42:49.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:42:49.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-20T16:43:19.558+0000] {processor.py:157} INFO - Started process (PID=6691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:43:19.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:43:19.562+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:19.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:43:19.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:43:19.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:19.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:43:19.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:19.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:43:19.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-20T16:43:50.116+0000] {processor.py:157} INFO - Started process (PID=6716) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:43:50.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:43:50.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:50.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:43:50.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:43:50.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:50.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:43:50.160+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:43:50.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:43:50.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.170 seconds
[2024-07-20T16:44:20.940+0000] {processor.py:157} INFO - Started process (PID=6741) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:44:20.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:44:20.947+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:20.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:44:20.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:44:21.006+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:21.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:44:21.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:21.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:44:21.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-20T16:44:51.451+0000] {processor.py:157} INFO - Started process (PID=6766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:44:51.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:44:51.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:51.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:44:51.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:44:51.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:51.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:44:51.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:44:51.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:44:51.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-20T16:45:22.029+0000] {processor.py:157} INFO - Started process (PID=6791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:45:22.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:45:22.039+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:22.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:45:22.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:45:22.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:22.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:45:22.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:22.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:45:22.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-20T16:45:52.423+0000] {processor.py:157} INFO - Started process (PID=6816) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:45:52.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:45:52.431+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:52.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:45:52.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:45:52.480+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:52.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:45:52.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:45:52.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:45:52.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-20T16:46:23.011+0000] {processor.py:157} INFO - Started process (PID=6841) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:46:23.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:46:23.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:23.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:46:23.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:46:23.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:23.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:46:23.072+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:23.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:46:23.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.228 seconds
[2024-07-20T16:46:53.730+0000] {processor.py:157} INFO - Started process (PID=6866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:46:53.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:46:53.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:53.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:46:53.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:46:53.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:53.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:46:53.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:46:53.949+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:46:53.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.234 seconds
[2024-07-20T16:47:24.454+0000] {processor.py:157} INFO - Started process (PID=6891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:47:24.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:47:24.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:24.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:47:24.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:47:24.511+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:24.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:47:24.526+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:24.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:47:24.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-20T16:47:55.007+0000] {processor.py:157} INFO - Started process (PID=6916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:47:55.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:47:55.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:55.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:47:55.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:47:55.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:55.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:47:55.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:47:55.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:47:55.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-20T16:48:25.505+0000] {processor.py:157} INFO - Started process (PID=6941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:48:25.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:48:25.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:25.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:48:25.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:48:25.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:25.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:48:25.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:25.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:48:25.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-20T16:48:56.571+0000] {processor.py:157} INFO - Started process (PID=6966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:48:56.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:48:56.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:56.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:48:56.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:48:56.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:56.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:48:56.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:48:56.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:48:56.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-20T16:49:27.070+0000] {processor.py:157} INFO - Started process (PID=6991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:49:27.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:49:27.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:27.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:49:27.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:49:27.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:27.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:49:27.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:27.140+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:49:27.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.241 seconds
[2024-07-20T16:49:57.676+0000] {processor.py:157} INFO - Started process (PID=7016) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:49:57.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:49:57.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:57.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:49:57.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:49:57.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:57.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:49:57.840+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:49:57.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:49:57.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.181 seconds
[2024-07-20T16:50:28.254+0000] {processor.py:157} INFO - Started process (PID=7041) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:50:28.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:50:28.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:28.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:50:28.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:50:28.296+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:28.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:50:28.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:28.309+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:50:28.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T16:50:58.770+0000] {processor.py:157} INFO - Started process (PID=7066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:50:58.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:50:58.779+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:58.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:50:58.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:50:58.840+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:58.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:50:58.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:50:58.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:50:58.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-20T16:51:29.295+0000] {processor.py:157} INFO - Started process (PID=7091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:51:29.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:51:29.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:29.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:51:29.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:51:29.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:29.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:51:29.361+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:29.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:51:29.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-20T16:51:59.771+0000] {processor.py:157} INFO - Started process (PID=7116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:51:59.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:51:59.774+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:59.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:51:59.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:51:59.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:59.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:51:59.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:51:59.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:51:59.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T16:52:30.228+0000] {processor.py:157} INFO - Started process (PID=7141) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:52:30.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:52:30.234+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:52:30.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:52:30.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:52:30.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:52:30.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:52:30.421+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:52:30.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:52:30.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.207 seconds
[2024-07-20T16:53:01.982+0000] {processor.py:157} INFO - Started process (PID=7166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:53:01.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T16:53:01.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:53:01.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:53:01.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T16:53:02.009+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:53:02.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T16:53:02.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T16:53:02.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T16:53:02.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-20T17:08:30.687+0000] {processor.py:157} INFO - Started process (PID=7193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:08:30.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:08:30.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:08:30.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:08:30.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:08:30.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:08:30.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:08:30.759+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:08:30.759+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:08:30.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-20T17:09:01.304+0000] {processor.py:157} INFO - Started process (PID=7218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:09:01.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:09:01.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:01.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:09:01.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:09:01.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:01.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:09:01.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:01.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:09:01.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T17:09:31.675+0000] {processor.py:157} INFO - Started process (PID=7243) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:09:31.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:09:31.679+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:31.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:09:31.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:09:31.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:31.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:09:31.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:09:31.721+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:09:31.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T17:10:02.125+0000] {processor.py:157} INFO - Started process (PID=7268) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:10:02.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:10:02.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:02.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:10:02.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:10:02.161+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:02.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:10:02.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:02.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:10:02.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T17:10:32.572+0000] {processor.py:157} INFO - Started process (PID=7293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:10:32.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:10:32.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:32.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:10:32.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:10:32.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:32.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:10:32.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:10:32.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:10:32.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-20T17:25:58.435+0000] {processor.py:157} INFO - Started process (PID=7320) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:25:58.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:25:58.438+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:25:58.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:25:58.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:25:58.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:25:58.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:25:58.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:25:58.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:25:58.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-20T17:26:28.864+0000] {processor.py:157} INFO - Started process (PID=7345) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:26:28.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:26:28.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:28.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:26:28.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:26:28.893+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:28.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:26:28.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:28.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:26:28.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T17:26:59.321+0000] {processor.py:157} INFO - Started process (PID=7370) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:26:59.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:26:59.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:59.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:26:59.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:26:59.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:59.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:26:59.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:26:59.366+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:26:59.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T17:27:29.777+0000] {processor.py:157} INFO - Started process (PID=7395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:27:29.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:27:29.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:27:29.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:27:29.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:27:29.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:27:29.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:27:29.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:27:29.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:27:29.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T17:43:03.563+0000] {processor.py:157} INFO - Started process (PID=7422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:43:03.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:43:03.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:03.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:43:03.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:43:03.590+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:03.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:43:03.599+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:03.599+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:43:03.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T17:43:34.242+0000] {processor.py:157} INFO - Started process (PID=7447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:43:34.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:43:34.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:34.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:43:34.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:43:34.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:34.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:43:34.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:43:34.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:43:34.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-20T17:44:04.920+0000] {processor.py:157} INFO - Started process (PID=7472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:44:04.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:44:04.925+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:04.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:44:04.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:44:04.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:04.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:44:04.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:04.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:44:04.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T17:44:35.355+0000] {processor.py:157} INFO - Started process (PID=7497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:44:35.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:44:35.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:35.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:44:35.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:44:35.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:35.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:44:35.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:44:35.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:44:35.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T17:45:05.786+0000] {processor.py:157} INFO - Started process (PID=7522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:45:05.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:45:05.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:05.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:45:05.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:45:05.818+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:05.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:45:05.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:05.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:45:05.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T17:45:36.289+0000] {processor.py:157} INFO - Started process (PID=7547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:45:36.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T17:45:36.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:36.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:45:36.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T17:45:36.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:36.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T17:45:36.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T17:45:36.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T17:45:36.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T18:01:56.097+0000] {processor.py:157} INFO - Started process (PID=7574) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:01:56.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:01:56.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:01:56.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:01:56.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:01:56.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:01:56.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:01:56.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:01:56.155+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:01:56.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.213 seconds
[2024-07-20T18:02:26.834+0000] {processor.py:157} INFO - Started process (PID=7599) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:02:26.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:02:26.837+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:26.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:02:26.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:02:26.868+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:26.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:02:26.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:26.959+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:02:26.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-20T18:02:57.490+0000] {processor.py:157} INFO - Started process (PID=7624) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:02:57.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:02:57.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:57.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:02:57.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:02:57.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:57.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:02:57.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:02:57.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:02:57.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:03:27.954+0000] {processor.py:157} INFO - Started process (PID=7649) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:03:27.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:03:27.957+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:27.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:03:27.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:03:27.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:27.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:03:27.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:27.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:03:28.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T18:03:58.439+0000] {processor.py:157} INFO - Started process (PID=7674) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:03:58.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:03:58.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:58.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:03:58.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:03:58.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:58.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:03:58.485+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:03:58.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:03:58.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T18:04:28.911+0000] {processor.py:157} INFO - Started process (PID=7699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:04:28.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:04:28.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:28.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:04:28.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:04:28.944+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:28.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:04:28.954+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:28.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:04:28.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T18:04:59.388+0000] {processor.py:157} INFO - Started process (PID=7724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:04:59.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:04:59.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:59.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:04:59.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:04:59.421+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:59.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:04:59.500+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:04:59.500+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:04:59.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:05:29.968+0000] {processor.py:157} INFO - Started process (PID=7749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:05:29.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:05:29.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:05:29.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:05:29.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:05:30.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:05:30.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:05:30.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:05:30.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:05:30.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-20T18:06:00.542+0000] {processor.py:157} INFO - Started process (PID=7774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:06:00.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:06:00.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:00.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:06:00.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:06:00.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:00.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:06:00.584+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:00.584+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:06:00.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:06:31.038+0000] {processor.py:157} INFO - Started process (PID=7799) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:06:31.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:06:31.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:31.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:06:31.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:06:31.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:31.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:06:31.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:06:31.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:06:31.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T18:07:01.492+0000] {processor.py:157} INFO - Started process (PID=7824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:07:01.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:07:01.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:01.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:07:01.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:07:01.522+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:01.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:07:01.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:01.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:07:01.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:07:31.953+0000] {processor.py:157} INFO - Started process (PID=7849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:07:31.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:07:31.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:31.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:07:31.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:07:31.986+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:31.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:07:31.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:07:31.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:07:32.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:08:02.630+0000] {processor.py:157} INFO - Started process (PID=7874) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:08:02.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:08:02.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:02.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:08:02.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:08:02.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:02.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:08:02.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:02.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:08:02.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-20T18:08:33.285+0000] {processor.py:157} INFO - Started process (PID=7899) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:08:33.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:08:33.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:33.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:08:33.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:08:33.318+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:33.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:08:33.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:08:33.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:08:33.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T18:09:03.765+0000] {processor.py:157} INFO - Started process (PID=7924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:09:03.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:09:03.772+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:03.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:09:03.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:09:03.804+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:03.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:09:03.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:03.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:09:03.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T18:09:34.196+0000] {processor.py:157} INFO - Started process (PID=7949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:09:34.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:09:34.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:34.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:09:34.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:09:34.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:34.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:09:34.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:09:34.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:09:34.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:10:04.571+0000] {processor.py:157} INFO - Started process (PID=7974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:10:04.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:10:04.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:04.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:10:04.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:10:04.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:04.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:10:04.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:04.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:10:04.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T18:10:35.077+0000] {processor.py:157} INFO - Started process (PID=7999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:10:35.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:10:35.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:35.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:10:35.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:10:35.110+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:35.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:10:35.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:10:35.190+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:10:35.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-20T18:11:05.628+0000] {processor.py:157} INFO - Started process (PID=8024) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:11:05.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:11:05.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:05.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:11:05.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:11:05.661+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:05.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:11:05.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:05.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:11:05.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-20T18:11:36.336+0000] {processor.py:157} INFO - Started process (PID=8049) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:11:36.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:11:36.340+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:36.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:11:36.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:11:36.368+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:36.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:11:36.377+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:11:36.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:11:36.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:12:06.727+0000] {processor.py:157} INFO - Started process (PID=8074) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:12:06.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:12:06.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:06.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:12:06.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:12:06.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:06.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:12:06.769+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:06.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:12:06.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T18:12:37.222+0000] {processor.py:157} INFO - Started process (PID=8099) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:12:37.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:12:37.225+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:37.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:12:37.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:12:37.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:37.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:12:37.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:12:37.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:12:37.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:13:07.685+0000] {processor.py:157} INFO - Started process (PID=8124) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:13:07.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:13:07.688+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:07.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:13:07.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:13:07.717+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:07.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:13:07.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:07.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:13:07.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:13:38.273+0000] {processor.py:157} INFO - Started process (PID=8149) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:13:38.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:13:38.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:38.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:13:38.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:13:38.306+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:38.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:13:38.384+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:13:38.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:13:38.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-20T18:14:08.790+0000] {processor.py:157} INFO - Started process (PID=8174) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:14:08.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:14:08.792+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:08.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:14:08.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:14:08.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:08.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:14:08.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:08.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:14:08.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:14:39.354+0000] {processor.py:157} INFO - Started process (PID=8199) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:14:39.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:14:39.357+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:39.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:14:39.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:14:39.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:39.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:14:39.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:14:39.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:14:39.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:15:09.855+0000] {processor.py:157} INFO - Started process (PID=8224) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:15:09.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:15:09.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:09.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:15:09.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:15:09.889+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:09.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:15:09.898+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:09.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:15:09.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:15:40.289+0000] {processor.py:157} INFO - Started process (PID=8249) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:15:40.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:15:40.294+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:40.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:15:40.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:15:40.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:40.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:15:40.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:15:40.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:15:40.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T18:16:10.687+0000] {processor.py:157} INFO - Started process (PID=8274) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:16:10.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:16:10.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:10.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:16:10.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:16:10.716+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:10.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:16:10.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:10.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:16:10.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-20T18:16:41.338+0000] {processor.py:157} INFO - Started process (PID=8299) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:16:41.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:16:41.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:41.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:16:41.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:16:41.373+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:41.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:16:41.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:16:41.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:16:41.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-20T18:17:11.905+0000] {processor.py:157} INFO - Started process (PID=8324) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:17:11.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:17:11.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:11.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:17:11.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:17:12.007+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:12.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:17:12.016+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:12.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:17:12.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:17:42.495+0000] {processor.py:157} INFO - Started process (PID=8349) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:17:42.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:17:42.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:42.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:17:42.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:17:42.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:42.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:17:42.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:17:42.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:17:42.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T18:18:12.937+0000] {processor.py:157} INFO - Started process (PID=8374) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:18:12.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:18:12.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:12.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:18:12.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:18:12.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:12.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:18:12.980+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:12.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:18:12.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:18:43.354+0000] {processor.py:157} INFO - Started process (PID=8399) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:18:43.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:18:43.358+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:43.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:18:43.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:18:43.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:43.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:18:43.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:18:43.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:18:43.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:19:13.805+0000] {processor.py:157} INFO - Started process (PID=8424) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:19:13.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:19:13.809+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:13.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:19:13.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:19:13.833+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:13.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:19:13.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:13.910+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:19:13.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-20T18:19:44.433+0000] {processor.py:157} INFO - Started process (PID=8449) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:19:44.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:19:44.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:44.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:19:44.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:19:44.465+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:44.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:19:44.544+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:19:44.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:19:44.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:20:14.966+0000] {processor.py:157} INFO - Started process (PID=8474) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:20:14.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:20:14.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:14.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:20:14.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:20:15.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:15.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:20:15.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:15.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:20:15.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-20T18:20:45.510+0000] {processor.py:157} INFO - Started process (PID=8499) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:20:45.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:20:45.515+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:45.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:20:45.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:20:45.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:45.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:20:45.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:20:45.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:20:45.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:21:15.976+0000] {processor.py:157} INFO - Started process (PID=8524) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:21:15.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:21:15.979+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:15.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:21:15.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:21:16.009+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:16.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:21:16.020+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:16.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:21:16.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T18:21:46.416+0000] {processor.py:157} INFO - Started process (PID=8549) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:21:46.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:21:46.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:46.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:21:46.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:21:46.451+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:46.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:21:46.461+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:21:46.461+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:21:46.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-20T18:22:16.946+0000] {processor.py:157} INFO - Started process (PID=8574) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:22:16.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:22:16.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:16.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:22:16.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:22:16.971+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:16.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:22:17.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:17.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:22:17.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-20T18:22:47.503+0000] {processor.py:157} INFO - Started process (PID=8599) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:22:47.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:22:47.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:47.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:22:47.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:22:47.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:47.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:22:47.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:22:47.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:22:47.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-20T18:23:18.058+0000] {processor.py:157} INFO - Started process (PID=8624) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:23:18.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:23:18.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:18.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:23:18.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:23:18.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:18.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:23:18.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:18.100+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:23:18.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:23:48.531+0000] {processor.py:157} INFO - Started process (PID=8649) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:23:48.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:23:48.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:48.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:23:48.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:23:48.566+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:48.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:23:48.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:23:48.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:23:48.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T18:24:18.972+0000] {processor.py:157} INFO - Started process (PID=8674) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:24:18.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:24:18.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:18.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:24:18.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:24:19.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:19.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:24:19.011+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:19.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:24:19.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T18:24:49.432+0000] {processor.py:157} INFO - Started process (PID=8699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:24:49.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:24:49.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:49.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:24:49.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:24:49.463+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:49.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:24:49.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:24:49.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:24:49.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:25:20.092+0000] {processor.py:157} INFO - Started process (PID=8724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:25:20.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:25:20.096+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:20.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:25:20.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:25:20.121+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:20.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:25:20.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:20.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:25:20.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-20T18:25:50.661+0000] {processor.py:157} INFO - Started process (PID=8749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:25:50.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:25:50.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:50.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:25:50.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:25:50.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:50.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:25:50.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:25:50.770+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:25:50.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-20T18:26:21.196+0000] {processor.py:157} INFO - Started process (PID=8774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:26:21.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:26:21.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:21.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:26:21.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:26:21.229+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:21.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:26:21.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:21.239+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:26:21.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:26:51.697+0000] {processor.py:157} INFO - Started process (PID=8799) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:26:51.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:26:51.700+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:51.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:26:51.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:26:51.729+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:51.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:26:51.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:26:51.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:26:51.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T18:27:22.206+0000] {processor.py:157} INFO - Started process (PID=8824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:27:22.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:27:22.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:22.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:27:22.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:27:22.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:22.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:27:22.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:22.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:27:22.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:27:52.705+0000] {processor.py:157} INFO - Started process (PID=8849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:27:52.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:27:52.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:52.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:27:52.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:27:52.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:52.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:27:52.816+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:27:52.816+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:27:52.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-20T18:28:23.322+0000] {processor.py:157} INFO - Started process (PID=8874) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:28:23.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:28:23.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:23.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:28:23.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:28:23.357+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:23.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:28:23.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:23.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:28:23.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:28:53.883+0000] {processor.py:157} INFO - Started process (PID=8899) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:28:53.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:28:53.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:53.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:28:53.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:28:53.988+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:53.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:28:53.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:28:53.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:28:54.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:29:24.451+0000] {processor.py:157} INFO - Started process (PID=8924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:29:24.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:29:24.454+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:24.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:29:24.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:29:24.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:24.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:29:24.495+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:24.494+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:29:24.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T18:29:54.932+0000] {processor.py:157} INFO - Started process (PID=8949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:29:54.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:29:54.937+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:54.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:29:54.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:29:54.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:54.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:29:54.980+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:29:54.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:29:54.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T18:30:25.381+0000] {processor.py:157} INFO - Started process (PID=8974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:30:25.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:30:25.386+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:25.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:30:25.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:30:25.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:25.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:30:25.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:25.428+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:30:25.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-20T18:30:55.956+0000] {processor.py:157} INFO - Started process (PID=8999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:30:55.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:30:55.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:55.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:30:55.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:30:55.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:55.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:30:56.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:30:56.078+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:30:56.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-20T18:31:26.506+0000] {processor.py:157} INFO - Started process (PID=9024) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:31:26.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:31:26.509+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:26.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:31:26.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:31:26.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:26.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:31:26.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:26.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:31:26.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-20T18:31:57.198+0000] {processor.py:157} INFO - Started process (PID=9049) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:31:57.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:31:57.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:57.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:31:57.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:31:57.228+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:57.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:31:57.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:31:57.237+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:31:57.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T18:32:27.562+0000] {processor.py:157} INFO - Started process (PID=9074) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:32:27.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:32:27.564+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:27.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:32:27.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:32:27.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:27.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:32:27.603+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:27.603+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:32:27.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T18:32:58.035+0000] {processor.py:157} INFO - Started process (PID=9099) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:32:58.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:32:58.038+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:58.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:32:58.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:32:58.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:58.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:32:58.081+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:32:58.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:32:58.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T18:33:28.515+0000] {processor.py:157} INFO - Started process (PID=9124) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:33:28.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:33:28.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:28.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:33:28.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:33:28.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:28.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:33:28.626+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:28.626+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:33:28.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:33:59.196+0000] {processor.py:157} INFO - Started process (PID=9149) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:33:59.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:33:59.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:59.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:33:59.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:33:59.231+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:59.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:33:59.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:33:59.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:33:59.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-20T18:34:29.721+0000] {processor.py:157} INFO - Started process (PID=9174) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:34:29.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:34:29.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:34:29.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:34:29.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:34:29.833+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:34:29.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:34:29.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:34:29.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:34:29.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-20T18:35:00.293+0000] {processor.py:157} INFO - Started process (PID=9199) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:35:00.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:35:00.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:00.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:35:00.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:35:00.327+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:00.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:35:00.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:00.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:35:00.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T18:35:30.736+0000] {processor.py:157} INFO - Started process (PID=9224) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:35:30.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:35:30.739+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:30.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:35:30.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:35:30.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:30.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:35:30.778+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:35:30.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:35:30.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T18:36:01.201+0000] {processor.py:157} INFO - Started process (PID=9249) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:36:01.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:36:01.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:01.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:36:01.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:36:01.235+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:01.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:36:01.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:01.245+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:36:01.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-20T18:36:31.744+0000] {processor.py:157} INFO - Started process (PID=9274) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:36:31.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:36:31.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:31.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:36:31.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:36:31.771+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:31.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:36:31.853+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:36:31.853+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:36:31.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-20T18:37:02.323+0000] {processor.py:157} INFO - Started process (PID=9299) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:37:02.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:37:02.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:02.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:37:02.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:37:02.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:02.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:37:02.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:02.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:37:02.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:37:33.000+0000] {processor.py:157} INFO - Started process (PID=9324) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:37:33.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:37:33.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:33.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:37:33.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:37:33.106+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:33.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:37:33.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:37:33.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:37:33.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-20T18:38:03.537+0000] {processor.py:157} INFO - Started process (PID=9349) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:38:03.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:38:03.544+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:03.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:38:03.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:38:03.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:03.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:38:03.583+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:03.583+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:38:03.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T18:38:33.944+0000] {processor.py:157} INFO - Started process (PID=9374) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:38:33.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:38:33.950+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:33.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:38:33.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:38:33.978+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:33.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:38:33.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:38:33.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:38:33.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T18:39:04.404+0000] {processor.py:157} INFO - Started process (PID=9399) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:39:04.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:39:04.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:04.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:39:04.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:39:04.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:04.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:39:04.450+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:04.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:39:04.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-20T18:39:34.939+0000] {processor.py:157} INFO - Started process (PID=9424) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:39:34.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:39:34.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:34.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:39:34.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:39:34.972+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:34.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:39:35.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:39:35.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:39:35.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-20T18:40:05.479+0000] {processor.py:157} INFO - Started process (PID=9449) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:40:05.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:40:05.482+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:05.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:40:05.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:40:05.513+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:05.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:40:05.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:05.591+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:40:05.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-20T18:40:36.170+0000] {processor.py:157} INFO - Started process (PID=9474) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:40:36.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:40:36.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:36.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:40:36.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:40:36.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:36.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:40:36.279+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:40:36.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:40:36.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-20T18:41:06.778+0000] {processor.py:157} INFO - Started process (PID=9499) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:41:06.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:41:06.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:06.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:41:06.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:41:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:06.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:41:06.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:06.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:41:06.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-20T18:41:37.234+0000] {processor.py:157} INFO - Started process (PID=9524) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:41:37.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:41:37.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:37.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:41:37.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:41:37.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:37.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:41:37.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:41:37.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:41:37.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T18:42:07.752+0000] {processor.py:157} INFO - Started process (PID=9549) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:42:07.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:42:07.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:07.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:42:07.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:42:07.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:07.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:42:07.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:07.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:42:07.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-20T18:42:38.344+0000] {processor.py:157} INFO - Started process (PID=9574) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:42:38.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:42:38.351+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:38.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:42:38.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:42:38.377+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:38.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:42:38.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:42:38.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:42:38.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-20T18:43:08.999+0000] {processor.py:157} INFO - Started process (PID=9599) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:43:09.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:43:09.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:09.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:43:09.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:43:09.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:09.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:43:09.107+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:09.106+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:43:09.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-20T18:43:39.691+0000] {processor.py:157} INFO - Started process (PID=9624) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:43:39.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:43:39.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:39.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:43:39.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:43:39.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:39.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:43:39.732+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:43:39.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:43:39.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T18:44:10.106+0000] {processor.py:157} INFO - Started process (PID=9649) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:44:10.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:44:10.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:10.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:44:10.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:44:10.140+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:10.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:44:10.150+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:10.150+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:44:10.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T18:44:40.535+0000] {processor.py:157} INFO - Started process (PID=9674) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:44:40.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:44:40.539+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:40.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:44:40.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:44:40.568+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:40.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:44:40.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:44:40.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:44:40.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:45:11.084+0000] {processor.py:157} INFO - Started process (PID=9699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:45:11.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:45:11.086+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:11.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:45:11.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:45:11.113+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:11.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:45:11.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:11.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:45:11.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-20T18:45:41.773+0000] {processor.py:157} INFO - Started process (PID=9724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:45:41.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:45:41.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:41.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:45:41.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:45:41.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:41.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:45:41.885+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:45:41.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:45:41.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:46:12.479+0000] {processor.py:157} INFO - Started process (PID=9749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:46:12.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:46:12.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:12.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:46:12.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:46:12.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:12.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:46:12.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:12.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:46:12.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-20T18:46:43.133+0000] {processor.py:157} INFO - Started process (PID=9774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:46:43.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:46:43.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:43.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:46:43.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:46:43.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:43.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:46:43.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:46:43.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:46:43.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T18:47:13.587+0000] {processor.py:157} INFO - Started process (PID=9799) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:47:13.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:47:13.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:13.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:47:13.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:47:13.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:13.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:47:13.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:13.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:47:13.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T18:47:44.030+0000] {processor.py:157} INFO - Started process (PID=9824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:47:44.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:47:44.033+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:44.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:47:44.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:47:44.065+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:44.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:47:44.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:47:44.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:47:44.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-20T18:48:14.659+0000] {processor.py:157} INFO - Started process (PID=9849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:48:14.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:48:14.663+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:14.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:48:14.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:48:14.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:14.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:48:14.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:14.770+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:48:14.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-20T18:48:45.226+0000] {processor.py:157} INFO - Started process (PID=9874) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:48:45.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:48:45.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:45.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:48:45.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:48:45.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:45.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:48:45.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:48:45.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:48:45.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-20T18:49:15.891+0000] {processor.py:157} INFO - Started process (PID=9899) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:49:15.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:49:15.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:15.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:49:15.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:49:15.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:15.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:49:16.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:16.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:49:16.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-20T18:49:46.544+0000] {processor.py:157} INFO - Started process (PID=9924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:49:46.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:49:46.548+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:46.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:49:46.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:49:46.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:46.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:49:46.586+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:49:46.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:49:46.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T18:50:17.042+0000] {processor.py:157} INFO - Started process (PID=9949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:50:17.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:50:17.046+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:17.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:50:17.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:50:17.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:17.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:50:17.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:17.083+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:50:17.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T18:50:47.457+0000] {processor.py:157} INFO - Started process (PID=9974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:50:47.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:50:47.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:47.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:50:47.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:50:47.492+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:47.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:50:47.573+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:50:47.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:50:47.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-20T18:51:18.130+0000] {processor.py:157} INFO - Started process (PID=9999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:51:18.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:51:18.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:18.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:51:18.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:51:18.162+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:18.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:51:18.239+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:18.239+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:51:18.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-20T18:51:48.803+0000] {processor.py:157} INFO - Started process (PID=10024) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:51:48.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:51:48.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:48.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:51:48.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:51:48.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:48.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:51:48.911+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:51:48.911+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:51:48.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-20T18:52:19.457+0000] {processor.py:157} INFO - Started process (PID=10049) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:52:19.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:52:19.462+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:19.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:52:19.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:52:19.492+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:19.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:52:19.501+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:19.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:52:19.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T18:52:49.873+0000] {processor.py:157} INFO - Started process (PID=10074) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:52:49.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:52:49.881+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:49.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:52:49.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:52:49.911+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:49.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:52:49.922+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:52:49.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:52:49.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T18:53:20.350+0000] {processor.py:157} INFO - Started process (PID=10099) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:53:20.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:53:20.353+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:20.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:53:20.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:53:20.380+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:20.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:53:20.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:20.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:53:20.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-20T18:53:50.927+0000] {processor.py:157} INFO - Started process (PID=10124) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:53:50.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:53:50.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:50.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:53:50.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:53:50.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:50.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:53:51.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:53:51.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:53:51.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-20T18:54:21.488+0000] {processor.py:157} INFO - Started process (PID=10149) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:54:21.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:54:21.491+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:21.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:54:21.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:54:21.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:21.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:54:21.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:21.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:54:21.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-20T18:54:52.038+0000] {processor.py:157} INFO - Started process (PID=10174) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:54:52.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:54:52.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:52.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:54:52.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:54:52.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:52.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:54:52.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:54:52.145+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:54:52.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-20T18:55:22.614+0000] {processor.py:157} INFO - Started process (PID=10199) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:55:22.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:55:22.619+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:22.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:55:22.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:55:22.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:22.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:55:22.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:22.669+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:55:22.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T18:55:53.143+0000] {processor.py:157} INFO - Started process (PID=10224) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:55:53.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:55:53.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:53.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:55:53.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:55:53.183+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:53.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:55:53.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:55:53.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:55:53.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T18:56:23.638+0000] {processor.py:157} INFO - Started process (PID=10249) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:56:23.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:56:23.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:23.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:56:23.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:56:23.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:23.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:56:23.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:23.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:56:23.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.180 seconds
[2024-07-20T18:56:54.362+0000] {processor.py:157} INFO - Started process (PID=10274) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:56:54.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:56:54.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:54.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:56:54.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:56:54.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:54.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:56:54.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:56:54.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:56:54.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-20T18:57:24.936+0000] {processor.py:157} INFO - Started process (PID=10299) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:57:24.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:57:24.939+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:24.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:57:24.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:57:25.040+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:25.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:57:25.047+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:25.047+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:57:25.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:57:55.607+0000] {processor.py:157} INFO - Started process (PID=10324) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:57:55.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:57:55.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:55.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:57:55.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:57:55.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:55.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:57:55.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:57:55.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:57:55.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-20T18:58:26.284+0000] {processor.py:157} INFO - Started process (PID=10349) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:58:26.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:58:26.286+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:26.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:58:26.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:58:26.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:26.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:58:26.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:26.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:58:26.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T18:58:56.738+0000] {processor.py:157} INFO - Started process (PID=10374) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:58:56.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:58:56.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:56.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:58:56.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:58:56.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:56.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:58:56.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:58:56.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:58:56.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-20T18:59:27.322+0000] {processor.py:157} INFO - Started process (PID=10399) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:59:27.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:59:27.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:27.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:59:27.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:59:27.351+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:27.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:59:27.430+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:27.430+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:59:27.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-20T18:59:57.851+0000] {processor.py:157} INFO - Started process (PID=10424) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:59:57.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T18:59:57.854+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:57.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:59:57.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T18:59:57.883+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:57.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T18:59:57.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T18:59:57.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T18:59:57.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-20T19:00:28.426+0000] {processor.py:157} INFO - Started process (PID=10449) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:00:28.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:00:28.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:28.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:00:28.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:00:28.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:28.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:00:28.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:28.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:00:28.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-20T19:00:59.045+0000] {processor.py:157} INFO - Started process (PID=10474) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:00:59.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:00:59.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:59.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:00:59.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:00:59.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:59.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:00:59.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:00:59.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:00:59.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-20T19:01:29.826+0000] {processor.py:157} INFO - Started process (PID=10499) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:01:29.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:01:29.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:01:29.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:01:29.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:01:29.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:01:29.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:01:29.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:01:29.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:01:29.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:02:00.248+0000] {processor.py:157} INFO - Started process (PID=10524) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:02:00.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:02:00.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:00.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:02:00.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:02:00.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:00.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:02:00.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:00.282+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:02:00.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-20T19:02:30.668+0000] {processor.py:157} INFO - Started process (PID=10549) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:02:30.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:02:30.671+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:30.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:02:30.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:02:30.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:30.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:02:30.707+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:02:30.707+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:02:30.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T19:03:01.045+0000] {processor.py:157} INFO - Started process (PID=10574) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:03:01.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:03:01.047+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:01.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:03:01.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:03:01.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:01.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:03:01.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:01.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:03:01.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T19:03:31.495+0000] {processor.py:157} INFO - Started process (PID=10599) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:03:31.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:03:31.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:31.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:03:31.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:03:31.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:31.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:03:31.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:03:31.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:03:31.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T19:04:01.987+0000] {processor.py:157} INFO - Started process (PID=10624) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:04:01.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:04:01.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:01.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:04:02.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:04:02.020+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:02.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:04:02.031+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:02.031+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:04:02.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:04:32.403+0000] {processor.py:157} INFO - Started process (PID=10649) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:04:32.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:04:32.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:32.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:04:32.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:04:32.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:32.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:04:32.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:04:32.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:04:32.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:05:02.926+0000] {processor.py:157} INFO - Started process (PID=10674) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:05:02.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:05:02.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:02.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:05:02.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:05:02.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:02.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:05:02.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:02.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:05:02.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:05:33.347+0000] {processor.py:157} INFO - Started process (PID=10699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:05:33.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:05:33.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:33.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:05:33.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:05:33.379+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:33.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:05:33.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:05:33.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:05:33.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:06:03.798+0000] {processor.py:157} INFO - Started process (PID=10724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:06:03.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:06:03.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:03.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:06:03.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:06:03.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:03.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:06:03.839+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:03.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:06:03.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:06:34.224+0000] {processor.py:157} INFO - Started process (PID=10749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:06:34.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:06:34.228+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:34.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:06:34.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:06:34.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:34.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:06:34.267+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:06:34.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:06:34.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:07:04.718+0000] {processor.py:157} INFO - Started process (PID=10774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:07:04.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:07:04.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:04.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:07:04.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:07:04.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:04.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:07:04.760+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:04.760+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:07:04.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:07:35.181+0000] {processor.py:157} INFO - Started process (PID=10799) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:07:35.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:07:35.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:35.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:07:35.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:07:35.212+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:35.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:07:35.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:07:35.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:07:35.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:08:05.609+0000] {processor.py:157} INFO - Started process (PID=10824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:08:05.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:08:05.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:05.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:08:05.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:08:05.639+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:05.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:08:05.649+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:05.649+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:08:05.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:08:36.124+0000] {processor.py:157} INFO - Started process (PID=10849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:08:36.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:08:36.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:36.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:08:36.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:08:36.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:36.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:08:36.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:08:36.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:08:36.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:09:06.579+0000] {processor.py:157} INFO - Started process (PID=10874) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:09:06.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:09:06.585+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:06.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:09:06.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:09:06.612+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:06.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:09:06.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:06.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:09:06.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:09:37.099+0000] {processor.py:157} INFO - Started process (PID=10899) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:09:37.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:09:37.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:37.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:09:37.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:09:37.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:37.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:09:37.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:09:37.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:09:37.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:10:07.524+0000] {processor.py:157} INFO - Started process (PID=10924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:10:07.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:10:07.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:07.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:10:07.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:10:07.553+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:07.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:10:07.563+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:07.562+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:10:07.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T19:10:37.925+0000] {processor.py:157} INFO - Started process (PID=10949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:10:37.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:10:37.927+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:37.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:10:37.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:10:37.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:37.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:10:37.963+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:10:37.963+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:10:37.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T19:11:08.379+0000] {processor.py:157} INFO - Started process (PID=10974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:11:08.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:11:08.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:08.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:11:08.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:11:08.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:08.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:11:08.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:08.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:11:08.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:11:38.817+0000] {processor.py:157} INFO - Started process (PID=10999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:11:38.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:11:38.822+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:38.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:11:38.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:11:38.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:38.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:11:38.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:11:38.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:11:38.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:12:09.288+0000] {processor.py:157} INFO - Started process (PID=11024) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:12:09.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:12:09.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:09.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:12:09.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:12:09.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:09.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:12:09.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:09.331+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:12:09.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:12:39.748+0000] {processor.py:157} INFO - Started process (PID=11049) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:12:39.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:12:39.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:39.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:12:39.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:12:39.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:39.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:12:39.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:12:39.793+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:12:39.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:13:10.202+0000] {processor.py:157} INFO - Started process (PID=11074) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:13:10.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:13:10.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:10.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:13:10.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:13:10.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:10.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:13:10.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:10.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:13:10.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:13:40.613+0000] {processor.py:157} INFO - Started process (PID=11099) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:13:40.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:13:40.616+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:40.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:13:40.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:13:40.645+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:40.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:13:40.658+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:13:40.658+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:13:40.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:14:11.109+0000] {processor.py:157} INFO - Started process (PID=11124) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:14:11.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:14:11.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:11.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:14:11.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:14:11.144+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:11.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:14:11.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:11.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:14:11.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:14:41.576+0000] {processor.py:157} INFO - Started process (PID=11149) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:14:41.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:14:41.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:41.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:14:41.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:14:41.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:41.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:14:41.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:14:41.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:14:41.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:15:12.037+0000] {processor.py:157} INFO - Started process (PID=11174) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:15:12.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:15:12.041+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:12.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:15:12.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:15:12.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:12.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:15:12.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:12.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:15:12.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:15:42.541+0000] {processor.py:157} INFO - Started process (PID=11199) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:15:42.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:15:42.547+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:42.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:15:42.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:15:42.581+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:42.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:15:42.591+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:15:42.591+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:15:42.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T19:16:13.027+0000] {processor.py:157} INFO - Started process (PID=11224) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:16:13.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:16:13.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:13.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:16:13.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:16:13.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:13.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:16:13.077+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:13.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:16:13.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T19:16:43.434+0000] {processor.py:157} INFO - Started process (PID=11249) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:16:43.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:16:43.436+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:43.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:16:43.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:16:43.461+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:43.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:16:43.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:16:43.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:16:43.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:17:13.879+0000] {processor.py:157} INFO - Started process (PID=11274) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:17:13.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:17:13.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:13.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:17:13.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:17:13.912+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:13.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:17:13.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:13.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:17:13.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:17:44.360+0000] {processor.py:157} INFO - Started process (PID=11299) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:17:44.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:17:44.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:44.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:17:44.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:17:44.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:44.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:17:44.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:17:44.402+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:17:44.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:18:14.828+0000] {processor.py:157} INFO - Started process (PID=11324) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:18:14.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:18:14.831+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:14.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:18:14.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:18:14.860+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:14.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:18:14.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:14.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:18:14.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:18:45.244+0000] {processor.py:157} INFO - Started process (PID=11349) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:18:45.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:18:45.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:45.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:18:45.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:18:45.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:45.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:18:45.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:18:45.282+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:18:45.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T19:19:15.706+0000] {processor.py:157} INFO - Started process (PID=11374) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:19:15.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:19:15.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:15.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:19:15.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:19:15.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:15.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:19:15.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:15.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:19:15.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:19:46.204+0000] {processor.py:157} INFO - Started process (PID=11399) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:19:46.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:19:46.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:46.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:19:46.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:19:46.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:46.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:19:46.243+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:19:46.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:19:46.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T19:20:16.685+0000] {processor.py:157} INFO - Started process (PID=11424) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:20:16.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:20:16.688+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:16.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:20:16.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:20:16.716+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:16.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:20:16.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:16.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:20:16.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:20:47.074+0000] {processor.py:157} INFO - Started process (PID=11449) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:20:47.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:20:47.078+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:47.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:20:47.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:20:47.107+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:47.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:20:47.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:20:47.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:20:47.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:21:17.511+0000] {processor.py:157} INFO - Started process (PID=11474) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:21:17.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:21:17.513+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:17.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:21:17.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:21:17.546+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:17.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:21:17.559+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:17.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:21:17.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T19:21:47.965+0000] {processor.py:157} INFO - Started process (PID=11499) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:21:47.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:21:47.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:47.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:21:47.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:21:47.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:47.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:21:48.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:21:48.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:21:48.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:22:18.434+0000] {processor.py:157} INFO - Started process (PID=11524) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:22:18.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:22:18.438+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:18.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:22:18.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:22:18.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:18.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:22:18.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:18.478+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:22:18.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:22:48.916+0000] {processor.py:157} INFO - Started process (PID=11549) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:22:48.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:22:48.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:48.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:22:48.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:22:48.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:48.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:22:48.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:22:48.959+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:22:48.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:23:19.357+0000] {processor.py:157} INFO - Started process (PID=11574) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:23:19.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:23:19.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:19.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:23:19.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:23:19.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:19.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:23:19.405+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:19.405+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:23:19.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T19:23:49.839+0000] {processor.py:157} INFO - Started process (PID=11599) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:23:49.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:23:49.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:49.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:23:49.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:23:49.870+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:49.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:23:49.880+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:23:49.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:23:49.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:24:20.274+0000] {processor.py:157} INFO - Started process (PID=11624) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:24:20.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:24:20.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:20.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:24:20.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:24:20.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:20.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:24:20.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:20.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:24:20.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:24:50.794+0000] {processor.py:157} INFO - Started process (PID=11649) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:24:50.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:24:50.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:50.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:24:50.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:24:50.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:50.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:24:50.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:24:50.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:24:50.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:25:21.196+0000] {processor.py:157} INFO - Started process (PID=11674) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:25:21.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:25:21.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:21.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:25:21.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:25:21.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:21.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:25:21.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:21.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:25:21.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:25:51.684+0000] {processor.py:157} INFO - Started process (PID=11699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:25:51.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:25:51.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:51.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:25:51.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:25:51.716+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:51.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:25:51.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:25:51.726+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:25:51.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:26:22.147+0000] {processor.py:157} INFO - Started process (PID=11724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:26:22.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:26:22.152+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:22.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:26:22.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:26:22.183+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:22.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:26:22.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:22.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:26:22.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:26:52.657+0000] {processor.py:157} INFO - Started process (PID=11749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:26:52.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:26:52.661+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:52.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:26:52.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:26:52.689+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:52.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:26:52.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:26:52.698+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:26:52.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:27:23.129+0000] {processor.py:157} INFO - Started process (PID=11774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:27:23.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:27:23.132+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:23.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:27:23.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:27:23.164+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:23.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:27:23.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:23.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:27:23.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:27:53.604+0000] {processor.py:157} INFO - Started process (PID=11799) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:27:53.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:27:53.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:53.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:27:53.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:27:53.636+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:53.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:27:53.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:27:53.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:27:53.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:28:24.070+0000] {processor.py:157} INFO - Started process (PID=11824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:28:24.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:28:24.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:24.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:28:24.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:28:24.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:24.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:28:24.116+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:24.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:28:24.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T19:28:54.512+0000] {processor.py:157} INFO - Started process (PID=11849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:28:54.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:28:54.515+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:54.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:28:54.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:28:54.543+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:54.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:28:54.552+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:28:54.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:28:54.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:29:24.970+0000] {processor.py:157} INFO - Started process (PID=11874) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:29:24.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:29:24.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:24.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:29:24.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:29:25.004+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:25.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:29:25.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:25.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:29:25.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:29:55.390+0000] {processor.py:157} INFO - Started process (PID=11899) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:29:55.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:29:55.394+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:55.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:29:55.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:29:55.425+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:55.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:29:55.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:29:55.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:29:55.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:30:25.808+0000] {processor.py:157} INFO - Started process (PID=11924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:30:25.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:30:25.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:25.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:30:25.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:30:25.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:25.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:30:25.851+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:25.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:30:25.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:30:56.327+0000] {processor.py:157} INFO - Started process (PID=11949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:30:56.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:30:56.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:56.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:30:56.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:30:56.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:56.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:30:56.367+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:30:56.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:30:56.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:31:26.758+0000] {processor.py:157} INFO - Started process (PID=11974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:31:26.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:31:26.760+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:26.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:31:26.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:31:26.786+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:26.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:31:26.798+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:26.798+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:31:26.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:31:57.203+0000] {processor.py:157} INFO - Started process (PID=11999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:31:57.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:31:57.206+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:57.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:31:57.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:31:57.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:57.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:31:57.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:31:57.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:31:57.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:32:27.633+0000] {processor.py:157} INFO - Started process (PID=12024) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:32:27.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:32:27.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:27.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:32:27.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:32:27.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:27.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:32:27.674+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:27.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:32:27.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:32:58.100+0000] {processor.py:157} INFO - Started process (PID=12049) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:32:58.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:32:58.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:58.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:32:58.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:32:58.129+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:58.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:32:58.139+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:32:58.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:32:58.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:33:28.500+0000] {processor.py:157} INFO - Started process (PID=12074) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:33:28.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:33:28.504+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:28.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:33:28.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:33:28.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:28.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:33:28.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:28.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:33:28.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:33:59.012+0000] {processor.py:157} INFO - Started process (PID=12099) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:33:59.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:33:59.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:59.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:33:59.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:33:59.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:59.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:33:59.057+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:33:59.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:33:59.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:34:29.436+0000] {processor.py:157} INFO - Started process (PID=12124) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:34:29.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:34:29.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:29.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:34:29.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:34:29.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:29.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:34:29.481+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:29.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:34:29.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:34:59.832+0000] {processor.py:157} INFO - Started process (PID=12149) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:34:59.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:34:59.835+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:59.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:34:59.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:34:59.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:59.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:34:59.877+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:34:59.877+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:34:59.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:35:30.245+0000] {processor.py:157} INFO - Started process (PID=12174) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:35:30.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:35:30.248+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:35:30.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:35:30.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:35:30.279+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:35:30.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:35:30.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:35:30.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:35:30.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:36:00.663+0000] {processor.py:157} INFO - Started process (PID=12199) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:36:00.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:36:00.666+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:00.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:36:00.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:36:00.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:00.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:36:00.708+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:00.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:36:00.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:36:31.152+0000] {processor.py:157} INFO - Started process (PID=12224) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:36:31.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:36:31.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:31.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:36:31.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:36:31.185+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:31.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:36:31.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:36:31.196+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:36:31.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:37:01.528+0000] {processor.py:157} INFO - Started process (PID=12249) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:37:01.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:37:01.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:01.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:37:01.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:37:01.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:01.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:37:01.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:01.570+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:37:01.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:37:32.018+0000] {processor.py:157} INFO - Started process (PID=12274) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:37:32.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:37:32.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:32.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:37:32.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:37:32.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:32.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:37:32.063+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:37:32.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:37:32.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:38:02.491+0000] {processor.py:157} INFO - Started process (PID=12299) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:38:02.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:38:02.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:02.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:38:02.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:38:02.526+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:02.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:38:02.538+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:02.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:38:02.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T19:38:32.859+0000] {processor.py:157} INFO - Started process (PID=12324) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:38:32.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:38:32.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:32.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:38:32.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:38:32.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:32.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:38:32.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:38:32.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:38:32.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:39:03.341+0000] {processor.py:157} INFO - Started process (PID=12349) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:39:03.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:39:03.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:03.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:39:03.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:39:03.373+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:03.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:39:03.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:03.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:39:03.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:39:33.800+0000] {processor.py:157} INFO - Started process (PID=12374) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:39:33.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:39:33.803+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:33.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:39:33.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:39:33.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:33.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:39:33.846+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:39:33.846+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:39:33.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:40:04.289+0000] {processor.py:157} INFO - Started process (PID=12399) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:40:04.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:40:04.292+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:04.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:40:04.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:40:04.319+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:04.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:40:04.329+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:04.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:40:04.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:40:34.730+0000] {processor.py:157} INFO - Started process (PID=12424) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:40:34.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:40:34.735+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:34.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:40:34.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:40:34.765+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:34.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:40:34.775+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:40:34.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:40:34.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:41:05.318+0000] {processor.py:157} INFO - Started process (PID=12449) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:41:05.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:41:05.324+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:05.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:41:05.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:41:05.349+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:05.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:41:05.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:05.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:41:05.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:41:35.802+0000] {processor.py:157} INFO - Started process (PID=12474) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:41:35.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:41:35.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:35.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:41:35.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:41:35.833+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:35.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:41:35.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:41:35.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:41:35.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:42:06.229+0000] {processor.py:157} INFO - Started process (PID=12499) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:42:06.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:42:06.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:06.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:42:06.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:42:06.261+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:06.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:42:06.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:06.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:42:06.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:42:36.700+0000] {processor.py:157} INFO - Started process (PID=12524) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:42:36.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:42:36.704+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:36.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:42:36.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:42:36.731+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:36.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:42:36.742+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:42:36.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:42:36.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:43:07.197+0000] {processor.py:157} INFO - Started process (PID=12549) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:43:07.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:43:07.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:07.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:43:07.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:43:07.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:07.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:43:07.249+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:07.249+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:43:07.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T19:43:37.690+0000] {processor.py:157} INFO - Started process (PID=12574) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:43:37.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:43:37.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:37.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:43:37.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:43:37.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:37.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:43:37.730+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:43:37.730+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:43:37.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T19:44:08.152+0000] {processor.py:157} INFO - Started process (PID=12599) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:44:08.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:44:08.155+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:08.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:44:08.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:44:08.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:08.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:44:08.192+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:08.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:44:08.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:44:38.649+0000] {processor.py:157} INFO - Started process (PID=12624) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:44:38.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:44:38.655+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:38.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:44:38.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:44:38.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:38.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:44:38.691+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:44:38.691+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:44:38.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T19:45:09.114+0000] {processor.py:157} INFO - Started process (PID=12649) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:45:09.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:45:09.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:09.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:45:09.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:45:09.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:09.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:45:09.158+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:09.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:45:09.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:45:39.565+0000] {processor.py:157} INFO - Started process (PID=12674) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:45:39.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:45:39.568+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:39.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:45:39.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:45:39.596+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:39.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:45:39.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:45:39.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:45:39.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:46:10.017+0000] {processor.py:157} INFO - Started process (PID=12699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:46:10.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:46:10.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:10.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:46:10.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:46:10.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:10.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:46:10.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:10.061+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:46:10.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:46:40.422+0000] {processor.py:157} INFO - Started process (PID=12724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:46:40.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:46:40.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:40.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:46:40.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:46:40.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:40.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:46:40.469+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:46:40.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:46:40.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T19:47:10.943+0000] {processor.py:157} INFO - Started process (PID=12749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:47:10.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:47:10.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:10.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:47:10.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:47:10.978+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:10.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:47:10.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:10.989+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:47:10.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:47:41.353+0000] {processor.py:157} INFO - Started process (PID=12774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:47:41.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:47:41.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:41.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:47:41.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:47:41.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:41.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:47:41.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:47:41.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:47:41.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:48:11.768+0000] {processor.py:157} INFO - Started process (PID=12799) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:48:11.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:48:11.771+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:11.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:48:11.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:48:11.797+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:11.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:48:11.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:11.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:48:11.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:48:42.200+0000] {processor.py:157} INFO - Started process (PID=12824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:48:42.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:48:42.205+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:42.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:48:42.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:48:42.234+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:42.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:48:42.243+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:48:42.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:48:42.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:49:12.608+0000] {processor.py:157} INFO - Started process (PID=12849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:49:12.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:49:12.613+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:12.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:49:12.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:49:12.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:12.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:49:12.653+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:12.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:49:12.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:49:43.084+0000] {processor.py:157} INFO - Started process (PID=12874) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:49:43.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:49:43.087+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:43.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:49:43.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:49:43.118+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:43.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:49:43.128+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:49:43.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:49:43.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:50:13.530+0000] {processor.py:157} INFO - Started process (PID=12899) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:50:13.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:50:13.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:13.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:50:13.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:50:13.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:13.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:50:13.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:13.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:50:13.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T19:50:43.957+0000] {processor.py:157} INFO - Started process (PID=12924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:50:43.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:50:43.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:43.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:50:43.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:50:43.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:43.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:50:44.000+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:50:44.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:50:44.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:51:14.369+0000] {processor.py:157} INFO - Started process (PID=12949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:51:14.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:51:14.373+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:14.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:51:14.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:51:14.400+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:14.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:51:14.410+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:14.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:51:14.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T19:51:44.775+0000] {processor.py:157} INFO - Started process (PID=12974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:51:44.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:51:44.778+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:44.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:51:44.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:51:44.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:44.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:51:44.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:51:44.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:51:44.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T19:52:15.240+0000] {processor.py:157} INFO - Started process (PID=12999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:52:15.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:52:15.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:15.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:52:15.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:52:15.272+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:15.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:52:15.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:15.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:52:15.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:52:45.671+0000] {processor.py:157} INFO - Started process (PID=13024) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:52:45.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:52:45.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:45.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:52:45.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:52:45.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:45.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:52:45.707+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:52:45.707+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:52:45.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T19:53:16.180+0000] {processor.py:157} INFO - Started process (PID=13049) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:53:16.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:53:16.184+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:16.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:53:16.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:53:16.210+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:16.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:53:16.227+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:16.227+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:53:16.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:53:46.624+0000] {processor.py:157} INFO - Started process (PID=13074) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:53:46.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:53:46.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:46.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:53:46.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:53:46.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:46.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:53:46.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:53:46.669+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:53:46.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T19:54:17.079+0000] {processor.py:157} INFO - Started process (PID=13099) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:54:17.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:54:17.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:17.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:54:17.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:54:17.115+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:17.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:54:17.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:17.124+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:54:17.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T19:54:47.569+0000] {processor.py:157} INFO - Started process (PID=13124) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:54:47.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:54:47.572+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:47.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:54:47.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:54:47.600+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:47.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:54:47.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:54:47.609+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:54:47.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T19:55:17.965+0000] {processor.py:157} INFO - Started process (PID=13149) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:55:17.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:55:17.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:17.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:55:17.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:55:17.998+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:17.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:55:18.008+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:18.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:55:18.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:55:48.411+0000] {processor.py:157} INFO - Started process (PID=13174) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:55:48.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:55:48.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:48.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:55:48.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:55:48.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:48.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:55:48.455+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:55:48.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:55:48.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:56:18.864+0000] {processor.py:157} INFO - Started process (PID=13199) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:56:18.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:56:18.867+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:18.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:56:18.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:56:18.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:18.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:56:18.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:18.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:56:18.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T19:56:49.273+0000] {processor.py:157} INFO - Started process (PID=13224) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:56:49.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:56:49.276+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:49.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:56:49.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:56:49.305+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:49.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:56:49.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:56:49.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:56:49.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T19:57:19.732+0000] {processor.py:157} INFO - Started process (PID=13249) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:57:19.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:57:19.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:19.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:57:19.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:57:19.764+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:19.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:57:19.776+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:19.776+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:57:19.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T19:57:50.121+0000] {processor.py:157} INFO - Started process (PID=13274) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:57:50.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:57:50.125+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:50.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:57:50.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:57:50.149+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:50.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:57:50.159+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:57:50.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:57:50.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T19:58:20.618+0000] {processor.py:157} INFO - Started process (PID=13299) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:58:20.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:58:20.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:20.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:58:20.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:58:20.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:20.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:58:20.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:20.657+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:58:20.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T19:58:51.016+0000] {processor.py:157} INFO - Started process (PID=13324) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:58:51.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:58:51.020+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:51.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:58:51.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:58:51.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:51.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:58:51.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:58:51.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:58:51.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T19:59:21.493+0000] {processor.py:157} INFO - Started process (PID=13349) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:59:21.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:59:21.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:21.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:59:21.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:59:21.526+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:21.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:59:21.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:21.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:59:21.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T19:59:51.891+0000] {processor.py:157} INFO - Started process (PID=13374) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:59:51.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T19:59:51.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:51.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:59:51.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T19:59:51.919+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:51.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T19:59:51.929+0000] {logging_mixin.py:151} INFO - [2024-07-20T19:59:51.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T19:59:51.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T20:00:22.378+0000] {processor.py:157} INFO - Started process (PID=13399) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:00:22.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:00:22.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:22.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:00:22.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:00:22.411+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:22.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:00:22.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:22.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:00:22.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:00:52.816+0000] {processor.py:157} INFO - Started process (PID=13424) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:00:52.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:00:52.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:52.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:00:52.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:00:52.848+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:52.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:00:52.858+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:00:52.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:00:52.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:01:23.298+0000] {processor.py:157} INFO - Started process (PID=13449) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:01:23.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:01:23.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:23.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:01:23.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:01:23.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:23.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:01:23.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:23.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:01:23.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T20:01:53.720+0000] {processor.py:157} INFO - Started process (PID=13474) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:01:53.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:01:53.723+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:53.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:01:53.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:01:53.749+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:53.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:01:53.759+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:01:53.759+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:01:53.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:02:24.170+0000] {processor.py:157} INFO - Started process (PID=13499) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:02:24.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:02:24.174+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:24.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:02:24.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:02:24.201+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:24.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:02:24.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:24.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:02:24.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T20:02:54.628+0000] {processor.py:157} INFO - Started process (PID=13524) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:02:54.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:02:54.632+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:54.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:02:54.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:02:54.662+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:54.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:02:54.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:02:54.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:02:54.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T20:18:26.274+0000] {processor.py:157} INFO - Started process (PID=13551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:18:26.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:18:26.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:26.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:18:26.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:18:26.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:26.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:18:26.388+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:26.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:18:26.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.146 seconds
[2024-07-20T20:18:56.876+0000] {processor.py:157} INFO - Started process (PID=13576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:18:56.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:18:56.880+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:56.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:18:56.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:18:56.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:56.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:18:56.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:18:56.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:18:56.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:19:27.359+0000] {processor.py:157} INFO - Started process (PID=13601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:19:27.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:19:27.364+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:27.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:19:27.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:19:27.393+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:27.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:19:27.404+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:27.403+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:19:27.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:19:57.819+0000] {processor.py:157} INFO - Started process (PID=13626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:19:57.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:19:57.823+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:57.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:19:57.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:19:57.854+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:57.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:19:57.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:19:57.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:19:57.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T20:20:28.262+0000] {processor.py:157} INFO - Started process (PID=13651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:20:28.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:20:28.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:28.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:20:28.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:20:28.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:28.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:20:28.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:28.308+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:20:28.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:20:58.716+0000] {processor.py:157} INFO - Started process (PID=13676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:20:58.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:20:58.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:58.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:20:58.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:20:58.746+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:58.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:20:58.755+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:20:58.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:20:58.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T20:21:29.145+0000] {processor.py:157} INFO - Started process (PID=13701) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:21:29.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:21:29.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:29.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:21:29.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:21:29.178+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:29.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:21:29.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:29.188+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:21:29.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T20:21:59.621+0000] {processor.py:157} INFO - Started process (PID=13726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:21:59.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:21:59.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:59.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:21:59.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:21:59.656+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:59.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:21:59.668+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:21:59.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:21:59.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T20:22:29.973+0000] {processor.py:157} INFO - Started process (PID=13751) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:22:29.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:22:29.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:22:29.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:22:29.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:22:30.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:22:30.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:22:30.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:22:30.015+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:22:30.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T20:23:00.438+0000] {processor.py:157} INFO - Started process (PID=13776) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:23:00.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:23:00.442+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:00.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:23:00.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:23:00.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:00.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:23:00.479+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:00.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:23:00.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:23:30.908+0000] {processor.py:157} INFO - Started process (PID=13801) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:23:30.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:23:30.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:30.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:23:30.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:23:30.942+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:30.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:23:30.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:23:30.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:23:30.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T20:24:01.360+0000] {processor.py:157} INFO - Started process (PID=13826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:24:01.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:24:01.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:01.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:24:01.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:24:01.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:01.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:24:01.401+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:01.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:24:01.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:24:31.831+0000] {processor.py:157} INFO - Started process (PID=13851) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:24:31.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:24:31.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:31.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:24:31.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:24:31.864+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:31.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:24:31.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:24:31.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:24:31.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:25:02.274+0000] {processor.py:157} INFO - Started process (PID=13876) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:25:02.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:25:02.277+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:02.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:25:02.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:25:02.301+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:02.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:25:02.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:02.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:25:02.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T20:25:32.784+0000] {processor.py:157} INFO - Started process (PID=13901) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:25:32.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:25:32.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:32.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:25:32.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:25:32.817+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:32.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:25:32.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:25:32.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:25:32.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T20:26:03.161+0000] {processor.py:157} INFO - Started process (PID=13926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:26:03.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:26:03.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:03.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:26:03.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:26:03.191+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:03.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:26:03.200+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:03.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:26:03.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-20T20:26:33.569+0000] {processor.py:157} INFO - Started process (PID=13951) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:26:33.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:26:33.575+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:33.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:26:33.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:26:33.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:33.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:26:33.611+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:26:33.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:26:33.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:27:04.001+0000] {processor.py:157} INFO - Started process (PID=13976) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:27:04.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:27:04.005+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:04.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:27:04.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:27:04.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:04.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:27:04.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:04.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:27:04.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T20:27:34.379+0000] {processor.py:157} INFO - Started process (PID=14001) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:27:34.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:27:34.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:34.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:27:34.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:27:34.412+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:34.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:27:34.422+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:27:34.422+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:27:34.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T20:28:04.862+0000] {processor.py:157} INFO - Started process (PID=14026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:28:04.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:28:04.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:04.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:28:04.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:28:04.891+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:04.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:28:04.902+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:04.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:28:04.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T20:28:35.307+0000] {processor.py:157} INFO - Started process (PID=14051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:28:35.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:28:35.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:35.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:28:35.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:28:35.336+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:35.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:28:35.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:28:35.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:28:35.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T20:29:05.793+0000] {processor.py:157} INFO - Started process (PID=14076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:29:05.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:29:05.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:05.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:29:05.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:29:05.826+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:05.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:29:05.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:05.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:29:05.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:29:36.242+0000] {processor.py:157} INFO - Started process (PID=14101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:29:36.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:29:36.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:36.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:29:36.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:29:36.271+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:36.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:29:36.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:29:36.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:29:36.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:30:06.704+0000] {processor.py:157} INFO - Started process (PID=14126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:30:06.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:30:06.710+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:06.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:30:06.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:30:06.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:06.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:30:06.748+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:06.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:30:06.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:30:37.133+0000] {processor.py:157} INFO - Started process (PID=14151) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:30:37.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:30:37.136+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:37.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:30:37.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:30:37.163+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:37.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:30:37.176+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:30:37.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:30:37.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:31:07.566+0000] {processor.py:157} INFO - Started process (PID=14176) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:31:07.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:31:07.569+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:07.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:31:07.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:31:07.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:07.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:31:07.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:07.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:31:07.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:31:38.057+0000] {processor.py:157} INFO - Started process (PID=14201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:31:38.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:31:38.061+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:38.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:31:38.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:31:38.088+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:38.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:31:38.100+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:31:38.100+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:31:38.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:32:08.490+0000] {processor.py:157} INFO - Started process (PID=14226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:32:08.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:32:08.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:08.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:32:08.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:32:08.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:08.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:32:08.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:08.545+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:32:08.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-20T20:32:38.943+0000] {processor.py:157} INFO - Started process (PID=14251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:32:38.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:32:38.949+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:38.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:32:38.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:32:38.979+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:38.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:32:38.990+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:32:38.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:32:38.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T20:33:09.385+0000] {processor.py:157} INFO - Started process (PID=14276) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:33:09.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:33:09.390+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:09.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:33:09.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:33:09.417+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:09.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:33:09.427+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:09.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:33:09.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:33:39.843+0000] {processor.py:157} INFO - Started process (PID=14301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:33:39.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:33:39.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:39.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:33:39.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:33:39.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:39.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:33:39.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:33:39.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:33:39.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T20:34:10.326+0000] {processor.py:157} INFO - Started process (PID=14326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:34:10.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:34:10.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:10.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:34:10.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:34:10.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:10.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:34:10.371+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:10.371+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:34:10.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T20:34:40.780+0000] {processor.py:157} INFO - Started process (PID=14351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:34:40.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:34:40.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:40.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:34:40.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:34:40.810+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:40.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:34:40.821+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:34:40.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:34:40.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T20:35:11.260+0000] {processor.py:157} INFO - Started process (PID=14376) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:35:11.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:35:11.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:11.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:35:11.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:35:11.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:11.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:35:11.306+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:11.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:35:11.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T20:35:41.703+0000] {processor.py:157} INFO - Started process (PID=14401) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:35:41.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:35:41.707+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:41.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:35:41.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:35:41.736+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:41.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:35:41.746+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:35:41.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:35:41.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:36:12.163+0000] {processor.py:157} INFO - Started process (PID=14426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:36:12.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:36:12.166+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:12.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:36:12.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:36:12.194+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:12.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:36:12.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:12.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:36:12.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:36:42.585+0000] {processor.py:157} INFO - Started process (PID=14451) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:36:42.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:36:42.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:42.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:36:42.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:36:42.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:42.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:36:42.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:36:42.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:36:42.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:37:13.013+0000] {processor.py:157} INFO - Started process (PID=14476) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:37:13.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:37:13.017+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:13.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:37:13.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:37:13.046+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:13.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:37:13.056+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:13.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:37:13.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T20:37:43.512+0000] {processor.py:157} INFO - Started process (PID=14501) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:37:43.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:37:43.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:43.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:37:43.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:37:43.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:43.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:37:43.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:37:43.555+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:37:43.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T20:38:13.970+0000] {processor.py:157} INFO - Started process (PID=14526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:38:13.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:38:13.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:13.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:38:13.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:38:14.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:14.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:38:14.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:14.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:38:14.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:38:44.453+0000] {processor.py:157} INFO - Started process (PID=14551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:38:44.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:38:44.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:44.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:38:44.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:38:44.485+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:44.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:38:44.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:38:44.498+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:38:44.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:39:14.844+0000] {processor.py:157} INFO - Started process (PID=14576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:39:14.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:39:14.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:14.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:39:14.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:39:14.876+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:14.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:39:14.886+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:14.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:39:14.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:39:45.368+0000] {processor.py:157} INFO - Started process (PID=14601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:39:45.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:39:45.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:45.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:39:45.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:39:45.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:45.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:39:45.412+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:39:45.412+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:39:45.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:40:15.829+0000] {processor.py:157} INFO - Started process (PID=14626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:40:15.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:40:15.831+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:15.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:40:15.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:40:15.852+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:15.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:40:15.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:15.861+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:40:15.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-20T20:40:46.246+0000] {processor.py:157} INFO - Started process (PID=14651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:40:46.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:40:46.251+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:46.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:40:46.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:40:46.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:46.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:40:46.290+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:40:46.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:40:46.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T20:41:16.719+0000] {processor.py:157} INFO - Started process (PID=14676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:41:16.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:41:16.726+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:16.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:41:16.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:41:16.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:16.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:41:16.763+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:16.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:41:16.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T20:41:47.158+0000] {processor.py:157} INFO - Started process (PID=14701) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:41:47.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:41:47.162+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:47.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:41:47.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:41:47.192+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:47.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:41:47.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:41:47.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:41:47.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:42:17.674+0000] {processor.py:157} INFO - Started process (PID=14726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:42:17.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:42:17.678+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:17.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:42:17.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:42:17.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:17.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:42:17.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:17.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:42:17.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:42:48.086+0000] {processor.py:157} INFO - Started process (PID=14751) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:42:48.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:42:48.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:48.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:42:48.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:42:48.119+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:48.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:42:48.132+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:42:48.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:42:48.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T20:43:18.503+0000] {processor.py:157} INFO - Started process (PID=14776) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:43:18.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:43:18.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:18.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:43:18.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:43:18.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:18.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:43:18.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:18.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:43:18.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T20:43:49.009+0000] {processor.py:157} INFO - Started process (PID=14801) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:43:49.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:43:49.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:49.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:43:49.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:43:49.039+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:49.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:43:49.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:43:49.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:43:49.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T20:44:19.480+0000] {processor.py:157} INFO - Started process (PID=14826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:44:19.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:44:19.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:19.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:44:19.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:44:19.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:19.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:44:19.522+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:19.522+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:44:19.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:44:49.936+0000] {processor.py:157} INFO - Started process (PID=14851) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:44:49.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:44:49.940+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:49.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:44:49.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:44:49.969+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:49.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:44:49.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:44:49.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:44:49.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:45:20.409+0000] {processor.py:157} INFO - Started process (PID=14876) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:45:20.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:45:20.412+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:20.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:45:20.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:45:20.438+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:20.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:45:20.450+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:20.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:45:20.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:45:50.860+0000] {processor.py:157} INFO - Started process (PID=14901) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:45:50.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:45:50.864+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:50.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:45:50.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:45:50.892+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:50.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:45:50.903+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:45:50.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:45:50.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:46:21.297+0000] {processor.py:157} INFO - Started process (PID=14926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:46:21.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:46:21.300+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:21.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:46:21.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:46:21.332+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:21.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:46:21.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:21.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:46:21.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T20:46:51.740+0000] {processor.py:157} INFO - Started process (PID=14951) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:46:51.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:46:51.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:51.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:46:51.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:46:51.771+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:51.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:46:51.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:46:51.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:46:51.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:47:22.129+0000] {processor.py:157} INFO - Started process (PID=14976) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:47:22.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:47:22.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:22.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:47:22.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:47:22.149+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:22.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:47:22.160+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:22.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:47:22.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-20T20:47:52.555+0000] {processor.py:157} INFO - Started process (PID=15001) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:47:52.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:47:52.558+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:52.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:47:52.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:47:52.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:52.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:47:52.596+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:47:52.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:47:52.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:48:23.040+0000] {processor.py:157} INFO - Started process (PID=15026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:48:23.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:48:23.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:23.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:48:23.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:48:23.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:23.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:48:23.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:23.083+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:48:23.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:48:53.544+0000] {processor.py:157} INFO - Started process (PID=15051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:48:53.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:48:53.548+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:53.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:48:53.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:48:53.577+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:53.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:48:53.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:48:53.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:48:53.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:49:23.972+0000] {processor.py:157} INFO - Started process (PID=15076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:49:23.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:49:23.976+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:23.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:49:23.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:49:24.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:24.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:49:24.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:24.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:49:24.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:49:54.422+0000] {processor.py:157} INFO - Started process (PID=15101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:49:54.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:49:54.425+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:54.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:49:54.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:49:54.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:54.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:49:54.466+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:49:54.466+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:49:54.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:50:24.827+0000] {processor.py:157} INFO - Started process (PID=15126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:50:24.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:50:24.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:24.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:50:24.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:50:24.857+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:24.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:50:24.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:24.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:50:24.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:50:55.308+0000] {processor.py:157} INFO - Started process (PID=15151) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:50:55.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:50:55.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:55.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:50:55.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:50:55.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:55.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:50:55.350+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:50:55.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:50:55.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:51:25.734+0000] {processor.py:157} INFO - Started process (PID=15176) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:51:25.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:51:25.738+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:25.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:51:25.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:51:25.767+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:25.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:51:25.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:25.777+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:51:25.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T20:51:56.176+0000] {processor.py:157} INFO - Started process (PID=15201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:51:56.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:51:56.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:56.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:51:56.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:51:56.208+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:56.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:51:56.218+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:51:56.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:51:56.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:52:26.597+0000] {processor.py:157} INFO - Started process (PID=15226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:52:26.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:52:26.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:26.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:52:26.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:52:26.631+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:26.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:52:26.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:26.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:52:26.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T20:52:57.019+0000] {processor.py:157} INFO - Started process (PID=15251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:52:57.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:52:57.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:57.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:52:57.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:52:57.054+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:57.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:52:57.063+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:52:57.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:52:57.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:53:27.496+0000] {processor.py:157} INFO - Started process (PID=15276) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:53:27.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:53:27.502+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:27.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:53:27.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:53:27.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:27.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:53:27.543+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:27.543+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:53:27.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T20:53:57.993+0000] {processor.py:157} INFO - Started process (PID=15301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:53:57.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:53:57.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:57.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:53:58.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:53:58.034+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:58.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:53:58.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:53:58.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:53:58.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T20:54:28.490+0000] {processor.py:157} INFO - Started process (PID=15326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:54:28.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:54:28.493+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:28.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:54:28.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:54:28.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:28.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:54:28.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:28.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:54:28.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:54:58.982+0000] {processor.py:157} INFO - Started process (PID=15351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:54:58.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:54:58.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:58.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:54:58.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:54:59.011+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:59.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:54:59.021+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:54:59.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:54:59.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:55:29.418+0000] {processor.py:157} INFO - Started process (PID=15376) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:55:29.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:55:29.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:29.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:55:29.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:55:29.450+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:29.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:55:29.459+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:29.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:55:29.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T20:55:59.849+0000] {processor.py:157} INFO - Started process (PID=15401) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:55:59.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:55:59.853+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:59.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:55:59.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:55:59.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:59.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:55:59.892+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:55:59.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:55:59.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:56:30.289+0000] {processor.py:157} INFO - Started process (PID=15426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:56:30.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:56:30.292+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:56:30.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:56:30.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:56:30.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:56:30.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:56:30.333+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:56:30.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:56:30.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T20:57:00.714+0000] {processor.py:157} INFO - Started process (PID=15451) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:57:00.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:57:00.718+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:00.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:57:00.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:57:00.747+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:00.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:57:00.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:00.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:57:00.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T20:57:31.144+0000] {processor.py:157} INFO - Started process (PID=15476) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:57:31.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:57:31.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:31.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:57:31.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:57:31.178+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:31.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:57:31.187+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:57:31.187+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:57:31.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T20:58:01.585+0000] {processor.py:157} INFO - Started process (PID=15501) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:58:01.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:58:01.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:01.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:58:01.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:58:01.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:01.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:58:01.629+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:01.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:58:01.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T20:58:32.028+0000] {processor.py:157} INFO - Started process (PID=15526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:58:32.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:58:32.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:32.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:58:32.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:58:32.066+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:32.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:58:32.082+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:58:32.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:58:32.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T20:59:02.500+0000] {processor.py:157} INFO - Started process (PID=15551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:59:02.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:59:02.504+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:02.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:59:02.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:59:02.531+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:02.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:59:02.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:02.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:59:02.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T20:59:32.909+0000] {processor.py:157} INFO - Started process (PID=15576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:59:32.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T20:59:32.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:32.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:59:32.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T20:59:32.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:32.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T20:59:32.956+0000] {logging_mixin.py:151} INFO - [2024-07-20T20:59:32.956+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T20:59:32.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T21:00:03.342+0000] {processor.py:157} INFO - Started process (PID=15601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:00:03.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:00:03.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:03.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:00:03.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:00:03.370+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:03.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:00:03.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:03.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:00:03.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:00:33.826+0000] {processor.py:157} INFO - Started process (PID=15626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:00:33.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:00:33.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:33.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:00:33.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:00:33.861+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:33.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:00:33.870+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:00:33.870+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:00:33.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:01:04.270+0000] {processor.py:157} INFO - Started process (PID=15651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:01:04.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:01:04.273+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:04.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:01:04.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:01:04.298+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:04.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:01:04.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:04.308+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:01:04.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T21:01:34.752+0000] {processor.py:157} INFO - Started process (PID=15676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:01:34.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:01:34.758+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:34.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:01:34.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:01:34.787+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:34.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:01:34.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:01:34.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:01:34.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:02:05.141+0000] {processor.py:157} INFO - Started process (PID=15701) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:02:05.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:02:05.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:05.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:02:05.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:02:05.172+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:05.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:02:05.183+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:05.183+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:02:05.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:02:35.635+0000] {processor.py:157} INFO - Started process (PID=15726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:02:35.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:02:35.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:35.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:02:35.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:02:35.667+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:35.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:02:35.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:02:35.696+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:02:35.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-20T21:03:06.106+0000] {processor.py:157} INFO - Started process (PID=15751) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:03:06.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:03:06.109+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:06.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:03:06.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:03:06.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:06.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:03:06.148+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:06.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:03:06.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:03:36.572+0000] {processor.py:157} INFO - Started process (PID=15776) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:03:36.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:03:36.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:36.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:03:36.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:03:36.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:36.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:03:36.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:03:36.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:03:36.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:04:06.972+0000] {processor.py:157} INFO - Started process (PID=15801) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:04:06.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:04:06.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:06.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:04:06.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:04:07.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:07.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:04:07.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:07.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:04:07.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:04:37.370+0000] {processor.py:157} INFO - Started process (PID=15826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:04:37.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:04:37.374+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:37.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:04:37.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:04:37.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:37.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:04:37.412+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:04:37.412+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:04:37.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T21:05:07.855+0000] {processor.py:157} INFO - Started process (PID=15851) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:05:07.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:05:07.859+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:07.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:05:07.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:05:07.888+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:07.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:05:07.901+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:07.901+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:05:07.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:05:38.291+0000] {processor.py:157} INFO - Started process (PID=15876) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:05:38.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:05:38.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:38.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:05:38.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:05:38.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:38.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:05:38.335+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:05:38.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:05:38.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:06:08.773+0000] {processor.py:157} INFO - Started process (PID=15901) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:06:08.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:06:08.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:08.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:06:08.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:06:08.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:08.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:06:08.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:08.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:06:08.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:06:39.220+0000] {processor.py:157} INFO - Started process (PID=15926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:06:39.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:06:39.223+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:39.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:06:39.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:06:39.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:39.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:06:39.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:06:39.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:06:39.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:07:09.680+0000] {processor.py:157} INFO - Started process (PID=15951) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:07:09.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:07:09.683+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:09.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:07:09.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:07:09.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:09.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:07:09.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:09.721+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:07:09.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:07:40.109+0000] {processor.py:157} INFO - Started process (PID=15976) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:07:40.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:07:40.112+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:40.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:07:40.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:07:40.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:40.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:07:40.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:07:40.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:07:40.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T21:08:10.569+0000] {processor.py:157} INFO - Started process (PID=16001) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:08:10.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:08:10.574+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:10.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:08:10.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:08:10.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:10.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:08:10.615+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:10.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:08:10.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:08:41.039+0000] {processor.py:157} INFO - Started process (PID=16026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:08:41.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:08:41.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:41.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:08:41.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:08:41.070+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:41.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:08:41.083+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:08:41.083+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:08:41.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:09:11.452+0000] {processor.py:157} INFO - Started process (PID=16051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:09:11.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:09:11.454+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:11.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:09:11.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:09:11.479+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:11.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:09:11.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:11.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:09:11.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T21:09:41.877+0000] {processor.py:157} INFO - Started process (PID=16076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:09:41.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:09:41.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:41.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:09:41.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:09:41.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:41.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:09:41.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:09:41.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:09:41.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:10:12.305+0000] {processor.py:157} INFO - Started process (PID=16101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:10:12.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:10:12.309+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:12.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:10:12.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:10:12.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:12.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:10:12.351+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:12.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:10:12.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:10:42.770+0000] {processor.py:157} INFO - Started process (PID=16126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:10:42.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:10:42.774+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:42.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:10:42.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:10:42.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:42.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:10:42.811+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:10:42.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:10:42.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:11:13.280+0000] {processor.py:157} INFO - Started process (PID=16151) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:11:13.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:11:13.283+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:13.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:11:13.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:11:13.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:13.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:11:13.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:13.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:11:13.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:11:43.788+0000] {processor.py:157} INFO - Started process (PID=16176) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:11:43.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:11:43.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:43.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:11:43.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:11:43.829+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:43.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:11:43.840+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:11:43.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:11:43.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T21:12:14.253+0000] {processor.py:157} INFO - Started process (PID=16201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:12:14.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:12:14.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:14.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:12:14.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:12:14.287+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:14.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:12:14.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:14.297+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:12:14.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:12:44.678+0000] {processor.py:157} INFO - Started process (PID=16226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:12:44.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:12:44.682+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:44.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:12:44.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:12:44.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:44.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:12:44.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:12:44.721+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:12:44.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:13:15.160+0000] {processor.py:157} INFO - Started process (PID=16251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:13:15.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:13:15.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:15.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:13:15.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:13:15.195+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:15.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:13:15.205+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:15.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:13:15.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:13:45.617+0000] {processor.py:157} INFO - Started process (PID=16276) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:13:45.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:13:45.620+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:45.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:13:45.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:13:45.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:45.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:13:45.659+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:13:45.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:13:45.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:14:15.957+0000] {processor.py:157} INFO - Started process (PID=16301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:14:15.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:14:15.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:15.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:14:15.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:14:15.989+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:15.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:14:16.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:16.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:14:16.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:14:46.374+0000] {processor.py:157} INFO - Started process (PID=16326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:14:46.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:14:46.377+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:46.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:14:46.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:14:46.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:46.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:14:46.416+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:14:46.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:14:46.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T21:15:16.775+0000] {processor.py:157} INFO - Started process (PID=16351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:15:16.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:15:16.777+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:16.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:15:16.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:15:16.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:16.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:15:16.813+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:16.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:15:16.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-20T21:15:47.215+0000] {processor.py:157} INFO - Started process (PID=16376) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:15:47.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:15:47.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:47.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:15:47.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:15:47.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:47.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:15:47.257+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:15:47.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:15:47.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:16:17.670+0000] {processor.py:157} INFO - Started process (PID=16401) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:16:17.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:16:17.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:17.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:16:17.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:16:17.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:17.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:16:17.707+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:17.707+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:16:17.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-20T21:16:48.144+0000] {processor.py:157} INFO - Started process (PID=16426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:16:48.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:16:48.147+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:48.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:16:48.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:16:48.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:48.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:16:48.191+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:16:48.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:16:48.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T21:17:18.621+0000] {processor.py:157} INFO - Started process (PID=16451) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:17:18.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:17:18.625+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:18.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:17:18.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:17:18.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:18.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:17:18.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:18.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:17:18.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:17:49.048+0000] {processor.py:157} INFO - Started process (PID=16476) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:17:49.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:17:49.051+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:49.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:17:49.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:17:49.079+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:49.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:17:49.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:17:49.089+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:17:49.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:18:19.475+0000] {processor.py:157} INFO - Started process (PID=16501) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:18:19.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:18:19.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:19.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:18:19.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:18:19.510+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:19.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:18:19.520+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:19.520+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:18:19.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:18:49.946+0000] {processor.py:157} INFO - Started process (PID=16526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:18:49.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:18:49.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:49.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:18:49.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:18:49.973+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:49.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:18:49.987+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:18:49.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:18:49.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T21:19:20.410+0000] {processor.py:157} INFO - Started process (PID=16551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:19:20.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:19:20.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:20.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:19:20.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:19:20.443+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:20.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:19:20.453+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:20.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:19:20.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:19:50.881+0000] {processor.py:157} INFO - Started process (PID=16576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:19:50.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:19:50.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:50.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:19:50.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:19:50.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:50.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:19:50.923+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:19:50.923+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:19:50.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:20:21.356+0000] {processor.py:157} INFO - Started process (PID=16601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:20:21.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:20:21.360+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:21.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:20:21.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:20:21.387+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:21.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:20:21.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:21.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:20:21.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:20:51.811+0000] {processor.py:157} INFO - Started process (PID=16626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:20:51.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:20:51.815+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:51.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:20:51.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:20:51.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:51.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:20:51.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:20:51.856+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:20:51.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:21:22.311+0000] {processor.py:157} INFO - Started process (PID=16651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:21:22.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:21:22.315+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:22.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:21:22.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:21:22.344+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:22.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:21:22.354+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:22.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:21:22.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:21:52.786+0000] {processor.py:157} INFO - Started process (PID=16676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:21:52.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:21:52.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:52.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:21:52.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:21:52.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:52.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:21:52.832+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:21:52.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:21:52.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:22:23.281+0000] {processor.py:157} INFO - Started process (PID=16701) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:22:23.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:22:23.285+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:23.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:22:23.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:22:23.317+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:23.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:22:23.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:23.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:22:23.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:22:53.742+0000] {processor.py:157} INFO - Started process (PID=16726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:22:53.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:22:53.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:53.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:22:53.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:22:53.770+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:53.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:22:53.781+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:22:53.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:22:53.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:23:24.234+0000] {processor.py:157} INFO - Started process (PID=16751) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:23:24.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:23:24.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:24.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:23:24.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:23:24.265+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:24.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:23:24.279+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:24.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:23:24.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:23:54.710+0000] {processor.py:157} INFO - Started process (PID=16776) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:23:54.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:23:54.715+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:54.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:23:54.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:23:54.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:54.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:23:54.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:23:54.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:23:54.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:24:25.149+0000] {processor.py:157} INFO - Started process (PID=16801) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:24:25.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:24:25.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:25.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:24:25.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:24:25.180+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:25.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:24:25.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:25.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:24:25.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:24:55.567+0000] {processor.py:157} INFO - Started process (PID=16826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:24:55.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:24:55.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:55.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:24:55.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:24:55.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:55.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:24:55.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:24:55.609+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:24:55.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:25:25.998+0000] {processor.py:157} INFO - Started process (PID=16851) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:25:25.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:25:26.001+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:26.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:25:26.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:25:26.035+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:26.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:25:26.045+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:26.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:25:26.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T21:25:56.410+0000] {processor.py:157} INFO - Started process (PID=16876) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:25:56.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:25:56.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:56.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:25:56.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:25:56.444+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:56.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:25:56.454+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:25:56.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:25:56.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:26:26.852+0000] {processor.py:157} INFO - Started process (PID=16901) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:26:26.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:26:26.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:26.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:26:26.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:26:26.884+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:26.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:26:26.894+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:26.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:26:26.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:26:57.256+0000] {processor.py:157} INFO - Started process (PID=16926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:26:57.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:26:57.259+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:57.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:26:57.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:26:57.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:57.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:26:57.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:26:57.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:26:57.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-20T21:27:27.719+0000] {processor.py:157} INFO - Started process (PID=16951) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:27:27.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:27:27.721+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:27.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:27:27.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:27:27.753+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:27.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:27:27.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:27.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:27:27.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:27:58.190+0000] {processor.py:157} INFO - Started process (PID=16976) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:27:58.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:27:58.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:58.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:27:58.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:27:58.223+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:58.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:27:58.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:27:58.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:27:58.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:28:28.598+0000] {processor.py:157} INFO - Started process (PID=17001) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:28:28.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:28:28.600+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:28.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:28:28.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:28:28.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:28.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:28:28.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:28.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:28:28.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:28:59.044+0000] {processor.py:157} INFO - Started process (PID=17026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:28:59.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:28:59.047+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:59.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:28:59.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:28:59.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:59.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:28:59.085+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:28:59.085+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:28:59.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:29:29.435+0000] {processor.py:157} INFO - Started process (PID=17051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:29:29.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:29:29.438+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:29.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:29:29.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:29:29.470+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:29.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:29:29.479+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:29.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:29:29.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:29:59.911+0000] {processor.py:157} INFO - Started process (PID=17076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:29:59.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:29:59.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:59.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:29:59.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:29:59.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:59.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:29:59.952+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:29:59.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:29:59.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:30:30.381+0000] {processor.py:157} INFO - Started process (PID=17101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:30:30.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:30:30.383+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:30:30.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:30:30.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:30:30.405+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:30:30.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:30:30.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:30:30.415+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:30:30.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-20T21:31:00.803+0000] {processor.py:157} INFO - Started process (PID=17126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:31:00.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:31:00.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:00.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:31:00.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:31:00.833+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:00.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:31:00.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:00.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:31:00.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:31:31.166+0000] {processor.py:157} INFO - Started process (PID=17151) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:31:31.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:31:31.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:31.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:31:31.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:31:31.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:31.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:31:31.205+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:31:31.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:31:31.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:32:01.615+0000] {processor.py:157} INFO - Started process (PID=17176) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:32:01.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:32:01.617+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:01.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:32:01.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:32:01.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:01.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:32:01.661+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:01.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:32:01.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:32:32.095+0000] {processor.py:157} INFO - Started process (PID=17201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:32:32.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:32:32.099+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:32.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:32:32.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:32:32.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:32.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:32:32.138+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:32:32.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:32:32.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:33:02.555+0000] {processor.py:157} INFO - Started process (PID=17226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:33:02.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:33:02.558+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:02.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:33:02.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:33:02.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:02.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:33:02.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:02.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:33:02.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:33:33.046+0000] {processor.py:157} INFO - Started process (PID=17251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:33:33.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:33:33.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:33.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:33:33.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:33:33.075+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:33.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:33:33.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:33:33.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:33:33.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:34:03.481+0000] {processor.py:157} INFO - Started process (PID=17276) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:34:03.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:34:03.484+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:03.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:34:03.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:34:03.512+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:03.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:34:03.525+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:03.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:34:03.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:34:33.990+0000] {processor.py:157} INFO - Started process (PID=17301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:34:33.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:34:33.993+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:33.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:34:34.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:34:34.023+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:34.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:34:34.032+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:34:34.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:34:34.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:35:04.410+0000] {processor.py:157} INFO - Started process (PID=17326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:35:04.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:35:04.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:04.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:35:04.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:35:04.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:04.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:35:04.452+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:04.452+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:35:04.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:35:34.869+0000] {processor.py:157} INFO - Started process (PID=17351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:35:34.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:35:34.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:34.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:35:34.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:35:34.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:34.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:35:34.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:35:34.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:35:34.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:36:05.291+0000] {processor.py:157} INFO - Started process (PID=17376) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:36:05.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:36:05.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:05.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:36:05.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:36:05.322+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:05.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:36:05.335+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:05.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:36:05.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:36:35.681+0000] {processor.py:157} INFO - Started process (PID=17401) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:36:35.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:36:35.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:35.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:36:35.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:36:35.713+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:35.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:36:35.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:36:35.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:36:35.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T21:37:06.125+0000] {processor.py:157} INFO - Started process (PID=17426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:37:06.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:37:06.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:06.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:37:06.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:37:06.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:06.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:37:06.165+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:06.164+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:37:06.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:37:36.621+0000] {processor.py:157} INFO - Started process (PID=17451) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:37:36.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:37:36.624+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:36.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:37:36.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:37:36.654+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:36.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:37:36.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:37:36.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:37:36.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:38:07.084+0000] {processor.py:157} INFO - Started process (PID=17476) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:38:07.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:38:07.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:07.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:38:07.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:38:07.123+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:07.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:38:07.134+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:07.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:38:07.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T21:38:37.594+0000] {processor.py:157} INFO - Started process (PID=17501) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:38:37.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:38:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:37.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:38:37.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:38:37.625+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:37.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:38:37.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:38:37.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:38:37.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:39:08.010+0000] {processor.py:157} INFO - Started process (PID=17526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:39:08.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:39:08.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:08.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:39:08.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:39:08.042+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:08.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:39:08.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:08.053+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:39:08.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:39:38.416+0000] {processor.py:157} INFO - Started process (PID=17551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:39:38.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:39:38.419+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:38.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:39:38.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:39:38.446+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:38.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:39:38.457+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:39:38.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:39:38.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T21:40:08.833+0000] {processor.py:157} INFO - Started process (PID=17576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:40:08.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:40:08.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:08.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:40:08.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:40:08.875+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:08.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:40:08.886+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:08.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:40:08.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-20T21:40:39.293+0000] {processor.py:157} INFO - Started process (PID=17601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:40:39.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:40:39.295+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:39.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:40:39.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:40:39.323+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:39.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:40:39.335+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:40:39.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:40:39.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:41:09.770+0000] {processor.py:157} INFO - Started process (PID=17626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:41:09.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:41:09.773+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:09.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:41:09.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:41:09.804+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:09.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:41:09.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:09.814+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:41:09.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:41:40.242+0000] {processor.py:157} INFO - Started process (PID=17651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:41:40.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:41:40.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:40.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:41:40.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:41:40.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:40.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:41:40.279+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:41:40.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:41:40.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T21:42:10.643+0000] {processor.py:157} INFO - Started process (PID=17676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:42:10.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:42:10.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:10.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:42:10.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:42:10.675+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:10.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:42:10.685+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:10.685+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:42:10.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:42:41.098+0000] {processor.py:157} INFO - Started process (PID=17701) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:42:41.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:42:41.101+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:41.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:42:41.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:42:41.132+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:41.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:42:41.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:42:41.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:42:41.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:43:11.575+0000] {processor.py:157} INFO - Started process (PID=17726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:43:11.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:43:11.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:11.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:43:11.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:43:11.604+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:11.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:43:11.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:11.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:43:11.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:43:42.056+0000] {processor.py:157} INFO - Started process (PID=17751) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:43:42.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:43:42.060+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:42.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:43:42.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:43:42.089+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:42.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:43:42.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:43:42.103+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:43:42.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T21:44:12.464+0000] {processor.py:157} INFO - Started process (PID=17776) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:44:12.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:44:12.468+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:12.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:44:12.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:44:12.496+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:12.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:44:12.507+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:12.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:44:12.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:44:42.912+0000] {processor.py:157} INFO - Started process (PID=17801) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:44:42.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:44:42.917+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:42.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:44:42.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:44:42.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:42.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:44:42.955+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:44:42.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:44:42.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:45:13.354+0000] {processor.py:157} INFO - Started process (PID=17826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:45:13.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:45:13.357+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:13.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:45:13.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:45:13.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:13.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:45:13.397+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:13.397+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:45:13.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:45:43.802+0000] {processor.py:157} INFO - Started process (PID=17851) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:45:43.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:45:43.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:43.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:45:43.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:45:43.835+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:43.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:45:43.845+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:45:43.844+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:45:43.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:46:14.235+0000] {processor.py:157} INFO - Started process (PID=17876) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:46:14.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:46:14.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:14.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:46:14.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:46:14.266+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:14.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:46:14.278+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:14.278+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:46:14.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:46:44.674+0000] {processor.py:157} INFO - Started process (PID=17901) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:46:44.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:46:44.677+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:44.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:46:44.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:46:44.709+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:44.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:46:44.719+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:46:44.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:46:44.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:47:15.074+0000] {processor.py:157} INFO - Started process (PID=17926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:47:15.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:47:15.076+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:15.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:47:15.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:47:15.103+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:15.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:47:15.113+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:15.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:47:15.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T21:47:45.486+0000] {processor.py:157} INFO - Started process (PID=17951) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:47:45.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:47:45.488+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:45.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:47:45.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:47:45.518+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:45.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:47:45.530+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:47:45.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:47:45.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:48:15.964+0000] {processor.py:157} INFO - Started process (PID=17976) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:48:15.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:48:15.966+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:15.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:48:15.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:48:15.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:15.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:48:16.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:16.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:48:16.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T21:48:46.382+0000] {processor.py:157} INFO - Started process (PID=18001) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:48:46.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:48:46.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:46.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:48:46.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:48:46.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:46.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:48:46.424+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:48:46.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:48:46.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T21:49:16.900+0000] {processor.py:157} INFO - Started process (PID=18026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:49:16.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:49:16.904+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:16.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:49:16.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:49:16.933+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:16.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:49:16.945+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:16.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:49:16.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:49:47.322+0000] {processor.py:157} INFO - Started process (PID=18051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:49:47.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:49:47.325+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:47.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:49:47.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:49:47.353+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:47.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:49:47.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:49:47.363+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:49:47.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T21:50:17.759+0000] {processor.py:157} INFO - Started process (PID=18076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:50:17.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:50:17.762+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:17.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:50:17.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:50:17.790+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:17.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:50:17.801+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:17.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:50:17.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:50:48.278+0000] {processor.py:157} INFO - Started process (PID=18101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:50:48.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:50:48.282+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:48.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:50:48.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:50:48.311+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:48.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:50:48.320+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:50:48.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:50:48.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:51:18.790+0000] {processor.py:157} INFO - Started process (PID=18126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:51:18.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:51:18.793+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:18.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:51:18.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:51:18.825+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:18.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:51:18.835+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:18.835+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:51:18.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T21:51:49.231+0000] {processor.py:157} INFO - Started process (PID=18151) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:51:49.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:51:49.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:49.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:51:49.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:51:49.269+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:49.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:51:49.280+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:51:49.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:51:49.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T21:52:19.681+0000] {processor.py:157} INFO - Started process (PID=18176) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:52:19.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:52:19.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:19.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:52:19.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:52:19.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:19.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:52:19.724+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:19.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:52:19.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:52:50.138+0000] {processor.py:157} INFO - Started process (PID=18201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:52:50.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:52:50.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:50.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:52:50.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:52:50.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:50.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:52:50.179+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:52:50.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:52:50.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T21:53:20.566+0000] {processor.py:157} INFO - Started process (PID=18226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:53:20.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:53:20.570+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:20.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:53:20.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:53:20.598+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:20.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:53:20.608+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:20.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:53:20.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:53:51.076+0000] {processor.py:157} INFO - Started process (PID=18251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:53:51.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:53:51.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:51.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:53:51.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:53:51.107+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:51.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:53:51.117+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:53:51.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:53:51.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T21:54:21.551+0000] {processor.py:157} INFO - Started process (PID=18276) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:54:21.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:54:21.555+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:21.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:54:21.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:54:21.585+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:21.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:54:21.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:21.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:54:21.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T21:54:52.024+0000] {processor.py:157} INFO - Started process (PID=18301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:54:52.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:54:52.026+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:52.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:54:52.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:54:52.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:52.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:54:52.062+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:54:52.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:54:52.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:55:22.443+0000] {processor.py:157} INFO - Started process (PID=18326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:55:22.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:55:22.447+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:22.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:55:22.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:55:22.476+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:22.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:55:22.486+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:22.486+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:55:22.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:55:52.916+0000] {processor.py:157} INFO - Started process (PID=18351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:55:52.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:55:52.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:52.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:55:52.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:55:52.948+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:52.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:55:52.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:55:52.959+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:55:52.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T21:56:23.326+0000] {processor.py:157} INFO - Started process (PID=18376) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:56:23.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:56:23.328+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:23.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:56:23.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:56:23.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:23.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:56:23.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:23.366+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:56:23.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T21:56:53.773+0000] {processor.py:157} INFO - Started process (PID=18401) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:56:53.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:56:53.780+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:53.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:56:53.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:56:53.806+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:53.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:56:53.819+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:56:53.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:56:53.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T21:57:24.252+0000] {processor.py:157} INFO - Started process (PID=18426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:57:24.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:57:24.256+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:24.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:57:24.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:57:24.287+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:24.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:57:24.297+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:24.297+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:57:24.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:57:54.665+0000] {processor.py:157} INFO - Started process (PID=18451) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:57:54.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:57:54.669+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:54.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:57:54.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:57:54.695+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:54.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:57:54.705+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:57:54.705+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:57:54.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T21:58:25.142+0000] {processor.py:157} INFO - Started process (PID=18476) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:58:25.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:58:25.145+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:25.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:58:25.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:58:25.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:25.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:58:25.186+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:25.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:58:25.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T21:58:55.641+0000] {processor.py:157} INFO - Started process (PID=18501) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:58:55.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:58:55.646+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:55.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:58:55.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:58:55.677+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:55.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:58:55.687+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:58:55.687+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:58:55.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T21:59:26.116+0000] {processor.py:157} INFO - Started process (PID=18526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:59:26.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:59:26.120+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:26.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:59:26.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:59:26.143+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:26.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:59:26.154+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:26.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:59:26.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T21:59:56.593+0000] {processor.py:157} INFO - Started process (PID=18551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:59:56.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T21:59:56.601+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:56.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:59:56.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T21:59:56.627+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:56.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T21:59:56.637+0000] {logging_mixin.py:151} INFO - [2024-07-20T21:59:56.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T21:59:56.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T22:00:26.991+0000] {processor.py:157} INFO - Started process (PID=18576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:00:26.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:00:26.997+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:26.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:00:27.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:00:27.027+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:27.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:00:27.036+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:27.036+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:00:27.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T22:00:57.500+0000] {processor.py:157} INFO - Started process (PID=18601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:00:57.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:00:57.504+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:57.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:00:57.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:00:57.532+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:57.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:00:57.541+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:00:57.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:00:57.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T22:01:27.915+0000] {processor.py:157} INFO - Started process (PID=18626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:01:27.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:01:27.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:27.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:01:27.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:01:27.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:27.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:01:27.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:27.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:01:27.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T22:01:58.412+0000] {processor.py:157} INFO - Started process (PID=18651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:01:58.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:01:58.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:58.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:01:58.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:01:58.445+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:58.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:01:58.455+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:01:58.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:01:58.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T22:02:28.852+0000] {processor.py:157} INFO - Started process (PID=18676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:02:28.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:02:28.854+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:28.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:02:28.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:02:28.877+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:28.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:02:28.893+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:28.893+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:02:28.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T22:02:59.350+0000] {processor.py:157} INFO - Started process (PID=18701) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:02:59.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:02:59.355+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:59.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:02:59.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:02:59.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:59.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:02:59.391+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:02:59.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:02:59.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T22:18:41.599+0000] {processor.py:157} INFO - Started process (PID=18726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:18:41.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:18:41.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:18:41.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:18:41.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:18:41.634+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:18:41.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:18:41.647+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:18:41.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:18:41.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T22:22:08.198+0000] {processor.py:157} INFO - Started process (PID=18753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:22:08.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:22:08.203+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:08.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:22:08.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:22:08.242+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:08.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:22:08.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:08.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:22:08.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-20T22:22:38.749+0000] {processor.py:157} INFO - Started process (PID=18778) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:22:38.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:22:38.752+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:38.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:22:38.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:22:38.784+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:38.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:22:38.795+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:22:38.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:22:38.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T22:23:09.204+0000] {processor.py:157} INFO - Started process (PID=18803) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:23:09.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:23:09.210+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:09.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:23:09.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:23:09.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:09.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:23:09.258+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:09.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:23:09.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-20T22:23:39.753+0000] {processor.py:157} INFO - Started process (PID=18828) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:23:39.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:23:39.757+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:39.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:23:39.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:23:39.789+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:39.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:23:39.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:23:39.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:23:39.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T22:24:10.162+0000] {processor.py:157} INFO - Started process (PID=18853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:24:10.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:24:10.164+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:10.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:24:10.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:24:10.190+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:10.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:24:10.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:10.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:24:10.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T22:24:40.514+0000] {processor.py:157} INFO - Started process (PID=18878) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:24:40.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:24:40.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:40.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:24:40.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:24:40.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:40.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:24:40.554+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:24:40.554+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:24:40.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T22:25:10.946+0000] {processor.py:157} INFO - Started process (PID=18903) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:25:10.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:25:10.951+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:10.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:25:10.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:25:10.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:10.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:25:10.996+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:10.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:25:11.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T22:25:41.379+0000] {processor.py:157} INFO - Started process (PID=18928) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:25:41.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:25:41.385+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:41.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:25:41.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:25:41.415+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:41.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:25:41.425+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:25:41.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:25:41.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T22:26:11.876+0000] {processor.py:157} INFO - Started process (PID=18953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:26:11.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:26:11.880+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:11.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:26:11.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:26:11.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:11.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:26:11.920+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:11.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:26:11.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T22:26:42.357+0000] {processor.py:157} INFO - Started process (PID=18978) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:26:42.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:26:42.363+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:42.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:26:42.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:26:42.396+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:42.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:26:42.407+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:26:42.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:26:42.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T22:27:12.778+0000] {processor.py:157} INFO - Started process (PID=19003) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:27:12.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:27:12.782+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:12.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:27:12.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:27:12.808+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:12.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:27:12.820+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:12.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:27:12.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T22:27:43.211+0000] {processor.py:157} INFO - Started process (PID=19028) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:27:43.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:27:43.213+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:43.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:27:43.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:27:43.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:43.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:27:43.247+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:27:43.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:27:43.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-20T22:28:13.638+0000] {processor.py:157} INFO - Started process (PID=19053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:28:13.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:28:13.641+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:13.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:28:13.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:28:13.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:13.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:28:13.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:13.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:28:13.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T22:28:44.130+0000] {processor.py:157} INFO - Started process (PID=19078) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:28:44.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:28:44.132+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:44.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:28:44.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:28:44.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:44.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:28:44.169+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:28:44.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:28:44.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-20T22:29:14.534+0000] {processor.py:157} INFO - Started process (PID=19103) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:29:14.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:29:14.537+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:14.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:29:14.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:29:14.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:14.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:29:14.578+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:14.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:29:14.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T22:29:45.048+0000] {processor.py:157} INFO - Started process (PID=19128) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:29:45.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:29:45.052+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:45.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:29:45.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:29:45.080+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:45.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:29:45.091+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:29:45.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:29:45.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T22:30:15.454+0000] {processor.py:157} INFO - Started process (PID=19153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:30:15.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:30:15.456+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:15.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:30:15.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:30:15.482+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:15.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:30:15.497+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:15.497+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:30:15.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T22:30:45.926+0000] {processor.py:157} INFO - Started process (PID=19178) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:30:45.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:30:45.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:45.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:30:45.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:30:45.961+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:45.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:30:45.974+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:30:45.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:30:45.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T22:31:16.339+0000] {processor.py:157} INFO - Started process (PID=19203) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:31:16.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:31:16.342+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:16.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:31:16.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:31:16.371+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:16.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:31:16.381+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:16.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:31:16.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T22:31:46.717+0000] {processor.py:157} INFO - Started process (PID=19228) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:31:46.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:31:46.720+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:46.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:31:46.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:31:46.745+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:46.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:31:46.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:31:46.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:31:46.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T22:32:17.192+0000] {processor.py:157} INFO - Started process (PID=19253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:32:17.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:32:17.195+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:17.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:32:17.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:32:17.227+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:17.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:32:17.237+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:17.237+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:32:17.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T22:32:47.652+0000] {processor.py:157} INFO - Started process (PID=19278) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:32:47.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:32:47.657+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:47.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:32:47.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:32:47.686+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:47.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:32:47.696+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:32:47.696+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:32:47.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T22:33:18.032+0000] {processor.py:157} INFO - Started process (PID=19303) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:33:18.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:33:18.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:18.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:33:18.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:33:18.063+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:18.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:33:18.073+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:18.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:33:18.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T22:33:48.491+0000] {processor.py:157} INFO - Started process (PID=19328) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:33:48.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:33:48.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:48.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:33:48.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:33:48.523+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:48.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:33:48.536+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:33:48.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:33:48.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T22:34:18.979+0000] {processor.py:157} INFO - Started process (PID=19353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:34:18.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:34:18.985+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:18.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:34:19.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:34:19.024+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:19.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:34:19.043+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:19.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:34:19.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-20T22:34:49.511+0000] {processor.py:157} INFO - Started process (PID=19378) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:34:49.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:34:49.514+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:49.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:34:49.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:34:49.542+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:49.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:34:49.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:34:49.557+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:34:49.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T22:35:19.954+0000] {processor.py:157} INFO - Started process (PID=19403) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:35:19.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:35:19.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:19.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:35:19.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:35:19.984+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:19.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:35:19.995+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:19.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:35:20.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T22:35:50.403+0000] {processor.py:157} INFO - Started process (PID=19428) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:35:50.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:35:50.405+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:50.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:35:50.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:35:50.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:50.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:35:50.449+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:35:50.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:35:50.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T22:36:20.833+0000] {processor.py:157} INFO - Started process (PID=19453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:36:20.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:36:20.838+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:20.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:36:20.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:36:20.866+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:20.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:36:20.877+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:20.877+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:36:20.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T22:36:51.259+0000] {processor.py:157} INFO - Started process (PID=19478) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:36:51.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:36:51.262+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:51.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:36:51.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:36:51.291+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:51.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:36:51.302+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:36:51.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:36:51.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T22:53:18.395+0000] {processor.py:157} INFO - Started process (PID=19503) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:53:18.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:53:18.399+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:18.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:53:18.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:53:18.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:18.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:53:18.441+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:18.441+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:53:18.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T22:53:48.821+0000] {processor.py:157} INFO - Started process (PID=19530) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:53:48.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:53:48.828+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:48.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:53:48.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:53:48.857+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:48.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:53:48.869+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:53:48.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:53:48.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T22:54:19.233+0000] {processor.py:157} INFO - Started process (PID=19555) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:54:19.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:54:19.236+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:19.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:54:19.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:54:19.263+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:19.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:54:19.273+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:19.273+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:54:19.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T22:54:49.593+0000] {processor.py:157} INFO - Started process (PID=19580) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:54:49.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T22:54:49.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:49.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:54:49.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T22:54:49.628+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:49.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T22:54:49.638+0000] {logging_mixin.py:151} INFO - [2024-07-20T22:54:49.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T22:54:49.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:10:45.923+0000] {processor.py:157} INFO - Started process (PID=19607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:10:45.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:10:45.927+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:10:45.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:10:45.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:10:45.960+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:10:45.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:10:45.970+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:10:45.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:10:45.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T23:11:16.459+0000] {processor.py:157} INFO - Started process (PID=19632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:11:16.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:11:16.464+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:16.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:11:16.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:11:16.494+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:16.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:11:16.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:16.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:11:16.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T23:11:46.963+0000] {processor.py:157} INFO - Started process (PID=19657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:11:46.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:11:46.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:46.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:11:46.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:11:47.003+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:47.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:11:47.015+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:11:47.015+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:11:47.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-20T23:12:17.418+0000] {processor.py:157} INFO - Started process (PID=19682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:12:17.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:12:17.420+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:17.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:12:17.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:12:17.447+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:17.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:12:17.458+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:17.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:12:17.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T23:12:47.833+0000] {processor.py:157} INFO - Started process (PID=19707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:12:47.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:12:47.835+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:47.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:12:47.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:12:47.863+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:47.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:12:47.873+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:12:47.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:12:47.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:13:18.316+0000] {processor.py:157} INFO - Started process (PID=19732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:13:18.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:13:18.319+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:18.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:13:18.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:13:18.348+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:18.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:13:18.359+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:18.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:13:18.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T23:13:48.832+0000] {processor.py:157} INFO - Started process (PID=19757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:13:48.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:13:48.834+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:48.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:13:48.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:13:48.856+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:48.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:13:48.865+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:13:48.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:13:48.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-20T23:14:19.260+0000] {processor.py:157} INFO - Started process (PID=19782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:14:19.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:14:19.264+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:19.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:14:19.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:14:19.293+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:19.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:14:19.303+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:19.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:14:19.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:14:49.709+0000] {processor.py:157} INFO - Started process (PID=19807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:14:49.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:14:49.712+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:49.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:14:49.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:14:49.743+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:49.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:14:49.756+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:14:49.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:14:49.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T23:15:20.192+0000] {processor.py:157} INFO - Started process (PID=19832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:15:20.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:15:20.196+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:20.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:15:20.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:15:20.223+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:20.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:15:20.238+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:20.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:15:20.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:15:50.696+0000] {processor.py:157} INFO - Started process (PID=19857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:15:50.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:15:50.700+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:50.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:15:50.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:15:50.725+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:50.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:15:50.737+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:15:50.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:15:50.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T23:16:21.199+0000] {processor.py:157} INFO - Started process (PID=19882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:16:21.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:16:21.204+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:21.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:16:21.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:16:21.233+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:21.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:16:21.246+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:21.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:16:21.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T23:16:51.745+0000] {processor.py:157} INFO - Started process (PID=19907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:16:51.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:16:51.750+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:51.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:16:51.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:16:51.778+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:51.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:16:51.789+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:16:51.789+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:16:51.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:17:22.235+0000] {processor.py:157} INFO - Started process (PID=19932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:17:22.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:17:22.241+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:22.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:17:22.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:17:22.270+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:22.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:17:22.281+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:22.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:17:22.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T23:17:52.758+0000] {processor.py:157} INFO - Started process (PID=19957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:17:52.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:17:52.761+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:52.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:17:52.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:17:52.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:52.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:17:52.800+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:17:52.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:17:52.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:18:23.183+0000] {processor.py:157} INFO - Started process (PID=19982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:18:23.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:18:23.189+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:23.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:18:23.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:18:23.218+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:23.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:18:23.229+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:23.229+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:18:23.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T23:18:53.701+0000] {processor.py:157} INFO - Started process (PID=20007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:18:53.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:18:53.706+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:53.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:18:53.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:18:53.731+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:53.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:18:53.741+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:18:53.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:18:53.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T23:19:24.146+0000] {processor.py:157} INFO - Started process (PID=20032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:19:24.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:19:24.151+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:24.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:19:24.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:19:24.175+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:24.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:19:24.188+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:24.188+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:19:24.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T23:19:54.582+0000] {processor.py:157} INFO - Started process (PID=20057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:19:54.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:19:54.587+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:54.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:19:54.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:19:54.618+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:54.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:19:54.629+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:19:54.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:19:54.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T23:20:25.016+0000] {processor.py:157} INFO - Started process (PID=20082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:20:25.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:20:25.021+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:25.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:20:25.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:20:25.048+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:25.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:20:25.058+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:25.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:20:25.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:20:55.428+0000] {processor.py:157} INFO - Started process (PID=20107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:20:55.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:20:55.432+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:55.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:20:55.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:20:55.460+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:55.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:20:55.470+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:20:55.470+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:20:55.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:21:25.953+0000] {processor.py:157} INFO - Started process (PID=20132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:21:25.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:21:25.959+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:25.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:21:25.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:21:25.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:25.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:21:26.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:26.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:21:26.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-20T23:21:56.349+0000] {processor.py:157} INFO - Started process (PID=20157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:21:56.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:21:56.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:56.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:21:56.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:21:56.382+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:56.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:21:56.392+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:21:56.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:21:56.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:22:26.876+0000] {processor.py:157} INFO - Started process (PID=20182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:22:26.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:22:26.879+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:26.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:22:26.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:22:26.909+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:26.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:22:26.921+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:26.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:22:26.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T23:22:57.329+0000] {processor.py:157} INFO - Started process (PID=20207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:22:57.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:22:57.331+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:57.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:22:57.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:22:57.362+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:57.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:22:57.374+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:22:57.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:22:57.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-20T23:23:27.839+0000] {processor.py:157} INFO - Started process (PID=20232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:23:27.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:23:27.842+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:27.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:23:27.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:23:27.872+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:27.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:23:27.882+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:27.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:23:27.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:23:58.307+0000] {processor.py:157} INFO - Started process (PID=20257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:23:58.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:23:58.310+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:58.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:23:58.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:23:58.339+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:58.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:23:58.352+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:23:58.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:23:58.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:24:28.766+0000] {processor.py:157} INFO - Started process (PID=20282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:24:28.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:24:28.768+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:28.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:24:28.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:24:28.796+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:28.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:24:28.807+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:28.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:24:28.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T23:24:59.257+0000] {processor.py:157} INFO - Started process (PID=20307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:24:59.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:24:59.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:59.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:24:59.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:24:59.288+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:59.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:24:59.299+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:24:59.299+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:24:59.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:25:29.661+0000] {processor.py:157} INFO - Started process (PID=20332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:25:29.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:25:29.664+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:25:29.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:25:29.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:25:29.692+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:25:29.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:25:29.701+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:25:29.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:25:29.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T23:26:00.150+0000] {processor.py:157} INFO - Started process (PID=20357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:26:00.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:26:00.153+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:00.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:26:00.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:26:00.182+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:00.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:26:00.193+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:00.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:26:00.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:26:30.562+0000] {processor.py:157} INFO - Started process (PID=20382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:26:30.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:26:30.565+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:30.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:26:30.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:26:30.592+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:30.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:26:30.605+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:26:30.605+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:26:30.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:27:01.073+0000] {processor.py:157} INFO - Started process (PID=20407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:27:01.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:27:01.084+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:01.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:27:01.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:27:01.124+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:01.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:27:01.135+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:01.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:27:01.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-20T23:27:31.586+0000] {processor.py:157} INFO - Started process (PID=20432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:27:31.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:27:31.588+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:31.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:27:31.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:27:31.614+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:31.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:27:31.626+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:27:31.626+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:27:31.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T23:28:02.027+0000] {processor.py:157} INFO - Started process (PID=20457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:28:02.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:28:02.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:02.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:28:02.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:28:02.059+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:02.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:28:02.069+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:02.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:28:02.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:28:32.431+0000] {processor.py:157} INFO - Started process (PID=20482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:28:32.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:28:32.434+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:32.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:28:32.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:28:32.467+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:32.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:28:32.478+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:28:32.478+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:28:32.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T23:29:02.908+0000] {processor.py:157} INFO - Started process (PID=20507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:29:02.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:29:02.914+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:02.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:29:02.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:29:02.943+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:02.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:29:02.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:02.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:29:02.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:29:33.323+0000] {processor.py:157} INFO - Started process (PID=20532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:29:33.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:29:33.326+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:33.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:29:33.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:29:33.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:33.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:29:33.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:29:33.366+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:29:33.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:30:03.690+0000] {processor.py:157} INFO - Started process (PID=20557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:30:03.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:30:03.693+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:03.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:30:03.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:30:03.722+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:03.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:30:03.734+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:03.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:30:03.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:30:34.164+0000] {processor.py:157} INFO - Started process (PID=20582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:30:34.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:30:34.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:34.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:30:34.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:30:34.197+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:34.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:30:34.207+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:30:34.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:30:34.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:31:04.667+0000] {processor.py:157} INFO - Started process (PID=20607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:31:04.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:31:04.670+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:04.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:31:04.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:31:04.697+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:04.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:31:04.711+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:04.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:31:04.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:31:35.194+0000] {processor.py:157} INFO - Started process (PID=20632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:31:35.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:31:35.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:35.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:31:35.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:31:35.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:35.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:31:35.244+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:31:35.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:31:35.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-20T23:32:05.659+0000] {processor.py:157} INFO - Started process (PID=20657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:32:05.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:32:05.665+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:05.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:32:05.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:32:05.690+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:05.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:32:05.700+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:05.700+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:32:05.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T23:32:36.043+0000] {processor.py:157} INFO - Started process (PID=20682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:32:36.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:32:36.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:36.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:32:36.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:32:36.110+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:36.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:32:36.122+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:32:36.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:32:36.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-20T23:33:06.516+0000] {processor.py:157} INFO - Started process (PID=20707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:33:06.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:33:06.521+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:06.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:33:06.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:33:06.550+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:06.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:33:06.560+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:06.560+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:33:06.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:33:37.027+0000] {processor.py:157} INFO - Started process (PID=20732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:33:37.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:33:37.030+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:37.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:33:37.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:33:37.058+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:37.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:33:37.068+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:33:37.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:33:37.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:34:07.523+0000] {processor.py:157} INFO - Started process (PID=20757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:34:07.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:34:07.527+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:07.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:34:07.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:34:07.557+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:07.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:34:07.567+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:07.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:34:07.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:34:37.937+0000] {processor.py:157} INFO - Started process (PID=20782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:34:37.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:34:37.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:37.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:34:37.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:34:37.968+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:37.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:34:37.977+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:34:37.977+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:34:37.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T23:35:08.399+0000] {processor.py:157} INFO - Started process (PID=20807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:35:08.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:35:08.402+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:08.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:35:08.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:35:08.429+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:08.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:35:08.439+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:08.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:35:08.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T23:35:38.985+0000] {processor.py:157} INFO - Started process (PID=20832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:35:38.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:35:38.991+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:38.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:35:39.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:35:39.037+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:39.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:35:39.050+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:35:39.050+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:35:39.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-20T23:36:09.503+0000] {processor.py:157} INFO - Started process (PID=20857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:36:09.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:36:09.508+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:09.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:36:09.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:36:09.534+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:09.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:36:09.545+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:09.545+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:36:09.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:36:39.928+0000] {processor.py:157} INFO - Started process (PID=20882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:36:39.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:36:39.931+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:39.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:36:39.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:36:39.958+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:39.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:36:39.971+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:36:39.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:36:39.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T23:37:10.326+0000] {processor.py:157} INFO - Started process (PID=20907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:37:10.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:37:10.330+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:10.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:37:10.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:37:10.356+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:10.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:37:10.366+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:10.366+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:37:10.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-20T23:37:40.696+0000] {processor.py:157} INFO - Started process (PID=20932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:37:40.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:37:40.698+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:40.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:37:40.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:37:40.727+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:40.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:37:40.740+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:37:40.739+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:37:40.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:38:11.171+0000] {processor.py:157} INFO - Started process (PID=20957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:38:11.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:38:11.173+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:11.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:38:11.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:38:11.199+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:11.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:38:11.209+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:11.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:38:11.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-20T23:38:41.628+0000] {processor.py:157} INFO - Started process (PID=20982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:38:41.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:38:41.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:41.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:38:41.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:38:41.660+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:41.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:38:41.672+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:38:41.671+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:38:41.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T23:39:12.128+0000] {processor.py:157} INFO - Started process (PID=21007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:39:12.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:39:12.131+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:12.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:39:12.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:39:12.157+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:12.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:39:12.168+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:12.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:39:12.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T23:39:42.644+0000] {processor.py:157} INFO - Started process (PID=21032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:39:42.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:39:42.649+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:42.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:39:42.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:39:42.681+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:42.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:39:42.694+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:39:42.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:39:42.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-20T23:40:13.072+0000] {processor.py:157} INFO - Started process (PID=21057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:40:13.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:40:13.074+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:13.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:40:13.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:40:13.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:13.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:40:13.114+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:13.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:40:13.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:40:43.466+0000] {processor.py:157} INFO - Started process (PID=21082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:40:43.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:40:43.471+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:43.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:40:43.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:40:43.498+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:43.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:40:43.511+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:40:43.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:40:43.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:41:13.958+0000] {processor.py:157} INFO - Started process (PID=21107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:41:13.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:41:13.962+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:13.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:41:13.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:41:13.992+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:13.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:41:14.002+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:14.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:41:14.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:41:44.370+0000] {processor.py:157} INFO - Started process (PID=21132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:41:44.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:41:44.373+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:44.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:41:44.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:41:44.403+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:44.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:41:44.413+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:41:44.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:41:44.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:42:14.809+0000] {processor.py:157} INFO - Started process (PID=21157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:42:14.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:42:14.814+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:14.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:42:14.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:42:14.841+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:14.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:42:14.852+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:14.852+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:42:14.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:42:45.216+0000] {processor.py:157} INFO - Started process (PID=21182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:42:45.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:42:45.222+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:45.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:42:45.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:42:45.250+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:45.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:42:45.260+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:42:45.260+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:42:45.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:43:15.588+0000] {processor.py:157} INFO - Started process (PID=21207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:43:15.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:43:15.590+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:15.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:43:15.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:43:15.621+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:15.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:43:15.633+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:15.633+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:43:15.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T23:43:46.026+0000] {processor.py:157} INFO - Started process (PID=21232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:43:46.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:43:46.029+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:46.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:43:46.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:43:46.053+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:46.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:43:46.065+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:43:46.065+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:43:46.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-20T23:44:16.462+0000] {processor.py:157} INFO - Started process (PID=21257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:44:16.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:44:16.466+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:16.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:44:16.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:44:16.495+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:16.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:44:16.505+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:16.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:44:16.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:44:46.942+0000] {processor.py:157} INFO - Started process (PID=21282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:44:46.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:44:46.946+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:46.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:44:46.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:44:46.975+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:46.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:44:46.984+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:44:46.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:44:46.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:45:17.404+0000] {processor.py:157} INFO - Started process (PID=21307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:45:17.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:45:17.406+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:17.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:45:17.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:45:17.428+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:17.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:45:17.437+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:17.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:45:17.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-20T23:45:47.802+0000] {processor.py:157} INFO - Started process (PID=21332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:45:47.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:45:47.805+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:47.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:45:47.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:45:47.836+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:47.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:45:47.847+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:45:47.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:45:47.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T23:46:18.277+0000] {processor.py:157} INFO - Started process (PID=21357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:46:18.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:46:18.280+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:18.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:46:18.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:46:18.308+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:18.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:46:18.321+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:18.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:46:18.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-20T23:46:48.756+0000] {processor.py:157} INFO - Started process (PID=21382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:46:48.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:46:48.759+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:48.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:46:48.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:46:48.788+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:48.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:46:48.802+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:46:48.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:46:48.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:47:19.212+0000] {processor.py:157} INFO - Started process (PID=21407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:47:19.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:47:19.217+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:19.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:47:19.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:47:19.245+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:19.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:47:19.254+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:19.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:47:19.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T23:47:49.641+0000] {processor.py:157} INFO - Started process (PID=21432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:47:49.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:47:49.644+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:49.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:47:49.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:47:49.673+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:49.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:47:49.684+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:47:49.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:47:49.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:48:20.197+0000] {processor.py:157} INFO - Started process (PID=21457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:48:20.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:48:20.202+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:20.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:48:20.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:48:20.230+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:20.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:48:20.240+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:20.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:48:20.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:48:50.574+0000] {processor.py:157} INFO - Started process (PID=21482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:48:50.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:48:50.576+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:50.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:48:50.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:48:50.597+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:50.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:48:50.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:48:50.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:48:50.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-20T23:49:21.094+0000] {processor.py:157} INFO - Started process (PID=21507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:49:21.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:49:21.097+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:21.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:49:21.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:49:21.127+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:21.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:49:21.137+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:21.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:49:21.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:49:51.603+0000] {processor.py:157} INFO - Started process (PID=21532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:49:51.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:49:51.606+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:51.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:49:51.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:49:51.637+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:51.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:49:51.648+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:49:51.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:49:51.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-20T23:50:22.128+0000] {processor.py:157} INFO - Started process (PID=21557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:50:22.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:50:22.130+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:22.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:50:22.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:50:22.156+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:22.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:50:22.167+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:22.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:50:22.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-20T23:50:52.600+0000] {processor.py:157} INFO - Started process (PID=21582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:50:52.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:50:52.602+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:52.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:50:52.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:50:52.630+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:52.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:50:52.640+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:50:52.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:50:52.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T23:51:23.059+0000] {processor.py:157} INFO - Started process (PID=21607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:51:23.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:51:23.062+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:23.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:51:23.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:51:23.090+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:23.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:51:23.102+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:23.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:51:23.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-20T23:51:53.576+0000] {processor.py:157} INFO - Started process (PID=21632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:51:53.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:51:53.580+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:53.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:51:53.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:51:53.609+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:53.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:51:53.623+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:51:53.623+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:51:53.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-20T23:52:23.979+0000] {processor.py:157} INFO - Started process (PID=21657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:52:23.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:52:23.982+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:23.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:52:23.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:52:24.012+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:24.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:52:24.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:24.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:52:24.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:52:54.487+0000] {processor.py:157} INFO - Started process (PID=21682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:52:54.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:52:54.489+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:54.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:52:54.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:52:54.517+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:54.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:52:54.526+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:52:54.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:52:54.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-20T23:53:24.981+0000] {processor.py:157} INFO - Started process (PID=21707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:53:24.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:53:24.984+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:24.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:53:24.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:53:25.013+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:25.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:53:25.022+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:25.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:53:25.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-20T23:53:55.474+0000] {processor.py:157} INFO - Started process (PID=21732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:53:55.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:53:55.477+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:55.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:53:55.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:53:55.506+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:55.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:53:55.516+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:53:55.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:53:55.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:54:25.907+0000] {processor.py:157} INFO - Started process (PID=21757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:54:25.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:54:25.913+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:25.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:54:25.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:54:25.941+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:25.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:54:25.953+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:25.952+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:54:25.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-20T23:54:56.344+0000] {processor.py:157} INFO - Started process (PID=21782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:54:56.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:54:56.348+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:56.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:54:56.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:54:56.375+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:56.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:54:56.387+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:54:56.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:54:56.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-20T23:55:26.872+0000] {processor.py:157} INFO - Started process (PID=21807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:55:26.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-20T23:55:26.874+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:55:26.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:55:26.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-20T23:55:26.899+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:55:26.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-20T23:55:26.910+0000] {logging_mixin.py:151} INFO - [2024-07-20T23:55:26.910+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-20T00:30:00+00:00, run_after=2024-07-21T00:30:00+00:00
[2024-07-20T23:55:26.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
