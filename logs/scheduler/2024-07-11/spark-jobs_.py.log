[2024-07-11T11:07:01.913+0000] {processor.py:157} INFO - Started process (PID=9201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:07:01.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:07:01.917+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:01.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:07:01.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:07:02.020+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:02.020+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-11T11:07:02.021+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:02.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:07:02.035+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:02.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-10T00:30:00+00:00, run_after=2024-07-11T00:30:00+00:00
[2024-07-11T11:07:02.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-11T11:07:07.991+0000] {processor.py:157} INFO - Started process (PID=9206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:07:07.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:07:07.994+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:07.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:07:08.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:07:08.065+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:08.065+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-11T11:07:08.068+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:08.068+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-11T11:07:08.072+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:08.071+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-11T11:07:08.072+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:08.072+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:spark_data_processing_pipeline' as access control is unset.
[2024-07-11T11:07:08.072+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:08.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:07:08.077+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:08.077+0000] {dag.py:2937} INFO - Creating ORM DAG for spark_data_processing_pipeline
[2024-07-11T11:07:08.083+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:07:08.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:07:08.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-11T11:12:01.972+0000] {processor.py:157} INFO - Started process (PID=9411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:12:01.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:12:01.974+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:12:01.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:12:01.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:12:02.005+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:12:02.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:12:02.017+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:12:02.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:12:02.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:12:32.447+0000] {processor.py:157} INFO - Started process (PID=9436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:12:32.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:12:32.450+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:12:32.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:12:32.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:12:32.486+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:12:32.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:12:32.497+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:12:32.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:12:32.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-11T11:13:02.906+0000] {processor.py:157} INFO - Started process (PID=9461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:13:02.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:13:02.908+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:13:02.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:13:02.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:13:02.982+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:13:02.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:13:03.005+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:13:03.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:13:03.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-11T11:13:33.402+0000] {processor.py:157} INFO - Started process (PID=9486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:13:33.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:13:33.405+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:13:33.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:13:33.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:13:33.454+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:13:33.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:13:33.467+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:13:33.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:13:33.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-11T11:14:03.802+0000] {processor.py:157} INFO - Started process (PID=9511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:14:03.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:14:03.804+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:14:03.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:14:03.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:14:03.835+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:14:03.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:14:03.848+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:14:03.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:14:03.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:14:34.341+0000] {processor.py:157} INFO - Started process (PID=9536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:14:34.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:14:34.344+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:14:34.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:14:34.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:14:34.379+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:14:34.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:14:34.390+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:14:34.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:14:34.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-11T11:15:04.782+0000] {processor.py:157} INFO - Started process (PID=9561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:15:04.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:15:04.785+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:15:04.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:15:04.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:15:04.828+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:15:04.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:15:04.840+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:15:04.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:15:04.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-11T11:15:35.249+0000] {processor.py:157} INFO - Started process (PID=9586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:15:35.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:15:35.250+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:15:35.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:15:35.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:15:35.281+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:15:35.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:15:35.293+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:15:35.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:15:35.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-11T11:16:05.851+0000] {processor.py:157} INFO - Started process (PID=9611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:16:05.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:16:05.853+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:16:05.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:16:05.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:16:05.887+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:16:05.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:16:05.899+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:16:05.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:16:05.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-11T11:16:36.242+0000] {processor.py:157} INFO - Started process (PID=9636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:16:36.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:16:36.244+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:16:36.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:16:36.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:16:36.277+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:16:36.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:16:36.287+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:16:36.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:16:36.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:17:06.755+0000] {processor.py:157} INFO - Started process (PID=9661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:17:06.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:17:06.757+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:17:06.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:17:06.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:17:06.788+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:17:06.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:17:06.800+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:17:06.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:17:06.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:17:37.260+0000] {processor.py:157} INFO - Started process (PID=9686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:17:37.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:17:37.263+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:17:37.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:17:37.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:17:37.323+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:17:37.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:17:37.345+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:17:37.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:17:37.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-11T11:18:07.716+0000] {processor.py:157} INFO - Started process (PID=9711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:18:07.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:18:07.717+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:18:07.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:18:07.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:18:07.748+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:18:07.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:18:07.761+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:18:07.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:18:07.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-11T11:18:38.152+0000] {processor.py:157} INFO - Started process (PID=9736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:18:38.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:18:38.154+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:18:38.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:18:38.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:18:38.187+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:18:38.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:18:38.199+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:18:38.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:18:38.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:19:08.648+0000] {processor.py:157} INFO - Started process (PID=9761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:19:08.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:19:08.649+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:19:08.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:19:08.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:19:08.684+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:19:08.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:19:08.695+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:19:08.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:19:08.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:19:39.075+0000] {processor.py:157} INFO - Started process (PID=9786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:19:39.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:19:39.076+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:19:39.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:19:39.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:19:39.109+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:19:39.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:19:39.122+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:19:39.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:19:39.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:20:09.490+0000] {processor.py:157} INFO - Started process (PID=9811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:20:09.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:20:09.491+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:20:09.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:20:09.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:20:09.523+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:20:09.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:20:09.535+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:20:09.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:20:09.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:20:39.916+0000] {processor.py:157} INFO - Started process (PID=9836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:20:39.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:20:39.918+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:20:39.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:20:39.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:20:39.951+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:20:39.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:20:39.963+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:20:39.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:20:39.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:21:10.420+0000] {processor.py:157} INFO - Started process (PID=9861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:21:10.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:21:10.422+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:21:10.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:21:10.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:21:10.465+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:21:10.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:21:10.478+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:21:10.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:21:10.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-11T11:21:40.914+0000] {processor.py:157} INFO - Started process (PID=9886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:21:40.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:21:40.916+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:21:40.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:21:40.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:21:40.949+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:21:40.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:21:40.961+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:21:40.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:21:40.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:22:11.353+0000] {processor.py:157} INFO - Started process (PID=9911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:22:11.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:22:11.355+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:22:11.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:22:11.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:22:11.387+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:22:11.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:22:11.400+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:22:11.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:22:11.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:22:41.964+0000] {processor.py:157} INFO - Started process (PID=9936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:22:41.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:22:41.966+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:22:41.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:22:41.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:22:42.043+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:22:42.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:22:42.065+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:22:42.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:22:42.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-11T11:23:12.413+0000] {processor.py:157} INFO - Started process (PID=9961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:23:12.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:23:12.415+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:23:12.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:23:12.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:23:12.447+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:23:12.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:23:12.459+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:23:12.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:23:12.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:23:42.873+0000] {processor.py:157} INFO - Started process (PID=9986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:23:42.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:23:42.875+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:23:42.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:23:42.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:23:42.909+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:23:42.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:23:42.922+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:23:42.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:23:42.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-11T11:24:13.374+0000] {processor.py:157} INFO - Started process (PID=10011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:24:13.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:24:13.376+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:24:13.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:24:13.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:24:13.407+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:24:13.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:24:13.418+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:24:13.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:24:13.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-11T11:24:43.761+0000] {processor.py:157} INFO - Started process (PID=10036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:24:43.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:24:43.763+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:24:43.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:24:43.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:24:43.794+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:24:43.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:24:43.805+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:24:43.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:24:43.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-11T11:25:14.252+0000] {processor.py:157} INFO - Started process (PID=10061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:25:14.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:25:14.254+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:25:14.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:25:14.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:25:14.290+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:25:14.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:25:14.303+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:25:14.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:25:14.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-11T11:25:44.690+0000] {processor.py:157} INFO - Started process (PID=10086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:25:44.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:25:44.692+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:25:44.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:25:44.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:25:44.724+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:25:44.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:25:44.735+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:25:44.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:25:44.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:26:15.109+0000] {processor.py:157} INFO - Started process (PID=10111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:26:15.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:26:15.110+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:26:15.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:26:15.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:26:15.142+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:26:15.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:26:15.154+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:26:15.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:26:15.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:26:45.530+0000] {processor.py:157} INFO - Started process (PID=10136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:26:45.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:26:45.531+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:26:45.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:26:45.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:26:45.564+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:26:45.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:26:45.576+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:26:45.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:26:45.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-11T11:27:16.044+0000] {processor.py:157} INFO - Started process (PID=10161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:27:16.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:27:16.046+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:27:16.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:27:16.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:27:16.079+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:27:16.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:27:16.091+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:27:16.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:27:16.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:27:46.508+0000] {processor.py:157} INFO - Started process (PID=10186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:27:46.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:27:46.509+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:27:46.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:27:46.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:27:46.541+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:27:46.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:27:46.553+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:27:46.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:27:46.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:28:17.087+0000] {processor.py:157} INFO - Started process (PID=10211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:28:17.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:28:17.090+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:28:17.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:28:17.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:28:17.185+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:28:17.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:28:17.205+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:28:17.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:28:17.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-11T11:28:47.582+0000] {processor.py:157} INFO - Started process (PID=10236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:28:47.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:28:47.583+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:28:47.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:28:47.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:28:47.618+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:28:47.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:28:47.630+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:28:47.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:28:47.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:29:17.982+0000] {processor.py:157} INFO - Started process (PID=10261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:29:17.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:29:17.983+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:29:17.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:29:17.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:29:18.007+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:29:18.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:29:18.018+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:29:18.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:29:18.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-11T11:29:48.402+0000] {processor.py:157} INFO - Started process (PID=10286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:29:48.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:29:48.404+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:29:48.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:29:48.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:29:48.436+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:29:48.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:29:48.448+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:29:48.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:29:48.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:30:18.853+0000] {processor.py:157} INFO - Started process (PID=10311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:30:18.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:30:18.855+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:30:18.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:30:18.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:30:18.882+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:30:18.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:30:18.891+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:30:18.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:30:18.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-11T11:30:49.273+0000] {processor.py:157} INFO - Started process (PID=10336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:30:49.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:30:49.274+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:30:49.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:30:49.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:30:49.296+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:30:49.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:30:49.305+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:30:49.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:30:49.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-11T11:31:19.776+0000] {processor.py:157} INFO - Started process (PID=10361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:31:19.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:31:19.778+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:31:19.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:31:19.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:31:19.806+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:31:19.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:31:19.816+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:31:19.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:31:19.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-11T11:31:50.196+0000] {processor.py:157} INFO - Started process (PID=10386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:31:50.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:31:50.198+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:31:50.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:31:50.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:31:50.228+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:31:50.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:31:50.238+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:31:50.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:31:50.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-11T11:32:20.664+0000] {processor.py:157} INFO - Started process (PID=10411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:32:20.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:32:20.666+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:32:20.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:32:20.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:32:20.695+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:32:20.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:32:20.704+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:32:20.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:32:20.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T11:32:51.127+0000] {processor.py:157} INFO - Started process (PID=10436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:32:51.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:32:51.128+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:32:51.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:32:51.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:32:51.156+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:32:51.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:32:51.166+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:32:51.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:32:51.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T11:33:21.560+0000] {processor.py:157} INFO - Started process (PID=10461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:33:21.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:33:21.561+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:33:21.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:33:21.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:33:21.585+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:33:21.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:33:21.595+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:33:21.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:33:21.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-11T11:33:51.994+0000] {processor.py:157} INFO - Started process (PID=10486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:33:51.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:33:51.995+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:33:51.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:33:52.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:33:52.024+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:33:52.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:33:52.034+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:33:52.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:33:52.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-11T11:34:22.479+0000] {processor.py:157} INFO - Started process (PID=10511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:34:22.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:34:22.481+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:34:22.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:34:22.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:34:22.509+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:34:22.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:34:22.519+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:34:22.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:34:22.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-11T11:34:52.892+0000] {processor.py:157} INFO - Started process (PID=10536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:34:52.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:34:52.893+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:34:52.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:34:52.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:34:52.919+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:34:52.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:34:52.928+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:34:52.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:34:52.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-11T11:35:23.337+0000] {processor.py:157} INFO - Started process (PID=10561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:35:23.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:35:23.339+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:35:23.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:35:23.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:35:23.371+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:35:23.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:35:23.381+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:35:23.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:35:23.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-11T11:35:53.763+0000] {processor.py:157} INFO - Started process (PID=10586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:35:53.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:35:53.765+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:35:53.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:35:53.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:35:53.817+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:35:53.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:35:53.836+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:35:53.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:35:53.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-11T11:36:24.227+0000] {processor.py:157} INFO - Started process (PID=10611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:36:24.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:36:24.229+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:36:24.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:36:24.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:36:24.259+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:36:24.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:36:24.271+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:36:24.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:36:24.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-11T11:36:54.663+0000] {processor.py:157} INFO - Started process (PID=10636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:36:54.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:36:54.665+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:36:54.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:36:54.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:36:54.705+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:36:54.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:36:54.717+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:36:54.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:36:54.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-11T11:37:25.114+0000] {processor.py:157} INFO - Started process (PID=10661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:37:25.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:37:25.115+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:37:25.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:37:25.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:37:25.147+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:37:25.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:37:25.158+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:37:25.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:37:25.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:37:55.529+0000] {processor.py:157} INFO - Started process (PID=10686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:37:55.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:37:55.530+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:37:55.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:37:55.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:37:55.571+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:37:55.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:37:55.588+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:37:55.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:37:55.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-11T11:38:26.020+0000] {processor.py:157} INFO - Started process (PID=10711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:38:26.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:38:26.022+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:38:26.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:38:26.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:38:26.054+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:38:26.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:38:26.069+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:38:26.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:38:26.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-11T11:38:56.462+0000] {processor.py:157} INFO - Started process (PID=10736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:38:56.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:38:56.463+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:38:56.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:38:56.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:38:56.496+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:38:56.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:38:56.507+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:38:56.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:38:56.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-11T11:39:26.933+0000] {processor.py:157} INFO - Started process (PID=10761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:39:26.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:39:26.935+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:39:26.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:39:26.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:39:26.967+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:39:26.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:39:26.979+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:39:26.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:39:26.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:39:57.363+0000] {processor.py:157} INFO - Started process (PID=10786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:39:57.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:39:57.366+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:39:57.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:39:57.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:39:57.400+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:39:57.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:39:57.419+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:39:57.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:39:57.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-11T11:40:27.830+0000] {processor.py:157} INFO - Started process (PID=10811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:40:27.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:40:27.832+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:40:27.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:40:27.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:40:27.864+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:40:27.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:40:27.876+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:40:27.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:40:27.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:40:58.302+0000] {processor.py:157} INFO - Started process (PID=10836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:40:58.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:40:58.304+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:40:58.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:40:58.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:40:58.338+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:40:58.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:40:58.349+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:40:58.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:40:58.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-11T11:41:28.817+0000] {processor.py:157} INFO - Started process (PID=10861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:41:28.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:41:28.819+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:41:28.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:41:28.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:41:28.852+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:41:28.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:41:28.864+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:41:28.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:41:28.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:41:59.259+0000] {processor.py:157} INFO - Started process (PID=10886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:41:59.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:41:59.261+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:41:59.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:41:59.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:41:59.293+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:41:59.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:41:59.307+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:41:59.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:41:59.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:42:29.756+0000] {processor.py:157} INFO - Started process (PID=10911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:42:29.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:42:29.757+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:42:29.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:42:29.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:42:29.793+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:42:29.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:42:29.810+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:42:29.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:42:29.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-11T11:43:00.295+0000] {processor.py:157} INFO - Started process (PID=10936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:43:00.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:43:00.298+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:43:00.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:43:00.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:43:00.348+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:43:00.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:43:00.362+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:43:00.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:43:00.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-11T11:43:31.031+0000] {processor.py:157} INFO - Started process (PID=10961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:43:31.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:43:31.034+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:43:31.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:43:31.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:43:31.084+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:43:31.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:43:31.101+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:43:31.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:43:31.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-11T11:44:01.443+0000] {processor.py:157} INFO - Started process (PID=10986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:44:01.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:44:01.444+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:44:01.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:44:01.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:44:01.477+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:44:01.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:44:01.488+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:44:01.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:44:01.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:44:31.900+0000] {processor.py:157} INFO - Started process (PID=11011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:44:31.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:44:31.902+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:44:31.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:44:31.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:44:31.936+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:44:31.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:44:31.951+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:44:31.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:44:31.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-11T11:45:02.351+0000] {processor.py:157} INFO - Started process (PID=11036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:45:02.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:45:02.353+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:45:02.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:45:02.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:45:02.384+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:45:02.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:45:02.396+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:45:02.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:45:02.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:45:32.805+0000] {processor.py:157} INFO - Started process (PID=11061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:45:32.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:45:32.807+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:45:32.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:45:32.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:45:32.840+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:45:32.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:45:32.852+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:45:32.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:45:32.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-11T11:46:03.287+0000] {processor.py:157} INFO - Started process (PID=11086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:46:03.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:46:03.289+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:46:03.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:46:03.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:46:03.323+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:46:03.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:46:03.335+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:46:03.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:46:03.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-11T11:46:33.750+0000] {processor.py:157} INFO - Started process (PID=11111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:46:33.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:46:33.752+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:46:33.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:46:33.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:46:33.785+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:46:33.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:46:33.797+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:46:33.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:46:33.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:47:04.226+0000] {processor.py:157} INFO - Started process (PID=11136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:47:04.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:47:04.228+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:47:04.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:47:04.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:47:04.265+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:47:04.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:47:04.276+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:47:04.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:47:04.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-11T11:47:34.674+0000] {processor.py:157} INFO - Started process (PID=11161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:47:34.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:47:34.676+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:47:34.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:47:34.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:47:34.708+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:47:34.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:47:34.720+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:47:34.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:47:34.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:48:05.145+0000] {processor.py:157} INFO - Started process (PID=11186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:48:05.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:48:05.147+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:48:05.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:48:05.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:48:05.181+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:48:05.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:48:05.194+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:48:05.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:48:05.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-11T11:48:35.579+0000] {processor.py:157} INFO - Started process (PID=11211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:48:35.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:48:35.580+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:48:35.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:48:35.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:48:35.609+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:48:35.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:48:35.621+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:48:35.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:48:35.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-11T11:49:06.065+0000] {processor.py:157} INFO - Started process (PID=11236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:49:06.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:49:06.067+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:49:06.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:49:06.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:49:06.101+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:49:06.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:49:06.111+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:49:06.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:49:06.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:49:36.528+0000] {processor.py:157} INFO - Started process (PID=11261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:49:36.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:49:36.531+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:49:36.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:49:36.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:49:36.562+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:49:36.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:49:36.574+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:49:36.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:49:36.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T11:50:06.974+0000] {processor.py:157} INFO - Started process (PID=11286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:50:06.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:50:06.976+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:50:06.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:50:06.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:50:07.014+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:50:07.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:50:07.028+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:50:07.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:50:07.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-11T11:50:37.487+0000] {processor.py:157} INFO - Started process (PID=11311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:50:37.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:50:37.489+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:50:37.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:50:37.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:50:37.513+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:50:37.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:50:37.523+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:50:37.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:50:37.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-11T11:51:07.835+0000] {processor.py:157} INFO - Started process (PID=11336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:51:07.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:51:07.837+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:51:07.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:51:07.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:51:07.878+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:51:07.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:51:07.893+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:51:07.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:51:07.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-11T11:51:38.343+0000] {processor.py:157} INFO - Started process (PID=11361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:51:38.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:51:38.347+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:51:38.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:51:38.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:51:38.389+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:51:38.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:51:38.404+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:51:38.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:51:38.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-11T11:52:08.776+0000] {processor.py:157} INFO - Started process (PID=11386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:52:08.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:52:08.778+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:52:08.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:52:08.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:52:08.819+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:52:08.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:52:08.831+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:52:08.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:52:08.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-11T11:52:39.251+0000] {processor.py:157} INFO - Started process (PID=11411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:52:39.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:52:39.253+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:52:39.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:52:39.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:52:39.288+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:52:39.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:52:39.301+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:52:39.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:52:39.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-11T11:53:09.715+0000] {processor.py:157} INFO - Started process (PID=11436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:53:09.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:53:09.716+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:53:09.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:53:09.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:53:09.745+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:53:09.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:53:09.756+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:53:09.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:53:09.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-11T11:53:40.131+0000] {processor.py:157} INFO - Started process (PID=11461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:53:40.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:53:40.133+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:53:40.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:53:40.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:53:40.158+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:53:40.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:53:40.168+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:53:40.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:53:40.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-11T11:54:10.522+0000] {processor.py:157} INFO - Started process (PID=11486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:54:10.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:54:10.523+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:54:10.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:54:10.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:54:10.542+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:54:10.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:54:10.551+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:54:10.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:54:10.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.037 seconds
[2024-07-11T11:54:41.019+0000] {processor.py:157} INFO - Started process (PID=11511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:54:41.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:54:41.021+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:54:41.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:54:41.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:54:41.058+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:54:41.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:54:41.071+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:54:41.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:54:41.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-11T11:55:11.522+0000] {processor.py:157} INFO - Started process (PID=11536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:55:11.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:55:11.525+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:55:11.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:55:11.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:55:11.603+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:55:11.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:55:11.631+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:55:11.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:55:11.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-11T11:55:41.925+0000] {processor.py:157} INFO - Started process (PID=11561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:55:41.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:55:41.927+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:55:41.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:55:41.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:55:41.961+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:55:41.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:55:41.973+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:55:41.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:55:41.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T11:56:12.432+0000] {processor.py:157} INFO - Started process (PID=11586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:56:12.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:56:12.434+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:56:12.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:56:12.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:56:12.465+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:56:12.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:56:12.476+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:56:12.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:56:12.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-11T11:56:42.900+0000] {processor.py:157} INFO - Started process (PID=11611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:56:42.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:56:42.903+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:56:42.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:56:42.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:56:42.936+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:56:42.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:56:42.946+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:56:42.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:56:42.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T11:57:13.481+0000] {processor.py:157} INFO - Started process (PID=11636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:57:13.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:57:13.483+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:57:13.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:57:13.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:57:13.505+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:57:13.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:57:13.515+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:57:13.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:57:13.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-11T11:57:43.964+0000] {processor.py:157} INFO - Started process (PID=11661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:57:43.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:57:43.966+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:57:43.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:57:43.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:57:44.017+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:57:44.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:57:44.036+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:57:44.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:57:44.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-11T11:58:14.463+0000] {processor.py:157} INFO - Started process (PID=11686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:58:14.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:58:14.465+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:58:14.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:58:14.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:58:14.505+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:58:14.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:58:14.520+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:58:14.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:58:14.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-11T11:58:44.855+0000] {processor.py:157} INFO - Started process (PID=11711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:58:44.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:58:44.855+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:58:44.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:58:44.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:58:44.873+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:58:44.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:58:44.882+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:58:44.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:58:44.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.036 seconds
[2024-07-11T11:59:15.322+0000] {processor.py:157} INFO - Started process (PID=11736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:59:15.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:59:15.324+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:59:15.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:59:15.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:59:15.359+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:59:15.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:59:15.373+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:59:15.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:59:15.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-11T11:59:45.836+0000] {processor.py:157} INFO - Started process (PID=11761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:59:45.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T11:59:45.838+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:59:45.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:59:45.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T11:59:45.872+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:59:45.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T11:59:45.889+0000] {logging_mixin.py:151} INFO - [2024-07-11T11:59:45.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T11:59:45.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-11T12:00:16.639+0000] {processor.py:157} INFO - Started process (PID=11786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:00:16.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:00:16.640+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:00:16.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:00:16.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:00:16.666+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:00:16.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:00:16.676+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:00:16.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:00:16.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-11T12:00:47.080+0000] {processor.py:157} INFO - Started process (PID=11811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:00:47.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:00:47.082+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:00:47.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:00:47.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:00:47.113+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:00:47.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:00:47.123+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:00:47.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:00:47.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-11T12:01:17.558+0000] {processor.py:157} INFO - Started process (PID=11836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:01:17.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:01:17.559+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:01:17.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:01:17.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:01:17.594+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:01:17.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:01:17.604+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:01:17.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:01:17.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-11T12:01:47.991+0000] {processor.py:157} INFO - Started process (PID=11861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:01:47.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:01:47.993+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:01:47.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:01:48.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:01:48.023+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:01:48.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:01:48.033+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:01:48.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:01:48.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T12:02:18.461+0000] {processor.py:157} INFO - Started process (PID=11886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:02:18.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:02:18.462+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:02:18.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:02:18.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:02:18.492+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:02:18.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:02:18.501+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:02:18.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:02:18.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-11T12:02:48.917+0000] {processor.py:157} INFO - Started process (PID=11911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:02:48.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:02:48.919+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:02:48.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:02:48.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:02:48.950+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:02:48.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:02:48.962+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:02:48.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:02:48.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-11T12:03:19.342+0000] {processor.py:157} INFO - Started process (PID=11936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:03:19.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:03:19.344+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:03:19.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:03:19.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:03:19.375+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:03:19.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:03:19.385+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:03:19.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:03:19.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-11T12:03:49.774+0000] {processor.py:157} INFO - Started process (PID=11961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:03:49.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:03:49.776+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:03:49.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:03:49.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:03:49.805+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:03:49.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:03:49.814+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:03:49.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:03:49.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-11T12:04:20.236+0000] {processor.py:157} INFO - Started process (PID=11986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:04:20.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:04:20.238+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:04:20.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:04:20.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:04:20.278+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:04:20.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:04:20.290+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:04:20.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:04:20.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-11T12:04:50.697+0000] {processor.py:157} INFO - Started process (PID=12011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:04:50.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:04:50.700+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:04:50.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:04:50.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:04:50.733+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:04:50.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:04:50.742+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:04:50.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:04:50.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-11T12:05:21.119+0000] {processor.py:157} INFO - Started process (PID=12036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:05:21.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:05:21.120+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:05:21.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:05:21.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:05:21.148+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:05:21.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:05:21.158+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:05:21.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:05:21.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-11T12:05:51.554+0000] {processor.py:157} INFO - Started process (PID=12061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:05:51.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:05:51.556+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:05:51.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:05:51.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:05:51.587+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:05:51.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:05:51.597+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:05:51.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:05:51.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-11T12:06:22.016+0000] {processor.py:157} INFO - Started process (PID=12086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:06:22.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:06:22.018+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:06:22.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:06:22.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:06:22.048+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:06:22.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:06:22.058+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:06:22.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:06:22.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-11T12:06:52.475+0000] {processor.py:157} INFO - Started process (PID=12111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:06:52.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:06:52.478+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:06:52.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:06:52.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:06:52.517+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:06:52.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:06:52.527+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:06:52.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:06:52.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-11T12:07:22.981+0000] {processor.py:157} INFO - Started process (PID=12136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:07:22.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:07:22.982+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:07:22.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:07:22.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:07:23.011+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:07:23.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:07:23.021+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:07:23.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:07:23.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T12:07:53.371+0000] {processor.py:157} INFO - Started process (PID=12161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:07:53.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:07:53.373+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:07:53.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:07:53.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:07:53.402+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:07:53.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:07:53.411+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:07:53.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:07:53.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T12:08:23.885+0000] {processor.py:157} INFO - Started process (PID=12186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:08:23.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:08:23.887+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:08:23.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:08:23.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:08:23.914+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:08:23.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:08:23.924+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:08:23.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:08:23.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-11T12:08:54.259+0000] {processor.py:157} INFO - Started process (PID=12211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:08:54.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:08:54.261+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:08:54.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:08:54.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:08:54.292+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:08:54.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:08:54.302+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:08:54.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:08:54.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-11T12:09:24.659+0000] {processor.py:157} INFO - Started process (PID=12236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:09:24.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:09:24.660+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:09:24.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:09:24.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:09:24.689+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:09:24.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:09:24.699+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:09:24.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:09:24.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T12:09:55.649+0000] {processor.py:157} INFO - Started process (PID=12261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:09:55.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:09:55.651+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:09:55.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:09:55.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:09:55.684+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:09:55.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:09:55.694+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:09:55.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:09:55.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-11T12:10:26.383+0000] {processor.py:157} INFO - Started process (PID=12286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:10:26.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:10:26.386+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:10:26.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:10:26.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:10:26.480+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:10:26.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:10:26.500+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:10:26.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:10:26.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-11T12:10:56.862+0000] {processor.py:157} INFO - Started process (PID=12311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:10:56.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:10:56.864+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:10:56.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:10:56.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:10:56.911+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:10:56.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:10:56.923+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:10:56.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:10:56.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-11T12:11:27.319+0000] {processor.py:157} INFO - Started process (PID=12336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:11:27.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:11:27.321+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:11:27.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:11:27.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:11:27.350+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:11:27.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:11:27.359+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:11:27.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:11:27.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T12:11:57.790+0000] {processor.py:157} INFO - Started process (PID=12361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:11:57.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:11:57.794+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:11:57.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:11:57.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:11:57.890+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:11:57.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:11:57.911+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:11:57.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:11:57.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-11T12:12:28.275+0000] {processor.py:157} INFO - Started process (PID=12386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:12:28.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:12:28.277+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:12:28.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:12:28.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:12:28.306+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:12:28.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:12:28.315+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:12:28.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:12:28.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T12:12:58.714+0000] {processor.py:157} INFO - Started process (PID=12411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:12:58.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:12:58.716+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:12:58.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:12:58.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:12:58.746+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:12:58.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:12:58.755+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:12:58.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:12:58.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-11T12:13:29.145+0000] {processor.py:157} INFO - Started process (PID=12436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:13:29.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:13:29.147+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:13:29.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:13:29.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:13:29.170+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:13:29.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:13:29.180+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:13:29.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:13:29.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-11T12:13:59.561+0000] {processor.py:157} INFO - Started process (PID=12461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:13:59.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:13:59.563+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:13:59.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:13:59.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:13:59.591+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:13:59.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:13:59.601+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:13:59.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:13:59.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-11T12:14:29.992+0000] {processor.py:157} INFO - Started process (PID=12486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:14:29.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:14:29.994+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:14:29.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:14:30.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:14:30.026+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:14:30.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:14:30.036+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:14:30.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:14:30.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-11T12:15:00.487+0000] {processor.py:157} INFO - Started process (PID=12511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:15:00.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:15:00.490+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:15:00.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:15:00.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:15:00.519+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:15:00.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:15:00.528+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:15:00.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:15:00.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-11T12:15:30.953+0000] {processor.py:157} INFO - Started process (PID=12536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:15:30.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:15:30.955+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:15:30.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:15:30.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:15:31.005+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:15:31.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:15:31.025+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:15:31.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:15:31.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-11T12:16:01.459+0000] {processor.py:157} INFO - Started process (PID=12561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:16:01.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:16:01.461+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:16:01.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:16:01.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:16:01.491+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:16:01.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:16:01.501+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:16:01.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:16:01.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-11T12:16:31.853+0000] {processor.py:157} INFO - Started process (PID=12586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:16:31.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:16:31.856+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:16:31.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:16:31.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:16:31.924+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:16:31.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:16:31.952+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:16:31.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:16:31.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-11T12:17:02.326+0000] {processor.py:157} INFO - Started process (PID=12611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:17:02.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:17:02.327+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:17:02.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:17:02.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:17:02.357+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:17:02.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:17:02.370+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:17:02.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:17:02.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-11T12:17:32.748+0000] {processor.py:157} INFO - Started process (PID=12636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:17:32.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:17:32.750+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:17:32.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:17:32.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:17:32.782+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:17:32.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:17:32.792+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:17:32.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:17:32.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-11T12:18:03.152+0000] {processor.py:157} INFO - Started process (PID=12661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:18:03.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:18:03.154+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:18:03.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:18:03.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:18:03.184+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:18:03.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:18:03.194+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:18:03.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:18:03.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-11T12:18:33.664+0000] {processor.py:157} INFO - Started process (PID=12686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:18:33.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:18:33.665+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:18:33.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:18:33.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:18:33.694+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:18:33.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:18:33.704+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:18:33.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:18:33.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-11T12:19:04.118+0000] {processor.py:157} INFO - Started process (PID=12711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:19:04.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:19:04.121+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:19:04.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:19:04.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:19:04.149+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:19:04.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:19:04.158+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:19:04.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:19:04.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-11T12:19:34.734+0000] {processor.py:157} INFO - Started process (PID=12736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:19:34.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:19:34.737+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:19:34.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:19:34.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:19:34.767+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:19:34.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:19:34.776+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:19:34.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:19:34.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-11T12:20:05.265+0000] {processor.py:157} INFO - Started process (PID=12761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:20:05.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:20:05.267+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:20:05.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:20:05.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:20:05.299+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:20:05.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:20:05.309+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:20:05.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:20:05.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-11T12:20:35.682+0000] {processor.py:157} INFO - Started process (PID=12786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:20:35.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:20:35.683+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:20:35.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:20:35.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:20:35.713+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:20:35.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:20:35.723+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:20:35.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:20:35.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-11T12:21:06.157+0000] {processor.py:157} INFO - Started process (PID=12811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:21:06.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:21:06.159+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:21:06.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:21:06.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:21:06.188+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:21:06.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:21:06.198+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:21:06.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:21:06.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-11T12:21:36.662+0000] {processor.py:157} INFO - Started process (PID=12836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:21:36.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:21:36.665+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:21:36.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:21:36.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:21:36.724+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:21:36.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:21:36.739+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:21:36.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:21:36.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-11T12:22:07.141+0000] {processor.py:157} INFO - Started process (PID=12861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:22:07.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:22:07.143+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:22:07.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:22:07.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:22:07.177+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:22:07.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:22:07.189+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:22:07.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:22:07.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-11T12:22:37.654+0000] {processor.py:157} INFO - Started process (PID=12886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:22:37.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:22:37.655+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:22:37.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:22:37.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:22:37.686+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:22:37.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:22:37.697+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:22:37.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:22:37.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-11T12:23:08.124+0000] {processor.py:157} INFO - Started process (PID=12911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:23:08.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:23:08.126+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:23:08.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:23:08.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:23:08.159+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:23:08.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:23:08.173+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:23:08.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:23:08.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-11T12:23:38.627+0000] {processor.py:157} INFO - Started process (PID=12936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:23:38.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:23:38.631+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:23:38.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:23:38.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:23:38.675+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:23:38.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:23:38.687+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:23:38.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:23:38.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-11T12:24:09.135+0000] {processor.py:157} INFO - Started process (PID=12961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:24:09.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:24:09.136+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:24:09.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:24:09.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:24:09.169+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:24:09.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:24:09.180+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:24:09.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:24:09.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-11T12:24:39.676+0000] {processor.py:157} INFO - Started process (PID=12986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:24:39.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:24:39.678+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:24:39.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:24:39.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:24:39.710+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:24:39.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:24:39.720+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:24:39.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:24:39.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-11T12:25:10.209+0000] {processor.py:157} INFO - Started process (PID=13011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:25:10.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:25:10.211+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:25:10.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:25:10.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:25:10.233+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:25:10.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:25:10.242+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:25:10.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:25:10.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-11T12:25:40.693+0000] {processor.py:157} INFO - Started process (PID=13036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:25:40.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:25:40.695+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:25:40.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:25:40.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:25:40.731+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:25:40.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:25:40.747+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:25:40.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:25:40.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-11T12:26:11.255+0000] {processor.py:157} INFO - Started process (PID=13061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:26:11.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:26:11.256+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:26:11.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:26:11.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:26:11.286+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:26:11.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:26:11.297+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:26:11.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:26:11.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-11T12:26:41.673+0000] {processor.py:157} INFO - Started process (PID=13086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:26:41.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-11T12:26:41.675+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:26:41.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:26:41.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-11T12:26:41.699+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:26:41.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-11T12:26:41.708+0000] {logging_mixin.py:151} INFO - [2024-07-11T12:26:41.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-10T01:00:00+00:00, run_after=2024-07-11T01:00:00+00:00
[2024-07-11T12:26:41.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
